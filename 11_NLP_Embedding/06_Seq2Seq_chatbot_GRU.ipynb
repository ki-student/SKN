{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23870109-6d31-4db7-b782-b699fe671867",
   "metadata": {},
   "source": [
    "# GRU(Gated Recurrent Units) 모델\n",
    "- https://arxiv.org/pdf/1406.1078\n",
    "- LSTM의 RNN의 한계점인 기억력 소실문제를 해결하여 긴 sequence의 데이터에서도 좋은 성능을 내는 모델이다. 그러나 복잡한 구조로 parameter가 많아지게 되었고 연산량이 많은 문제점이 있다.\n",
    "    - parameter가 많아지면서 데이터양이 부족할 경우 과대적합이 발생하고 연산량이 많아 학습에 많은 시간이 걸리게 된다.\n",
    "- LSTM의 이런 문제를 개선하기 위한 변형 모델이 GRU이다.\n",
    "\n",
    "## LSTM과 차이\n",
    "1. LSTM은 forget gate, input gate, output gete 세개의 Gate연산을 함. GRU는 **reset gate와 update gate** 로 흐름을 제어한다.\n",
    "2. LSTM은 이전 처리결과로 Cell State, Hidden State 두개가 있었는데 이것을 하나로 합쳐 **Hidden State**로 출력한다.\n",
    "\n",
    "## GRU 성능\n",
    "- GRU는 적은 파라미터 수와 연산비용이 적게 드는 것에 비해 LSTM과 비슷한 성능을 내는 것으로 알려졌다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18729a02-f014-4082-826f-824b9d7adbf6",
   "metadata": {},
   "source": [
    "## GRU Cell 구조\n",
    "\n",
    "![gru_cell](figures/rnn/23_gru_cell.png)    \n",
    "[이미지 Source](https://www.oreilly.com/library/view/advanced-deep-learning/9781789956177/8ad9dc41-3237-483e-8f6b-7e5f653dc693.xhtml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9740062-d77e-4b55-946d-4135af3c8e28",
   "metadata": {},
   "source": [
    "- **Reset Gate**\n",
    "    - 이전 timestep까지의 hidden state(feature)를 현재 timestep의 hidden state(feature) 계산시 얼마나 반영할 지 비율을 결정하는 gate.\n",
    "    - $r_{t} = \\sigma(h_{t-1}\\cdot U_{r} + X_{t}\\cdot W_{r})$\n",
    "        - $U_{r},\\, W_{r}$ 는 파라미터\n",
    "        - $\\sigma$: sigmoid(logisic) 함수\n",
    "- **Update Gate**\n",
    "    - 현재 timestep의 hidden state($h_t$)를 계산할 때 이전 time step까지 정보($h_{t-1}$)와 현재 time step의 정보($X_t$)를 각각 얼마나 반영할지 비율을 정의한다.\n",
    "    - $z_{t} = \\sigma(h_{t-1}\\cdot U_{z} + X_{t}\\cdot W_{z})$\n",
    "        - $U_{z},\\, W_{z}$ 는 파라미터\n",
    "        - $\\sigma$: sigmoid(logisic) 함수\n",
    "    - $h_t$를 계산할 때 $z_{t}$ 는 이전 정보인 $h_{t-1}$을 얼마나 반영할지 $1-z_{t}$는 현재 정보를 얼마나 반영할 지를 정한다.\n",
    "- **Cell의 출력값인 $h_t$ 계산**\n",
    "    - $z_{t}\\times h_{t-1} + tanh(h_{t-1} * r_{t}+X_{t}\\cdot W)\\times(1-z_{t})$\n",
    "    - 이전 정보에는 $z_t$를 곱해 얼마나 $h_t$ 에 더할지 연산\n",
    "    - 현재 정보($X_t$)에는 이전 정보를 일부를 반영한다. 이전 정보를 얼마나 반영할지를 reset gate 결과를 곱해 결정한다. 활성화 함수 tanh를 이용해 비선형성을 추가 한 결과에 $1-z_t$를 곱한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c6f7c4-0cfb-4ac8-b7dd-834a44c18880",
   "metadata": {},
   "source": [
    "## Pytorch GRU\n",
    "- `nn.GRU` 클래스 이용\n",
    "    - https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
    "- **입력**\n",
    "    - **input**: (seq_length, batch, hidden_size) shape의 tensor. (batch_first=False), batch_first=True이면 `seq_length`와 `batch` 위치가 바뀐다.\n",
    "    - **hidden**: (D * num_layers, batch, hidden_size) shape의 Tensor. D(양방향:2, 단방향:1), hidden은 생략하면 0이 입력됨.\n",
    "- **출력** - output과 hidden state가 반환된다.\n",
    "    - **output**\n",
    "        - 모든 sequence의 처리결과들을 모아서 제공.\n",
    "        - shape: (seq_length, batch, D * hidden_size) : D(양방향:2, 단방향:1), batch_first=True이면 `seq_length`와 `batch` 위치가 바뀐다.\n",
    "    - **hidden**\n",
    "        - 마지막 time step 처리결과\n",
    "        - shape: (D * num_layers, batch, hidden) : D(양방향:2, 단방향:1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "702c5b37-cadd-4e88-af53-581268bc2b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRU 입출력  확인\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# dummy data\n",
    "input_data = torch.randn((20, 2, 10))  \n",
    "# (20: seq len, 2: batch, 10: 개별 timestep의 입력 feature수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d86e6-0a72-4fde-9e57-51417b1ed782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2, 256])\n",
      "torch.Size([1, 2, 256])\n"
     ]
    }
   ],
   "source": [
    "# 단방향, layer수 : 1\n",
    "gru1 = nn.GRU(\n",
    "    input_size=10,   # 개별 timestep의 feature 수(embedding_dim)\n",
    "    hidden_size=256, # 각 timestep 별로 256개의 특성을 추출(unit수)\n",
    "    num_layers=1, # 몇층(layer)를 쌓을 지. (default: 1)\n",
    "    bidirectional=False # 양방향 여부 (default: False)\n",
    ")\n",
    "out1, hidden1 = gru1(input_data)\n",
    "#모든 timestep의 hidden state값을 묶어서 반환.[20:seq len, 2:batch, 256:hidden_size]\n",
    "print(out1.shape) \n",
    "# 마지막 timestep 처리 hidden state값 [1: seq len, 2, 256]\n",
    "print(hidden1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "794b0319-660e-42f0-a390-6ec71ade0b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2, 512])\n",
      "torch.Size([2, 2, 256])\n"
     ]
    }
   ],
   "source": [
    "# bidirectional=True (양방향), layer수 : 1\n",
    "gru2 = nn.GRU(\n",
    "    input_size=10,\n",
    "    hidden_size=256, \n",
    "    num_layers=1, # 몇층(layer)를 쌓을 지. (default: 1)\n",
    "    bidirectional=True # 양방향 여부 (default: False)\n",
    ")\n",
    "out2, hidden2 = gru2(input_data)\n",
    "\n",
    "# [20:seq_len, 2:batch, 512:hidden_size * 2]   양(정/역)방향 hidden state를 합쳐서(concat) 반환.\n",
    "print(out2.shape)\n",
    "# [2:정/역방향 두개, 2:batch, 256:hidden size]\n",
    "print(hidden2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf63dd57-148c-4a77-9ceb-aedde38a86b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2, 256])\n",
      "torch.Size([4, 2, 256])\n"
     ]
    }
   ],
   "source": [
    "# multi layer\n",
    "gru3 = nn.GRU(\n",
    "    input_size=10,\n",
    "    hidden_size=256, \n",
    "    num_layers=4, # 몇층(layer)를 쌓을 지. (default: 1)\n",
    "    bidirectional=False # 양방향 여부 (default: False)\n",
    ")\n",
    "out3, hidden3 = gru3(input_data)\n",
    "\n",
    "#[20, 2, 256] - 마지막 GRU Layer가 출력한 결과들이 최종 feature이므로 그것을 모아서 반환.\n",
    "# num_layers가 몇개든 out의 shape은 동일.\n",
    "print(out3.shape)\n",
    "# [4: 레이어수, 2, 256]  - 각 layer의 마지막 hidden state들을 모아서 반환\n",
    "print(hidden3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1abf35-6271-41de-a217-63ff74d33837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2, 512])\n",
      "torch.Size([8, 2, 256])\n"
     ]
    }
   ],
   "source": [
    "# multi layer, 양방향\n",
    "\n",
    "gru4 = nn.GRU(\n",
    "    input_size=10,\n",
    "    hidden_size=256, \n",
    "    num_layers=4, # 몇층(layer)를 쌓을 지. (default: 1)\n",
    "    bidirectional=True # 양방향 여부 (default: False)\n",
    ")\n",
    "out4, hidden4 = gru4(input_data)\n",
    "print(out4.shape) # [20, 2, 512: 양방향 hidden 합친것]\n",
    "# [8:양방향(2) x 레이어수(4), 2, 256]\n",
    "print(hidden4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780b5bac-e226-40e3-9e8c-96e3cf9ad9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8389555c-17d0-41ed-abfc-42046bf8aeaa",
   "metadata": {},
   "source": [
    "# Encoder-Decoder 구조\n",
    "- 두개의 네트워크를 연결한 구조\n",
    "- Encoder network는 입력을 이해하고 Decoder network는 (Encoder의 이해를 바탕으로) 출력을 생성한다.\n",
    "\n",
    "## Seq2Seq\n",
    "- Encoder-Decoder 구조를 RNN 계열에 적용한 모델.\n",
    "- Encoder는 입력 Sequence의 전체 의미(특징)을 표현하는 **context vector**를 출력한다.\n",
    "    - **Context Vector는**\n",
    "        - 번역의 경우 번역할 대상 문장에서 **번역 결과를 만들때 필요한 feature들**을 가지고 있다.\n",
    "        - Chatbot의 경우 입력된 질문에서 **답변을 만들때 필요한 feature들**을 가지고 있다.\n",
    "- Decoder는 Encoder가 출력한 Context Vector를 입력받아 결과 sequence를 생성한다.\n",
    "    - **결과 sequence는**\n",
    "        - **번역**의 경우 번역 문장을 생성한다.\n",
    "        - **chatbot**의 경우 질문에 대한 답변을 생성한다.\n",
    "\n",
    "![seq2seq](figures/seq2seq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9887d108-2ac6-425e-9643-d351e44282c7",
   "metadata": {},
   "source": [
    "# Seq2Seq 를 이용한 Chatbot 모델 구현\n",
    "- Encoder를 이용해 질문의 특성을 추출하고 Decoder를 이용해 답변을 생성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daec7aee-1d3b-4990-b934-a4254a6e17ef",
   "metadata": {},
   "source": [
    "# Chatbot Dataset\n",
    "\n",
    "- https://github.com/songys/Chatbot_data\n",
    "- columns\n",
    "    - Q: 질문\n",
    "    - A: 답\n",
    "    - label: 일상다반사 0, 이별(부정) 1, 사랑(긍정) 2\n",
    "- **Download**\n",
    "\n",
    "![dataset](figures/chatbot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa75cf8-9cd9-4a72-a610-4392b80ca6b5",
   "metadata": {},
   "source": [
    "# Chatbot Dataset Loading 및 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbd0c3c-2b8f-4a4c-b90c-a0fa6d828c4c",
   "metadata": {},
   "source": [
    "## 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ed2c29e-1aef-48c3-87ba-a89cc8ed6146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requests 모듈로 받기\n",
    "import requests\n",
    "import os\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fc98856-b66d-4e2e-bc8a-27e3d34dcfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/songys/Chatbot_data/refs/heads/master/ChatbotData.csv\"\n",
    "res = requests.get(url)\n",
    "if res.status_code == 200:\n",
    "    with open(\"data/chatbot_data.csv\", \"wt\", encoding=\"utf-8\") as fw:\n",
    "        fw.write(res.text)\n",
    "else:\n",
    "    print(f\"불러오지 못함: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e670d063-8c71-4ddf-b6b0-15631c7f58da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11823, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/chatbot_data.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "796816ae-1851-4b97-892b-671b5f869cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11823 entries, 0 to 11822\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Q       11823 non-null  object\n",
      " 1   A       11823 non-null  object\n",
      " 2   label   11823 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 277.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e784426-2a6d-4988-b9bc-4bfbd37b26e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨 제거\n",
    "df.drop(columns='label', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eaeb3e95-7b21-418e-9936-988b76d38070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A\n",
       "0           12시 땡!   하루가 또 가네요.\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.\n",
       "4          PPL 심하네   눈살이 찌푸려지죠."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38845196-7a1d-4da8-9227-3d99ec5024ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A\n",
       "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!\n",
       "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.\n",
       "11820              흑기사 해주는 짝남.                    설렜겠어요.\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.\n",
       "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "424db411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q    0\n",
       "A    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aad072-2245-41e8-9863-a0b451262fdd",
   "metadata": {},
   "source": [
    "# Dataset, DataLoader 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6e0b8d-ee13-488b-ae6e-2a7d4189fd6c",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "### Subword방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e20849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleansing이나 정규화 같은 작업을 하지 않는 이유는 단어 문장이 어색해지고 뜻이 달라질 수 있기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d080f3aa-6d49-464f-9469-91ef9bcd351c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11823, 11823, 11823)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# token 학습 -> vocab 사전 생성.\n",
    "## 질문들 + 답변들 합쳐서 학습.\n",
    "question_texts = df['Q']\n",
    "answer_texts = df['A']\n",
    "all_texts = list(question_texts + \" \"+answer_texts) # 같은 index끼리 합치기 => list로 변환(vocab 생성을 위함)\n",
    "len(question_texts), len(answer_texts), len(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8ea110e-9215-4385-9d41-2d6675fd2c17",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12시 땡! 하루가 또 가네요.',\n",
       " '1지망 학교 떨어졌어 위로해 드립니다.',\n",
       " '3박4일 놀러가고 싶다 여행은 언제나 좋죠.',\n",
       " '3박4일 정도 놀러가고 싶다 여행은 언제나 좋죠.',\n",
       " 'PPL 심하네 눈살이 찌푸려지죠.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "155f3e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             12시 땡!\n",
       "1        1지망 학교 떨어졌어\n",
       "2       3박4일 놀러가고 싶다\n",
       "3    3박4일 정도 놀러가고 싶다\n",
       "4            PPL 심하네\n",
       "Name: Q, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "707d8143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     하루가 또 가네요.\n",
       "1      위로해 드립니다.\n",
       "2    여행은 언제나 좋죠.\n",
       "3    여행은 언제나 좋죠.\n",
       "4     눈살이 찌푸려지죠.\n",
       "Name: A, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac2eea8d-c5c6-42e0-9314-c94043113668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60438a5d-a238-42e3-96ea-c02d458fbee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10_000 # 총 어휘수\n",
    "min_frequency = 5   # 어휘사전에 등록될 단어(토큰)의 최소 빈도수\n",
    "\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "trainer = BpeTrainer(\n",
    "    vocab_size=vocab_size,\n",
    "    min_frequency=min_frequency,\n",
    "    continuing_subword_prefix='##', # 연결 subword 앞에 붙일 접두어지정. \n",
    "    special_tokens=[\"[PAD]\", \"[UNK]\", \"[SOS]\"] # [SOS]: 문장의 시작을 의미하는 토큰.\n",
    ")\n",
    "# ex) tokenizer: token + ##izer\n",
    "## 학습\n",
    "tokenizer.train_from_iterator(all_texts, trainer=trainer) # 리스트로 부터 학습\n",
    "## tokenizer.train(\"파일경로\") # 파일에 있는 text를 학습."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad5b0c24-3261-4c24-be02-6cff4f789540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 어휘수: 7043\n"
     ]
    }
   ],
   "source": [
    "print(\"총 어휘수:\", tokenizer.get_vocab_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44198fe6-9e49-49c4-ab70-d3ab3b2bdf45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2290, 3852, 2258, 5914, 8, 3270, 2447, 322, 2243, 8, 1, 1, 1, 1602]\n",
      "['오늘', '날씨가', '너무', '좋습니다', '.', '즐거운', '하루', '되', '##세요', '.', '[UNK]', '[UNK]', '[UNK]', '##ㅋ']\n"
     ]
    }
   ],
   "source": [
    "# 토큰화\n",
    "encode = tokenizer.encode(\"오늘 날씨가 너무 좋습니다. 즐거운 하루 되세요. 쿄쿄쿜ㅋ\")\n",
    "print(encode.ids)       # 토큰 id\n",
    "print(encode.tokens)    # 토큰(단어)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a74d35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'오늘'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.id_to_token(2290)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bb1c6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2290"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.token_to_id(\"오늘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80caf0b3-01d5-4631-87c1-f48ab2f5bafc",
   "metadata": {},
   "source": [
    "### Tokenizer 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abe8873a-dde0-4c0b-9146-0da961f55bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"saved_model/chatbot\"\n",
    "os.makedirs(dir_path, exist_ok=True)\n",
    "vocab_path = os.path.join(dir_path, \"chatbot_bpe.json\")\n",
    "tokenizer.save(vocab_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b068c-ead0-4f75-bd01-4a0ebf486774",
   "metadata": {},
   "source": [
    "## Dataset, DataLoader 정의\n",
    "\n",
    "\n",
    "### Dataset 정의 및 생성\n",
    "- 모든 문장의 토큰 수는 동일하게 맞춰준다.\n",
    "    - DataLoader는 batch 를 구성할 때 batch에 포함되는 데이터들의 shape이 같아야 한다. 그래야 하나의 batch로 묶을 수 있다.\n",
    "    - 문장의 최대 길이를 정해주고 **최대 길이보다 짧은 문장은 `<PAD>` 토큰을 추가**하고 **최대길이보다 긴 문장은 최대 길이에 맞춰 짤라준다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ae89444-25b0-4b96-819a-640e35d933dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler\n",
    "from torch import optim\n",
    "\n",
    "device = \"MPS\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d181d3a2-a7eb-482a-8c9e-b03feaca8f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotDataset(Dataset):\n",
    "    \"\"\"\n",
    "    ChatbotDataset\n",
    "    parameter:\n",
    "        question_texts: list[str] - 질문 texts 목록. 리스트에 질문들을 담아서 받는다. [\"질문1\", \"질문2\", ...]\n",
    "        answer_texts: list[str] - 답 texts 목록. 리스트에 답변들을 담아서 받는다.     [\"답1\", \"답2\", ...]\n",
    "        max_length: 개별 문장의 token 개수. 모든 문장의 토큰수를 max_length에 맞춘다.\n",
    "        tokenizer: Tokenizer\n",
    "        vocab_size: int 총단어수\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, question_texts, answer_texts, max_length, tokenizer):\n",
    "        \"\"\"\n",
    "        parameter\n",
    "            question_texts: list[str] - 질문 texts 목록. 리스트에 질문들을 담아서 받는다. [\"질문1\", \"질문2\", ...]\n",
    "            answer_texts: list[str] - 답 texts 목록. 리스트에 답변들을 담아서 받는다.     [\"답1\", \"답2\", ...]\n",
    "            max_length: 개별 문장의 token 개수. 모든 문장의 토큰수를 max_length에 맞춘다.\n",
    "            tokenizer: Tokenizer\n",
    "        \"\"\"\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        # 받아온 q/a 문장 리스트를 max_length의 token list로 변환해서 attribute로 저장\n",
    "        self.question_texts = [self.__process_sequence(q) for q in question_texts]\n",
    "        self.answer_texts = [self.__process_sequence(a) for a in answer_texts]\n",
    "    \n",
    "    def __pad_token_sequence(self, token_sequence): \n",
    "        \"\"\"\n",
    "        max_length 길이에 맞춰 token_id 리스트를 구성한다.\n",
    "        max_length 보다 길면 뒤에를 자르고 max_length 보다 짧으면 [PAD] 토큰을 추가한다.\n",
    "        \n",
    "        Parameter\n",
    "            token_sentence: list[int] - 길이를 맞출 한 문장 token_id 목록\n",
    "        Return\n",
    "            list[int] - length가 max_length인 token_id 목록\n",
    "        \"\"\"\n",
    "        pad_token = self.tokenizer.token_to_id('[PAD]')         # [PAD] 토큰 id 조회 -> 첫번째 토큰이라 0\n",
    "        seq_len = len(token_sequence) # 입력 문장의 토큰수\n",
    "        if seq_len > self.max_length: # 문장 최대 토큰수 보다 길다면.\n",
    "            return token_sequence[:self.max_length]\n",
    "        else:\n",
    "            return token_sequence + ([pad_token] * (self.max_length - seq_len))\n",
    "    \n",
    "    def __process_sequence(self, text): \n",
    "        \"\"\"\n",
    "        한 문장(str)을 받아서 padding이 추가된 token_id 리스트로 변환 후 반환\n",
    "        Parameter\n",
    "            text: str - token_id 리스트로 변환할 한 문장\n",
    "        Return\n",
    "            list[int] - 입력받은 문장에 대한 token_id 리스트\n",
    "        \"\"\"\n",
    "        # encoding\n",
    "        encode = self.tokenizer.encode(text) # \"........\" => [. , . , .]\n",
    "        # max_length 크기에 맞춘다.\n",
    "        token_ids = self.__pad_token_sequence(encode.ids) #[3400, 20, 6, 0, 0, 0 ..]\n",
    "        return token_ids\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.question_texts)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # return  index의 (질문토큰들,  답변토큰들)\n",
    "        q = self.question_texts[index]  # List\n",
    "        a = self.answer_texts[index]\n",
    "        # List->LongTensor. nn.Embedding()의 입력(정수타입)으로 들어간다. \n",
    "        return torch.tensor(q, dtype=torch.int64), torch.tensor(a, dtype=torch.int64)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23c3e4ad-d4f4-4d2d-98e5-1f190129ca5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17., 19., 41.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 적당한 max_length 값: 전체 문장 총 토큰수의 9분위수\n",
    "import numpy as np\n",
    "a = [len(tokenizer.encode(s).ids) for s in all_texts]\n",
    "# a[:5]\n",
    "np.quantile(a, q=[0.9, 0.95, 1.0])\n",
    "# max_length=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "abc56d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.58.0-cp312-cp312-macosx_10_13_universal2.whl.metadata (104 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.8-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/giwonjun/anaconda3/envs/dl/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/giwonjun/anaconda3/envs/dl/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-11.2.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.9 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/giwonjun/anaconda3/envs/dl/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/giwonjun/anaconda3/envs/dl/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.3-cp312-cp312-macosx_11_0_arm64.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached contourpy-1.3.2-cp312-cp312-macosx_11_0_arm64.whl (255 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.58.0-cp312-cp312-macosx_10_13_universal2.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached kiwisolver-1.4.8-cp312-cp312-macosx_11_0_arm64.whl (65 kB)\n",
      "Using cached pillow-11.2.1-cp312-cp312-macosx_11_0_arm64.whl (3.0 MB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [matplotlib]7\u001b[0m [matplotlib]\n",
      "\u001b[1A\u001b[2KSuccessfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.0 kiwisolver-1.4.8 matplotlib-3.10.3 pillow-11.2.1 pyparsing-3.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9635c49e-98fd-4da0-8a69-f39151d4d9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(a, 30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "566e885c-77ec-4c7b-b05d-e493e125b460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11823"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############# Dataset 셍상\n",
    "MAX_LENGTH = 20\n",
    "dataset = ChatbotDataset(question_texts, answer_texts, MAX_LENGTH, tokenizer)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "409f90d0-4669-4851-a606-e52556fd9802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  10, 1881, 1284,  368,    3,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " tensor([6119,  378,   47, 2252,    8,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6d2b6f-ccf7-4aec-9c08-176a2456e813",
   "metadata": {},
   "source": [
    "### Trainset / Testset 나누기\n",
    "train : test = 9 : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "377218ae-8d2b-4f59-a20a-03800663e298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(dataset) * 0.95)\n",
    "len(dataset) - int(len(dataset) * 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eb7d0d5a-c8ba-48be-bc46-d5ba12cd89e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11231 592\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(dataset)*0.95)                 # train set의 개수\n",
    "test_size = len(dataset) - train_size               # test set의 개수\n",
    "print(train_size, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "42aed6cf-4aa2-4262-a4d4-964365ce7dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_split()이용해서 분리\n",
    "###shuffle 후 개수에 맞게 나눔 -> 순서대로 x\n",
    "train_set, test_set = random_split(dataset, [train_size, test_size])\n",
    "# random_split(dataset객체, [나눌 개수, ...])\n",
    "# random_split(dataset객체, [10, 20, 40, 50]) -> 5개로 나눔, 각각 개수가 지정한 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0ef5990a-9233-4c0a-9e18-c7f38d3f995e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(__main__.ChatbotDataset, torch.utils.data.dataset.Subset)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset), type(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b497cead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11231, 592)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4b274f-8c8a-4aa6-af6d-a66bf5c38210",
   "metadata": {},
   "source": [
    "### DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c51e1123-cbdd-4dce-8998-d4638ce04e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c61053a2-8362-47ff-a167-efcbdf2c8226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175, 10)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(test_loader) # step 수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdaf424-c7de-46be-b74b-88a3efcdf352",
   "metadata": {},
   "source": [
    "# 모델 정의\n",
    "\n",
    "## Seq2Seq 모델 정의\n",
    "- Seq2Seq 모델은 Encoder와 Decoder의 입력 Sequence의 길이와 순서가 자유롭기 때문에 챗봇이나 번역에 이상적인 구조다.\n",
    "    - 단일 RNN은 각 timestep 마다 입력과 출력이 있기 때문에 입/출력 sequence의 개수가 같아야 한다.\n",
    "    - 챗봇의 질문/답변이나 번역의 대상/결과 문장의 경우는 사용하는 어절 수가 다른 경우가 많기 때문에 단일 RNN 모델은 좋은 성능을 내기 어렵다.\n",
    "    - Seq2Seq는 **입력처리(질문,번역대상)처리 RNN과 출력 처리(답변, 번역결과) RNN 이 각각 만들고 그 둘을 연결한 형태로 길이가 다르더라도 상관없다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17d7410-a73e-4be1-b41d-9ea07d6b0911",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "Encoder는 하나의 Vector를 생성하며 그 Vector는 **입력 문장의 의미**를 N 차원 공간 저장하고 있다. 이 Vector를 **Context Vector** 라고 한다.    \n",
    "![encoder](figures/seq2seq_encoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7840f7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.6655, -0.6934, -2.3851,  1.0179,  0.1167],\n",
       "        [-0.5706, -0.7126,  0.9928,  0.6919, -0.5588],\n",
       "        [-0.2059,  0.0985, -0.6105, -0.2652, -1.2712],\n",
       "        [ 0.4928,  1.2026, -0.4990, -0.9785,  0.0924],\n",
       "        [ 1.7420, -0.6785, -0.2736,  0.7306, -0.7097],\n",
       "        [ 0.6898, -0.7596,  0.6445,  0.0307, -0.1340],\n",
       "        [ 0.1046,  1.1059,  0.8596,  1.0254, -0.0596],\n",
       "        [ 0.5539,  0.2109, -0.7966,  0.2337,  0.1306],\n",
       "        [ 0.8494,  0.1534, -1.0938, -0.5518, -0.5562]], requires_grad=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_l = nn.Embedding(10,5, padding_idx=0)\n",
    "e_l.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ff60f00e-707c-47e9-ab60-dad42d0ec508",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, \n",
    "                 hidden_size, bidirectional=True, num_layers=1, dropout_rate=0.0):\n",
    "        super().__init__()\n",
    "        # Encoder는 context vector(문장의 feature)를 생성하는 것이 목적 (분류기는 생성안함.)\n",
    "        # Embedding Layer, GRU Layer를 생성.\n",
    "        self.vocab_size = vocab_size # 어휘사전의 총 어휘수(토큰수)\n",
    "        # 임베딩레이어\n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size,      # 총 어휘개수 (weight행렬의 행수)\n",
    "            embedding_dim,   # embedding vector shape: [vocab_size, embedding_dim] / weight행렬의 열수\n",
    "            padding_idx=0    # [PAD] (패딩 토큰의 ID) - padding의 embedding vector는 학습이 안되도록 함(vector값 0으로 구성)\n",
    "        )\n",
    "        # GRU\n",
    "        self.gru = nn.GRU(\n",
    "            embedding_dim, # 개별 토큰(time step)의 크기.\n",
    "            hidden_size,   # hidden state의 크기 - 개별 토큰별로 몇개의 feature를 추출할지\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout_rate if num_layers > 1 else 0.0         # stacked rnn일 경우 dropout 적용\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # X shape: (batch, seq_len)\n",
    "        X = self.embedding(X) # (batch, seq_len, embedding_dim)\n",
    "        X = X.transpose(1, 0) # (seq_len, batch, embedding_dim)\n",
    "        out, hidden = self.gru(X)\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7c9fcf-6d84-4c2f-b7b5-82ea92b80150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Encoder                                  [20, 64, 512]             --\n",
       "├─Embedding: 1-1                         [64, 20, 200]             200,000\n",
       "├─GRU: 1-2                               [20, 64, 512]             703,488\n",
       "==========================================================================================\n",
       "Total params: 903,488\n",
       "Trainable params: 903,488\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 913.26\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 7.29\n",
       "Params size (MB): 3.61\n",
       "Estimated Total Size (MB): 10.92\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "encoder_model = Encoder(1000, 200, 256)                # 1000:batch_size, 200:embedding 차원수, 256:hidden size\n",
    "dummy_data = torch.zeros((64, 20), dtype=torch.int64)  #(batch:64, seq_len:20)\n",
    "summary(encoder_model, input_data=dummy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e8344f-8cf7-45a8-8092-ab20365cdb91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24779603-15ac-4ba1-a24c-6e86658b3ad6",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "- Encoder의 출력(context vector)를 받아서 번역 결과 sequence를 출력한다.\n",
    "- Decoder는 매 time step의 입력으로 **이전 time step에서 예상한 단어와 hidden state값이** 입력된다.\n",
    "- Decoder의 처리결과 hidden state를 Estimator(Linear+Softmax)로 입력하여 **입력 단어에 대한 번역 단어가 출력된다.** (이 출력단어가 다음 step의 입력이 된다.)\n",
    "    - Decoder의 첫 time step 입력은 문장의 시작을 의미하는 <SOS>(start of string) 토큰이고 hidden state는 context vector(encoder 마지막 hidden state) 이다.\n",
    "\n",
    "![decoder](figures/seq2seq_decoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "282f60e8-7e86-479a-8522-d32aab86b1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "# auto regressive model은 단방향만 가능\n",
    "    def __init__(self, vocab_size, embedding_dim, \n",
    "                 hidden_size, num_layers=1, bidirectional=False, dropout_rate=0.0):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size # 총 어휘사전 토큰 개수.\n",
    "        # embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        # GRU \n",
    "        ## Auto Regressive RNN은 단방향만 가능. \n",
    "        self.gru = nn.GRU(\n",
    "            embedding_dim,\n",
    "            hidden_size, \n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout_rate if num_layers > 1 else 0.0\n",
    "        )\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        # 분류기 (다음 단어(토큰)를 추론)\n",
    "           # - 다중분류(단어사전의 단어들의 다음 단어일 확를)\n",
    "        self.lr = nn.Linear(\n",
    "            hidden_size,  # GRU 출력 값 중 마지막 hidden state값을 입력으로 받음.\n",
    "            vocab_size    # 출력: 다음 단어일 확률.\n",
    "        )\n",
    "        \n",
    "    def forward(self, X, hidden):\n",
    "        # X: torch.LongTensor: shape - [batch] : 한 단어씩 입력을 받음.\n",
    "        # hidden: torch.FloatTensor: shape - [1, batch, hidden_size] (이전까지의 특성)\n",
    "        \n",
    "        X = X.unsqueeze(1) # seq_len 축을 추가. [batch] -> [batch, 1:seq_length] (Embedding Layer의 input shape)\n",
    "        X = self.embedding(X) # [batch, 1, embedding 차원]\n",
    "        X = X.transpose(1, 0) # [1, batch, embedding 차원]\n",
    "        \n",
    "        out, hidden = self.gru(X, hidden)\n",
    "        last_out = out[-1] # out: 전체 hidden state값-> 마지막 hidden state을 추출\n",
    "        self.dropout(last_out)          # weight에 대한 과적합 방지\n",
    "        last_out = self.lr(last_out)\n",
    "\n",
    "        return last_out, hidden # (hidden: 다음 timestep에 전달.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dbb1cd25-b1e6-4f64-9319-e397561845ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Decoder                                  [64, 1000]                --\n",
       "├─Embedding: 1-1                         [64, 1, 200]              200,000\n",
       "├─GRU: 1-2                               [1, 64, 256]              351,744\n",
       "├─Dropout: 1-3                           [64, 256]                 --\n",
       "├─Linear: 1-4                            [64, 1000]                257,000\n",
       "==========================================================================================\n",
       "Total params: 808,744\n",
       "Trainable params: 808,744\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 51.76\n",
       "==========================================================================================\n",
       "Input size (MB): 0.07\n",
       "Forward/backward pass size (MB): 0.75\n",
       "Params size (MB): 3.23\n",
       "Estimated Total Size (MB): 4.05\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### summary\n",
    "\n",
    "decoder_model = Decoder(1000, 200, 256)\n",
    "\n",
    "dummy_input = torch.ones((64, ), dtype=torch.int64)\n",
    "dummy_hidden = torch.ones((1, 64, 256), dtype=torch.float32)\n",
    "\n",
    "summary(decoder_model, input_data=(dummy_input, dummy_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cdf137-057b-4e41-95cd-c58219032b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3563f5b2-f18b-42b5-9bd4-f4f8abd767ac",
   "metadata": {},
   "source": [
    "## Seq2Seq 모델\n",
    "\n",
    "- Encoder - Decoder 를 Layer로 가지며 Encoder로 질문의 feature를 추출하고 Decoder로 답변을 생성한다.\n",
    "\n",
    "### Teacher Forcing\n",
    "- **Teacher forcing** 기법은, RNN계열 모델이 다음 단어를 예측할 때, 이전 timestep에서 예측된 단어를 입력으로 사용하는 대신 **실제 정답 단어(ground truth) 단어를** 입력으로 사용하는 방법이다.\n",
    "    - 모델은 이전 시점의 출력 단어를 다음 시점의 입력으로 사용한다. 그러나 모델이 학습할 때 초반에는 정답과 많이 다른 단어가 생성되어 엉뚱한 입력이 들어가 학습이 빠르게 되지 않는 문제가 있다.\n",
    "- **장점**\n",
    "    - **수렴 속도 증가**: 정답 단어를 사용하기 때문에 모델이 더 빨리 학습할 수있다.\n",
    "    - **안정적인 학습**: 초기 학습 단계에서 모델의 예측이 불안정할 때, 잘못된 예측으로 인한 오류가 다음 단계로 전파되는 것을 막아줍니다.\n",
    "- **단점**\n",
    "    - **노출 편향(Exposure Bias) 문제:** 실제 예측 시에는 정답을 제공할 수 없으므로 모델은 전단계의 출력값을 기반으로 예측해 나가야 한다. 학습 과정과 추론과정의 이러한 차이 때문에 모델의 성능이 떨어질 수있다.\n",
    "        - 이런 문제를 해결하기 학습 할 때 **Teacher forcing을 random하게 적용하여 학습시킨다.**\n",
    "![seq2seq](figures/seq2seq.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc90b660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq2seq = encoder class와 decoder class를 묶어주는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "116f8d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SOS_TOKEN = tokenizer.token_to_id(\"[SOS]\")\n",
    "SOS_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bd4aa18b-985a-47fd-868a-47a570dc1545",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_TOKEN = tokenizer.token_to_id(\"[SOS]\")\n",
    "SOS_TOKEN\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder.to(device)\n",
    "        self.decoder = decoder.to(device)\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, inputs, outputs, teacher_forcing_rate=0.99):\n",
    "        \"\"\"\n",
    "        parameter\n",
    "            inputs: 질문 - (batch, seq_length)\n",
    "            outputs: 답변(정답) - (batch, seq_length)\n",
    "            teacher_forcing_rate: teacher_forcing 적용 확률.\n",
    "        \"\"\"\n",
    "        # Q\n",
    "        if inputs.dim() == 1: # (seq_length) # 질문이 한개일 경우 질문 문장 토큰만 입력될 수있다.\n",
    "            inputs = inputs.unsqueeze(0) # (1:batch, seq_length)\n",
    "        # A\n",
    "        if outputs.dim() == 1:\n",
    "            outputs = inputs.unsqueeze(0)\n",
    "\n",
    "        batch_size, output_length = outputs.shape    # output_length: 답변문장의 토큰수\n",
    "        output_vocab_size = self.decoder.vocab_size  # 어휘사전 토큰 총 개수.\n",
    "\n",
    "        # 생성된 문장을 저장할 변수\n",
    "        ## (seq length, batch size, vocab_size(단어별 확률))\n",
    "        predicted_outputs = torch.zeros(output_length, batch_size, output_vocab_size).to(self.device)\n",
    "\n",
    "        ###### encoder를 이용해서 질문 문장의 context vector 추출.\n",
    "        encoder_out, encoder_hidden = self.encoder(inputs)\n",
    "        # encoder_out: [seq_len, batch, hidden_size * 2(양방향-단방향:1)]\n",
    "        # encoder_hidden: [2(양방향-단방향:1), batch, hidden_size]\n",
    "\n",
    "        # decoder의 첫번째 hidden state값 -> context vector\n",
    "        decoder_hidden = encoder_out[-1].unsqueeze(0) # [1, batch, hidden] #마지막 hidden state = context vector(문맥-전체문장-정보)\n",
    "        # 하나의 sequence에서 64개의 feature 출력\n",
    "\n",
    "        # Decoder에 넣을 첫번째 time step의 값: [SOS]\n",
    "        decoder_input = torch.full((batch_size, ), fill_value=SOS_TOKEN, device=self.device)\n",
    "        # 1차원 64개의 features를 SOS(2)로 채움 -> 64개의 문장을 만들기 위해 initialize\n",
    "\n",
    "        # 순회(반복) 하면서 단어들을 하나씩 생성.\n",
    "        for t in range(output_length): # max_length 만큼 생성.\n",
    "            # decoder_input(개별토큰id): [batch_size] - 첫 timestep: [SOS], 두번째: 생성된 토큰\n",
    "            # decoder_out(batch_size, vocab_size): 다음 단어일 확률\n",
    "            # decoder_hidden(1, batch, hidden * 2(양방향, 단: 1)) - 현재 입력의 feature(다음 timestep의 hidden으로 사용)\n",
    "            decoder_out, decoder_hidden = self.decoder(decoder_input, decoder_hidden) \n",
    "\n",
    "            predicted_outputs[t] = decoder_out # t 번째 예측 단어를 저장.\n",
    "\n",
    "            #### 다음 timestep에 넣어줄 값을 생성.\n",
    "            ##### teacher_forcing 적용: 정답, 비적용: 모델이 추론한 결과\n",
    "            teacher_forcing = teacher_forcing_rate > random.random()        # 0~1사이의 실수(난수)를 반환해 bool 값을 teather_forcing 저장\n",
    "            # teacher_forcing_rate의 확률만큼 True.\n",
    "            teacher_forcing_rate = teacher_forcing_rate * 0.99 \n",
    "            # 점점 t_f이 적용될 가능성을 줄인다.\n",
    "                          #    (모델이 추론한 값이 다음 입력으로 사용할 확률을 높여준다.)\n",
    "\n",
    "            # 모델이 추론한 단어중 가장 확률이 높은(TOP-1) 단어를 추출 \n",
    "            top1 = decoder_out.argmax(-1)\n",
    "            # teacher_foring이 True: 정답, False: 예측(top1)\n",
    "            decoder_input = outputs[:, t] if teacher_forcing else top1\n",
    "\n",
    "        return predicted_outputs.transpose(1, 0) # (batch, seq_length, vocab_size) 변환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf0ecb0-c657-4ca5-abf4-a31bab50300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.random() # 랜덤값생성-0 ~ 1 실수를 반환. 모든 값들이 나올 확률은 동일 - 균등분포"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e89fed5-b059-4371-b836-c3eb59bebdfb",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dac7b8a-935e-4f3a-9fa5-efbacbfc19d7",
   "metadata": {},
   "source": [
    "## 모델생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0280640f-243a-4413-8e8c-dc0285b7aaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  하이퍼파라미터들 정의\n",
    "VOCAB_SIZE = tokenizer.get_vocab_size()\n",
    "\n",
    "ENCODER_BIDIRECTIONAL = True # 인코더 양방향 여부\n",
    "ENCODER_HIDDEN_SIZE = 200    # 인코더 hidden_size\n",
    "# DECODER의 hidden size는 encoder의 마지막 timestep의 hidden size에 맞춤\n",
    "DECODER_HIDDEN_SIZE = ENCODER_HIDDEN_SIZE * 2 if ENCODER_BIDIRECTIONAL else ENCODER_HIDDEN_SIZE\n",
    "EMBEDDING_DIM = 256  # 임베딩 차원수\n",
    "TEACHER_FORCING_RATE = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a609b827-8287-4ea8-8df7-03a37ac8157d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7043"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8723fbf1-263d-4cad-93cd-e5d015ce880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 모델 생성\n",
    "encoder = Encoder(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_size=ENCODER_HIDDEN_SIZE,\n",
    "    num_layers=1,\n",
    "    bidirectional=ENCODER_BIDIRECTIONAL\n",
    ")\n",
    "decoder = Decoder(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_size=DECODER_HIDDEN_SIZE,\n",
    "    num_layers=1  # auto regressive 모델이므로 단방향 GRU생성.\n",
    ")\n",
    "model = Seq2Seq(encoder, decoder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "465b9510-8603-41fe-bee3-f4fbf1c95189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(7043, 256, padding_idx=0)\n",
      "    (gru): GRU(256, 200, bidirectional=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(7043, 256, padding_idx=0)\n",
      "    (gru): GRU(256, 400)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (lr): Linear(in_features=400, out_features=7043, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba83263-e042-4579-9784-2403eb3c3fa1",
   "metadata": {},
   "source": [
    "## loss함수, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4f94e396-11dd-44a6-b414-11c082747c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "model = model.to(device)\n",
    "# 다음 단어를 추론하는 다중분류\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a659df1-87a2-4fe0-a095-e031ed130e68",
   "metadata": {},
   "source": [
    "## train/evaluation 함수 정의\n",
    "\n",
    "### train 함수정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f3b6a36e-c023-47e0-9e86-081d40f06f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 epoch 학습 함수.\n",
    "def train_fn(model, data_loader, optimizer, loss_fn, device, \n",
    "             teacher_forcing_rate=0.99):\n",
    "\n",
    "    model.train()  # Seq2Seq모델.\n",
    "    loss_list = [] # step별 loss를 저장.\n",
    "\n",
    "    for X, y in data_loader:            # X:질문 y:답변\n",
    "        # device 로 이동\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # 추론\n",
    "        pred = model(X, y, teacher_forcing_rate)\n",
    "        # pred: 추론한 답변 문장: (batch, seq_length, vocab_size:토큰일 확률)\n",
    "        \n",
    "        # pred와 정답의 shape을 변경 (loss 함수에 넣을 수 있는 shape으로 변환.)\n",
    "        # pred를 reshape (batch, seq_len, vocab_size) -> (batch*seq_len, vocab_size)\n",
    "        y_hat = pred.reshape(-1, pred.shape[2]) \n",
    "        # 정답(y)을 reshape (batch, seq_len:토큰수) -> (batch * seq_len)\n",
    "        y = y.reshape(-1)\n",
    "        # CrossEntropyLoss(): 정답 - 원핫인코딩 안된 형태, 추론값: softmax 처리 안된 상태\n",
    "        #       - 정답  shape: (batch, ) => (batch*seq_len)\n",
    "        #       - 추론값shape: (batch, class개수) => (batch*seq_len, class개수 - vocabsize)\n",
    "\n",
    "        # Loss 계산\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        # gradient 계산\n",
    "        loss.backward()\n",
    "        # 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "        # 파라미터 초기화\n",
    "        optimizer.zero_grad()\n",
    "        loss_list.append(loss.item())\n",
    "    return np.mean(loss_list)#.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8981388d-ad33-4318-844b-29a5a434d2a7",
   "metadata": {},
   "source": [
    "### Test 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b2a786b6-f5e3-4db7-a9c6-087abc3e7c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fn(model, data_loader, loss_fn, device):\n",
    "    \n",
    "    # 1 에폭 테스트\n",
    "    model.eval()\n",
    "    loss_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            # 이동\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # 추론\n",
    "            # 추론 - 답변생성 : decoder가 생성한 단어를 다음 단어로 넣어서 추정\n",
    "            # teacher forcing은 train 시에만 적용\n",
    "            pred = model(X, y, teacher_forcing_rate=0.0)\n",
    "            # loss 계산\n",
    "            # y와 pred의 shape을 CrossEntropyLoss 입력에 맞게 reshape\n",
    "            y_hat = pred.reshape(-1, pred.shape[2])\n",
    "            y = y.reshape(-1)\n",
    "            loss_list.append(loss_fn(y_hat, y).item())\n",
    "    \n",
    "    return np.mean(loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a71e20c-8a03-44f4-bbbc-8f4e51b85636",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335aa2c8-4e29-46dd-90bd-69a41301adf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0에서 저장. inf에서 2.31185로 개선됨.\n",
      "[0/10] train loss: 2.4732564612797328, val loss: 2.3118486523628237\n",
      "[1/10] train loss: 1.9159037501471383, val loss: 2.5185787677764893\n",
      "[2/10] train loss: 1.6942953620638166, val loss: 2.724695253372192\n",
      "[3/10] train loss: 1.46434451852526, val loss: 2.7998637199401855\n",
      "[4/10] train loss: 1.2450171627317157, val loss: 2.9109485149383545\n",
      "[5/10] train loss: 1.0570309700284686, val loss: 3.0696502685546876\n",
      "[6/10] train loss: 0.903663957459586, val loss: 3.1512421369552612\n",
      "[7/10] train loss: 0.7966075413567679, val loss: 3.377869200706482\n",
      "[8/10] train loss: 0.6841330703667232, val loss: 3.5045292377471924\n",
      "[9/10] train loss: 0.6262589115755899, val loss: 3.5784843444824217\n",
      "걸린시간: 393.95530700683594\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "MODEL_SAVE_PATH = 'saved_model/chatbot/seq2seq-chatbot-model.pt'\n",
    "\n",
    "best_loss = np.inf\n",
    "s = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_fn(model, train_loader, optimizer, loss_fn, \n",
    "                          device, TEACHER_FORCING_RATE)\n",
    "    val_loss = test_fn(model, test_loader, loss_fn, device)\n",
    "\n",
    "    # 저장\n",
    "    if val_loss < best_loss:\n",
    "        torch.save(model, MODEL_SAVE_PATH)\n",
    "        print(f\"{epoch}에서 저장. {best_loss:.5f}에서 {val_loss:.5f}로 개선됨.\")\n",
    "        best_loss = val_loss\n",
    "\n",
    "    print(f\"[{epoch}/{EPOCHS}] train loss: {train_loss}, val loss: {val_loss}\")\n",
    "\n",
    "e = time.time()\n",
    "print(\"걸린시간:\", (e-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ba4757ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = 'saved_model/chatbot/seq2seq-chatbot-model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bf61c71e-3bbb-4a8b-8681-1dce2e4758f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH_LAST = 'saved_model/chatbot/seq2seq-chatbot-model_last.pt'\n",
    "torch.save(model, MODEL_SAVE_PATH_LAST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "32793631-fe59-43f3-aac5-1e2d88eb1e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 저장 모델 Load\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# map_location=device : 다른 device에 학습한 것을 읽어올 때 현재 device를 지정해서 \n",
    "#                                                현재 device에 맞춰 load하도록한다.\n",
    "best_model = torch.load(MODEL_SAVE_PATH, weights_only=False, map_location=device)\n",
    "best_model.device = device # Attribute device를 현재 device로 지정.\n",
    "\n",
    "last_model = torch.load(MODEL_SAVE_PATH_LAST, weights_only=False, map_location=device)\n",
    "last_model.device = device # Attribute device를 현재 device로 지정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5280dca7-029c-4eb6-b079-39963d7b7932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fe0585a-eb35-47dd-88bf-276d749f5f00",
   "metadata": {},
   "source": [
    "# 결과확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bcf956-b7e1-4f05-bd96-723fe0624339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "def handle_special_tokens(decoded_string):\n",
    "    \"\"\"\n",
    "    Subword 처리\n",
    "    subword는 단어의 시작으로 쓰인 것과 중간 부분(연결)에 사용된 두가지 subword가 있다.  연결 subword는 `#`과 같은 특수문자로 시작 한다.\n",
    "    tokenizer.decode() 결과 문자열은 subword의 특수문자('##')을 처리하지 않는다. 이것을 처리하는 함수\n",
    "    ex) \"이 기회 ##는 내 ##꺼 ##야\" ==> \"이 기회는 내꺼야\"\n",
    "    \n",
    "    Parameter\n",
    "        decoded_string: str - Tokenizer가 decode한 중간 subword의 특수문자 처리가 안된 문자열. \n",
    "    Return\n",
    "        str: subword 특수문자 처리한 문자열\n",
    "    \"\"\"\n",
    "    \n",
    "    tokens = decoded_string.split() # 공백기준으로 토큰화.\n",
    "    new_tokens = []\n",
    "    for token in tokens:\n",
    "        if token.startswith(\"##\"): # 연결 토큰\n",
    "            if new_tokens: # len(new_tokens) != 0 원소가 하나라도 있으면\n",
    "                # 토큰에서 ##을 제거하고 리스트의 마지막 원소(문자열) 뒤에 붙인다.\n",
    "                new_tokens[-1] += token[2:]\n",
    "            else: # new_tokens가 빈 리스트. 현재 token이 첫번째 단어. ##을 지우고 append\n",
    "                new_tokens.append(token[2:])\n",
    "        else: # 단어의 시작인 토큰. (##이 없는 토큰) -> list에 추가.\n",
    "            new_tokens.append(token)\n",
    "        \n",
    "    return \" \".join(new_tokens) \n",
    "    \n",
    "\n",
    "# dataset에서 일부 데이터들을 가지고 확인\n",
    "def random_evaluation(model, dataset, device, n=10):\n",
    "    \"\"\"\n",
    "    Dataset에서 일부 질문-답변 쌍들을 가져다 모델에 질문을 넣어 추론한 결과와 함께 확인.\n",
    "    Parameter\n",
    "        model: 학습된 seq2seq 모델\n",
    "        dataset: 질문-답변 쌍울 추출할 dataset\n",
    "        device\n",
    "        n: int - 추출할 질문-답변 쌍 개수 default: 10\n",
    "    \"\"\"\n",
    "    ## 평가할 데이터셋을 만들기\n",
    "    n_samples = len(dataset)       # Dataset의 총 데이터개수\n",
    "    index = list(range(n_samples)) # Dataset의 index만들기.\n",
    "    np.random.shuffle(index)       # 값들을 랜덤하게 섞어준다.\n",
    "    sample_index = index[ : n]     # 평가할 데이터 개수만큼 index 생성.\n",
    "    \n",
    "    # Dataloader 생성\n",
    "    # SubsetRandomSampler: 지정한 index들 안에서 random한 순서로 제공.\n",
    "    sampler = SubsetRandomSampler(sample_index)\n",
    "    sample_loader = DataLoader(dataset, batch_size=n, sampler=sampler)\n",
    "    \n",
    "    ## 추론 후 확인\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in sample_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            output = model(X, y, 0.0) # [batch, seq_len, vocab_size]\n",
    "\n",
    "            # torch.Tensor -> ndarray (tokenizer decode에 넣기 위해.)\n",
    "            ## tensor를 cpu로 이동후 변환가능.\n",
    "            ### tensor가 grad를 가지고 있으면(계산그래프에 포함되 있으면)\n",
    "            ####                               -> tensor.detach().cpu().ndarray()\n",
    "            pred = output.cpu().numpy()  # X.to(\"cpu\") -> 모델추정 답변\n",
    "            X = X.cpu().numpy() \n",
    "            y = y.cpu().numpy()\n",
    "\n",
    "            for i in range(n):\n",
    "                q = handle_special_tokens(tokenizer.decode(X[i]))\n",
    "                a = handle_special_tokens(tokenizer.decode(y[i]))\n",
    "                p = handle_special_tokens(tokenizer.decode(pred[i].argmax(-1)))\n",
    "                print(f\"질문: {q}\")\n",
    "                print(f\"정답: {a}\")\n",
    "                print(f\"예측: {p}\")\n",
    "                print('==================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287b94a1-bc0a-474a-8415-57dc5ea4b894",
   "metadata": {},
   "source": [
    "- Sampler:\n",
    "    -  DataLoader가 Datatset의 값들을 읽어서 batch를 만들때 index 순서를 정해주는 객체.\n",
    "    -  DataLoader의 기본 sampler는 SequentialSampler 이다. shuffle=True 일경우 RandomSampler: 랜덤한 순서로 제공."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4af09c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 도시락 싸왔어\n",
      "정답: 맛있게 드세요 .\n",
      "예측: 맛있게 드세요 .\n",
      "==================================================\n",
      "질문: 우리집 망한 거 같애\n",
      "정답: 철 들고 공부하세요 .\n",
      "예측: 공부하면 더 많은 선택을 할 수 있죠 .\n",
      "==================================================\n",
      "질문: 계속 그 사람한테 의지해도 될까 ?\n",
      "정답: 의지해도 좋을 사람이라면 의지해도 돼요 .\n",
      "예측: 다듬기만해도 괜찮을 거예요 .\n",
      "==================================================\n",
      "질문: 비밀이 너무 많은 거 같아\n",
      "정답: 하나씩 비밀을 공유해보세요 .\n",
      "예측: 가벼운 산책을 해보세요 .\n",
      "==================================================\n",
      "질문: 기회를 못 잡았어\n",
      "정답: 더 좋은 기회가 올 거예요 .\n",
      "예측: 더 괜찮아 질 거예요 .\n",
      "==================================================\n",
      "질문: 정말로 헤어졌습니다\n",
      "정답: 마음 고생 많았어요 .\n",
      "예측: 많이 힘든가봐요 .\n",
      "==================================================\n",
      "질문: 예쁜데 연애 안하는 여자\n",
      "정답: 눈에 차는 남자가 없어서일 수도 있어요 .\n",
      "예측: 사랑은 더지는 중요하지 않아요 .\n",
      "==================================================\n",
      "질문: 친구같데 .\n",
      "정답: 너무 편하게 느꼈나봅니다 .\n",
      "예측: 많이 힘든가봐요 .\n",
      "==================================================\n",
      "질문: 화낼 힘도 없다\n",
      "정답: 지금은 조금 쉬는 것도 좋을 것 같습니다 .\n",
      "예측: 저도 싫어요 .\n",
      "==================================================\n",
      "질문: 어이 없는 헤어짐\n",
      "정답: 예상하지 못한 이별이었네요 .\n",
      "예측: 마음이 허전하겠어요 .\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "random_evaluation(model, train_set, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "929fb9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 이어주려고 해서 더 어색해졌어\n",
      "정답: 일부로 부추기면 가끔 안 좋은 결과가 나오기도 해요 .\n",
      "예측: 그분과 함께 했던 나날이었을테니까요 .\n",
      "==================================================\n",
      "질문: 같이 있었는데 .\n",
      "정답: 지금은 아닌가요 .\n",
      "예측: 짝사랑은 누구나 해요 .\n",
      "==================================================\n",
      "질문: 지금 자면 밤에 못 자겠지 ?\n",
      "정답: 낮잠은 20분만 자세요 .\n",
      "예측: 저는 둘이 가는 걸 좋아해요 .\n",
      "==================================================\n",
      "질문: 넥타이핀 선물 괜찮겠지 ?\n",
      "정답: 실용적인 선물이라 괜찮을 거예요 .\n",
      "예측: 직접 물어보는 게 좋을 것 같아요 .\n",
      "==================================================\n",
      "질문: 사랑하기에 시간이 부족해\n",
      "정답: 시간은 핑계예요 .\n",
      "예측: 너무 낙담하지 마세요 .\n",
      "==================================================\n",
      "질문: 붙잡고싶어\n",
      "정답: 그대로 돌아오지는 않을 거란 걸 인정하세요 .\n",
      "예측: 제가 1호팬 하겠습니다 .\n",
      "==================================================\n",
      "질문: 집에 갈 때 피맥 먹고 싶다 .\n",
      "정답: 보다보면 괜찮아요 .\n",
      "예측: 봄은 두근두근하죠 .\n",
      "==================================================\n",
      "질문: 몰래 동거하고 있어\n",
      "정답: 허락을 맡고 당당하게 하는 게 좋을 것 같아요 .\n",
      "예측: 지금도 늦지 않았어요 .\n",
      "==================================================\n",
      "질문: 학생일 때 썸 괜찮을까\n",
      "정답: 지금은 지나면 돌아오지 않아요 .\n",
      "예측: 서로 배려하고 존중하고 존중하고 사랑할 수 있어요 .\n",
      "==================================================\n",
      "질문: 내일 모의고사 본다\n",
      "정답: 공부한 만큼 나올 거예요 .\n",
      "예측: 저도 듣고 싶어요 .\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "random_evaluation(model, test_set, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eea556c4-7534-409b-ae8e-a4d0c189e87c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========BEST Model===========\n",
      "질문: 뭐 먹지 ?\n",
      "정답: 색다른걸 드셔보세요 .\n",
      "예측: 잘 .\n",
      "==================================================\n",
      "질문: 심장이 주저 앉은듯 합니다\n",
      "정답: 충격이 컸을거라 생각해요 .\n",
      "예측: 잘 .\n",
      "==================================================\n",
      "질문: 사랑 없이도 잘 살았는데\n",
      "정답: 사랑 없이도 잘 살았던 자신으로 돌아가봐요\n",
      "예측: 잘 .\n",
      "==================================================\n",
      "질문: 방학 끝나서 좋아\n",
      "정답: 친구들이 보고싶었나봐요 .\n",
      "예측: 잘 .\n",
      "==================================================\n",
      "질문: 나를 좋아하지 않는 그 사람이 너무 미워 .\n",
      "정답: 충분히 미워하고 천천히 정리하세요 .\n",
      "예측: 잘 .\n",
      "==================================================\n",
      "질문: 게임 아이템 지르는 남친\n",
      "정답: 이해할 수 있는 적정선을 정해보세요 .\n",
      "예측: 잘 .\n",
      "==================================================\n",
      "질문: 전 제가 찬건 줄 알았는데\n",
      "정답: 누가 찼는지는 중요하지 않을지도 몰라요 .\n",
      "예측: 잘 .\n",
      "==================================================\n",
      "질문: 헤어진것인가 아닌것인가\n",
      "정답: 애매하네요 .\n",
      "예측: 잘 .\n",
      "==================================================\n",
      "질문: 솔직히 그녀가 미친듯이 불행했으면 좋겠다 .\n",
      "정답: 진심은 그렇지 않을거란 거 알아요 .\n",
      "예측: 잘 .\n",
      "==================================================\n",
      "질문: 사랑 힘들다\n",
      "정답: 상대방도 좋지만 나를 먼저 사랑해주세요 .\n",
      "예측: 잘 .\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=========BEST Model===========\")\n",
    "random_evaluation(best_model, test_set, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "50c1f705-58e6-43f0-9abe-af87bf090cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============Last Model=================\n",
      "질문: 기절할 정도로 피곤해야 잠드는데\n",
      "정답: 잠 못 드는 밤인가봐요 .\n",
      "예측: 그분과 함께 했던 나날이었을테니까요 .\n",
      "==================================================\n",
      "질문: 아 . 힘든 목일이네\n",
      "정답: 곧 주말이 올 거예요 .\n",
      "예측: 많이 힘든가봐요 .\n",
      "==================================================\n",
      "질문: 권태기 이기적인 거 알지만\n",
      "정답: 사람은 모두 이기적인 동물이에요 .\n",
      "예측: 그런 일이 가능한지 몰랐네요 .\n",
      "==================================================\n",
      "질문: 매일 그녀 꿈을 꾸네\n",
      "정답: 그녀 생각이 많이 나서 그럴거예요 .\n",
      "예측: 이젠 그분을 놓아줄 때가 되었나봐요 .\n",
      "==================================================\n",
      "질문: 좋아하는 여자 생겼으면 좋겠다 .\n",
      "정답: 곧 생길거라 믿어요 .\n",
      "예측: 사랑은 끝나도 당신의 시간은 여전히 진행 중인 걸 잊지 마세요 .\n",
      "==================================================\n",
      "질문: 고백합니다\n",
      "정답: 성공하길 바랄게요 .\n",
      "예측: 많이 답답할거라 생각해요 .\n",
      "==================================================\n",
      "질문: 지금 자면 밤에 못 자겠지 ?\n",
      "정답: 낮잠은 20분만 자세요 .\n",
      "예측: 저는 둘이 가는 걸 좋아해요 .\n",
      "==================================================\n",
      "질문: 내가 왜 해야하는지 모르겠어\n",
      "정답: 그 이유를 찾는 과정이 되겠네요 .\n",
      "예측: 내가 맞는 것과 맞지 않은 걸 구별해보세요 .\n",
      "==================================================\n",
      "질문: 돈 벌면 뭐하나\n",
      "정답: 저 주세요 .\n",
      "예측: 살짝 뒤돌아봐도 괜찮아요 .\n",
      "==================================================\n",
      "질문: 우린 운명인줄 알았는데\n",
      "정답: 운명은 또 만들어가면 돼요 .\n",
      "예측: 더 괜찮아 질 거예요 .\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=============Last Model=================\")\n",
    "random_evaluation(last_model, test_set, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "476eae22-4c6a-4f55-8dd2-87f8dd1ba46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[2732, 2447,  556, 2075, 3661,    8,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [ 203, 1635, 2639,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0]]),\n",
       " tensor([[2732, 2502, 3033, 6719,    8,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [2372, 2356, 3800, 2669,    8,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0]])]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler = SubsetRandomSampler([1,2])\n",
    "sample_loader = DataLoader(train_set, batch_size=2, sampler=sampler)\n",
    "a = next(iter(sample_loader))\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4965d1-a305-4465-8f64-f689d55490ac",
   "metadata": {},
   "source": [
    "# 새로운 데이터 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "827215a2-7bdb-44c5-b891-8ff15ae621f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotInputDataset(Dataset):\n",
    "    \"\"\"\n",
    "    질문만 받아서 생성하는 Dataset\n",
    "    - 새로운 데이터 추론용. (섭)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, question_texts, max_length, tokenizer):\n",
    "        \"\"\"\n",
    "        parameter\n",
    "            question_texts: list[str] - 질문 texts 목록. 리스트에 질문들을 담아서 받는다. [\"질문1\", \"질문2\", ...]\n",
    "            max_length: 개별 문장의 token 개수. 모든 문장의 토큰수를 max_length에 맞춘다.\n",
    "            tokenizer: Tokenizer\n",
    "        \"\"\"\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.question_texts = [self.__process_sequence(q) for q in question_texts]\n",
    "    \n",
    "    def __pad_token_sequence(self, token_sequence): \n",
    "        \"\"\"\n",
    "        max_length 길이에 맞춰 token_id 리스트를 구성한다.\n",
    "        max_length 보다 길면 뒤에를 자르고 max_length 보다 짧으면 [PAD] 토큰을 추가한다.\n",
    "        \n",
    "        Parameter\n",
    "            token_sentence: list[int] - 길이를 맞출 한 문장 token_id 목록\n",
    "        Return\n",
    "            list[int] - length가 max_length인 token_id 목록\n",
    "        \"\"\"\n",
    "        pad_token = self.tokenizer.token_to_id('[PAD]')\n",
    "        seq_len = len(token_sequence) # 입력 문장의 토큰수\n",
    "        if seq_len > self.max_length: # 문장 최대 토큰수 보다 길다면.\n",
    "            return token_sequence[:self.max_length]\n",
    "        else:\n",
    "            return token_sequence + ([pad_token] * (self.max_length - seq_len))\n",
    "    \n",
    "    def __process_sequence(self, text): \n",
    "        \"\"\"\n",
    "        한 문장(str)을 받아서 padding이 추가된 token_id 리스트로 변환 후 반환\n",
    "        Parameter\n",
    "            text: str - token_id 리스트로 변환할 한 문장\n",
    "        Return\n",
    "            list[int] - 입력받은 문장에 대한 token_id 리스트\n",
    "        \"\"\"\n",
    "        # encoding\n",
    "        encode = self.tokenizer.encode(text) # \"........\" => [. , . , .]\n",
    "        # max_length 크기에 맞춘다.\n",
    "        token_ids = self.__pad_token_sequence(encode.ids) #[3400, 20, 6, 0, 0, 0 ..]\n",
    "        return token_ids\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.question_texts)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # 질문만 반환.\n",
    "        q = self.question_texts[index]  # List\n",
    "        \n",
    "        # List->LongTensor. nn.Embedding()의 입력(정수타입)으로 들어간다. \n",
    "        return torch.tensor(q, dtype=torch.int64) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bb7661e1-c673-4e4b-85a5-df92d1b34e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [\n",
    "    \"난 가족들과 주말에 여행갈 거야.\", \n",
    "    \"와! 내일 주말이다.\",\n",
    "    \"너무 피곤하네요. 좀 쉬었으면 좋겠어요.\",\n",
    "    \"지금 몇시에요.\",\n",
    "    \"여자 친구와 내일 저녁에 만나기로 했어.\"    \n",
    "]\n",
    "input_dataset = ChatbotInputDataset(input_data, MAX_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4537cfe8-6bec-40d0-82ca-11aa6dbb90c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataset, model, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        for X in dataset:  # Dataset에서 한 질문씩을 조회\n",
    "            X = X.to(device)\n",
    "            output = model(X.unsqueeze(0), X.unsqueeze(0), 0.0)\n",
    "            pred = output.cpu().numpy()\n",
    "            X = X.cpu().numpy()\n",
    "            q = handle_special_tokens(tokenizer.decode(X))\n",
    "            a = handle_special_tokens(tokenizer.decode(pred[0].argmax(-1)))\n",
    "            print(f\"질문: {q}\")\n",
    "            print(f\"예상답: {a}\")\n",
    "            print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fb59d732-5a02-40b2-b70c-6ccaaa2cdd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 난 가족들과 주말에 여행갈 거야 .\n",
      "예상답: 좋은 소식이네요 .\n",
      "=========================================================\n",
      "질문: 와 ! 내일 주말이다 .\n",
      "예상답: 보험처리 하세요 .\n",
      "=========================================================\n",
      "질문: 너무 피곤하네요 . 좀 쉬었으면 좋겠어요 .\n",
      "예상답: 이제 그녀를 놓아주세요 .\n",
      "=========================================================\n",
      "질문: 지금 몇시에요 .\n",
      "예상답: 저도 데려가세요 .\n",
      "=========================================================\n",
      "질문: 여자 친구와 내일 저녁에 만나기로 했어 .\n",
      "예상답: 새로운 연애를 시작해보시는건 어떠세요 .\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "predict(input_dataset, last_model, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
