{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3fa1505-5df4-415a-b490-73573300ae62",
   "metadata": {},
   "source": [
    "# Gensim 패키지\n",
    "- Python으로 작성된 오픈 소스 라이브러리로, 자연어 처리와 관련된 다양한 기능을 제공한다.\n",
    "- 주요 기능\n",
    "    - **Word Embeddings**\n",
    "        - word2vec, fastext, doc2vec 등 다양한 word embedding 모델을 제공\n",
    "    - **토픽 모델링 (Topic Modeling)**\n",
    "        - LDA등 문장의 주제를 파악하는 모델 제공\n",
    "    - **텍스트/word 유사도 계산**\n",
    "    - **문서 군집화**\n",
    "        - 비슷한 주제의 문서들을 군집화.\n",
    "    - 다양한 dataset과 pretrained model 제공\n",
    "        - https://github.com/piskvorky/gensim-data\n",
    "- https://radimrehurek.com/gensim/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb22fe8-39a2-493b-90d1-6eb59884bfbe",
   "metadata": {},
   "source": [
    "## 설치\n",
    "- `pip install gensim`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22013f4-94ed-4cba-8d86-31836ba16af1",
   "metadata": {},
   "source": [
    "# Word2Vec 학습\n",
    "\n",
    "- gensim.models.Word2Vec\n",
    "- 주요 파라미터\n",
    "    - sentences\n",
    "        -  학습에 사용할 문서의 리스트. 각 문서의 단어들을 리스트로 묶고 그 문서들을 리스트로 묶은 중첩 리스트.\n",
    "        - 예시: \\[\\['word1', 'word2', 'word3'], \\['word4', 'word5']]\n",
    "    - vector_size\n",
    "        -  embedding vector 크기. 기본값: 100\n",
    "    - window\n",
    "        -  context window 크기. 중심단어를 기준으로 좌우 몇개의 단어를 확인하는지 크기. 기본값: 5\n",
    "    - min_count\n",
    "        - 이 설정보다 낮은 빈도로 등장하는 단어는 무시한다. 데이터 노이즈를 줄이는데 도움이된다. 기본값: 5\n",
    "    - sg\n",
    "        - 모델 아키텍처 결정.\n",
    "        - `0`: CBOW, `1`: Skip-gram. 기본값: 0\n",
    "    - epochs\n",
    "        - epochs 수 설정. 기본값: 5\n",
    "    - alpha\n",
    "        - initial leaning rate. 기본값: 0.025\n",
    "    - min_alpha\n",
    "        - 최소 learning rate. 기본값: 0.0001\n",
    "        - epoch 마다 learning rate를 alpha 에서 min_alpha 까지 선형적으로 줄여나간다.\n",
    "    - workers\n",
    "        -  사용 Thread 수. 기본값: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f350467-b0c2-46fa-b1f7-e2c57a4bf439",
   "metadata": {},
   "source": [
    "## 학습(Train)\n",
    "1. Word2Vec 의 initializer에 sentences를 넣어 한번에 학습한다.\n",
    "2. Word2Vec 클래스에 학습 설정을 하고 `train()` 메소드를 이용해 학습한다.\n",
    "    - epoch 단위로 작업을 할 경우 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a02a4e9-2d24-4ede-8395-0482661809a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 텍스트 데이터\n",
    "sentences = [\n",
    "    \"Natural language processing is an exciting field of study\",\n",
    "    \"Word embeddings are a type of word representation\",\n",
    "    \"Gensim is a powerful library for text processing\",\n",
    "    \"Word2Vec creates vector representations of words\", \n",
    "    \"Gensim runs on Linux, Windows and OS X, as well as any other platform that supports Python and NumPy.\"\n",
    "    \"All Gensim source code is hosted on Github under the GNU LGPL license, maintained by its open source community.\",\n",
    "    \"For commercial arrangements, see Business Support.\",\n",
    "    \"Gensim can process arbitrarily large corpora, using data-streamed algorithms.\",\n",
    "    \"There are no \\\"dataset must fit in RAM\\\" limitations.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b455f3f-def9-487e-a3a4-f9563562e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "def tokenizer(docs):\n",
    "    # 소문자로 모두 변환\n",
    "    # 알파벳, 숫자, _를 제외한 모든 문자들을 제거\n",
    "    return [nltk.word_tokenize(re.sub(r\"[^\\w\\s]\", \"\", doc.lower())) for doc in docs]\n",
    "    # [^\\w] : \\w(알파벳,숫자,_), \\s(공백)을 제외한 나머지 문자 찾기 / \\w와 \\s 사이에 or의 의미 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f3a73dc-943f-4baa-a072-c9b30ea482e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7791fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c33d8473-e106-4d7e-b115-b0072833efbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "model1 = Word2Vec(\n",
    "    sentences=tokens,                # 학습 시킬 데이터\n",
    "    vector_size=10,                  # embedding vector의 차원(한개 단어에서 몇개의 feature를 추출할지)\n",
    "    window=2,                        # window size 설정. 주변단어의 개수\n",
    "    min_count=1,                     # 최소 출연 빈도수\n",
    "    epochs=10,\n",
    "    workers=os.cpu_count()           # 병렬처리 개수\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "395fd7bb-3e14-49c2-9abe-5f3663f481a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch loss:147.74391174316406\n",
      "1 epoch loss:139.40313720703125\n",
      "2 epoch loss:108.19081115722656\n",
      "3 epoch loss:159.9152069091797\n",
      "4 epoch loss:163.42904663085938\n",
      "5 epoch loss:143.5673370361328\n",
      "6 epoch loss:136.47251892089844\n",
      "7 epoch loss:130.15609741210938\n",
      "8 epoch loss:164.7725067138672\n",
      "9 epoch loss:156.24295043945312\n"
     ]
    }
   ],
   "source": [
    "# 학습데이터, epoch을 설정하지 않음 => 학습 안된 모델을 반환\n",
    "model2 = Word2Vec(vector_size=10, window=2, min_count=1, workers=os.cpu_count())\n",
    "# model에 vocab 설정\n",
    "model2.build_vocab(tokens)\n",
    "# 학습\n",
    "epoch=10\n",
    "for e in range(epoch):\n",
    "    model2.train(\n",
    "        tokens,         # 학습데이터\n",
    "        total_examples=model2.corpus_count,         # 학습데이터(문서) 개수\n",
    "        epochs=1,\n",
    "        compute_loss=True                           # 학습이 끝나면 loss를 계산\n",
    "    )\n",
    "    loss = model2.get_latest_training_loss()        # train() 시 계산된 loss 조회\n",
    "    print(f\"{e} epoch loss:{loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7fe805-022b-4e1a-b0ea-8e5bc692fa75",
   "metadata": {},
   "source": [
    "## 학습 후 결과 조회\n",
    "\n",
    "- **KeyedVectors 조회**\n",
    "    - KeyedVectors는 단어와 vector를 매핑한 객체로 embedding vector를 이용한 다양한 조회를 지원한다.\n",
    "    - model.wv 로 조회해서 사용.\n",
    "- **Embedding Vector 조회**\n",
    "  - model.wv.vectors\n",
    "- **단어 목록 조회**\n",
    "    - model.wv.index_to_key, model.wv.key_to_index\n",
    "- **단어 벡터 조회**\n",
    "    - model.wv[word]: 특정 단어의 vector반환\n",
    "- **Vocab에 대상 단어가 있는지 확인**\n",
    "    - \"대상단어\" in model.wv\n",
    "- **유사단어들 찾기**\n",
    "    - model.wv.most_similar(word)\n",
    "- **단어간 유사도 비교**\n",
    "    - model.wv.similarity(word1, word2)\n",
    "- 유사도를 계산할 때 **코사인 유사도(Cosine Similarity)** 를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba473d91",
   "metadata": {},
   "source": [
    "> # 코사인 유사도\n",
    "> - 두 벡터 간의 유사성을 측정하는 중요한 방법 중 하나.\n",
    "> - 코사인 유사도는 두 벡터 간의 코사인 각도를 이용하여 유사도를 계산한다. 이때 벡터의 **크기는 결과에 영향을 미치지 않고, 오직 방향만이 중요**하다.\n",
    "> ## 공식\n",
    "> \n",
    "> $$ similarity = cos(\\theta) = \\frac{A⋅B}{||A||\\ ||B||} = \\frac{\\sum_{i=1}^{n}{A_i×B_i}}{\\sqrt{\\sum_{i=1}^{n}(A_i)^2}×\\sqrt{\\sum_{i=1}^{n}(B_i)^2}} $$\n",
    "> \n",
    "> ## 결과 해석\n",
    "> \n",
    "> - **값의 범위**: -1에서 1 사이의 값을 가집니다\n",
    ">   - 1: 두 벡터가 완전히 동일한 방향 (0도의 cosine 값)\n",
    ">   - 0: 두 벡터가 직교 (90도의 cosine 값)\n",
    ">   - -1: 두 벡터가 정반대 방향 (180도의 cosine 값)\n",
    "> \n",
    "> ![cosine_similarity](figures/gensim_consin_sim.png)\n",
    ">\n",
    "> ## Python 코사인 유사도 계산\n",
    "> ```python\n",
    "> from numpy import dot\n",
    "> from numpy.linalg import norm\n",
    "> \n",
    "> def cosine_similarity(A, B):\n",
    ">     return dot(A, B)/(norm(A)*norm(B))\n",
    "> ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c5d0e0b-0d18-40ac-91c4-11e9114acbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x103fb5940>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.wv               # KeyedVectors -> 토큰-embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36df1892-1804-4f23-a396-b52f82238d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gensim',\n",
       " 'is',\n",
       " 'of',\n",
       " 'for',\n",
       " 'processing',\n",
       " 'source',\n",
       " 'as',\n",
       " 'on',\n",
       " 'word',\n",
       " 'are',\n",
       " 'a',\n",
       " 'and',\n",
       " 'words',\n",
       " 'runs',\n",
       " 'linux',\n",
       " 'os',\n",
       " 'windows',\n",
       " 'vector',\n",
       " 'x',\n",
       " 'well',\n",
       " 'any',\n",
       " 'representations',\n",
       " 'limitations',\n",
       " 'creates',\n",
       " 'word2vec',\n",
       " 'text',\n",
       " 'platform',\n",
       " 'library',\n",
       " 'powerful',\n",
       " 'representation',\n",
       " 'type',\n",
       " 'embeddings',\n",
       " 'study',\n",
       " 'field',\n",
       " 'exciting',\n",
       " 'an',\n",
       " 'language',\n",
       " 'other',\n",
       " 'that',\n",
       " 'ram',\n",
       " 'see',\n",
       " 'support',\n",
       " 'can',\n",
       " 'process',\n",
       " 'arbitrarily',\n",
       " 'large',\n",
       " 'corpora',\n",
       " 'using',\n",
       " 'datastreamed',\n",
       " 'algorithms',\n",
       " 'there',\n",
       " 'no',\n",
       " 'dataset',\n",
       " 'must',\n",
       " 'fit',\n",
       " 'in',\n",
       " 'business',\n",
       " 'arrangements',\n",
       " 'supports',\n",
       " 'commercial',\n",
       " 'python',\n",
       " 'numpyall',\n",
       " 'code',\n",
       " 'hosted',\n",
       " 'github',\n",
       " 'under',\n",
       " 'the',\n",
       " 'gnu',\n",
       " 'lgpl',\n",
       " 'license',\n",
       " 'maintained',\n",
       " 'by',\n",
       " 'its',\n",
       " 'open',\n",
       " 'community',\n",
       " 'natural']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.wv.index_to_key          # vocab: token_id -> token(단어)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9607cc94-67cf-4a87-8a42-ab88683cd514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gensim': 0,\n",
       " 'is': 1,\n",
       " 'of': 2,\n",
       " 'for': 3,\n",
       " 'processing': 4,\n",
       " 'source': 5,\n",
       " 'as': 6,\n",
       " 'on': 7,\n",
       " 'word': 8,\n",
       " 'are': 9,\n",
       " 'a': 10,\n",
       " 'and': 11,\n",
       " 'words': 12,\n",
       " 'runs': 13,\n",
       " 'linux': 14,\n",
       " 'os': 15,\n",
       " 'windows': 16,\n",
       " 'vector': 17,\n",
       " 'x': 18,\n",
       " 'well': 19,\n",
       " 'any': 20,\n",
       " 'representations': 21,\n",
       " 'limitations': 22,\n",
       " 'creates': 23,\n",
       " 'word2vec': 24,\n",
       " 'text': 25,\n",
       " 'platform': 26,\n",
       " 'library': 27,\n",
       " 'powerful': 28,\n",
       " 'representation': 29,\n",
       " 'type': 30,\n",
       " 'embeddings': 31,\n",
       " 'study': 32,\n",
       " 'field': 33,\n",
       " 'exciting': 34,\n",
       " 'an': 35,\n",
       " 'language': 36,\n",
       " 'other': 37,\n",
       " 'that': 38,\n",
       " 'ram': 39,\n",
       " 'see': 40,\n",
       " 'support': 41,\n",
       " 'can': 42,\n",
       " 'process': 43,\n",
       " 'arbitrarily': 44,\n",
       " 'large': 45,\n",
       " 'corpora': 46,\n",
       " 'using': 47,\n",
       " 'datastreamed': 48,\n",
       " 'algorithms': 49,\n",
       " 'there': 50,\n",
       " 'no': 51,\n",
       " 'dataset': 52,\n",
       " 'must': 53,\n",
       " 'fit': 54,\n",
       " 'in': 55,\n",
       " 'business': 56,\n",
       " 'arrangements': 57,\n",
       " 'supports': 58,\n",
       " 'commercial': 59,\n",
       " 'python': 60,\n",
       " 'numpyall': 61,\n",
       " 'code': 62,\n",
       " 'hosted': 63,\n",
       " 'github': 64,\n",
       " 'under': 65,\n",
       " 'the': 66,\n",
       " 'gnu': 67,\n",
       " 'lgpl': 68,\n",
       " 'license': 69,\n",
       " 'maintained': 70,\n",
       " 'by': 71,\n",
       " 'its': 72,\n",
       " 'open': 73,\n",
       " 'community': 74,\n",
       " 'natural': 75}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c3c06ac-5bb3-4a2f-b0ac-d1aa0c747f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00530078,  0.00215998,  0.0511257 ,  0.08994552, -0.0929675 ,\n",
       "       -0.07124555,  0.06510045,  0.08978292, -0.05092729, -0.0380263 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특정 단어의 embedding vector 조회\n",
    "model1.wv[\"gensim\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ea50a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model1.wv[\"안녕\"]           # 값이 없어 key error 발생\n",
    "\"인녕\" in model1.wv, \"gensim\" in model1.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52677076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "없어 뭐 꼬아?\n"
     ]
    }
   ],
   "source": [
    "word = \"안녕\"\n",
    "if word in model1.wv:\n",
    "    print(model1.wv[word])\n",
    "else:   print(\"없어 뭐 꼬아?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c0e15d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('numpyall', 0.7189714908599854),\n",
       " ('study', 0.713896632194519),\n",
       " ('that', 0.6710396409034729),\n",
       " ('can', 0.641579270362854),\n",
       " ('datastreamed', 0.5988761782646179),\n",
       " ('is', 0.5452057123184204),\n",
       " ('other', 0.5355265140533447),\n",
       " ('maintained', 0.5195195078849792),\n",
       " ('representations', 0.5130788087844849),\n",
       " ('in', 0.5079874396324158)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유사도 검사\n",
    "model1.wv.most_similar(\"gensim\")                    # gensim과 가장 유사한 단어를 순서대로 10개 반환\n",
    "# (단어, 유사도) 유사도 -1~1  ->   1에 가까울수록 유사도가 높음 / 코사인 유사도 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c35496a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('numpyall', 0.7189714908599854),\n",
       " ('study', 0.713896632194519),\n",
       " ('that', 0.6710396409034729)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.wv.most_similar(\"gensim\", topn=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e674612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7138967"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어간의 유사도\n",
    "model1.wv.similarity(\"gensim\", \"study\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63224cac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52de32ef-2dc7-49a6-b829-68b14f797267",
   "metadata": {},
   "source": [
    "## 모델 저장 및 로딩\n",
    "\n",
    "### 모델 저장, 로딩\n",
    "- `model.save('저장파일 경로')`\n",
    "  - gensim 자체 포맷으로 저장된다.\n",
    "- `gensim.models.Word2Vec.load('저장파일 경로')`\n",
    "  - `model.save()`로 저장된 모델을 Loading한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b9517b7-ee62-4313-a78e-42d5240cb276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "model1.save(\"saved_models/w2v_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1f55800-3dd3-4054-9c07-d48961518099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "load_model = Word2Vec.load(\"saved_models/w2v_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92b40b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('numpyall', 0.7189714908599854),\n",
       " ('study', 0.713896632194519),\n",
       " ('that', 0.6710396409034729),\n",
       " ('can', 0.641579270362854),\n",
       " ('datastreamed', 0.5988761782646179),\n",
       " ('is', 0.5452057123184204),\n",
       " ('other', 0.5355265140533447),\n",
       " ('maintained', 0.5195195078849792),\n",
       " ('representations', 0.5130788087844849),\n",
       " ('in', 0.5079874396324158)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model.wv.most_similar(\"gensim\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34742583-58b5-40c8-b3ab-a641147cdd07",
   "metadata": {},
   "source": [
    "### Word Embedding Vector만 저장 및 로드\n",
    "- `KeyedVectors` 를 이용해 저장한다.\n",
    "    - `model.wv.save_word2vec_format('저장경로', binary=True|False)`\n",
    "        - binary=True: binary 파일로 저장한다. 용량이 작은 대신 내용확인이 안된다.\n",
    "        - binary=False: csv(공백구분자) 형식 text로 저장한다. 내용을 확인할 수있지만 파일용량이 크다.\n",
    "- `KeyedVectors.load_word2vec_format(\"저장경로\", binary=True|False)`\n",
    "    - 저장시 binary에 맞춰 읽는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a9dfab01-5ed0-4749-a585-fb26ba817495",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.wv.save_word2vec_format(\"saved_models/keyedvector.bin\", binary=True)\n",
    "model1.wv.save_word2vec_format(\"saved_models/keyedvector.csv\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "114fe1da-cf7d-411d-a46a-8d69045df1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "load_wv_bin = KeyedVectors.load_word2vec_format(\"saved_models/keyedvector.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a72063a1-afa5-4c69-b271-982d1f185843",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_wv_csv = KeyedVectors.load_word2vec_format(\"saved_models/keyedvector.csv\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0b8b43cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('numpyall', 0.7189714908599854),\n",
       " ('study', 0.713896632194519),\n",
       " ('that', 0.6710396409034729),\n",
       " ('can', 0.641579270362854),\n",
       " ('datastreamed', 0.5988761782646179),\n",
       " ('is', 0.5452057123184204),\n",
       " ('other', 0.5355265140533447),\n",
       " ('maintained', 0.5195195078849792),\n",
       " ('representations', 0.5130788087844849),\n",
       " ('in', 0.5079874396324158)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_wv_bin.most_similar(\"gensim\")\n",
    "load_wv_csv.most_similar(\"gensim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f6ca4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5905f537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d66b7152-2745-4e30-bc6f-5e417ab25f00",
   "metadata": {},
   "source": [
    "## Pretrained 모델 사용하기\n",
    "- https://github.com/Kyubyong/wordvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bc4f7b0a-8620-4c34-b463-3c186a70c107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile(\"ko_new.zip\") as zf:       # 압축을 풀 파일의 경로\n",
    "    zf.extractall(\"saved_models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "52eab43d-4df0-44b6-a531-83f66c427996",
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_wv = KeyedVectors.load_word2vec_format(\n",
    "    \"saved_models/ko_new.txt\",\n",
    "    binary=False,\n",
    "    encoding='utf-8'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7907d09e-8fd1-4462-9679-ca182617e1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('아침', 0.8432559370994568), ('밤', 0.7863156795501709), ('새벽', 0.7520349025726318)]\n"
     ]
    }
   ],
   "source": [
    "word = \"저녁\"\n",
    "result = ko_wv.most_similar(word, topn=3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a81d3f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.4055068e+00, -1.1325349e+00,  8.1074381e-01, -5.0247613e-02,\n",
       "        2.1491051e-01, -1.9841902e+00,  8.0733681e-01,  2.0333993e+00,\n",
       "       -2.9718000e-01, -3.9601573e-01,  2.0054409e-01,  1.0981818e-01,\n",
       "        6.5035206e-01,  7.2890747e-01, -1.1681221e+00, -1.8119998e+00,\n",
       "        8.8641578e-01,  1.2009319e+00, -4.7502378e-01,  4.1354772e-01,\n",
       "       -7.5538319e-01, -9.7632490e-02,  5.9691077e-01, -5.7045072e-01,\n",
       "       -1.1796158e-01, -8.1746149e-01,  4.7462374e-01, -4.5166805e-01,\n",
       "       -5.7070792e-01, -9.3876463e-01,  2.5449281e+00, -1.1985859e+00,\n",
       "       -8.1546649e-02,  5.5710924e-01, -2.4425223e-01,  4.1034997e-01,\n",
       "       -9.3672651e-01,  2.3033054e+00, -3.6426643e-01,  9.6841204e-01,\n",
       "        3.2277573e-02, -4.0561062e-01, -7.6284319e-01, -8.6872977e-01,\n",
       "       -5.5202201e-02,  1.1278684e-01, -1.9026634e+00, -1.0162231e+00,\n",
       "        2.3134122e+00,  1.5543437e+00,  8.2596488e-02,  8.8935697e-01,\n",
       "        6.8150657e-01, -1.5668654e+00, -9.2090231e-01, -4.5446405e-01,\n",
       "        1.0511016e+00,  3.4135616e-01,  6.8268530e-02,  5.2757758e-01,\n",
       "        7.1595293e-01, -5.5954272e-01,  7.0541364e-04,  3.7370467e-01,\n",
       "        5.3015995e-01,  1.1531280e+00, -4.3870203e-02,  1.0782568e+00,\n",
       "        8.0354953e-01, -1.5248027e+00,  1.0977759e+00,  9.0980768e-01,\n",
       "       -8.6870277e-01,  1.6569854e+00,  5.9870398e-01, -9.2723495e-01,\n",
       "        1.6660676e+00, -5.9807104e-01,  1.1034924e+00, -5.0312054e-01,\n",
       "        1.3878357e+00, -2.2096331e-01,  5.8850700e-01,  3.0609265e-01,\n",
       "       -1.1284148e+00, -2.0477197e+00, -5.9907264e-01, -2.6021450e+00,\n",
       "        2.8679565e-01,  6.3199234e-01,  5.8493227e-01,  1.8080400e+00,\n",
       "        8.4323758e-01, -8.7139271e-02,  1.3835149e+00,  3.9046541e-01,\n",
       "        9.0694422e-01,  5.0616455e-01,  1.0112194e+00,  1.4830657e+00,\n",
       "        2.1799731e-01,  4.1756579e-01, -4.5389894e-01, -4.4468251e-01,\n",
       "       -1.5429323e+00,  7.5122696e-01, -1.4055469e+00,  6.1238390e-01,\n",
       "       -2.7296398e+00, -6.8119453e-04,  1.0909556e+00,  1.2078356e+00,\n",
       "        1.6336672e+00,  8.0101591e-01,  7.8516352e-01, -4.1448891e-02,\n",
       "       -1.2702569e+00,  1.4179435e+00, -1.1175996e+00, -1.2664565e+00,\n",
       "       -6.2692672e-02, -1.1412697e+00,  3.6590257e-01,  5.4607165e-01,\n",
       "        9.9746221e-01, -5.9017706e-01, -1.5315062e+00, -1.0728992e+00,\n",
       "        2.2951686e-01,  7.1268862e-01, -3.0538049e-01,  8.6655998e-01,\n",
       "        1.4746802e+00,  1.5171154e+00,  8.3005011e-01, -1.2008083e+00,\n",
       "        1.2866819e-01, -6.4120001e-01, -5.6468457e-01, -1.4646150e+00,\n",
       "        7.9416358e-01,  1.9702054e+00, -4.9150413e-01,  1.1725165e+00,\n",
       "        7.0260113e-01, -2.2728593e+00, -1.0815086e+00,  2.1721959e-01,\n",
       "       -7.0104086e-01, -7.9418409e-01, -5.2173935e-02, -1.2131649e+00,\n",
       "       -2.0334503e-01,  2.5768580e+00,  8.1279159e-01, -1.3304241e-03,\n",
       "       -4.9573973e-01,  1.1275493e+00,  2.0272388e-01, -1.0156900e+00,\n",
       "       -5.0013971e-01, -8.9310020e-01, -5.3737289e-01, -1.5754910e+00,\n",
       "        2.7265087e-01, -1.6137844e+00, -1.2696629e+00, -6.6573250e-01,\n",
       "       -1.6553886e+00, -1.3716513e+00,  1.5141650e-03, -1.2417453e-01,\n",
       "        4.3871936e-01,  6.3294208e-01, -5.5000001e-01, -5.6431657e-01,\n",
       "       -4.6710819e-01, -1.3336300e+00, -1.4112504e+00,  7.0038670e-01,\n",
       "        1.1789978e+00, -2.0755587e+00,  8.2925296e-01,  2.9224235e-01,\n",
       "        2.6299998e-01,  6.6697949e-01, -4.7844615e-02, -3.3861113e-01,\n",
       "        5.0202632e-01, -1.2887833e+00,  5.2841359e-01,  1.5346214e+00,\n",
       "       -1.0830921e+00,  8.7017453e-01,  1.8527542e+00,  2.3131454e+00,\n",
       "        1.3058428e-01,  1.3701631e+00,  1.7523633e-01, -1.1160300e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ko_wv[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb37baa",
   "metadata": {},
   "source": [
    "# 빅카인즈 뉴스 데이터를 이용한 Word2Vec 학습\n",
    "- 빅카인즈\n",
    "    - 한국언론진흥재단에서 운영하는 뉴스빅데이터 분석 서비스 사이트\n",
    "- 빅카인즈에서 특정 분야의 기사들을 수집해서 학습시킨다.\n",
    "    - https://www.bigkinds.or.kr/\n",
    "    - 회원가입 (구글, 네이버, 카카오 계정으로 가입 가능) 후 로그인\n",
    "    - 뉴스분석 > 뉴스검색$\\cdot$분석 클릭\n",
    "    ![word2vec_bigkinds1.png](figures/word2vec_bigkinds1.png)\n",
    "    - 기간, 언론사, 분류, 상세검색 등 검색 조건입력 후 조회\n",
    "    ![word2vec_bigkinds1.png](figures/word2vec_bigkinds2.png)\n",
    "    - 결과 다운로드\n",
    "        - step3 분석결과및 시각화 -> 맨 아래 `엑셀다운로드` 클릭 \n",
    "    ![word2vec_bigkinds1.png](figures/word2vec_bigkinds3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c3d0d2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giwonjun/anaconda3/envs/dl/lib/python3.12/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"NewsResult_20250223-20250523.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "34fb2f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2303, 19)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4771754d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2303 entries, 0 to 2302\n",
      "Data columns (total 19 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   뉴스 식별자             2303 non-null   float64\n",
      " 1   일자                 2303 non-null   int64  \n",
      " 2   언론사                2303 non-null   object \n",
      " 3   기고자                1910 non-null   object \n",
      " 4   제목                 2303 non-null   object \n",
      " 5   통합 분류1             2303 non-null   object \n",
      " 6   통합 분류2             1933 non-null   object \n",
      " 7   통합 분류3             1664 non-null   object \n",
      " 8   사건/사고 분류1          2303 non-null   object \n",
      " 9   사건/사고 분류2          938 non-null    object \n",
      " 10  사건/사고 분류3          307 non-null    object \n",
      " 11  인물                 1390 non-null   object \n",
      " 12  위치                 2254 non-null   object \n",
      " 13  기관                 2247 non-null   object \n",
      " 14  키워드                2303 non-null   object \n",
      " 15  특성추출(가중치순 상위 50개)  2303 non-null   object \n",
      " 16  본문                 2303 non-null   object \n",
      " 17  URL                2256 non-null   object \n",
      " 18  분석제외 여부            60 non-null     object \n",
      "dtypes: float64(1), int64(1), object(17)\n",
      "memory usage: 342.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d2040e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>제목</th>\n",
       "      <th>본문</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>검사 판사가 유권자 결정 바꾸는 선거법 ‘삭제→부활→삭제’ 30년사</td>\n",
       "      <td>공직선거법 위반 혐의로 재판을 받는 이재명 더불어민주당 대통령 후보는 대법원 전원합...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>환경장관 만난 김태흠 충남지사 “청양 부여 지천댐 조속 건설을”</td>\n",
       "      <td>김태흠 충남지사가 청양 부여 지천댐 건설을 조속하게 추진해 줄 것을 정부에 요청했다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[유석재의 돌발史전] 나는 이제 더 이상 ‘마오’를 존경하지 않는다</td>\n",
       "      <td>일반적인 신문기사라면야 그럴 일이 거의 없겠습니다만, 이 ‘돌발史전’은 인터넷상에만...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“이 정책만은 정권 초월해야” 부처별 ‘지속 과제’ 지키기 안간힘</td>\n",
       "      <td>“누가 대통령 되든 정책 기조 달라져” \\n기재부, 대선 후보 경제공약 분석 중 \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>안전사고 대국 中 잇따라 인명 사고 발생</td>\n",
       "      <td>아시아투데이 홍순도 베이징 특파원 = 안전사고 대국이 될 수밖에 없는 중국에 최근 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      제목  \\\n",
       "0  검사 판사가 유권자 결정 바꾸는 선거법 ‘삭제→부활→삭제’ 30년사   \n",
       "1    환경장관 만난 김태흠 충남지사 “청양 부여 지천댐 조속 건설을”   \n",
       "2  [유석재의 돌발史전] 나는 이제 더 이상 ‘마오’를 존경하지 않는다   \n",
       "3   “이 정책만은 정권 초월해야” 부처별 ‘지속 과제’ 지키기 안간힘   \n",
       "4                 안전사고 대국 中 잇따라 인명 사고 발생   \n",
       "\n",
       "                                                  본문  \n",
       "0  공직선거법 위반 혐의로 재판을 받는 이재명 더불어민주당 대통령 후보는 대법원 전원합...  \n",
       "1  김태흠 충남지사가 청양 부여 지천댐 건설을 조속하게 추진해 줄 것을 정부에 요청했다...  \n",
       "2  일반적인 신문기사라면야 그럴 일이 거의 없겠습니다만, 이 ‘돌발史전’은 인터넷상에만...  \n",
       "3  “누가 대통령 되든 정책 기조 달라져” \\n기재부, 대선 후보 경제공약 분석 중 \\...  \n",
       "4  아시아투데이 홍순도 베이징 특파원 = 안전사고 대국이 될 수밖에 없는 중국에 최근 ...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[\"제목\", \"본문\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d721c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 문서 : 개별 뉴스 기사(제목+본문)\n",
    "\n",
    "# 전처리 + 토큰화 - 소문자로 통일 / 형태소 단위로 토큰화 진행\n",
    "\n",
    "# gensim을 이용해 enbedding 모델 학습\n",
    "\n",
    "# 결과 확인 : 유사도 검사"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
