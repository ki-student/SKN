{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ee8245-0329-4185-971d-21bf20cc780e",
   "metadata": {},
   "source": [
    "# Chain\n",
    "\n",
    "**Chain**(체인)은 여러 컴포넌트(요소)를 정해진 순서대로 연결하여 **복잡한 AI 작업을 단계별로 자동화**할 수 있도록 돕는 구조이다.\n",
    "\n",
    "- 각 컴포넌트는 입력을 받아 특정 처리를 수행한 후 다음 단계로 결과를 전달한다.\n",
    "- 복잡한 작업을 여러 개의 단순한 단계로 나누고, 각 단계를 순차적으로 실행함으로써 전체 작업을 체계적으로 구성할 수 있다.\n",
    "\n",
    "## 기본 개념\n",
    "\n",
    "- 체인은 하나의 LLM 호출에 그치지 않고 **여러 LLM 호출이나 도구 실행을 순차적으로 연결**할 수 있다.\n",
    "- 예를 들어, 사용자의 질문 → 검색 → 요약 → 응답 생성 같은 일련의 작업을 체인으로 구성할 수 있다.\n",
    "- 체인을 사용하면 코드의 재사용성과 유지 보수성이 향상된다.\n",
    "\n",
    "## LangChain에서의 Chain 구성 방식\n",
    "\n",
    "LangChain은 다음 두 가지 방식을 통해 체인을 구성할 수 있다.\n",
    "\n",
    "### 1. Off-the-shelf Chains 방식 (클래식 방식)\n",
    "\n",
    "- LangChain에서 제공하는 **미리 정의된 Chain 클래스**(예: `LLMChain`, `SequentialChain`, `SimpleSequentialChain`)를 활용하는 방식이다.\n",
    "- 이 방식은 LangChain의 **초기 구조**이며, 대부분의 클래스는 현재 **더 이상 사용되지 않음(deprecated)** 상태이다.\n",
    "\n",
    "> 현재 LangChain에서는 이 방식을 권장하지 않는다.\n",
    "\n",
    "### 2. LCEL (LangChain Expression Language) 방식\n",
    "\n",
    "- 체인을 함수형 방식으로 선언할 수 있는 **표현식 기반의 체인 구성 언어**이다.\n",
    "- LCEL 방식은 간결하고 선언적인 문법을 제공하여 **직관적이고 확장성 있는 체인 구성**이 가능하다.\n",
    "- `Runnable`이라는 공통 인터페이스를 기반으로 다양한 요소를 조합하여 체인을 구성한다.\n",
    "- 체인의 각 구성 요소는 `invoke()` 메서드로 실행된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb0a7d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# off-the-shelf 방식\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"{item}에 어울리는 이름 {count}개를 만들어 주세요.\"\n",
    ")\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 변수:값 -> (prompt_template) prompt -> (model) 응답결과 -> (parser) -> 최종결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25ae105b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/69/bt3_5fns57n_cp5_ydbrhfh80000gn/T/ipykernel_67577/1602056365.py:2: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain import LLMChain\n",
    "chain = LLMChain(\n",
    "    prompt=prompt_template,\n",
    "    llm=model,\n",
    "    output_parser=parser\n",
    ")\n",
    "response = chain.invoke({\"item\":\"가방\", \"count\":5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cde071db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'item': '가방',\n",
       " 'count': 5,\n",
       " 'text': '물론입니다! 가방에 어울리는 이름 5개를 제안해 드릴게요.\\n\\n1. **여행자 (Traveler)** - 여행을 함께할 수 있는 가방에 어울리는 이름.\\n2. **스타일리스트 (Stylist)** - 패션에 포인트를 줄 수 있는 세련된 가방에 적합한 이름.\\n3. **하루 (Haru)** - 일상적인 사용을 고려한 가볍고 실용적인 가방에 어울리는 이름.\\n4. **비비안 (Vivian)** - 우아함과 실용성을 겸비한 여성 가방에 적합한 이름.\\n5. **모험가 (Adventurer)** - 다양한 환경에서 사용할 수 있는 튼튼한 가방을 위한 이름.\\n\\n이 이름들이 가방의 특성을 잘 표현하기를 바랍니다!'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ba00ec-6c7c-496e-b31f-f3978b74bdba",
   "metadata": {},
   "source": [
    "# [LCEL](https://python.langchain.com/docs/how_to/#langchain-expression-language-lcel) (LangChain Expression Language)\n",
    "- LCEL은 LangChain의 핵심 기능인 체인(Chain)을 더욱 간결하고 유연하게 구성할 수 있도록 고안된 **선언형 체인(chain) 구성 언어**이다.\n",
    "- 파이프 연산자 `|`를 사용해 선언적 방법으로 여러 작업을 연결한다.\n",
    "- 체인을 구성하는 각 요소는 `Runnable` 타입으로, 체인 내에서 실행 가능한 단위이다.\n",
    "- 각 단계는 invoke() 메서드를 통해 실행되며, 앞 단계의 출력이 다음 단계의 입력으로 자동 전달된다.\n",
    "    - [Runnable 컴포넌트별 입출력 타입](https://python.langchain.com/docs/concepts/runnables/#input-and-output-types)\n",
    "    - 각 컴포넌트의 input과 output 타입에 맞춰 값이 전달되도록 한다.\n",
    "- https://python.langchain.com/v0.2/docs/concepts/#langchain-expression-language-lcel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f0d52c-23da-4ec6-87cc-925e3d6259ea",
   "metadata": {},
   "source": [
    "## [Runnable](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html)\n",
    "- LangChain의 Runnable은 실행 가능한 작업 단위를 캡슐화한 개념으로, 데이터 흐름의 각 단계를 정의하고 **체인(chain) 에 포함 되어**  복잡한 작업의 각 단계를 수행 한다.\n",
    "- Chain을 구성하는 class들은 Runnable의 상속 받아 구현한다.\n",
    "- **Prompt Template클래스**, **Chat 모델, LLM 모델 클래스**, **Output Parser 클래스** 등 다양한 컴포넌트가 Runnable을 상속받아 구현된다.\n",
    "\n",
    "### 주요 특징\n",
    "- 작업 단위의 캡슐화:\n",
    "    - Runnable은 특정 작업(예: 프롬프트 생성, LLM 호출, 출력 파싱 등)을 수행하는 독립적인 컴포넌트이다.\n",
    "    - 각 컴포넌트는 독립적으로 테스트 및 재사용이 가능하며, 조합하여 복잡한 체인을 구성할 수 있다.\n",
    "- 체인 연결 및 작업 흐름 관리:\n",
    "    - Runnable은 체인(chain, 일련의 연결된 작업 흐름)을 구성하는 기본 단위로 사용된다.\n",
    "    - LangChain Expression Language(LCEL)를 사용하면 | 연산자를 통해 여러 Runnable을 쉽게 연결할 수 있다.\n",
    "    - 력과 출력의 형식을 일관되게 유지하여 각 단계가 자연스럽게 연결된다.\n",
    "- 모듈화 및 디버깅 용이성:\n",
    "    - 각 단계가 명확히 분리되어 문제 발생 시 어느 단계에서 오류가 발생했는지 쉽게 확인할 수 있다.\n",
    "    - 복잡한 작업을 작은 단위로 나누어 체계적으로 관리할 수 있다.\n",
    "      \n",
    "### Runnable의 표준 메소드\n",
    "- 모든 Runnable이 구현하는 공통 메소드\n",
    "    - `invoke()`: 단일 입력을 처리하여 결과를 반환.\n",
    "    - `batch()`: 여러 입력 데이터들을 한 번에 처리.\n",
    "    - `stream()`: 입력에 대해 스트리밍 방식으로 응답을 반환.\n",
    "    - `ainvoke()`: 비동기 방식으로 입력을 처리하여 결과를 반환.\n",
    "\n",
    "### Runnable의 주요 구현체(하위 클래스)\n",
    "\n",
    "- `RunnableSequence`\n",
    "    - 여러 `Runnable`을 순차적으로 연결하여 실행하는 구성이다.\n",
    "    - 각 단계의 출력이 다음 단계의 입력으로 전달된다.\n",
    "    - LCEL을 사용하여 체인을 구성할 경우 자동으로 `RunnableSequence`로 변환된다.\n",
    "-  `RunnablePassThrough`\n",
    "    - 입력 데이터를 가공하지 않고 그대로 다음 단계로 전달하는 `Runnable`이다.\n",
    "    - 선택적으로 미리 정의된 키-값 쌍을 함께 전달할 수 있다.\n",
    "\n",
    "- `RunnableParallel`\n",
    "    - 여러 `Runnable`을 병렬로 실행한 후, 결과를 결합하여 다음 단계로 전달한다.\n",
    "    - 병렬 처리를 통해 처리 속도를 개선할 수 있다.\n",
    "\n",
    "- `RunnableLambda`\n",
    "    - 일반 함수 또는 `lambda` 함수를 `Runnable`로 변환하여 체인에 포함할 수 있다.\n",
    "    - 사용자 정의 함수로 동작을 확장할 때 유용하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad98816c-6666-4d36-a91d-4b4f64519de4",
   "metadata": {},
   "source": [
    "#### Runnable 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24ebba76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f4040f4-b373-4f15-9c34-9026541ad755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import Runnable    # All Runnable의 TOP\n",
    "# 사용자 정의 Runnable\n",
    "class MyRunnable(Runnable):\n",
    "    \n",
    "    def invoke(self, input_data : str, config : dict = None):\n",
    "        # invoke() : 구현하는 Runnable이 해야하는 작업을 구현하는 method\n",
    "        # input_data : 입력값\n",
    "        # config : 일할 때 필요한 설정 값\n",
    "\n",
    "        if config is not None and config.get(\"lang\") == \"en\":\n",
    "            return f\"Explain {input_data} in one sentences.\"\n",
    "        return f\"{input_data}에 대해서 한 문장으로 설명 부탁~ 해요 ~\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43492e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Explain Apple in one sentences.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_runnable = MyRunnable()\n",
    "my_runnable.invoke(\"사과\")\n",
    "my_runnable.invoke(\"콤퓨타\")\n",
    "my_runnable.invoke(\"Apple\", {\"lang\" : \"en\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "073b7618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='An apple is a round, typically red, green, or yellow fruit produced by the apple tree (Malus domestica), known for its sweet to tangy flavor and crisp texture, often eaten raw or used in various culinary dishes.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 13, 'total_tokens': 60, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_62a23a81ef', 'id': 'chatcmpl-BgkAaQSYljlbEV6yQIaxDgkvTByF6', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--806b5342-929d-4665-acc3-fb38a082c490-0' usage_metadata={'input_tokens': 13, 'output_tokens': 47, 'total_tokens': 60, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "my_runnable = MyRunnable()\n",
    "model = ChatOpenAI(model_name = \"gpt-4o-mini\")\n",
    "\n",
    "prompt = my_runnable.invoke(\"apple\", {\"lang\" : \"en\"})\n",
    "response = model.invoke(prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfdde1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='LangChain은 자연어 처리 모델을 사용하여 다양한 애플리케이션을 구축하고, 언어 모델과 외부 데이터 소스를 통합하는 데 도움을 주는 프레임워크입니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 21, 'total_tokens': 64, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BgkAbOO6vAh3QdQTWzgkEqWobMAGr', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--4593b76b-354e-45aa-9aaa-e05e4631786b-0' usage_metadata={'input_tokens': 21, 'output_tokens': 43, 'total_tokens': 64, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "prompt = my_runnable.invoke(\"langchain\")\n",
    "response = model.invoke(prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d03838f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='배는 상큼하고 달콤한 맛을 지닌 과일로, 주로 여름철에 수확되어 생식으로 즐기거나 다양한 요리에 사용됩니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 22, 'total_tokens': 60, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BgkAcHZZIDLhJ4cA0nbnftPNwHIb4', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--a32f9490-333c-4ad4-893f-bb5bc8f967c8-0' usage_metadata={'input_tokens': 22, 'output_tokens': 38, 'total_tokens': 60, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# chain -> Runnable | Runnable | Runnable\n",
    "chain = my_runnable | model\n",
    "\n",
    "# chain 호출\n",
    "res = chain.invoke(\"과일 배\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "660fec73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배는 상큼하고 달콤한 맛을 지닌 과일로, 주로 여름철에 수확되어 생식으로 즐기거나 다양한 요리에 사용됩니다.\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "35afd0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "# 기본 체인 구성 : prompt_template -> model -> output parser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser, StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# role: system, user/human, ai/assistant\n",
    "# system: 채팅 전체에 적용되는 공통 지침을 지정하는 role\n",
    "prompt_template = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        (\"system\", \"당신은 오랜 경력의 한국관광가이드입니다. 여행객들에게 설명하듯이 친절하게 답변을 해주세요.\"),\n",
    "        (\"human\", \"{query}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=1.0)\n",
    "guide_chain = prompt_template | model | StrOutputParser()\n",
    "print(type(guide_chain))        # RunnableSequence => chain도 다른 chain의 구성요소로 포함될 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "42f0ac2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"서울에서 꼭 먹어야되는 돈까스 맛집을 세곳만 알려줘.\"\n",
    "response = guide_chain.invoke({\"query\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d1b5c832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "서울에는 맛있는 돈까스 맛집이 정말 많아요! 여행객 여러분이 드셔보셔야 할 최고의 돈까스 맛집 세 곳을 추천해 드릴게요.\n",
      "\n",
      "1. **우래옥** - 서울 종로구에 위치한 '우래옥'은 전통적인 스타일의 돈까스를 제공하는 곳입니다. 여기 돈까스는 두툼한 pork loin을 사용해 바삭한 튀김옷과 함께 육즙이 풍부해 먹을 때마다 감동을 느낄 수 있어요. 특히 매콤한 초고추장과 함께 먹으면 한층 더 맛이 살아납니다.\n",
      "\n",
      "2. **미쓰양평해장국** - 강남구에 위치한 이곳은 돈까스와 해장국을 전문으로 하는 곳이에요. '미쓰양평해장국'의 돈까스는 신선한 재료로 만들어져 바삭하면서도 부드러운 식감을 자랑해요. 특히 해장국과 함께 먹는 조합이 일품이랍니다!\n",
      "\n",
      "3. **돈까스 제왕** - 중구 회현동에 있는 이곳은 퓨전 스타일의 돈까스를 제공하고 있어요. 특히 여기의 '까뜨리 돈까스'는 갈비맛이 나는 특별한 소스와 함께 제공되는데, 돈까스의 맛에 새로운 변화를 주는 색다른 경험을 선사합니다.\n",
      "\n",
      "각 맛집마다 개성이 있으니, 꼭 한 번 들러보세요! 맛있는 돈까스와 함께 서울의 맛을 즐기며 행복한 여행이 되시길 바랍니다.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0287f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "while 1:\n",
    "    query = input(\"질문\")\n",
    "    if query == \"!quit\":\n",
    "        resp = guide_chain.invoke({\"query\":query})\n",
    "        print(\"User:\", query)\n",
    "        print(\"AI:\", resp)\n",
    "        print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6c137e-35bb-4e4d-8561-859b0650b62f",
   "metadata": {},
   "source": [
    "#### RunnableLambda 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a5ac9fd-2616-4031-a079-a1822d784e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LLM을(를) 한 문장으로 설명해줘'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "my_runnable2 = RunnableLambda(\n",
    "lambda input_data : f\"{input_data}을(를) 한 문장으로 설명해줘\"\n",
    ")\n",
    "my_runnable2.invoke(\"LLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e367cc2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LLM(대형 언어 모델)은 대량의 텍스트 데이터를 기반으로 학습하여 인간처럼 자연어를 이해하고 생성할 수 있는 인공지능 모델입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 20, 'total_tokens': 58, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BgkBVh4krSRW804yNEZpV0war3n5r', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--b7a51c26-a37e-4a0b-9b43-f11df19c4f06-0', usage_metadata={'input_tokens': 20, 'output_tokens': 38, 'total_tokens': 58, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = my_runnable2 | model\n",
    "chain.invoke(\"LLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7314838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sum(nums):\n",
    "    return nums[0] + nums[1]\n",
    "\n",
    "my_runnable2=RunnableLambda(sum)\n",
    "my_runnable2.invoke({0:10, 1:20})\n",
    "\n",
    "# invoke(입력데이터:str|dict, 설정정보:dict)\n",
    "# 입력데이터가 여러개일 경우 dict등의 자료구조를 이용해서 받는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b884fd4c-feaa-46f1-af21-c5779900e502",
   "metadata": {},
   "source": [
    "#### RunnablePassThrough 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e43fcf5-e5c7-4502-830f-b722b832f3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'key': 'value'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 앞 Runnable이 처리한 결과를 다음 Runnable에 그대로 전달\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "RunnablePassthrough().invoke(\"안녕하세요\")\n",
    "RunnablePassthrough().invoke({\"key\":\"value\"})\n",
    "# 무슨 타입이던지 받은 값을 그대로 넘김"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67c2c7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '홍길동', 'address': '서울시 금천구', 'phone': '010-1111-2222'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 앞 Runnable이 처리한 결과에 Item을 추가해서 다음 Runnable에 그대로 전달\n",
    "# 입력으로 dictionary를 받아 거기에 item 추가\n",
    "# RunnablePassthrough.assign(key=Runnable, key1=Runnable ,......)\n",
    "# -> 받은 dictionary에 추가해서 다음으로 전달\n",
    "address_runnable = RunnableLambda(lambda x: \"서울시 금천구\")\n",
    "phone_runnable = RunnableLambda(lambda x: \"010-1111-2222\")\n",
    "\n",
    "RunnablePassthrough.assign(address=address_runnable, phone=phone_runnable).invoke({\"name\":\"홍길동\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3ba482-5dab-41df-96d1-c6649ecb8cee",
   "metadata": {},
   "source": [
    "#### RunnableSequence 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd2c247-a4e3-4b1b-a494-400b077eba54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableSequence\n",
    "run1 = RunnableLambda(lambda x: x+1)\n",
    "run2 = RunnableLambda(lambda x: x*2)\n",
    "\n",
    "chain = run1 | run2\n",
    "chain.invoke(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a364492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2 = RunnableSequence(run1,run2)        # (prompt_template, model, output_parser)\n",
    "chain2.invoke(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1531bb-ad33-4d1b-a59b-62cf08cb4457",
   "metadata": {},
   "source": [
    "#### RunnableParallel 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cce6992c-85e1-4a2f-b16f-e294c50a3c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result1': 21, 'result2': 40, 'result3': 6, 'result4': 20}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnableLambda, RunnablePassthrough\n",
    "\n",
    "run1 = RunnableLambda(lambda x: x+1)\n",
    "run2 = RunnableLambda(lambda x: x*2)\n",
    "run3 = RunnableLambda(lambda x: x//3)\n",
    "\n",
    "runnable = RunnableParallel(\n",
    "    {\n",
    "        \"result1\":run1,\n",
    "        \"result2\":run2,\n",
    "        \"result3\":run3,\n",
    "        \"result4\":RunnablePassthrough()                         # 전달받은 값 그대로 반환\n",
    "    }\n",
    ")\n",
    "# runnable들을 각각 실행하고 그 결과를 key에 할당한 Dictionary를 반환\n",
    "runnable.invoke(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86103e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result1': 121, 'result2': 240, 'result3': 40}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run0 = RunnableLambda(lambda x: x+100)\n",
    "chain = run0 | {\n",
    "    \"result1\":run1,\n",
    "    \"result2\":run2,\n",
    "    \"result3\":run3,\n",
    "}\n",
    "chain.invoke(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe6327f-591c-4d0b-87b2-796d41ad6b98",
   "metadata": {},
   "source": [
    "#### LCEL Chain 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e916435d-e288-4ca3-9e32-b3c17e95d5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 음식 이름을 받아서 레시피를 \"영어\"로 출력하는 chain을 구성\n",
    "# prompt template -> model -> output parser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from textwrap import dedent\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# lang = RunnableLambda(lambda x: \"영어\")\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=dedent(\"\"\"\n",
    "        # Instrucion\n",
    "        당신은 숙련된 미슐렝 셰프입니다. 요청한 음식의 레시피를 작성해 주세요.\n",
    "        # Input data\n",
    "        음식이름 : {food}\n",
    "        # Output indicator\n",
    "        - 레시피는 영어로 작성해 주세요.\n",
    "\"\"\")\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "food_chain = prompt_template | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "228a9812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Recipe for Classic Pasta\n",
      "\n",
      "### Ingredients:\n",
      "- 400g (14 oz) of dried pasta (spaghetti, fettuccine, or penne)\n",
      "- 2 tablespoons of olive oil\n",
      "- 3 cloves of garlic, minced\n",
      "- 1 can (400g) of diced tomatoes (or 4 medium ripe tomatoes, chopped)\n",
      "- 1 teaspoon of sugar (optional, to balance acidity)\n",
      "- Salt and pepper to taste\n",
      "- Fresh basil leaves, for garnish\n",
      "- Grated Parmesan cheese, for serving\n",
      "\n",
      "### Instructions:\n",
      "\n",
      "1. **Cook the Pasta:**\n",
      "   - In a large pot, bring salted water to a boil. \n",
      "   - Add the dried pasta and cook according to package instructions until al dente.\n",
      "   - Reserve 1 cup of pasta cooking water, then drain the pasta and set aside.\n",
      "\n",
      "2. **Prepare the Sauce:**\n",
      "   - In a large skillet over medium heat, add the olive oil.\n",
      "   - Once hot, add the minced garlic and sauté for about 1 minute until fragrant, being careful not to burn it.\n",
      "   - Add the diced tomatoes (and sugar, if using) to the skillet. Stir to combine and let it simmer for about 10 minutes, allowing the sauce to thicken slightly.\n",
      "   - Season with salt and pepper to taste.\n",
      "\n",
      "3. **Combine Pasta and Sauce:**\n",
      "   - Add the drained pasta to the skillet with the tomato sauce.\n",
      "   - Toss well to combine, adding reserved pasta water little by little until you reach your desired consistency.\n",
      "\n",
      "4. **Serve:**\n",
      "   - Remove from heat and serve immediately.\n",
      "   - Garnish with fresh basil leaves and a generous sprinkle of grated Parmesan cheese.\n",
      "\n",
      "### Tips:\n",
      "- Feel free to add additional ingredients such as sautéed vegetables, cooked meat, or seafood for a more hearty dish.\n",
      "- For a bit of heat, add red pepper flakes when cooking the garlic.\n",
      "\n",
      "Enjoy your delicious homemade pasta! Buon appetito!\n"
     ]
    }
   ],
   "source": [
    "response = food_chain.invoke({\"food\":\"pasta\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "229170b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "prompt_template = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        (\"system\", \"당신은 오랜 경력의 미슐랭 셰프입니다. 학생들이 원하는 음식의 레시피를 {lang}로 알려주세요.\"),\n",
    "        (\"human\", \"{food}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=1.0)\n",
    "food_chain = prompt_template | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "047be191-28eb-4674-af53-9ac2a0d0ab97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "כמובן! הנה מתכון פשוט להכנת פסטה בבית:\n",
      "\n",
      "### מצרכים:\n",
      "- 2 כוסות קמח (עדיף קמח דורום)\n",
      "- 3 ביצים\n",
      "- 1/2 כפית מלח\n",
      "- 1 כף שמן זית (אופציונלי)\n",
      "\n",
      "### הוראות:\n",
      "1. **הכנת הבצק:**\n",
      "   - שימו את הקמח על השולחן או בקערה גדולה, וצרו גומה במרכז.\n",
      "   - הוסיפו את הביצים, המלח ושמן הזית וערבבו בעזרת מזלג עד שהתערובת מתחילה להתאחד.\n",
      "   - בעזרת הידיים, לושו את הבצק עד שהוא חלק וגמיש (כ-10 דקות). אם הבצק דביק, הוסיפו עוד מעט קמח.\n",
      "\n",
      "2. **מנוחה:**\n",
      "   - עטפו את הבצק בניילון נצמד או בנייר מוקה והניחו לו לנוח במקרר למשך 30 דקות.\n",
      "\n",
      "3. **הכנת הפסטה:**\n",
      "   - לאחר מנוחה, חלקו את הבצק ל-4 חלקים.\n",
      "   - רדו כל חלק לעובי הרצוי (בעזרת מכונת פסטה או רול-עץ).\n",
      "   - חתכו לעוביים הרצויים (ספגטי, פטוצ'יני וכו').\n",
      "\n",
      "4. **בישול:**\n",
      "   - בשלו סיר עם מים מומלחים. כאשר המים רותחים, הוסיפו את הפסטה ובשלו כ-2-3 דקות (או עד שהיא צפה).\n",
      "   - סננו את הפסטה והגישו עם רוטב אהוב עליכם.\n",
      "\n",
      "בתיאבון!\n"
     ]
    }
   ],
   "source": [
    "response = food_chain.invoke({\"lang\":\"히브리어\", \"food\":\"pasta\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9b9a0687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역 chain -> 입력된 내용을 지정한(입력한) 언어로 번역하는 체인\n",
    "# prompt template -> model -> output parser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "prompt_template2 = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        (\"system\", \"당신은 다개국어 능력자입니다. {content}을(를) {language}로 알려주세요.\")\n",
    "    ]\n",
    ")\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "translate_chain = prompt_template2 | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4418b6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"배고파\"는 독일어로 \"Ich habe Hunger\"라고 합니다.'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# translate_chain.invoke({\"content\":\"안녕하세요\", \"language\":\"한국어\"})\n",
    "response = \"배고파\"\n",
    "res = translate_chain.invoke({\"content\":response, \"language\":\"독일어\"})\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cfbc5c-6c03-48fc-9e4d-ddf8f34893f5",
   "metadata": {},
   "source": [
    "## Chain과 Chain간의 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "98e306d3-430f-4bfa-982c-a806e1910f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# food_chain + translate_chain\n",
    "# food_chain_prompt : 변수 - food\n",
    "# translate_chain : 변수 - language, content\n",
    "\n",
    "# RunnableParallel({\"key\":Runnable, \"key2\":Runnable})\n",
    "# LCEL에서 RunnableParallel => {\"key\":Runnable, \"key2\":Runnable} |\n",
    "chain = {\n",
    "            \"content\":food_chain,\n",
    "            \"language\":RunnableLambda(lambda x: x['language'])\n",
    "        } | translate_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7d1ab4d0-0f9f-4227-a821-5d9751d49942",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = chain.invoke({\"food\":\"파스타\", \"language\":\"영어\"})\n",
    "# food -> food_chain, language -> translate_chain\n",
    "# food_chain 최종결과(레시피) => {\"content\":레시피} 전달 -> translate_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d84d2d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here is the pasta recipe in English:\n",
      "\n",
      "### Pasta Recipe\n",
      "\n",
      "#### Ingredients:\n",
      "- 400g pasta (spaghetti, fettuccine, or your choice)\n",
      "- 2 tablespoons olive oil\n",
      "- 3 cloves garlic, minced\n",
      "- 1 teaspoon red pepper flakes (optional)\n",
      "- 1 can (400g) crushed tomatoes\n",
      "- 1 teaspoon salt (adjust to taste)\n",
      "- ½ teaspoon black pepper\n",
      "- 1 tablespoon sugar (to balance acidity)\n",
      "- Fresh basil leaves, torn (about 10-15 leaves)\n",
      "- Grated Parmesan cheese, for serving\n",
      "- Optional: Cooked protein of choice (chicken, shrimp, or chickpeas for a vegetarian option)\n",
      "\n",
      "#### Instructions:\n",
      "\n",
      "1. **Cook the Pasta:**  \n",
      "   Bring a large pot of salted water to a boil. Add the pasta and cook according to package instructions until al dente. Reserve 1 cup of pasta water, then drain the pasta and set aside.\n",
      "\n",
      "2. **Prepare the Sauce:**  \n",
      "   In a large skillet, heat the olive oil over medium heat. Add the minced garlic and red pepper flakes (if using) and sauté for about 1 minute until fragrant, ensuring not to burn the garlic.\n",
      "\n",
      "3. **Add Tomatoes:**  \n",
      "   Pour in the crushed tomatoes, and stir well. Add salt, black pepper, and sugar to the sauce. Let it simmer for about 10-15 minutes, allowing the flavors to meld and the sauce to thicken slightly.\n",
      "\n",
      "4. **Combine Pasta and Sauce:**  \n",
      "   Add the cooked pasta to the sauce, tossing gently to coat the pasta evenly. If the sauce is too thick, slowly add reserved pasta water until you reach your desired consistency.\n",
      "\n",
      "5. **Add Fresh Basil:**  \n",
      "   Stir in the fresh basil leaves, mixing well. Taste and adjust the seasoning if necessary.\n",
      "\n",
      "6. **Serve:**  \n",
      "   Plate the pasta hot, and garnish with additional fresh basil and grated Parmesan cheese over the top. Serve immediately.\n",
      "\n",
      "#### Tips:\n",
      "- For an extra touch, you can add a splash of cream to the sauce for a richer flavor or mix in some sautéed vegetables like spinach, bell peppers, or zucchini.\n",
      "- Pair with a fresh mixed salad and a glass of your favorite wine for a complete meal.\n",
      "\n",
      "Enjoy your homemade pasta!\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7dabe113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Наенгмён (Хүйтэн гоймон) жор\\n\\n#### Орц:\\n\\n**Гоймон для:**\\n- 200 г наенгмён гоймон (буурцагны гоймон)\\n- Ус (буцалгахынため)\\n- Мөс (хүйтэн усанд хөргөхийнため)\\n\\n**Шөл для:**\\n- 4 аяга үхрийн шөл (эсвэл 4 аяга ус, 2-3 уут хүчил, соёос нэмж хийж болно)\\n- 1 хоолны халбага соёос\\n- 1 хоолны халбага хүчил (яншуй эсвэл бургар ханд)\\n- 1 цайны халбага элсэн чихэр\\n- Давс амтлах\\n\\n**Гарнирын для:**\\n- 1 газрын төлд, нарийн хэрчиж\\n- 1 Азийн намар, нимгэн хэрчиж (сонголтоор)\\n- Вандуй хатаасалсан (хагас)\\n- Тахлын бургас (сонголтоор, исгэлэн амтанд)\\n- Сусамын үр (чулуугаар)\\n- Солонгосын гичний соус (сонголтоор)\\n\\n#### Заавар:\\n\\n1. **Гоймоныг бэлдэх:**\\n   - Том тогоо ус буцалгана. Наенгмён гоймоныг хийж, багцын зааврын дагуу, ихэвчлэн 3-5 минутын турш болгож бэлдэнэ.\\n   - Бэлдсэн гоймоныг шүүж, хөргөсөн усны доор усанд хөшүүлбэл, боловсруулалтыг зогсоож, илүүдэл крахмалыг арилгана. Мөсөөр хийсэн усанд шилжүүлж хөргөж тавина.\\n\\n2. **Шөл бэлтгэх:**\\n   - Тогоонд үхрийн шөлийг (эсвэл бэлтгэсэн ус) зөөлнөөр буцалгахад бэлдэнэ.\\n   - Соёос, хүчил, элсэн чихэр, давсыг нэмнэ. Амтлахад тохиромжтой байдлаас шалтгаалан амтыг тохируулна. Шөл хүйтэн болох хүртэл хөргөгчид хадгална.\\n\\n3. **Гарнирыг бэлтгэх:**\\n   - Газрын төлдийг нарийн хэрчиж, Азийн намрыг нимгэн хэрчиж бэлтгэнэ. Хатуу өндөг (7-8 минут буцалгаж) хийж, мөсөө усаар хөргөж, хальслах.\\n\\n4. **Наенгмёныг бэлтгэх:**\\n   - Хөргөгдсөн гоймоныг шүүж, үйлчилгээний саванд хуваана.\\n   - Хүйтэн шөл гоймон дээр хийж, сайтар хамарна.\\n   - Гоймон дээр газрын төлд, Азийн намрын хэрчим болон хагас хатуу өндөг харж тавина.\\n   - Сусамын үр дээр цацаж, тахлын бургасыг хүсвэл нэмнэ. Солонгосын гичний соусыг харгалзах жижиг саванд хийнэ.\\n\\n5. **Үйлчлэх:**\\n   - Шууд үйлчлэх бөгөөд таныг шинэ бүлек наенгмёнэс дээжлэх! Нэмж шөл эсвэл гарнирийг оруулах боломжтой.\\n\\n### Зөвлөмжүүд:\\n- Бүх бүрэлдэхүүн хэсэг хүйтэн байх хүртэл үйлчлэхэд хамгийн сайн мэдрэмжийг өгнө.\\n- Наенгмён нь олон талын, янз бүрийн орц найрлагаар тохируулах боломжтой.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"food\":\"냉면\", \"language\":\"몽골어\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b59505-5ef9-4bc5-9a32-9e359d3bf0a1",
   "metadata": {},
   "source": [
    "# 사용자 함수를 Chain에 적용하기\n",
    "\n",
    "## 사용자 함수를 Runnable로 정의 (RunnableLambda)\n",
    "- 임의의 함수를 Runnable로 정의 할 수있다.\n",
    "  - chain에 포함할 기능을 함수로 정의할 때 주로 사용. \n",
    "- `RunnableLambda(함수)` 사용\n",
    "  - 함수는 invoke() 메소드를 통해 입력받은 값을 받을 **한개의 파라미터**를 선언해야 한다.\n",
    "\n",
    "## 사용자 함수를 Chain으로 정의\n",
    "- Chain 을 구성하는 작업 사이에 추가 작업이 필요할 경우, 중간 결과를 모두 사용해야 하는 경우 함수로 구현한다.\n",
    "- `@chain` 데코레이터를 사용해 함수에 선언한다.\n",
    "\n",
    "### Runnable 에 사용할 **사용자 정의 함수** 구문\n",
    "- 이전 Chain의 출력을 입력 받는 **파라미터를 한개** 선언한다. (첫번째 파라미터)\n",
    "- `invoke()`로 호출 할때 전달 하는 추가 설정을 입력받는 파라미터를 선언한다.(두번째 파라미터 - Optional)\n",
    "  - RunnableConfig 타입의 값을 받는데 Dictionary 형식으로 `{\"configuable\": {\"설정이름\":\"설정값\"}}` 형식으로 받는다.\n",
    "- 만약 함수가 여러개의 인자를 받는 경우 단일 입력을 받아들이고 이를 여러 인수로 풀어내는 래퍼 함수를 작성하여 Runnable로 만든다.\n",
    "  ```python\n",
    "  def plus(num1, num2):\n",
    "      ...\n",
    "\n",
    "  def wrapper_plus(nums:dict|list):\n",
    "      return plus(nums['num1'], nums['num2'])\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c0de6e8-4bcf-412c-8983-9be3d7679ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "# 기존에 정의된 함수를 Runnable로 정의\n",
    "def plus(num1, num2, num3):\n",
    "    return num1+num2+num3\n",
    "\n",
    "# run1.invoke(1,2,3)   -> invoke는 3개 못받음\n",
    "\n",
    "def wrapper_plus(nums:list):\n",
    "    return plus(nums[0], nums[1], nums[2])\n",
    "\n",
    "run1 = RunnableLambda(wrapper_plus)\n",
    "run1.invoke([1,2,3])\n",
    "# invoke(input_data:첫번째, config:RunnableConfig-설정정보=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69710192-a281-43a2-b944-ccd3705d3b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 소재를 이용해서 이야기를 생성하는 chain\n",
    "# 장문을 입력 받아서 요약하는 chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "from textwrap import dedent\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "370c44ce-3e5b-4992-9ddf-cb2835c361be",
   "metadata": {},
   "outputs": [],
   "source": [
    "story_model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=1.0)\n",
    "story_prompt_template = PromptTemplate(\n",
    "    template=dedent(\"\"\"\n",
    "            # Instruction\n",
    "            당신은 아이들을 위한 이야기를 창작하는 스토리텔러입니다.\n",
    "            주어진 소재로 잠자리에서 아이들에게 들려줄 재미있는 이야기를 만들어 주세요.\n",
    "                    \n",
    "            # Input Data\n",
    "            소재 : {topic}\n",
    "            \n",
    "            # Output Indicator\n",
    "            - 이야기는 30문장 이내로 구성해 주세요.\n",
    "            - 이야기를 구어체로 작성해 주세요.\n",
    "\"\"\")\n",
    ")\n",
    "story_chain = story_prompt_template | story_model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f715475",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssummary_model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.1)\n",
    "# 요약 체인 구성\n",
    "summary_prompt = PromptTemplate(\n",
    "    template=dedent(\"\"\"\n",
    "            # Instruction\n",
    "            주어진 문장 내용을 2문장으로 요약해주세요.\n",
    "            \n",
    "            # Input Data\n",
    "            {content}\n",
    "\"\"\")\n",
    ")\n",
    "summary_chain = summary_prompt | ssummary_model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9069aa1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'국밥 할아버지는 마을에서 가장 맛있는 국밥을 끓이며 아이들에게 특별한 비법을 전수했습니다. 아이들은 할아버지와 함께 국밥을 배우며 꿈을 키우고, 마을의 자랑이 되는 국밥을 만들게 되었습니다.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = story_chain | summary_chain\n",
    "chain.invoke({\"topic\":\"국밥\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "623200c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain\n",
    "# 사용자 정의 체인 -> 흐름을 원하는 구조로 정의할 수 있다.\n",
    "@chain                  # decorator를 통해 runnable에 넣지 않고도 type을 runnable로 설정 가능\n",
    "def custom_chain(topic:str)->dict[str,str]:\n",
    "    # story_chain과 summary_chain을 원하는 흐름으로 구현\n",
    "    # story_chain의 결과와 summary_chain의 결과를 모두 반환하도록 처리\n",
    "    story = story_chain.invoke({\"topic\":topic})\n",
    "    summary = summary_chain.invoke({\"content\":story})\n",
    "\n",
    "    return {\"전체이야기\":story, \"이야기요약\":summary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc6531e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.runnables.base.RunnableLambda"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(custom_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb93c583",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = custom_chain.invoke(\"물\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bd9baf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['전체이야기', '이야기요약'])\n"
     ]
    }
   ],
   "source": [
    "print(type(res))\n",
    "print(res.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1d5b67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "옛날 옛적, 어느 작은 마을에 '물방울'이라는 이름의 소년이 살고 있었어요. 물방울은 아주 특별한 능력이 있었답니다. 그는 물을 다룰 수 있는 힘을 가지고 있었죠! 마을 사람들이 마실 물이 부족하다고 걱정할 때, 물방울이 나타나곤 했어요. \n",
      "\n",
      "“걱정하지 마세요!” 물방울은 말했다. “제가 시냇물을 불러올게요!” 그리고 손을 흔들자 시냇물은 그의 곁으로 쏠려왔죠. 사람들이 너무 놀라서 \"대단해!\"라고 외쳤어요. \n",
      "\n",
      "어느 날, 마을에 큰 문제가 생겼어요. 마을 근처의 강물이 마르기 시작한 거예요. 사람들은 비를 기다렸지만, 비는 오지 않았어요. 그러자 물방울은 결심했어요. “내가 강물을 다시 살려야 해!” \n",
      "\n",
      "물방울은 마을 꼭대기에 있는 높은 언덕으로 올라갔어요. 거기서 그는 큰 물의 신에게 기도를 했죠. “물의 신님, 도와주세요!” 그러자 물의 신이 나타났어요. \n",
      "\n",
      "“물방울아, 넌 용감하고 순수한 마음을 가졌구나. 너의 소원을 들어줄게.” 물의 신이 말했어요. 갑자기 하늘이 흐려지기 시작하더니, 빗방울들이 쏟아지기 시작했어요. 사람들은 모두 밖으로 나와서 비를 맞으며 놀랐어요! \n",
      "\n",
      "“우와! 물이 온다!” 사람들이 소리쳤고, 물방울은 신이 주신 비로 강물을 다시 채웠어요. 강물이 흘러넘치자 마을 사람들은 기뻐하며 서로 포옹했어요. \n",
      "\n",
      "그날 이후로 물방울은 마을의 영웅이 되었어요. 사람들은 그를 위해 매년 ‘물의 날’을 만들어 축제를 열었답니다. 사람들은 춤추고 노래하며 물의 소중함을 기념했어요. 물방울은 더이상 외롭지 않았고, 모두와 함께 행복하게 살았어요. \n",
      "\n",
      "“기억해요, 물은 우리 삶의 원천이에요,” 물방울은 항상 말했답니다. 이제 마을의 사람들도 물을 아끼고 소중히 여겼어요. 그렇게 물방울과 마을은 언제까지나 함께 행복하게 살았답니다. \n",
      "\n",
      "자, 이제 잘 자요! 물이 만들어낸 소중한 이야기를 꿈꾸며, 우리도 그 소중함을 기억해봐요!\n"
     ]
    }
   ],
   "source": [
    "print(res[\"전체이야기\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d90a855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물방울이라는 소년은 물을 다룰 수 있는 특별한 능력을 가지고 있어 마을의 물 부족 문제를 해결하며 영웅이 되었습니다. 그는 물의 신의 도움으로 비를 내리게 하여 강물을 다시 채우고, 마을 사람들은 매년 '물의 날'을 기념하며 물의 소중함을 잊지 않게 되었습니다.\n"
     ]
    }
   ],
   "source": [
    "print(res[\"이야기요약\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8b48ae-b4b2-412f-a7b5-17e9c1ebc1a4",
   "metadata": {},
   "source": [
    "# Cache\n",
    "\n",
    "- 응답 결과를 저장해서 같은 질문이 들어오면 LLM에 요청하지 않고 저장된 결과를 보여주도록 한다.\n",
    "    - 처리속도와 비용을 절감할 수 있다.\n",
    "    - 특히 chatbot같이 비슷한 질문을 하는 경우 유용하다.\n",
    "- 저장 방식은 `메모리`, `sqlite` 등 다양한 방식을 지원한다.\n",
    "  \n",
    "    ```python\n",
    "    set_llm_cache(Cache객체)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8c002f-7f0c-4357-b3ae-efe8569f04cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache, SQLiteCache\n",
    "# SQLite -> Python 내장 DB\n",
    "# set_llm_cache(InMemoryCache())                                   # memory에 대화 저장할 수 있는 cache 생성\n",
    "set_llm_cache(SQLiteCache(\"llm_cache.sqlite\"))                     # 파일로 저장\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "response = model.invoke(\"주요 프로그래밍 언어 5개를 소개해주세요.\")         # 질문이 바뀌지 않는다면 저장된 값을 바로 불러오므로 0초 소요 / 질문이 살짝이라도 바뀐다면 다시 10초가량 소요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b74a46a8-703c-452b-9d57-e80749c3f528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음은 주요 프로그래밍 언어 5가지를 소개합니다:\n",
      "\n",
      "1. **Python**:\n",
      "   - **특징**: 간결하고 읽기 쉬운 문법을 가진 고급 프로그래밍 언어로, 초보자에게 적합합니다. 데이터 분석, 웹 개발, 인공지능, 자동화 등 다양한 분야에 사용됩니다.\n",
      "   - **주요 라이브러리**: NumPy, pandas, TensorFlow, Flask, Django 등.\n",
      "\n",
      "2. **Java**:\n",
      "   - **특징**: 객체지향 프로그래밍 언어로, 플랫폼 독립성을 갖고 있어 \"Write Once, Run Anywhere\"라는 슬로건을 가지고 있습니다. 엔터프라이즈 애플리케이션, 모바일 앱(특히 안드로이드), 웹 서버 개발에 많이 쓰입니다.\n",
      "   - **주요 프레임워크**: Spring, Hibernate 등.\n",
      "\n",
      "3. **JavaScript**:\n",
      "   - **특징**: 주로 웹 개발에서 사용되는 스크립트 언어로, 클라이언트 사이드와 서버 사이드 양쪽 모두에서 활용됩니다. 사용자 인터페이스 및 동적인 웹 페이지를 만드는 데 필수적입니다.\n",
      "   - **주요 라이브러리 및 프레임워크**: React, Angular, Vue.js 등.\n",
      "\n",
      "4. **C++**:\n",
      "   - **특징**: C 언어를 기반으로 한 고급 언어로, 객체지향 프로그래밍, 메모리 제어, 시스템 프로그래밍에 강점이 있습니다. 게임 개발, 시스템 소프트웨어, 고성능 애플리케이션 등에서 널리 사용됩니다.\n",
      "   - **주요 라이브러리**: STL(Standard Template Library), Boost 등.\n",
      "\n",
      "5. **C#**:\n",
      "   - **특징**: Microsoft에서 개발한 언어로, 주로 .NET 프레임워크와 함께 사용됩니다. 윈도우 애플리케이션, 게임 개발(Unity 엔진을 사용한) 등에 적합합니다. 객체지향 프로그래밍과 강력한 타입 검사를 제공합니다.\n",
      "   - **주요 프레임워크**: ASP.NET, Xamarin 등.\n",
      "\n",
      "이 언어들은 각각의 특성과 용도에 따라 다양한 산업과 프로젝트에서 널리 사용되고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "520effd5-677c-46e3-9068-553e973bfea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# streaming 방식(한 단어씩 보여지는, 응답이 생성되는 것이 보여지는) 응답처리\n",
    "# - LLM 응답을 기다리지 않고 실시간으로 생성되는 토큰/청크를 받아서 처리한다.\n",
    "# - model.invoke(input, config)->(return type:)응답데이터 : 응답 완료될때까지 기다렸다가 보여줌 / model.stram(input, config)->Iterator : 토큰을 생성하면 바로 받아 보여줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd03919a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "res = model.stream(\"AI에 대해서 설명해줘.\")\n",
    "print(type(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aeff5bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI(인공지능)는 사람의 지능을 모방하거나 대체할 수 있는 컴퓨터 시스템 또는 프로그램을 지칭합니다. AI는 데이터를 분석하고, 학습하며, 문제를 해결하는 등의 기능을 수행할 수 있습니다. AI의 주요 분야는 다음과 같습니다:\n",
      "\n",
      "1. **기계 학습 (Machine Learning)**: AI의 하위 분야로, 데이터로부터 학습하여 예측하거나 결정을 내리는 알고리즘을 개발합니다. 예를 들어, 스팸 이메일 필터링이나 추천 시스템 등이 기계 학습을 활용합니다.\n",
      "\n",
      "2. **자연어 처리 (Natural Language Processing, NLP)**: 컴퓨터가 인간의 언어를 이해하고 해석할 수 있도록 하는 기술입니다. 챗봇, 번역기, 음성 인식 시스템 등이 이에 해당합니다.\n",
      "\n",
      "3. **컴퓨터 비전 (Computer Vision)**: 이미지나 비디오에서 정보를 추출하고 해석하는 기술입니다. 자율주행차, 얼굴 인식 시스템 등이 컴퓨터 비전의 예입니다.\n",
      "\n",
      "4. **전문 시스템 (Expert Systems)**: 특정 분야에서 전문가의 지식을 적용하여 문제를 해결할 수 있도록 설계된 시스템입니다. 의료 진단 시스템이나 금융 분석 도구 등이 포함될 수 있습니다.\n",
      "\n",
      "AI는 다양한 산업 분야에서 활용되고 있으며, 의료, 금융, 제조업, 서비스업 등에서 효율성을 높이고 혁신을 촉진하는 데 기여하고 있습니다. 그러나 AI의 발전에는 윤리적 문제나 일자리 대체와 같은 다양한 도전 과제가 동반되기도 합니다."
     ]
    }
   ],
   "source": [
    "for token in model.stream(\"AI에 대해 설명해줘.\"):\n",
    "    print(token.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13068eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d7be26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
