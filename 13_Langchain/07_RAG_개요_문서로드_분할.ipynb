{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "227316ea",
   "metadata": {},
   "source": [
    "# RAG(Retrieval Augmented Generation)\n",
    "- [RAG](https://python.langchain.com/v0.1/docs/modules/data_connection/)은 *Retrieval Augmented Generation*의 약자로, **검색 기반 생성 기법**을 의미한다. 이 기법은 LLM이 특정 문서에 기반하여 보다 정확하고 신뢰할 수 있는 답변을 생성할 수 있도록 돕는다.     \n",
    "- 사용자의 질문에 대해 자체적으로 구축한 데이터베이스(DB)나 외부 데이터베이스에서 질문과 관련된 문서를 검색하고, 이를 질문과 함께 LLM에 전달한다.\n",
    "- LLM은 같이 전달된 문서를 바탕으로 질문에 대한 답변을 생성한다. \n",
    "- 이를 통해 LLM이 학습하지 않은 내용도 다룰 수 있으며, 잘못된 정보를 생성하는 환각 현상(*hallucination*)을 줄일 수 있다.\n",
    "\n",
    "## RAG와 파인튜닝(Fine Tuning) 비교\n",
    "\n",
    "### 파인튜닝(Fine Tuning)\n",
    "\n",
    "- **정의**: 사전 학습(pre-trained)된 LLM에 특정 도메인의 데이터를 추가로 학습시켜 해당 도메인에 특화된 맞춤형 모델로 만드는 방식이다.\n",
    "- **장점**\n",
    "  - 특정 도메인에 최적화되어 높은 정확도와 성능을 낼 수 있다.\n",
    "- **단점**\n",
    "  - 모델 재학습에 많은 시간과 자원이 필요하다.\n",
    "  - 새로운 정보가 반영되지 않으며, 이를 위해서는 다시 학습해야 한다.\n",
    "\n",
    "### RAG\n",
    "\n",
    "- **정의**: 모델을 다시 학습시키지 않고, 외부 지식 기반에서 정보를 검색하여 실시간으로 답변에 활용하는 방식이다.\n",
    "- **장점**\n",
    "  - 최신 정보를 쉽게 반영할 수 있다.\n",
    "  - 모델을 수정하지 않아도 되므로 효율적이다.\n",
    "- **단점**\n",
    "  - 검색된 문서의 품질에 따라 답변의 정확성이 달라질 수 있다.\n",
    "  - 검색 시스템 구축이 필요하다.\n",
    "\n",
    "## 정리\n",
    "\n",
    "| 항목       | 파인튜닝 | RAG |\n",
    "| -------- | ---- | --- |\n",
    "| 도메인 최적화  | 가능   | 제한적 |\n",
    "| 최신 정보 반영 | 불가능  | 가능  |\n",
    "| 구현 난이도   | 높음   | 보통  |\n",
    "| 유연성      | 낮음   | 높음  |\n",
    "\n",
    "- LLM은 학습 당시의 데이터만을 기반으로 작동하므로 최신 정보나 기업 내부 자료와 같은 특정한 지식 기반에 접근할 수 없다.\n",
    "- 파인튜닝은 시간과 비용이 많이 들고 유지보수가 어렵다.\n",
    "-\t반면, RAG는 기존 LLM을 변경하지 않고도 외부 문서를 통해 그 한계를 보완할 수 있다.\n",
    "- RAG는 특히 빠르게 변화하는 정보를 다루는 분야(예: 기술 지원, 뉴스, 법률 등)에서 유용하게 활용된다. 반면, 정적인 정보에 대해 높은 정확도가 필요한 경우에는 파인튜닝이 효과적이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9017ca94-32e0-4460-8937-90a8d92ca07b",
   "metadata": {},
   "source": [
    "## RAG 작동 단계\n",
    "- 크게 \"**정보 저장(인덱싱)**\", \"**검색**, **생성**\"의 단계로 나눌 수 있다.\n",
    "  \n",
    "### 1. 정보 저장(인덱싱)\n",
    "RAG는 사전에 정보를 가공하여 **벡터 데이터베이스**(Vector 저장소)에 저장해 두고, 나중에 검색할 수 있도록 준비한다. 이 단계는 다음과 같은 과정으로 이루어진다.\n",
    "\n",
    "1. **Load (불러오기)**\n",
    "   - 답변시 참조할 사전 정보를 가진 데이터들을 불러온다.\n",
    "2. **Split/Chunking (문서 분할)**\n",
    "   - 긴 텍스트를 일정한 길이의 작은 덩어리(*chunk*)로 나눈다.\n",
    "   - 이렇게 해야 검색과 생성의 정확도를 높일 수 있다.\n",
    "3. **Embedding (임베딩)**\n",
    "   - 각 텍스트 조각을 **임베딩 벡터**로 변환한다.\n",
    "   - 임베딩 벡터는 그 문서의 의미를 벡터화 한 것으로 질문과 유사한 문서를 찾을 때 인덱스로 사용된다.\n",
    "4. **Store (저장)**\n",
    "   - 임베딩된 벡터를 **벡터 데이터베이스**(벡터 저장소)에 저장한다.\n",
    "   - 벡터 데이터베이스는 유사한 질문이나 문장을 빠르게 찾을 수 있도록 특화된 데이터 저장소이다.\n",
    "   \n",
    "![rag](figures/rag1.png)\n",
    "\n",
    "### 2. 검색, 생성\n",
    "\n",
    "사용자가 질문을 하면 다음과 같은 절차로 답변이 생성된다.\n",
    "1. **Retrieve (검색)**\n",
    "   - 사용자의 질문을 임베딩한 후, 이 질문 벡터와 유사한 context 벡터를 벡터 데이터베이스에서 검색하여 찾는다.\n",
    "2. **Query (질의 생성)**\n",
    "   - 벡터 데이터베이스에서 검색된 문서 조각과 사용자의 질문을 함께 **프롬프트**(prompt)로 구성하여 LLM에 전달한다.\n",
    "3. **Generation (응답 생성)**\n",
    "   - LLM은 받은 프롬프트에 대한 응답을 생성한다.\n",
    "   \n",
    "- **RAG 흐름**\n",
    "  \n",
    "![Retrieve and Generation](figures/rag2.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7e3d03-2250-4c79-aa83-7faf709ba4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21f6fd91-e3de-4f9d-9c8a-9c21de7a768c",
   "metadata": {},
   "source": [
    "# Document Loader\n",
    "- LLM에게 질의할 때 같이 제공할 Data들을 저장하기 위해 먼저 읽어들인다.(Load)\n",
    "- 데이터 Resouce는 다양하다.\n",
    "    - 데이터를 로드(load)하는 방식은 저장된 위치와 형식에 따라 다양하다. \n",
    "      - 로컬 컴퓨터(Local Computer)에 저장된 문서\n",
    "        - 예: CSV, Excel, JSON, TXT 파일 등\n",
    "      - 데이터베이스(Database)에 저장된 데이터셋\n",
    "      - 인터넷에 존재하는 데이터\n",
    "        - 예: 웹에 공개된 API, 웹 페이지에 있는 데이터, 클라우드 스토리지에 저장된 파일 등\n",
    "\n",
    "![rag_load](figures/rag_load.png)\n",
    "\n",
    "- 다양한 문서 형식(format)에 맞춰 읽어오는 다양한 **document loader** 들을 Langchain에서 지원한다.\n",
    "    - 다양한 Resource들로 부터 데이터를 읽기 위해서는 다양한 라이브러리를 이용해 서로 다른 방법으로 읽어야 한다.\n",
    "    - Langchain은 데이터를 읽는 다양한 방식의 코드를 하나의 interface로 사용 할 수 있도록 지원한다.\n",
    "        - https://python.langchain.com/docs/how_to/#document-loaders\n",
    "    - 다양한 3rd party library(ppt, github 등등 다양한 3rd party lib도 있음. )들과 연동해 다양한 Resource로 부터 데이터를 Loading 할 수 있다.\n",
    "        - https://python.langchain.com/docs/integrations/document_loaders/\n",
    "- **모든 document loader는 기본적으로 동일한 interface(사용법)로 호출할 수있다.**\n",
    "- **반환타입**\n",
    "    - **list[Document]**\n",
    "    - Load 한 문서는 Document객체에 정보들을 넣는다. 여러 문서를 읽을 수 있기 대문에 list에 묶어서 반환한다.\n",
    "        - **Document 속성**\n",
    "            - page_content: 문서의 내용\n",
    "            - metadata(option): 문서에 대한 메타데이터(정보)를 dict 형태로 저장한다. \n",
    "            - id(option): 문서의 고유 id\n",
    "     \n",
    "- **주의**\n",
    "    - Langchain을 이용해 RAG를 구현할 때 **꼭 Langchain의 DocumentLoader를 사용해야 하는 것은 아니다.**\n",
    "    - DocumentLoader는 데이터를 읽어오는 것을 도와주는 라이브러리일 뿐이다. 다른 라이브러리를 이용해서 읽어 들여도 상관없다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f25589-24a2-4f1f-9e8c-41e0594b6ce1",
   "metadata": {},
   "source": [
    "## 주요 Document Loader\n",
    "\n",
    "### Text file\n",
    "- TextLoader 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40998e95-a607-45d5-a3f6-2bb598b1aa19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 1\n",
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "path = \"data/olympic.txt\"\n",
    "\n",
    "# with open(path, 'rt') as f:\n",
    "#     doc = f.read()\n",
    "\n",
    "# 1. 객체 생성 -> 읽어올 자원의 정보(경로)를 제공.\n",
    "loader = TextLoader(path, encoding=\"utf-8\")\n",
    "\n",
    "# 2. 읽어 오기(Loading)\n",
    "docs = loader.load()  # lazy_load() -> 문서를 사용하는 시점에 읽어온다.\n",
    "\n",
    "print(type(docs), len(docs))\n",
    "print(type(docs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ec8523a-e87c-4214-aee9-c1aa8d1745c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 정보-metadata: {'source': 'data/olympic.txt'}\n",
      "문서식별자(ID): None\n",
      "문서내용:\n",
      "올림픽\n",
      "올림픽(영어: Olympic Games, 프랑스어: Jeux olympiques)은 전 세계 각 대륙 각국에서 모인 수천 명의 선수가 참가해 여름과 겨울에 스포츠 경기를 하\n"
     ]
    }
   ],
   "source": [
    "# Document 객체 속성\n",
    "doc = docs[0]\n",
    "print(\"문서의 정보-metadata:\", doc.metadata)\n",
    "print(\"문서식별자(ID):\", doc.id)\n",
    "print(\"문서내용:\")\n",
    "print(doc.page_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "591ae197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "with open(path, 'rt') as f:\n",
    "    load_doc = f.read()\n",
    "\n",
    "d = Document(page_content=load_doc, metadata={\"category\":\"올림픽\", \"path\":path})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bbbd08-6afc-4f2f-985b-c96da7c3b943",
   "metadata": {},
   "source": [
    "### PDF\n",
    "- PyPDF, Pymupdf 등 다양한 PDF 문서를 읽어들이는 파이썬의  3rd party library들을 이용해 pdf 문서를 Load 한다.\n",
    "    - https://python.langchain.com/docs/integrations/document_loaders/#pdfs\n",
    "- 각 PDF Loader 특징\n",
    "    -  PyMuPDFLoader\n",
    "        -   텍스트 뿐 아니라 이미지, 주석등의 정보를 추출하는데 성능이 좋다.\n",
    "        -   PyMuPDF 라이브러리 기반\n",
    "    - PyPDFLoader\n",
    "        - 텍스트를 빠르게 추출 할 수있다.\n",
    "        - PyPDF2 라이브러리 기반. 경량 라이브러리로 빠르고 큰 파일도 효율적으로 처리한다.\n",
    "    - PDFPlumberLoader\n",
    "        - 표와 같은 복잡한 구조의 데이터 처리하는데 강력한 성능을 보여준다. 텍스트, 이미지, 표 등을 모두 추출할 수 있다. \n",
    "        - PDFPlumber 라이브러리 기반\n",
    "- 설치 패키지\n",
    "    - DocumentLoader와 연동하는 라이브러리들을 설치 해야 한다.\n",
    "    - `pip install pypdf -qU`\n",
    "    - `pip install pymupdf -qU`\n",
    "    - `pip install pdfplumber -qU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6378f01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# 1. 객체 생성 -> raw 데이터 연결\n",
    "path = \"data/novel/금_따는_콩밭_김유정.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(path)\n",
    "\n",
    "docs = loader.load()  # List[Document]\n",
    "len(docs)  # 페이지당 하나의 문서(Document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9647515-7c2d-447d-a4e4-d70a18e4e025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 \n",
      "위키백과\n",
      "위키백과에  이  글\n",
      "과  관련된 \n",
      "자료가  있습니다 .\n",
      "금  따는  콩밭\n",
      "🙝 🙟 \n",
      "땅속  저  밑은  늘  음침하\n",
      "다 .\n",
      "고달픈  간드렛불 , 맥없이\n",
      "푸르끼하다 .\n",
      "밤과  달라서  낮엔  되우  흐릿하였다 .\n",
      "겉으로  황토  장벽으로  앞뒤좌우가  콕  막힌  좁직한  구뎅이 .\n",
      "흡사히  무덤  속같이  귀중중하다 . 싸늘한  침묵 , 쿠더브레한\n",
      "흙내와  징그러운  냉기만이  그  속에  자욱하다 .\n",
      "곡괭이는  뻔질  흙을  이르집는다 . 암팡스러이  내려쪼며 ,\n",
      "퍽  퍽  퍼억 .\n",
      "이렇게  메떨어진  소리뿐 . 그러나  간간  우수수  하고  벽이  헐\n",
      "린다 .\n",
      "영식이는  일손을  놓고  소맷자락을  끌어당기어  얼굴의  땀을\n",
      "훑는다 . 이놈의  줄이  언제나  잡힐는지  기가  찼다 . 흙  한줌을\n",
      "집어  코밑에  바짝  들여대고  손가락으로  샅샅이  뒤져본다 . 완\n",
      "연히  버력은  좀  변한  듯싶다 . 그러나  불통버력이  아주  다  풀\n",
      "린  것도  아니었다 . 밀똥버력이라야  금이  온다는데  왜  이리\n",
      "안  나오는지 .\n",
      "곡괭이를  다시  집어든다 . 땅에  무릎을  꿇고  궁뎅이를  번쩍\n",
      "든  채  식식거린다 . 곡괭이는  무작정  내려찍는다 . 바닥에서\n"
     ]
    }
   ],
   "source": [
    "print(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdbd7f13-c4d5-4db7-b5d7-27de7984624f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'Wikisource',\n",
       " 'creator': 'Wikisource',\n",
       " 'creationdate': '2024-11-24T07:05:35+00:00',\n",
       " 'author': 'Unknown',\n",
       " 'moddate': '2024-11-24T07:05:37+00:00',\n",
       " 'title': '금 따는 콩밭',\n",
       " 'source': 'data/novel/금_따는_콩밭_김유정.pdf',\n",
       " 'total_pages': 23,\n",
       " 'page': 1,\n",
       " 'page_label': '2'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bed2776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24aef24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdf\n",
      "  Using cached pymupdf-1.26.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (3.4 kB)\n",
      "Downloading pymupdf-1.26.1-cp39-abi3-macosx_11_0_arm64.whl (22.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.4/22.4 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pymupdf\n",
      "Successfully installed pymupdf-1.26.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3db535f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "loader = PyMuPDFLoader(path)\n",
    "\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "904bf667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "위키백과\n",
      "위키백과에 이 글\n",
      "과 관련된\n",
      "자료가 있습니다.\n",
      "금 따는 콩밭\n",
      "🙝🙟\n",
      "땅속 저 밑은 늘 음침하\n",
      "다.\n",
      "고달픈 간드렛불, 맥없이\n",
      "푸르끼하다.\n",
      "밤과 달라서 낮엔 되우 흐릿하였다.\n",
      "겉으로 황토 장벽으로 앞뒤좌우가 콕 막힌 좁직한 구뎅이.\n",
      "흡사히 무덤 속같이 귀중중하다. 싸늘한 침묵, 쿠더브레한\n",
      "흙내와 징그러운 냉기만이 그 속에 자욱하다.\n",
      "곡괭이는 뻔질 흙을 이르집는다. 암팡스러이 내려쪼며,\n",
      "퍽 퍽 퍼억.\n",
      "이렇게 메떨어진 소리뿐. 그러나 간간 우수수 하고 벽이 헐\n",
      "린다.\n",
      "영식이는 일손을 놓고 소맷자락을 끌어당기어 얼굴의 땀을\n",
      "훑는다. 이놈의 줄이 언제나 잡힐는지 기가 찼다. 흙 한줌을\n",
      "집어 코밑에 바짝 들여대고 손가락으로 샅샅이 뒤져본다. 완\n",
      "연히 버력은 좀 변한 듯싶다. 그러나 불통버력이 아주 다 풀\n",
      "린 것도 아니었다. 밀똥버력이라야 금이 온다는데 왜 이리\n",
      "안 나오는지.\n",
      "곡괭이를 다시 집어든다. 땅에 무릎을 꿇고 궁뎅이를 번쩍\n",
      "든 채 식식거린다. 곡괭이는 무작정 내려찍는다. 바닥에서\n"
     ]
    }
   ],
   "source": [
    "print(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a9baec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'Wikisource',\n",
       " 'creator': 'Wikisource',\n",
       " 'creationdate': '2024-11-24T07:05:35+00:00',\n",
       " 'source': 'data/novel/금_따는_콩밭_김유정.pdf',\n",
       " 'file_path': 'data/novel/금_따는_콩밭_김유정.pdf',\n",
       " 'total_pages': 23,\n",
       " 'format': 'PDF 1.4',\n",
       " 'title': '금 따는 콩밭',\n",
       " 'author': 'Unknown',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2024-11-24T07:05:37+00:00',\n",
       " 'trapped': '',\n",
       " 'modDate': \"D:20241124070537+00'00'\",\n",
       " 'creationDate': \"D:20241124070535+00'00'\",\n",
       " 'page': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196a703e-dd86-4cb5-82bf-8b6726aea0e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b507b334-e33b-435f-8a50-7dd31fa6da6b",
   "metadata": {},
   "source": [
    "### Web\n",
    "\n",
    "- WebBaseLoader 이용\n",
    "  - 입력받은 URL의 웹 문서를 읽어 문서로 로드한다. 웹 크롤링작업 없이 웹상의 문서를 가져올 수있다.\n",
    "  - 내부적으로 BeautifulSoup을 이용해 웹문서를 parsing한다.\n",
    "- https://python.langchain.com/docs/how_to/document_loader_web/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94e5a711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Using cached bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting beautifulsoup4 (from bs4)\n",
      "  Using cached beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->bs4)\n",
      "  Using cached soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from beautifulsoup4->bs4) (4.14.0)\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Using cached beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Using cached soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [bs4]\n",
      "\u001b[1A\u001b[2KSuccessfully installed beautifulsoup4-4.13.4 bs4-0.0.2 soupsieve-2.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a44adf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "url = [\n",
    "    \"https://m.sports.naver.com/wfootball/article/421/0008308548\",\n",
    "    \"https://m.sports.naver.com/wfootball/article/450/0000131435\"\n",
    "]\n",
    "\n",
    "my_user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36\"\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_path=url, # 개별 페이지 -> str, 여러페이지 -> list[str]\n",
    "    header_template={\n",
    "        \"user-agent\":my_user_agent\n",
    "    }\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b580ba5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://m.sports.naver.com/wfootball/article/421/0008308548',\n",
       " 'title': '[단독]쿠팡플레이, 스포츠패스 첫 가격 월 1만원…15일부터 시행',\n",
       " 'language': 'ko'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794e412b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da98b0ba-97ac-445d-85c8-1e000299f926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[단독]쿠팡플레이, 스포츠패스 첫 가격 월 1만원…15일부터 시행NAVER스포츠메뉴홈야구해외야구축구해외축구농구배구N골프일반e스포츠아웃도어NEW뉴스영상일정순위포토홈 바로가기NAVER스포츠마이팀팀 추가응원하는 팀을 구독해보세요!스포츠야구해외야구축구해외축구농구배구N골프일반e스포츠아웃도어콘텐츠오늘의 경기승부예측연재이슈톡대학스포츠랭킹기타고객센터공식 블로그메뉴 닫기본문 바로가기[단독]쿠팡플레이, 스포츠패스 첫 가격 월 1만원…15일부터 시행입력2025.06.12. 오후 2:00수정2025.06.12. 오후 3:39기사원문김정현 기자양새롬 기자공감좋아요0슬퍼요0화나요0팬이에요0후속기사 원해요0텍스트 음성 변환 서비스본문 듣기를 종료하였습니다.글자 크기 변경공유하기쿠팡 와우 회원, 월 총 요금  '1만 7890원'(쿠팡플레이 갈무리)/뉴스1(서울=뉴스1) 김정현 양새롬 기자 = 쿠팡플레이가 부가서비스인 '스포츠 패스'의 금액을 월 1만 원으로 확정했다.12일 업계에 따르면 쿠팡플레이는 오는 15일 해외 스포츠 등의 콘텐츠를 유료 부가 서비스로 제공하는 스포츠 패스의 요금을 월 1만 원으로 결정했다. 공식 가격은 1만 2000원이나, 출시 할인가로 추정된다.쿠팡 와우 멤버십 구독료인 월 7890원에 스포츠패스 금액을 더하면 월 이용금액은 1만 7890원이 된다. 할인가가 종료될 경우 월 구독료만 2만 원 수준이다.이번 패스를 통해 볼수 있는 스포츠 리그는 △FIFA대회(FIFA클럽월드컵)△유럽축구리그(프리미어리그 2025~2026 시즌, 라리가, 분데스리가, 분데스리가2, 리그1, EFL 챔피언십 EFL리그원, 에레디비시) △유럽축구 토너먼트(FA컵, 카라바오컵, 커뮤니티쉴드, 코파 델레이, 수페르코파데 에스파냐, DFB-포칼, DFL-슈퍼컵, 쿠프드프랑스, 트로페데 샹피옹, 버투트로피) △아시아축구(AFC아시안컵, AFC챔피언스리그 엘리트, AFC챔피언스리그2, 기타AFC주관 국제 대회) △세계축구(월드컵남미 예선, 클럽 친선경기, 해외 국가 친선경기) 등이다.축구 외에도 △레이싱(F1, F1 아카데미, 나스카) △골프(LIV 골프) △농구(남자 농구 아시아컵, 여자 농구 아시아컵) △미식 축구(NFL) 등도 스포츠 패스를 별도 구독해야 시청 가능하다. 올 가을부터는 NBA 경기도 독점 제공할 예정이다.쿠팡플레이는 대한민국 축구 대표팀, 한국 프로 축구, 이벤트 매치(쿠팡플레이 시리즈)는 별도 패스 가입 없이 와우 회원들이 시청할 수 있도록 할 예정이다. (쿠팡플레이 홈페이지 갈무리) /뉴스1이같은 정보는 쿠팡플레이 공식 홈페이지를 통해 '스포츠 패스' 페이지가 노출되며 알려졌다.2만 원에 육박하는 가격 정보가 알려지자 국내 스포츠 커뮤니티에서는 \"축구만 보는데 관심없는 중계도 묶어서 비싸게 판매하는 대신 선택 폭을 늘렸으면 한다\", \"돈 받는 건 좋은데 화질 개선에 대한 이야기는 없나\" 등의 반응을 보이고 있다.쿠팡플레이 관계자는 \"해당 가격 정보는 사실과 다르며, 스포츠 패스의 공식 가격 및 세부 내용은 추후 쿠팡플레이를 통해 정확히 안내드릴 예정\"이라고 말했다.한편 쿠팡플레이는 선택형 부가서비스 '패스(PASS)'를 6월 중 도입한다고 밝힌 바 있다.김정현 기자구독구독자 0응원수 0해킹 숨겼던 예스24, 거짓말하다 또 적발…KISA \"협조 없어\"삼성 갤럭시Z폴드7 '3차 티저' 공개…카메라 업그레이드 암시양새롬 기자구독구독자 0응원수 0SKT, 유심 교체예약 완료까지 열흘 남았는데…52만 명 이탈SKT 유심교체 700만 명 완료…잔여예약자 264만 명Copyright ⓒ 뉴스1. All rights reserved. 무단 전재 및 재배포,  AI학습 이용 금지.기사 섹션 분류 가이드기사 섹션 분류 안내스포츠 기사 섹션(종목) 정보는 언론사 분류와 기술 기반의 자동 분류 시스템을 따르고 있습니다. 오분류에 대한 건은 네이버스포츠로 제보 부탁드립니다.오분류 제보하기닫기K팝·K트롯 팬들의 놀이터, 스타1픽세상에 이런 일이...[사건의 재구성]주요뉴스해당 언론사에서 선정하며 언론사 페이지(아웃링크)로 이동해 볼 수 있습니다.상간녀의 '역공'…\"남편 바람나면 이유 있는 것\"\"고엽제로 거동도 불편한데\"…참전 용사 폭행 충격\"'니네 집 몇 평이야?' 작으면 무시…애들이 이사 가자 하네요\"\"KTX 양말 벗고 냄새 맡고 퍼덕\"…옆자리 승객 결국은지원, '9세 연하' 본인 스타일리스트와 재혼…가족들만 초대 '스몰 웨딩'좋아요0슬퍼요0화나요0팬이에요0후속기사 원해요0기사 공유하기\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb94a006",
   "metadata": {},
   "source": [
    "- 페이지의 일부분만 가져오기.\n",
    "- BeautifulSoup의 SoupStrainer 를 이용.\n",
    "    - BeautifulSoup(\"html문서\", parse_only=Strainer객체)\n",
    "        - Strainer객체에 지정된 영역에서만 내용 찾는다.\n",
    "    - Strainer(\"태그명\") -> 지정한 태그 내에서만 찾는다.\n",
    "    - Strainer(name=\"태그명\", attrs={속성명:속성값}) -> 지정한 태그 중 속성명=속성값인 것 내에서만 찾는다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be21355c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_path=url,\n",
    "    # WebBaseLoader가 bs4를 사용. bs4에 전달할 파라미터를 설정하는 변수\n",
    "    bs_kwargs={\n",
    "        \"parse_only\":bs4.SoupStrainer(attrs={\"class\":\"_article_content\"})\n",
    "    }\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "facaa491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿠팡 와우 회원, 월 총 요금  '1만 7890원'(쿠팡플레이 갈무리)/뉴스1(서울=뉴스1) 김정현 양새롬 기자 = 쿠팡플레이가 부가서비스인 '스포츠 패스'의 금액을 월 1만 원으로 확정했다.12일 업계에 따르면 쿠팡플레이는 오는 15일 해외 스포츠 등의 콘텐츠를 유료 부가 서비스로 제공하는 스포츠 패스의 요금을 월 1만 원으로 결정했다. 공식 가격은 1만 2000원이나, 출시 할인가로 추정된다.쿠팡 와우 멤버십 구독료인 월 7890원에 스포츠패스 금액을 더하면 월 이용금액은 1만 7890원이 된다. 할인가가 종료될 경우 월 구독료만 2만 원 수준이다.이번 패스를 통해 볼수 있는 스포츠 리그는 △FIFA대회(FIFA클럽월드컵)△유럽축구리그(프리미어리그 2025~2026 시즌, 라리가, 분데스리가, 분데스리가2, 리그1, EFL 챔피언십 EFL리그원, 에레디비시) △유럽축구 토너먼트(FA컵, 카라바오컵, 커뮤니티쉴드, 코파 델레이, 수페르코파데 에스파냐, DFB-포칼, DFL-슈퍼컵, 쿠프드프랑스, 트로페데 샹피옹, 버투트로피) △아시아축구(AFC아시안컵, AFC챔피언스리그 엘리트, AFC챔피언스리그2, 기타AFC주관 국제 대회) △세계축구(월드컵남미 예선, 클럽 친선경기, 해외 국가 친선경기) 등이다.축구 외에도 △레이싱(F1, F1 아카데미, 나스카) △골프(LIV 골프) △농구(남자 농구 아시아컵, 여자 농구 아시아컵) △미식 축구(NFL) 등도 스포츠 패스를 별도 구독해야 시청 가능하다. 올 가을부터는 NBA 경기도 독점 제공할 예정이다.쿠팡플레이는 대한민국 축구 대표팀, 한국 프로 축구, 이벤트 매치(쿠팡플레이 시리즈)는 별도 패스 가입 없이 와우 회원들이 시청할 수 있도록 할 예정이다. (쿠팡플레이 홈페이지 갈무리) /뉴스1이같은 정보는 쿠팡플레이 공식 홈페이지를 통해 '스포츠 패스' 페이지가 노출되며 알려졌다.2만 원에 육박하는 가격 정보가 알려지자 국내 스포츠 커뮤니티에서는 \"축구만 보는데 관심없는 중계도 묶어서 비싸게 판매하는 대신 선택 폭을 늘렸으면 한다\", \"돈 받는 건 좋은데 화질 개선에 대한 이야기는 없나\" 등의 반응을 보이고 있다.쿠팡플레이 관계자는 \"해당 가격 정보는 사실과 다르며, 스포츠 패스의 공식 가격 및 세부 내용은 추후 쿠팡플레이를 통해 정확히 안내드릴 예정\"이라고 말했다.한편 쿠팡플레이는 선택형 부가서비스 '패스(PASS)'를 6월 중 도입한다고 밝힌 바 있다.\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd26b68d",
   "metadata": {},
   "source": [
    "### ArxivLoader\n",
    "- https://github.com/lukasschwab/arxiv.py\n",
    "- [arXiv-아카이브](https://arxiv.org/) 는 미국 코렐대학에서 운영하는 **무료 논문 저장소**로, 물리학, 수학, 컴퓨터 과학, 생물학, 금융, 경제 등 **과학, 금융 분야의 논문**들을 공유한다.\n",
    "- `ArxivLoader` 를 사용해 원하는 주제의 논문들을 arXiv에서 가져와 load할 수 있다.\n",
    "- **arXiv API**를 사용해 논문을 가져올 수 있다.\n",
    "  - https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.arxiv.ArxivLoader.html\n",
    "- 설치\n",
    "  - `pip install langchain-community -qU`\n",
    "  - `pip install arxiv -qU`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "495aa934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting arxiv\n",
      "  Using cached arxiv-2.2.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: langchain-community in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (0.3.24)\n",
      "Collecting feedparser~=6.0.10 (from arxiv)\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: requests~=2.32.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from arxiv) (2.32.3)\n",
      "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from requests~=2.32.0->arxiv) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from requests~=2.32.0->arxiv) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from requests~=2.32.0->arxiv) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from requests~=2.32.0->arxiv) (2025.4.26)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-community) (0.3.63)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-community) (0.3.25)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-community) (2.0.41)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-community) (3.12.9)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-community) (2.9.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-community) (0.3.44)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-community) (2.2.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (2.11.5)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (4.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
      "Downloading arxiv-2.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "Building wheels for collected packages: sgmllib3k\n",
      "\u001b[33m  DEPRECATION: Building 'sgmllib3k' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'sgmllib3k'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for sgmllib3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6089 sha256=4780037acfa2f0ada97612c0d655d45592c8478d0481ee839d46901662d754fd\n",
      "  Stored in directory: /Users/giwonjun/Library/Caches/pip/wheels/03/f5/1a/23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, feedparser, arxiv\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [arxiv]\n",
      "\u001b[1A\u001b[2KSuccessfully installed arxiv-2.2.0 feedparser-6.0.11 sgmllib3k-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install arxiv langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f45cfa67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'itertools.islice'>\n"
     ]
    }
   ],
   "source": [
    "import arxiv \n",
    "\n",
    "# 검색 기준 설정.\n",
    "search = arxiv.Search(\n",
    "    query=\"RAG\", # 검색어\n",
    "    max_results=2, # 검색 결과 최대 개수.\n",
    "    sort_by=arxiv.SortCriterion.Relevance\n",
    ")\n",
    "# 정렬기준 - Relevance: 검색어 관련성이 높은 순서\n",
    "#          - LastUpdatedDate: 논문이 마지막으로 수정된 날짜 기준.\n",
    "#          - SubmittedDate: 처음 제출된 날짜 기준.\n",
    "\n",
    "# 검색\n",
    "client = arxiv.Client()\n",
    "result = client.results(search)\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6072b39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = next(result)  # 첫번째 문서 for page in result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a491e5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "논문제목: Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks\n",
      "저자: [arxiv.Result.Author('Yunfan Gao'), arxiv.Result.Author('Yun Xiong'), arxiv.Result.Author('Meng Wang'), arxiv.Result.Author('Haofen Wang')]\n",
      "논문 PDF URL: http://arxiv.org/pdf/2407.21059v1\n"
     ]
    }
   ],
   "source": [
    "print(\"논문제목:\", doc1.title)\n",
    "print(\"저자:\", doc1.authors)\n",
    "# print(\"요약: \", doc1.summary)\n",
    "print(\"논문 PDF URL:\", doc1.pdf_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "297d24d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다운로드\n",
    "import os\n",
    "os.makedirs(\"papers\", exist_ok=True)\n",
    "\n",
    "client = arxiv.Client()\n",
    "result = client.results(search)\n",
    "\n",
    "for idx, paper in enumerate(result, start=10):\n",
    "    paper.download_pdf(\"papers\", f\"{idx}.pdf\")\n",
    "# doc1.download_pdf(다운받을 디렉토리, 파일명명)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f14dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fitz in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (0.0.1.dev2)\n",
      "Requirement already satisfied: pymupdf in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (1.26.1)\n",
      "Requirement already satisfied: configobj in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from fitz) (5.0.9)\n",
      "Requirement already satisfied: configparser in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from fitz) (7.2.0)\n",
      "Requirement already satisfied: httplib2 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from fitz) (0.22.0)\n",
      "Requirement already satisfied: nibabel in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from fitz) (5.3.2)\n",
      "Requirement already satisfied: nipype in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from fitz) (1.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from fitz) (2.2.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from fitz) (2.3.0)\n",
      "Requirement already satisfied: pyxnat in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from fitz) (1.6.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from fitz) (1.15.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from httplib2->fitz) (3.2.3)\n",
      "Requirement already satisfied: packaging>=20 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nibabel->fitz) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nibabel->fitz) (4.14.0)\n",
      "Requirement already satisfied: click>=6.6.0 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nipype->fitz) (8.2.1)\n",
      "Requirement already satisfied: networkx>=2.5 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nipype->fitz) (3.5)\n",
      "Requirement already satisfied: prov>=1.5.2 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nipype->fitz) (2.0.2)\n",
      "Requirement already satisfied: pydot>=1.2.3 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nipype->fitz) (4.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nipype->fitz) (2.9.0.post0)\n",
      "Requirement already satisfied: rdflib>=5.0.0 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nipype->fitz) (7.1.4)\n",
      "Requirement already satisfied: simplejson>=3.8.0 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nipype->fitz) (3.20.1)\n",
      "Requirement already satisfied: traits>=6.2 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nipype->fitz) (7.0.2)\n",
      "Requirement already satisfied: filelock>=3.0.0 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nipype->fitz) (3.18.0)\n",
      "Requirement already satisfied: acres in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nipype->fitz) (0.5.0)\n",
      "Requirement already satisfied: etelemetry>=0.3.1 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nipype->fitz) (0.3.1)\n",
      "Requirement already satisfied: looseversion!=1.2 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nipype->fitz) (1.3.0)\n",
      "Requirement already satisfied: puremagic in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nipype->fitz) (1.29)\n",
      "Requirement already satisfied: colorama in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from click>=6.6.0->nipype->fitz) (0.4.6)\n",
      "Requirement already satisfied: requests in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from etelemetry>=0.3.1->nipype->fitz) (2.32.3)\n",
      "Requirement already satisfied: ci-info>=0.2 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from etelemetry>=0.3.1->nipype->fitz) (0.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from python-dateutil>=2.2->nipype->fitz) (1.17.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from pandas->fitz) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from pandas->fitz) (2025.2)\n",
      "Requirement already satisfied: lxml>=4.3 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from pyxnat->fitz) (5.4.0)\n",
      "Requirement already satisfied: pathlib>=1.0 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from pyxnat->fitz) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from requests->etelemetry>=0.3.1->nipype->fitz) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from requests->etelemetry>=0.3.1->nipype->fitz) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from requests->etelemetry>=0.3.1->nipype->fitz) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from requests->etelemetry>=0.3.1->nipype->fitz) (2025.4.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5acac658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import ArxivLoader\n",
    "\n",
    "loader = ArxivLoader(\n",
    "    query=\"Advanced RAG\", \n",
    "    top_k_results=1, # 몇개 검색할지 지정.\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e761a39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Published': '2024-07-26',\n",
       " 'Title': 'Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks',\n",
       " 'Authors': 'Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang',\n",
       " 'Summary': 'Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\\nof Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\\nincreasing demands of application scenarios have driven the evolution of RAG,\\nleading to the integration of advanced retrievers, LLMs and other complementary\\ntechnologies, which in turn has amplified the intricacy of RAG systems.\\nHowever, the rapid advancements are outpacing the foundational RAG paradigm,\\nwith many methods struggling to be unified under the process of\\n\"retrieve-then-generate\". In this context, this paper examines the limitations\\nof the existing RAG paradigm and introduces the modular RAG framework. By\\ndecomposing complex RAG systems into independent modules and specialized\\noperators, it facilitates a highly reconfigurable framework. Modular RAG\\ntranscends the traditional linear architecture, embracing a more advanced\\ndesign that integrates routing, scheduling, and fusion mechanisms. Drawing on\\nextensive research, this paper further identifies prevalent RAG\\npatterns-linear, conditional, branching, and looping-and offers a comprehensive\\nanalysis of their respective implementation nuances. Modular RAG presents\\ninnovative opportunities for the conceptualization and deployment of RAG\\nsystems. Finally, the paper explores the potential emergence of new operators\\nand paradigms, establishing a solid theoretical foundation and a practical\\nroadmap for the continued evolution and practical deployment of RAG\\ntechnologies.'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2111ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Modular RAG: Transforming RAG Systems into\n",
      "LEGO-like Reconfigurable Frameworks\n",
      "Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\n",
      "Abstract—Retrieval-augmented\n",
      "Generation\n",
      "(RAG)\n",
      "has\n",
      "markedly enhanced the capabilities of Large Language Models\n",
      "(LLMs) in tackling knowledge-intensive tasks. The increasing\n",
      "demands of application scenarios have driven the evolution\n",
      "of RAG, leading to the integration of advanced retrievers,\n",
      "LLMs and other complementary technologies, which in turn\n",
      "has amplified the intricacy of RAG systems. However, the rapid\n",
      "advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process\n",
      "of “retrieve-then-generate”. In this context, this paper examines\n",
      "the limitations of the existing RAG paradigm and introduces\n",
      "the modular RAG framework. By decomposing complex RAG\n",
      "systems into independent modules and specialized operators, it\n",
      "facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a\n",
      "more advanced design that integrates routing, scheduling, and\n",
      "fusion mechanisms. Drawing on extensive research, this paper\n",
      "further identifies prevalent RAG patterns—linear, conditional,\n",
      "branching, and looping—and offers a comprehensive analysis\n",
      "of their respective implementation nuances. Modular RAG\n",
      "presents\n",
      "innovative\n",
      "opportunities\n",
      "for\n",
      "the\n",
      "conceptualization\n",
      "and deployment of RAG systems. Finally, the paper explores\n",
      "the potential emergence of new operators and paradigms,\n",
      "establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment\n",
      "of RAG technologies.\n",
      "Index Terms—Retrieval-augmented generation, large language\n",
      "model, modular system, information retrieval\n",
      "I. INTRODUCTION\n",
      "L\n",
      "ARGE Language Models (LLMs) have demonstrated\n",
      "remarkable capabilities, yet they still face numerous\n",
      "challenges, such as hallucination and the lag in information up-\n",
      "dates [1]. Retrieval-augmented Generation (RAG), by access-\n",
      "ing external knowledge bases, provides LLMs with important\n",
      "contextual information, significantly enhancing their perfor-\n",
      "mance on knowledge-intensive tasks [2]. Currently, RAG, as\n",
      "an enhancement method, has been widely applied in various\n",
      "practical application scenarios, including knowledge question\n",
      "answering, recommendation systems, customer service, and\n",
      "personal assistants. [3]–[6]\n",
      "During the nascent stages of RAG , its core framework is\n",
      "constituted by indexing, retrieval, and generation, a paradigm\n",
      "referred to as Naive RAG [7]. However, as the complexity\n",
      "of tasks and the demands of applications have escalated, the\n",
      "Yunfan Gao is with Shanghai Research Institute for Intelligent Autonomous\n",
      "Systems, Tongji University, Shanghai, 201210, China.\n",
      "Yun Xiong is with Shanghai Key Laboratory of Data Science, School of\n",
      "Computer Science, Fudan University, Shanghai, 200438, China.\n",
      "Meng Wang and Haofen Wang are with College of Design and Innovation,\n",
      "Tongji University, Shanghai, 20092, China. (Corresponding author: Haofen\n",
      "Wang. E-mail: carter.whfcarter@gmail.com)\n",
      "limitations of Naive RAG have become increasingly apparent.\n",
      "As depicted in Figure 1, it predominantly hinges on the\n",
      "straightforward similarity of chunks, result in poor perfor-\n",
      "mance when confronted with complex queries and chunks with\n",
      "substantial variability. The primary challenges of Naive RAG\n",
      "include: 1) Shallow Understanding of Queries. The semantic\n",
      "similarity between a query and document chunk is not always\n",
      "highly consistent. Relying solely on similarity calculations\n",
      "for retrieval lacks an in-depth exploration of the relationship\n",
      "between the query and the document [8]. 2) Retrieval Re-\n",
      "dundancy and Noise. Feeding all retrieved chunks directly\n",
      "into LLMs is not always beneficial. Research indicates that\n",
      "an excess of redundant and noisy information may interfere\n",
      "with the LLM’s identification of key information, thereby\n",
      "increasing the risk of generating erroneous and hallucinated\n",
      "responses. [9]\n",
      "To overcome the aforementioned limitations, Advanced\n",
      "RAG paradigm focuses on optimizing the retrieval phase,\n",
      "aiming to enhance retrieval efficiency and strengthen the\n",
      "utilization of retrieved chunks. As shown in Figure 1 ,typical\n",
      "strategies involve pre-retrieval processing and post-retrieval\n",
      "processing. For instance, query rewriting is used to make\n",
      "the queries more clear and specific, thereby increasing the\n",
      "accuracy of retrieval [10], and the reranking of retrieval results\n",
      "is employed to enhance the LLM’s ability to identify and\n",
      "utilize key information [11].\n",
      "Despite the improvements in the practicality of Advanced\n",
      "RAG, there remains a gap between its capabilities and real-\n",
      "world application requirements. On one hand, as RAG tech-\n",
      "nology advances, user expectations rise, demands continue to\n",
      "evolve, and application settings become more complex. For\n",
      "instance, the integration of heterogeneous data and the new\n",
      "demands for system transparency, control, and maintainability.\n",
      "On the other hand, the growth in application demands has\n",
      "further propelled the evolution of RAG technology.\n",
      "As shown in Figure 2, to achieve more accurate and efficient\n",
      "task execution, modern RAG systems are progressively inte-\n",
      "grating more sophisticated function, such as organizing more\n",
      "refined index base in the form of knowledge graphs, integrat-\n",
      "ing structured data through query construction methods, and\n",
      "employing fine-tuning techniques to enable encoders to better\n",
      "adapt to domain-specific documents.\n",
      "In terms of process design, the current RAG system has\n",
      "surpassed the traditional linear retrieval-generation paradigm.\n",
      "Researchers use iterative retrieval [12] to obtain richer con-\n",
      "text, recursive retrieval [13] to handle complex queries, and\n",
      "adaptive retrieval [14] to provide overall autonomy and flex-\n",
      "ibility. This flexibility in the process significantly enhances\n",
      "arXiv:2407.21059v1  [cs.CL]  26 Jul 2024\n",
      "2\n",
      "Fig. 1. Cases of Naive RAG and Advanced RAG.When faced with complex\n",
      "questions, both encounter limitations and struggle to provide satisfactory\n",
      "answers. Despite the fact that Advanced RAG improves retrieval accuracy\n",
      "through hierarchical indexing, pre-retrieval, and post-retrieval processes, these\n",
      "relevant documents have not been used correctly.\n",
      "the expressive power and adaptability of RAG systems, en-\n",
      "abling them to better adapt to various application scenarios.\n",
      "However, this also makes the orchestration and scheduling of\n",
      "workflows more complex, posing greater challenges to system\n",
      "design. Specifically, RAG currently faces the following new\n",
      "challenges:\n",
      "Complex data sources integration. RAG are no longer\n",
      "confined to a single type of unstructured text data source but\n",
      "have expanded to include various data types, such as semi-\n",
      "structured data like tables and structured data like knowledge\n",
      "graphs [15]. Access to heterogeneous data from multiple\n",
      "sources can provide the system with a richer knowledge\n",
      "background, and more reliable knowledge verification capa-\n",
      "bilities [16].\n",
      "New demands for system interpretability, controllability,\n",
      "Fig. 2.\n",
      "Case of current Modular RAG.The system integrates diverse data\n",
      "and more functional components. The process is no longer confined to linear\n",
      "but is controlled by multiple control components for retrieval and generation,\n",
      "making the entire system more flexible and complex.\n",
      "3\n",
      "and maintainability. With the increasing complexity of sys-\n",
      "tems, system maintenance and debugging have become more\n",
      "challenging. Additionally, when issues arise, it is essential to\n",
      "quickly pinpoint the specific components that require opti-\n",
      "mization.\n",
      "Component selection and optimization. More neural net-\n",
      "works are involved in the RAG system, necessitating the\n",
      "selection of appropriate components to meet the needs of spe-\n",
      "cific tasks and resource configurations. Moreover, additional\n",
      "components enhance the effectiveness of RAG but also bring\n",
      "new collaborative work requirements [17]. Ensuring that these\n",
      "models perform as intended and work efficiently together to\n",
      "enhance the overall system performance is crucial.\n",
      "Workflow orchestration and scheduling. Components\n",
      "may need to be executed in a specific order, processed in paral-\n",
      "lel under certain conditions, or even judged by the LLM based\n",
      "on different outputs. Reasonable planning of the workflow is\n",
      "essential for improving system efficiency and achieving the\n",
      "desired outcomes [18].\n",
      "To address the design, management, and maintenance chal-\n",
      "lenges posed by the increasing complexity of RAG systems,\n",
      "and to meet the ever-growing and diverse demands and ex-\n",
      "pectations, this paper proposes Modular RAG architecture.\n",
      "In modern computing systems, modularization is becoming\n",
      "a trend. It can enhance the system’s scalability and maintain-\n",
      "ability and achieve efficient task execution through process\n",
      "control.\n",
      "The Modular RAG system consists of multiple independent\n",
      "yet tightly coordinated modules, each responsible for handling\n",
      "specific functions or tasks. This architecture is divided into\n",
      "three levels: the top level focuses on the critical stages of\n",
      "RAG, where each stage is treated as an independent module.\n",
      "This level not only inherits the main processes from the\n",
      "Advanced RAG paradigm but also introduces an orchestration\n",
      "module to control the coordination of RAG processes. The\n",
      "middle level is composed of sub-modules within each module,\n",
      "further refining and optimizing the functions. The bottom level\n",
      "consists of basic units of operation—operators. Within the\n",
      "Modular RAG framework, RAG systems can be represented\n",
      "in the form of computational graphs, where nodes represent\n",
      "specific operators. The comparison of the three paradigms is\n",
      "shown in the Figure 3. Modular RAG evolves based on the\n",
      "previous development of RAG. The relationships among these\n",
      "three paradigms are ones of inheritance and development.\n",
      "Advanced RAG is a special case of Modular RAG, while Naive\n",
      "RAG is a special case of Advanced RAG.\n",
      "The advantages of Modular RAG are significant, as it\n",
      "enhances the flexibility and scalability of RAG systems. Users\n",
      "can flexibly combine different modules and operators accord-\n",
      "ing to the requirements of data sources and task scenarios. In\n",
      "summary, the contributions of this paper are as follows:\n",
      "• This paper proposes a new paradigm called modular\n",
      "RAG, which employs a three-tier architectural design\n",
      "comprising modules, sub-modules, and operators to de-\n",
      "fine the RAG system in a unified and structured manner.\n",
      "This design not only enhances the system’s flexibility and\n",
      "scalability but also, through the independent design of\n",
      "operators, strengthens the system’s maintainability and\n",
      "comprehensibility.\n",
      "• Under the framework of Modular RAG, the orchestration\n",
      "of modules and operators forms the RAG Flow, which\n",
      "can flexibly express current RAG methods. This paper has\n",
      "further summarized six typical flow patterns and specific\n",
      "methods have been analyzed to reveal the universality of\n",
      "modular RAG in practical scenarios.\n",
      "• The Modular RAG framework offers exceptional flexi-\n",
      "bility and extensibility. This paper delves into the new\n",
      "opportunities brought by Modular RAG and provides a\n",
      "thorough discussion on the adaptation and expansion of\n",
      "new methods in different application scenarios, offering\n",
      "guidance for future research directions and practical ex-\n",
      "ploration.\n",
      "II. RELATED WORK\n",
      "The development of RAG technology can be summarized\n",
      "in three stages. Initially, retrieval-augmented techniques were\n",
      "introduced to improve the performance of pre-trained lan-\n",
      "guage models on knowledge-intensive tasks [19], [20]. In\n",
      "specific implementations, Retro [21] optimized pre-trained\n",
      "autoregressive models through retrieval augmentation, while\n",
      "Atlas [22] utilized a retrieval-augmented few-shot fine-tuning\n",
      "method, enabling language models to adapt to diverse tasks.\n",
      "IRCOT [23] further enriched the reasoning process during\n",
      "the inference phase by combining chain-of-thought and multi-\n",
      "step retrieval processes. Entering the second stage, as the\n",
      "language processing capabilities of LLMs significantly im-\n",
      "proved, retrieval-augmented techniques began to serve as a\n",
      "means of supplementing additional knowledge and providing\n",
      "references, aiming to reduce the hallucination. For instance,\n",
      "RRR [24] improved the rewriting phase, and LLMlingua [25]\n",
      "removed redundant tokens in retrieved document chunks.\n",
      "With the continuous progress of RAG technology, research\n",
      "has become more refined and focused, while also achieving\n",
      "innovative integration with other technologies such as graph\n",
      "neural networks [26] and fine-tuning techniques [27]. The\n",
      "overall pipeline has also become more flexible, such as using\n",
      "LLMs to proactively determine the timing of retrieval and\n",
      "generation [14], [28].\n",
      "The development of RAG technology has been acceler-\n",
      "ated by LLM technology and practical application needs.\n",
      "Researchers are examining and organizing the RAG frame-\n",
      "work and development pathways from different perspectives.\n",
      "Building upon the enhanced stages of RAG, Gao et al., [2] sub-\n",
      "divided RAG into enhancement during pre-training, inference,\n",
      "and fine-tuning stages. Based on the main processes of RAG,\n",
      "relevant works on RAG were organized from the perspectives\n",
      "of retrieval, generation, and augmentation methods. Huang\n",
      "et al., [29] categorize RAG methods into four main classes:\n",
      "pre-retrieval, retrieval, post-retrieval, generation, and provide\n",
      "a detailed discussion of the methods and techniques within\n",
      "each class. Hu et al., [30] discuss Retrieval-Augmented Lan-\n",
      "guage Models (RALMs) form three key components, including\n",
      "retrievers, language models, augmentations, and how their\n",
      "interactions lead to different model structures and applications.\n",
      "4\n",
      "Fig. 3. Comparison between three RAG paradigms. Modular RAG has evolved from previous paradigms and aligns with the current practical needs of RAG\n",
      "systems.\n",
      "They emphasize the importance of considering robustness,\n",
      "accuracy, and relevance when evaluating RALMs and pro-\n",
      "pose several evaluation methods. Ding et al., [31] provide a\n",
      "comprehensive review from the perspectives of architecture,\n",
      "training strategies, and applications. They specifically discuss\n",
      "four training methods of RALMs: training-free methods, in-\n",
      "dependent training methods, sequence training methods, and\n",
      "joint training methods, and compare their advantages and\n",
      "disadvantages. Zhao et al., [32]analyze the applications of\n",
      "RAG technology in various fields such as text generation,\n",
      "code generation, image generation, and video generation from\n",
      "the perspective of augmented intelligence with generative\n",
      "capabilities.\n",
      "The current collation of RAG systems primarily focuses\n",
      "on methods with a fixed process, mainly concerned with\n",
      "optimizing the retrieval and generation stages. However, it has\n",
      "not turned its attention to the new characteristics that RAG\n",
      "research is continuously evolving, namely the characteristics\n",
      "of process scheduling and functional componentization. There\n",
      "is currently a lack of comprehensive analysis of the overall\n",
      "RAG system, which has led to research on paradigms lagging\n",
      "behind the development of RAG technology.\n",
      "III. FRAMEWORK AND NOTATION\n",
      "For query Q = {qi}, a typical RAG system mainly consists\n",
      "of three key components. 1) Indexing. Given documents D =\n",
      "{d1, d2, . . . , dn} , where di represents the document chunk.\n",
      "Indexing is the process of converting di into vectors through\n",
      "an embedding model fe(·) , and then store vectors in vector\n",
      "database.\n",
      "I = {e1, e2, . . . , en}\n",
      "and\n",
      "ei = fe(di) ∈Rd\n",
      "(1)\n",
      "Notation\n",
      "Description\n",
      "q\n",
      "The original query\n",
      "y\n",
      "The output of LLM\n",
      "D\n",
      "A document retrieval repository composed of chunks di.\n",
      "R(q, D)\n",
      "Retriever,find similar chunks from D based on q.\n",
      "F\n",
      "RAG Flow\n",
      "P\n",
      "RAG Flow pattern\n",
      "fqe\n",
      "Query expansion function\n",
      "fqc\n",
      "Query transform function\n",
      "fcomp\n",
      "Chunk compression function\n",
      "fsel\n",
      "Chunk selection function\n",
      "fr\n",
      "Routing function\n",
      "M\n",
      "Module in modular RAG\n",
      "op\n",
      "The specific operators within the Module.\n",
      "TABLE I\n",
      "IMPORTANT NOTATION\n",
      "2) Retrieval . Transform the query into a vector using the\n",
      "same encoding model, and then filter out the top k document\n",
      "chunks that are most similar based on vector similarity.\n",
      "R : topk\n",
      "di∈D\n",
      "Sim(q, di) →Dq\n",
      "(2)\n",
      "Dq = {d1, d2, . . . , dk} represents the relevant documents for\n",
      "question q. The similarity function Sim(·) commonly used are\n",
      "dot product or cosine similarity.\n",
      "Sim(q, di) = eq · edi\n",
      "or\n",
      "eq · edi\n",
      "∥eq∥· ∥edi∥\n",
      "(3)\n",
      "3) Generation. After getting the relevant documents. The\n",
      "query q and the retrieved document Dq chunks are inputted\n",
      "together to the LLM to generate the final answer, where [·, ·]\n",
      "stands for concatenation.\n",
      "y = LLM([Dq, q])\n",
      "(4)\n",
      "5\n",
      "With the evolution of RAG technology, more and more func-\n",
      "tional components are being integrated into systems. Modular\n",
      "RAG paradigm includes three levels, ranging from large to\n",
      "small:\n",
      "L1 Module (M = {Ms}). The core process in RAG\n",
      "system.\n",
      "L2 Sub-module (Ms = {Op}).The functional modules in\n",
      "module.\n",
      "L3 Operator (Op = {fθi}). The the specific functional\n",
      "implementation in a module or sub-module. As a result, a\n",
      "Modular RAG system can be represented as:\n",
      "G = {q, D, M, {Ms}, {Op}}\n",
      "(5)\n",
      "The arrangement between modules and operators constitutes\n",
      "the RAG Flow F = (Mϕ1, . . . , Mϕn) where ϕ stands for\n",
      "the set of module parameters. A modular rag flow can be\n",
      "decomposed into a graph of sub-functions. In the simplest\n",
      "case,the graph is a linear chain.\n",
      "NaiveRAG : q\n",
      "R(q,D)\n",
      "−−−−−−−−−−−→\n",
      "T ext−Embedding Dq\n",
      "LLM([q,Dq])\n",
      "−−−−−−−−−−−→\n",
      "OpenAI/GP T −4 y\n",
      "(6)\n",
      "IV. MODULE AND OPERATOR\n",
      "This chapter will specifically introduce modules and op-\n",
      "erators under the Modular RAG framework. Based on the\n",
      "current stage of RAG development, we have established\n",
      "six main modules: Indexing, Pre-retrieval, Retrieval, Post-\n",
      "retrieval, Generation, and Orchestration.\n",
      "A. Indexing\n",
      "Indexing is the process of split document into manageable\n",
      "chunks and it is a key step in organizing a system. Indexing\n",
      "faces three main challenges. 1) Incomplete content represen-\n",
      "tation.The semantic information of chunks is influenced by the\n",
      "segmentation method, resulting in the loss or submergence of\n",
      "important information within longer contexts. 2) Inaccurate\n",
      "chunk similarity search. As data volume increases, noise in\n",
      "retrieval grows, leading to frequent matching with erroneous\n",
      "data, making the retrieval system fragile and unreliable. 3)\n",
      "Unclear reference trajectory. The retrieved chunks may orig-\n",
      "inate from any document, devoid of citation trails, potentially\n",
      "resulting in the presence of chunks from multiple different\n",
      "documents that, despite being semantically similar, contain\n",
      "content on entirely different topics.\n",
      "1) Chunk Optimization: The size of the chunks and the\n",
      "overlap between the chunks play a crucial role in the overall\n",
      "effectiveness of the RAG system. Given a chunk di, its chunk\n",
      "size is denoted as Li = |di|, and the overlap is denoted as\n",
      "Lo\n",
      "i = |di ∩di+1|. Larger chunks can capture more context,\n",
      "but they also generate more noise, requiring longer processing\n",
      "time and higher costs. While smaller chunks may not fully\n",
      "convey the necessary context, they do have less noise [17].\n",
      "Sliding Window using overlapping chunks in a sliding win-\n",
      "dow enhances semantic transitions. However, it has limitations\n",
      "such as imprecise context size control, potential truncation of\n",
      "words or sentences, and lacking semantic considerations.\n",
      "Metadata Attachment. Chunks can be enriched with meta-\n",
      "data like page number, file name, author, timestamp, sum-\n",
      "mary, or relevant questions. This metadata allows for filtered\n",
      "retrieval, narrowing the search scope.\n",
      "Small-to-Big [33] separate the chunks used for retrieval\n",
      "from those used for synthesis. Smaller chunks enhance re-\n",
      "trieval accuracy, while larger chunks provide more context.\n",
      "One approach is to retrieve smaller summarized chunks and\n",
      "reference their parent larger chunks. Alternatively, individual\n",
      "sentences could be retrieved along with their surrounding text.\n",
      "2) Structure Organization: One effective method for en-\n",
      "hancing information retrieval is to establish a hierarchical\n",
      "structure for the documents. By constructing chunks structure,\n",
      "RAG system can expedite the retrieval and processing of\n",
      "pertinent data.\n",
      "Hierarchical Index. In the hierarchical structure of docu-\n",
      "ments, nodes are arranged in parent-child relationships, with\n",
      "chunks linked to them. Data summaries are stored at each\n",
      "node, aiding in the swift traversal of data and assisting the\n",
      "RAG system in determining which chunks to extract. This\n",
      "approach can also mitigate the illusion caused by chunk\n",
      "extraction issues. The methods for constructing a structured\n",
      "index primarily include: 1) Structural awareness based on\n",
      "paragraph and sentence segmentation in docs. 2) Content\n",
      "awareness based on inherent structure in PDF, HTML, and\n",
      "Latex. 3) Semantic awareness based on semantic recognition\n",
      "and segmentation of text.\n",
      "KG Index [34]. Using Knowledge Graphs (KGs) to struc-\n",
      "ture documents helps maintain consistency by clarifying con-\n",
      "nections between concepts and entities, reducing the risk of\n",
      "mismatch errors. KGs also transform information retrieval\n",
      "into instructions intelligible to language models, improving re-\n",
      "trieval accuracy and enabling contextually coherent responses.\n",
      "This enhances the overall efficiency of the RAG system.\n",
      "For example, organizing a corpus in the format of graph\n",
      "G = {V, E, X}, where node V = {vi}n\n",
      "i=1 represent document\n",
      "structures (e.g.passage, pages, table) , edge E ⊂V × V rep-\n",
      "resent semantic or lexical similarity and belonging relations,\n",
      "and node features X = {Xi}n\n",
      "i=1 represent text or markdown\n",
      "content for passage.\n",
      "B. Pre-retrieval\n",
      "One of the primary challenges with Naive RAG is its\n",
      "direct reliance on the user’s original query as the basis for\n",
      "retrieval. Formulating a precise and clear question is difficult,\n",
      "and imprudent queries result in subpar retrieval effectiveness.\n",
      "The primary challenges in this module include: 1) Poorly\n",
      "worded queries. The question itself is complex, and the\n",
      "language is not well-organized. 2) Language complexity and\n",
      "ambiguity. Language models often struggle when dealing\n",
      "with specialized vocabulary or ambiguous abbreviations with\n",
      "multiple meanings. For instance, they may not discern whether\n",
      "LLM refers to Large Language Model or a Master of Laws in\n",
      "a legal context.\n",
      "1) Query Expansion : Expanding a single query into mul-\n",
      "tiple queries enriches the content of the query, providing\n",
      "6\n",
      "further context to address any lack of specific nuances, thereby\n",
      "ensuring the optimal relevance of the generated answers.\n",
      "fqe(q) = {q1, q2, . . . , qn}\n",
      "∀qi ∈{q1, q2, . . . , qn}, qi /∈Q\n",
      "(7)\n",
      "Multi-Query uses prompt engineering to expand queries\n",
      "via LLMs, allowing for parallel execution. These expansions\n",
      "are meticulously designed to ensure diversity and coverage.\n",
      "However, this approach can dilute the user’s original intent.\n",
      "To mitigate this, the model can be instructed to assign greater\n",
      "weight to the original query.\n",
      "Sub-Query. By decomposing and planning for complex\n",
      "problems, multiple sub-problems are generated. Specifically,\n",
      "least-to-most prompting [35] can be employed to decom-\n",
      "pose the complex problem into a series of simpler sub-\n",
      "problems. Depending on the structure of the original problem,\n",
      "the generated sub-problems can be executed in parallel or\n",
      "sequentially. Another approach involves the use of the Chain-\n",
      "of-Verification (CoVe) [36]. The expanded queries undergo\n",
      "validation by LLM to achieve the effect of reducing hallu-\n",
      "cinations.\n",
      "2) Query Transformation: Retrieve and generate based on\n",
      "a transformed query instead of the user’s original query.\n",
      "fqt(q) = q′\n",
      "(8)\n",
      "Rewrite. Original queries often fall short for retrieval in\n",
      "real-world scenarios. To address this, LLMs can be prompted\n",
      "to rewrite. Specialized smaller models can also be employed\n",
      "for this purpose [24]. The implementation of the query rewrite\n",
      "method in Taobao has significantly improved recall effective-\n",
      "ness for long-tail queries, leading to an increase in GMV [10].\n",
      "HyDE [37]. In order to bridge the semantic gap between\n",
      "questions and answers, it constructs hypothetical documents\n",
      "(assumed answers) when responding to queries instead of\n",
      "directly searching the query. It focuses on embedding simi-\n",
      "larity from answer to answer rather than seeking embedding\n",
      "similarity for the problem or query. In addition, it also in-\n",
      "cludes reverse HyDE, which generate hypothetical query for\n",
      "each chunks and focuses on retrieval from query to query.\n",
      "Step-back Prompting [38]. The original query is abstracted\n",
      "into a high-level concept question (step-back question). In the\n",
      "RAG system, both the step-back question and the original\n",
      "query are used for retrieval, and their results are combined\n",
      "to generate the language model’s answer.\n",
      "3) Query Construction: In addition to text data, an in-\n",
      "creasing amount of structured data, such as tables and graph\n",
      "data, is being integrated into RAG systems. To accommodate\n",
      "various data types, it is necessary to restructure the user’s\n",
      "query. This involve converting the query into another query\n",
      "language to access alternative data sources, with common\n",
      "methods including Text-to-SQL or Text-to-Cypher . In many\n",
      "scenarios, structured query languages (e.g., SQL, Cypher)\n",
      "are often used in conjunction with semantic information and\n",
      "metadata to construct more complex queries.\n",
      "fqc(q) = q∗, q∗∈Q∗= {SQL, Cypher, . . . }\n",
      "(9)\n",
      "C. Retrieval\n",
      "The retrieval process is pivotal in RAG systems. By lever-\n",
      "aging powerful embedding models, queries and text can be\n",
      "efficiently represented in latent spaces, which facilitates the\n",
      "establishment of semantic similarity between questions and\n",
      "documents, thereby enhancing retrieval. Three main consider-\n",
      "ations that need to be addressed include retrieval efficiency,\n",
      "quality, and the alignment of tasks, data and models.\n",
      "1) Retriever Selection: With the widespread adoption of\n",
      "RAG technology, the development of embedding models has\n",
      "been in full swing. In addition to traditional models based\n",
      "on statistics and pre-trained models based on the encoder\n",
      "structure, embedding models fine-tuned on LLMs have also\n",
      "demonstrated powerful capabilities [39]. However, they often\n",
      "come with more parameters, leading to weaker inference\n",
      "and retrieval efficiency. Therefore, it is crucial to select the\n",
      "appropriate retriever based on different task scenarios.\n",
      "Sparse Retriever uses statistical methods to convert queries\n",
      "and documents into sparse vectors. Its advantage lies in its\n",
      "efficiency in handling large datasets, focusing only on non-zero\n",
      "elements. However, it may be less effective than dense vectors\n",
      "in capturing complex semantics. Common methods include\n",
      "TF-IDF and BM25.\n",
      "Dense Retriever employs pre-trained language models\n",
      "(PLMs) to provide dense representations of queries and doc-\n",
      "uments. Despite higher computational and storage costs, it\n",
      "offers more complex semantic representations. Typical models\n",
      "include BERT structure PLMs, like ColBERT, and multi-task\n",
      "fine-tuned models like BGE [40] and GTE [41].\n",
      "Hybrid Retriever is to use both sparse and dense retrievers\n",
      "simultaneously. Two embedding techniques complement each\n",
      "other to enhance retrieval effectiveness. Sparse retriever can\n",
      "provide initial screening results. Additionally, sparse models\n",
      "enhance the zero-shot retrieval capabilities of dense models,\n",
      "particularly in handling queries with rare entities, thereby\n",
      "increasing system robustness.\n",
      "2) Retriever Fine-tuning: In cases where the context may\n",
      "diverge from pre-trained corpus, particularly in highly special-\n",
      "ized fields like healthcare, law, and other domains abundant in\n",
      "proprietary terminology. While this adjustment demands addi-\n",
      "tional effort, it can substantially enhance retrieval efficiency\n",
      "and domain alignment.\n",
      "Supervised Fine-Tuning (SFT). Fine-tuning a retrieval\n",
      "model based on labeled domain data is typically done using\n",
      "contrastive learning. This involves reducing the distance be-\n",
      "tween positive samples while increasing the distance between\n",
      "negative samples. The commonly used loss calculation is\n",
      "shown in the following:\n",
      "L(DR) = −1\n",
      "T\n",
      "T\n",
      "X\n",
      "i=1\n",
      "log\n",
      "e(sim(qi,d+\n",
      "i ))\n",
      "e(sim(qi,d+\n",
      "i )) + PN\n",
      "j=1 e(sim(qi,d−\n",
      "i ))\n",
      "(10)\n",
      "where d+\n",
      "i is the positive sample document corresponding to\n",
      "the i-th query, d−\n",
      "i\n",
      "is several negative sample, T is the total\n",
      "number of queries, N is the number of negative samples, and\n",
      "DR is the fine-tuning dataset.\n",
      "LM-supervised Retriever (LSR). In contrast to directly\n",
      "constructing a fine-tuning dataset from the dataset, LSR uti-\n",
      "7\n",
      "lizes the LM-generated results as supervisory signals to fine-\n",
      "tune the embedding model during the RAG process.\n",
      "PLSR(d|q, y) =\n",
      "ePLM(y|d,q)/β\n",
      "P\n",
      "d′∈D ePLM(y|d,q)/β)\n",
      "(11)\n",
      "PLM(y|d, q) is LM probability of the ground truth output y\n",
      "given the input context d and query q, and β is a hyper-\n",
      "paramter.\n",
      "Adapter. At times, fine-tuning a large retriever can be\n",
      "costly, especially when dealing with retrievers based on LLMs\n",
      "like gte-Qwen. In such cases, it can mitigate this by incorpo-\n",
      "rating an adapter module and conducting fine-tuning. Another\n",
      "benefit of adding an adapter is the ability to achieve better\n",
      "alignment with specific downstream tasks [42].\n",
      "D. Post-retrieval\n",
      "Feeding all retrieved chunks directly into the LLM is not an\n",
      "optimal choice. Post-processing the chunks can aid in better\n",
      "leveraging the contextual information. The primary challenges\n",
      "include: 1) Lost in the middle. Like humans, LLM tends\n",
      "to remember only the beginning or the end of long texts,\n",
      "while forgetting the middle portion [43]. 2) Noise/anti-fact\n",
      "chunks. Retrieved noisy or factually contradictory documents\n",
      "can impact the final retrieval generation [44].\n",
      "3) Context\n",
      "Window. Despite retrieving a substantial amount of relevant\n",
      "content, the limitation on the length of contextual information\n",
      "in large models prevents the inclusion of all this content.\n",
      "1) Rerank: Rerank the retrieved chunks without altering\n",
      "their content or length, to enhance the visibility of the more\n",
      "crucial document chunks. Given the retrieved set Dq and a\n",
      "re-ranking method frerank to obtain the re-ranked set:\n",
      "Dq\n",
      "r = frerank(q, Dq) = {d′\n",
      "1, d′\n",
      "2, . . . , d′\n",
      "k}\n",
      "wheref(d′\n",
      "1) ≥f(d′\n",
      "2) ≥. . . ≥f(d′\n",
      "k).\n",
      "(12)\n",
      "Rule-base rerank. Metrics are calculated to rerank chunks\n",
      "according to certain rules. Common metrics include: diversity,\n",
      "relevance and MRR (Maximal Marginal Relevance) [45]. The\n",
      "idea is to reduce redundancy and increase result diversity.\n",
      "MMR selects phrases for the final key phrase list based on a\n",
      "combined criterion of query relevance and information novelty.\n",
      "Model-base rerank. Utilize a language model to reorder the\n",
      "document chunks, commonly based on the relevance between\n",
      "the chunks and the query. Rerank models have become an\n",
      "important component of RAG systems, and relevant model\n",
      "technologies are also being iteratively upgraded. The scope\n",
      "reordering has also been extended to multimodal data such as\n",
      "tables and images [46].\n",
      "2) Compression: A common misconception in the RAG\n",
      "process is the belief that retrieving as many relevant docu-\n",
      "ments as possible and concatenating them to form a lengthy\n",
      "retrieval prompt is beneficial. However, excessive context can\n",
      "introduce more noise, diminishing the LLM’s perception of\n",
      "key information. A common approach to address this is to\n",
      "compress and select the retrieved content.\n",
      "Dq\n",
      "c = fcomp(q, Dq),\n",
      "where|dqc\n",
      "i | < |dq\n",
      "i |\n",
      "∀dq\n",
      "i ∈Dq\n",
      "(13)\n",
      "(Long)LLMLingua [47]. By utilizing aligned and trained\n",
      "small language models, such as GPT-2 Small or LLaMA-\n",
      "7B, the detection and removal of unimportant tokens from\n",
      "the prompt is achieved, transforming it into a form that is\n",
      "challenging for humans to comprehend but well understood by\n",
      "LLMs. This approach presents a direct and practical method\n",
      "for prompt compression, eliminating the need for additional\n",
      "training of LLMs while balancing language integrity and\n",
      "compression ratio.\n",
      "3) Selection: Unlike compressing the content of document\n",
      "chunks, Selection directly removes irrelevant chunks.\n",
      "Dq\n",
      "s = fsel(Dq) = {di ∈D | ¬P(di)}\n",
      "(14)\n",
      "Where fsel is the function for deletion operation and P(di) is\n",
      "a conditional predicate indicating that document (di) satisfies\n",
      "a certain condition. If document (di) satisfies (P(di)), it will\n",
      "be deleted. Conversely, documents for which (¬P(di)) is true\n",
      "will be retained.\n",
      "Selective Context. By identifying and removing redundant\n",
      "content in the input context, the input is refined, thus improv-\n",
      "ing the language model’s reasoning efficiency. In practice, se-\n",
      "lective context assesses the information content of lexical units\n",
      "based on the self-information computed by the base language\n",
      "model. By retaining content with higher self-information, this\n",
      "method offers a more concise and efficient textual representa-\n",
      "tion, without compromising their performance across diverse\n",
      "applications. However, it overlooks the interdependence be-\n",
      "tween compressed content and the alignment between the\n",
      "targeted language model and the small language model utilized\n",
      "for prompting compression [48].\n",
      "LLM-Critique. Another straightforward and effective ap-\n",
      "proach involves having the LLM evaluate the retrieved content\n",
      "before generating the final answer. This allows the LLM\n",
      "to filter out documents with poor relevance through LLM\n",
      "critique. For instance, in Chatlaw [49], the LLM is prompted\n",
      "to self-suggestion on the referenced legal provisions to assess\n",
      "their relevance.\n",
      "E. Generation\n",
      "Utilize the LLM to generate answers based on the user’s\n",
      "query and the retrieved contextual information. Select an\n",
      "appropriate model based on the task requirements, considering\n",
      "factors such as the need for fine-tuning, inference efficiency,\n",
      "and privacy protection.\n",
      "1) Generator Fine-tuning: In addition to direct LLM usage,\n",
      "targeted fine-tuning based on the scenario and data character-\n",
      "istics can yield better results. This is also one of the greatest\n",
      "advantages of using an on-premise setup LLMs.\n",
      "Instruct-Tuning. When LLMs lack data in a specific do-\n",
      "main, additional knowledge can be provided to the LLM\n",
      "through fine-tuning. General fine-tuning dataset can also be\n",
      "used as an initial step. Another benefit of fine-tuning is the\n",
      "ability to adjust the model’s input and output. For example, it\n",
      "can enable LLM to adapt to specific data formats and generate\n",
      "responses in a particular style as instructed [50].\n",
      "Reinforcement learning. Aligning LLM outputs with hu-\n",
      "man or retriever preferences through reinforcement learning is\n",
      "8\n",
      "a potential approach [51]. For instance, manually annotating\n",
      "the final generated answers and then providing feedback\n",
      "through reinforcement learning. In addition to aligning with\n",
      "human preferences, it is also possible to align with the\n",
      "preferences of fine-tuned models and retrievers.\n",
      "Dual Fine-tuing Fine-tuning both generator and retriever\n",
      "simultaneously to align their preferences. A typical approach,\n",
      "such as RA-DIT [27], aligns the scoring functions between\n",
      "retriever and generator using KL divergence. Retrieval likeli-\n",
      "hood of each retrieved document d is calculated as :\n",
      "PR(d|q) =\n",
      "e(sim(d,q))/γ\n",
      "P\n",
      "d∈Dq e(sim(d,q)/γ\n",
      "(15)\n",
      "PLM(y|d, q) is the LM probability of the ground truth output y\n",
      "given the input context d, question q, and γ is a hyperparamter.\n",
      "The overall loss is calculated as:\n",
      "L = 1\n",
      "|T|\n",
      "T\n",
      "X\n",
      "i=1\n",
      "KL(PR(d|q)||PLSR(d|q, y|))\n",
      "(16)\n",
      "2) Verification : Although RAG enhances the reliability\n",
      "of LLM-generated answers, in many scenarios, it requires to\n",
      "minimize the probability of hallucinations. Therefore, it can\n",
      "filter out responses that do not meet the required standards\n",
      "through additional verification module. Common verification\n",
      "methods include knowledge-base and model-base .\n",
      "yk = fverify(q, Dq, y)\n",
      "(17)\n",
      "Knowledge-base verification refers to directly validating the\n",
      "responses generated by LLMs through external knowledge.\n",
      "Generally, it extracts specific statements or triplets from re-\n",
      "sponse first. Then, relevant evidence is retrieved from verified\n",
      "knowledge base such as Wikipedia or specific knowledge\n",
      "graphs. Finally, each statement is incrementally compared with\n",
      "the evidence to determine whether the statement is supported,\n",
      "refuted, or if there is insufficient information [52].\n",
      "Model-based verification refers to using a small language\n",
      "model to verify the responses generated by LLMs [53].\n",
      "Given the input question, the retrieved knowledge, and the\n",
      "generated answer, a small language model is trained to de-\n",
      "termine whether the generated answer correctly reflects the\n",
      "retrieved knowledge. This process is framed as a multiple-\n",
      "choice question, where the verifier needs to judge whether the\n",
      "answer reflects correct answer . If the generated answer does\n",
      "not correctly reflect the retrieved knowledge, the answer can\n",
      "be iteratively regenerated until the verifier confirms that the\n",
      "answer is correct.\n",
      "F. Orchestration\n",
      "Orchestration pertains to the control modules that govern the\n",
      "RAG process. Unlike the traditional, rigid approach of a fixed\n",
      "process, RAG now incorporates decision-making at pivotal\n",
      "junctures and dynamically selects subsequent steps contingent\n",
      "upon the previous outcomes. This adaptive and modular ca-\n",
      "pability is a hallmark of modular RAG, distinguishing it from\n",
      "the more simplistic Naive and Advance RAG paradigm.\n",
      "1) Routing: In response to diverse queries, the RAG system\n",
      "routes to specific pipelines tailored for different scenario, a\n",
      "feature essential for a versatile RAG architecture designed\n",
      "to handle a wide array of situations. A decision-making\n",
      "mechanism is necessary to ascertain which modules will be\n",
      "engaged, based on the input from the model or supplementary\n",
      "metadata. Different routes are employed for distinct prompts\n",
      "or components. This routing mechanism is executed through\n",
      "a function, denoted as fr(·), which assigns a score αi to\n",
      "each module. These scores dictate the selection of the active\n",
      "subset of modules. Mathematically, the routing function is\n",
      "represented as:\n",
      "fr : Q →F\n",
      "(18)\n",
      "where fr(·) maps the identified query to its corresponding\n",
      "RAG flow.\n",
      "Metadata routing involves extracting key terms, or entities,\n",
      "from the query, applying a filtration process that uses these\n",
      "keywords and associated metadata within the chunks to refine\n",
      "the routing parameters. For a specific RAG flow, denoted as\n",
      "Fi, the pre-defined routing keywords are represented as the\n",
      "set Ki = {ki1, ki2, . . . , kin}. The keyword identified within\n",
      "the query qi is designated as K′\n",
      "i. The matching process for\n",
      "the query q is quantified by the key score equation:\n",
      "scorekey(qi, Fj) =\n",
      "1\n",
      "|K′\n",
      "j||Ki ∩K′\n",
      "j|\n",
      "(19)\n",
      "This equation calculates the overlap between the pre-defined\n",
      "keywords and those identified in the query, normalized by the\n",
      "count of keywords in K′\n",
      "j. The final step is to determine the\n",
      "most relevant flow for the query q:\n",
      "Fi(q) = argmaxFj∈Fscore(q, Fj)\n",
      "(20)\n",
      "Semantic routing routes to different modules based on the\n",
      "semantic information of the query. Given a pre-defined intent\n",
      "Θ = {θ1, θ2, . . . , θn}, the possibility of intent for query q is\n",
      "PΘ(θ|q) =\n",
      "ePLM (θ|q)\n",
      "P\n",
      "θ∈Θ ePLM (θ|q)) . Routing to specific RAG flow is\n",
      "determined by the semantic score:\n",
      "socresemantic(q, Fj) = argmaxθj∈ΘP(Θ)\n",
      "(21)\n",
      "The function δ(·) serves as a mapping function that assigns\n",
      "an intent to a distinct RAG flow Fi = δ(θi)\n",
      "Hybrid Routing can be implemented to improve query\n",
      "routing by integrating both semantic analysis and metadata-\n",
      "based approaches, which can be defined as follows:\n",
      "αi = a·scorekey(q, Fj)+(1−α)·maxθj∈Θsocresemantic(q, Fj)\n",
      "(22)\n",
      "a is a weighting factor that balances the contribution of the\n",
      "key-based score and the semantic score.\n",
      "2) Scheduling: The RAG system evolves in complexity\n",
      "and adaptability, with the ability to manage processes through\n",
      "a sophisticated scheduling module. The scheduling module\n",
      "plays a crucial role in the modular RAG , identifying critical\n",
      "junctures that require external data retrieval, assessing the\n",
      "adequacy of the responses, and deciding on the necessity for\n",
      "further investigation. It is commonly utilized in scenarios that\n",
      "involve recursive, iterative, and adaptive retrieval, ensuring\n",
      "9\n",
      "that the system makes informed decisions on when to cease\n",
      "generation or initiate a new retrieval loop.\n",
      "Rule judge. The subsequent steps are dictated by a set of\n",
      "established rules. Typically, the system evaluates the quality of\n",
      "generated answers through scoring mechanisms. The decision\n",
      "to proceed or halt the process is contingent upon whether these\n",
      "scores surpass certain predetermined thresholds, often related\n",
      "to the confidence levels of individual tokens, which can be\n",
      "defined as follow:\n",
      "yt =\n",
      "(\n",
      "ˆst\n",
      "if all tokens of ˆst have probs ≥τ\n",
      "st = LM([Dqt, x, y<t])\n",
      "otherwise\n",
      "Here, ˆst represents the tentative answer, and st is the output\n",
      "from the language model. The condition for accepting ˆst is that\n",
      "all tokens within it must have associated probabilities greater\n",
      "than or equal to the threshold τ. If this condition is not met,\n",
      "the system reverts to generating a new answer.\n",
      "LLM judge. The LLM independently determines the sub-\n",
      "sequent course of action. Two primary approaches facilitate\n",
      "this capability. The first method leverages LLM ’s in-context\n",
      "learning capability, and make judgments through prompt\n",
      "engineering. A significant advantage of this method is the\n",
      "elimination of model fine-tuning. Nonetheless, the format of\n",
      "the judgment output is contingent upon the LLM’s adherence\n",
      "to the provided instructions.\n",
      "The second approach involves the LLM generating specific\n",
      "tokens that initiate targeted actions through fine-tuning. This\n",
      "technique, with roots in the Toolformer [50], has been inte-\n",
      "grated into frameworks like Self-RAG [28]. This allows for a\n",
      "more direct control mechanism over the LLM’s actions, en-\n",
      "hancing the system’s responsiveness to specific triggers within\n",
      "the conversational context. However, it requires generating a\n",
      "large number of compliant instruction sets to fine-tune LLM.\n",
      "Knowledge-guide scheduling. Beyond the confines of rule-\n",
      "based methods and the complete reliance on LLMs for process\n",
      "control, a more adaptable intermediate approach emerges with\n",
      "knowledge-guided scheduling [26]. These methods harness\n",
      "the power of knowledge graphs, to steer the retrieval and\n",
      "generation processes. Specifically, it involves extracting infor-\n",
      "mation relevant to the question from a knowledge graph and\n",
      "constructing a reasoning chain. This reasoning chain consists\n",
      "of a series of logically interconnected nodes, each containing\n",
      "critical information for the problem-solving process. Based\n",
      "on the information from the nodes in this reasoning chain,\n",
      "information retrieval and content generation can be performed\n",
      "separately. By integrating this approach, it enhance not only\n",
      "the efficacy and precision of problem-solving but also the\n",
      "clarity of the explanations provided.\n",
      "3) Fusion: As RAG process has evolved beyond a linear\n",
      "pipeline, it frequently necessitates broadening the retrieval\n",
      "scope or enhancing diversity by exploring multiple pipelines.\n",
      "Consequently, after the expansion into various branches, the\n",
      "fusion module effectively integrates the information, ensuring\n",
      "a comprehensive and coherent response. The fusion module’s\n",
      "reliance is not just for merging answers but also for ensuring\n",
      "that the final output is both rich in content and reflective of\n",
      "the multifaceted nature of the inquiry.\n",
      "LLM fusion.One of the most straightforward methods for\n",
      "multi-branch aggregation is to leverage the powerful capa-\n",
      "bilities of LLMs to analyze and integrate information from\n",
      "different branches. However, this approach also faces some\n",
      "challenges, particularly when dealing with long answers that\n",
      "exceeds the LLM’s context window limitation. To mitigate this\n",
      "issue, it is common practice to first summarize each branch’s\n",
      "answer, extracting the key information before inputting it into\n",
      "the LLM, thus ensuring that the most important content is\n",
      "retained even within length constraints.\n",
      "Weighted ensemble\n",
      "is based on the weighted values of\n",
      "different tokens generated from multiple branches, leading to\n",
      "the comprehensive selection of the final output. This approach\n",
      "can be calculated as :\n",
      "p(y|q, Dq) =\n",
      "X\n",
      "d∈Dq\n",
      "p(y|d, q) · λ(d, q)\n",
      "(23)\n",
      "The weight λ(d, q) is determined by the similarity score\n",
      "between the document d and the input query q. This weight is\n",
      "calculated using the softmax function, which ensures that the\n",
      "weights are normalized and sum up to one.\n",
      "λ(d, q) =\n",
      "es(d,q)\n",
      "P\n",
      "d∈Dq es(d,q)\n",
      "(24)\n",
      "RRF (Reciprocal Rank Fusion) is an ensemble technique\n",
      "that synthesizes multiple retrieval result rankings into a co-\n",
      "hesive, unified list [54]. It employs a tailored weighted aver-\n",
      "aging approach to enhance collective predictive performance\n",
      "and ranking precision. The method’s strength is its dynamic\n",
      "weight assignment, which is informed by the interplay among\n",
      "branches. RRF is especially potent in scenarios characterized\n",
      "by model or source heterogeneity, where it can markedly\n",
      "amplify the accuracy of predictions.\n",
      "V. RAG FLOW AND FLOW PATTERN\n",
      "The collaboration between operators forms the workflow\n",
      "of the module, which we refer to as RAG flow F\n",
      "=\n",
      "(Mϕ1, . . . , Mϕn), where ϕ stands for the set of module param-\n",
      "eters. A modular rag flow can be decomposed into a graph of\n",
      "sub-functions. Through control logic, the operators can execute\n",
      "in a predetermined pipeline, while also performing conditional,\n",
      "branching or looping when necessary. In the simplest case. the\n",
      "graph is a linear chain.\n",
      "After conducting an in-depth analysis of current RAG meth-\n",
      "ods, we have identified a set of common RAG flow patterns,\n",
      "denoted as P. These patterns transcend various application\n",
      "domains and demonstrate a high level of consistency and\n",
      "reusability, revealing the prevalent structures and behaviors in\n",
      "process design. A RAG flow pattern can be defined as P =\n",
      "{Mϕ1 : {Op1} →Mϕ2 : {Op2} →. . . →Mϕn : {Opn}}\n",
      "A. Linear Pattern\n",
      "The modules in the modular RAG system are organized in\n",
      "a linear way, and can be described as Algorithm 1.\n",
      "Plinear = {M1 →M2 →. . . →Mn}\n",
      "(25)\n",
      "10\n",
      "Fig. 4.\n",
      "Linear RAG flow pattern. Each module is processed in a fixed\n",
      "sequential order.\n",
      "Fig. 5. RRR [24] is a typical linear flow that introduces a learnable query\n",
      "rewrite module before retrieval. This module employs reinforcement based on\n",
      "the output results of the LLM.\n",
      "The linear flow pattern is the simplest and most com-\n",
      "monly used pattern. As shown in Figure 4, the full linear\n",
      "RAG flow pattern mainly includes pre-retrieval processing,\n",
      "retrieval, post-retrieval processing, and generation modules.\n",
      "Plinearfull\n",
      "= {Mindexing\n",
      "→Mpre-retrieval\n",
      "→Mretrieval\n",
      "→\n",
      "Mpost-retrieval →Mgenerate}. If there are no pre-retrieval and\n",
      "post-retrieval modules, it follows the Naive RAG paradigm.\n",
      "Algorithm 1 Linear RAG Flow Pattern\n",
      "Require: original query q, documents D, retriever R, lan-\n",
      "guage model LLM, pre-processing function fpre, post-\n",
      "processing function fpost\n",
      "Ensure: final output ˆy\n",
      "1: Initialize:\n",
      "2: q′ ←fpre(q) // Pre-process the original query\n",
      "3: Dq′ ←R(q′, D) // Retrieve documents related to the pre-\n",
      "processed query\n",
      "4: ˆDq′ ←fpost(q′, Dq′) // Post-process the retrieved docu-\n",
      "ments\n",
      "5: ˆy ←LLM([q, ˆDq′]) // Generate output using the lan-\n",
      "guage model with the original query and post-processed\n",
      "documents\n",
      "6: return ˆy // Return the final output\n",
      "Common linear RAG flow involves a query transform\n",
      "module (such as rewrite or HyDE operators) at the pre-retrieval\n",
      "stage and utilize rerank at the post-retrieval stage. Rewrite-\n",
      "Retrieve-Read (RRR) [24] is a typical linear structure. As\n",
      "illustrated in Figure 5, the query rewrite module frewrite is a\n",
      "smaller trainable language model fine-tuned on T5-large, and\n",
      "in the context of reinforcement learning, the optimization of\n",
      "the rewriter is formalized as a Markov decision process, with\n",
      "the final output of the LLM serving as the reward. The retriever\n",
      "utilizes a sparse encoding model, BM25.\n",
      "B. Conditional Pattern\n",
      "The RAG flow with conditional structure involves select-\n",
      "ing different RAG pipeline based on different conditions,\n",
      "as illustrated in Figure 6. A detailed definition is shown in\n",
      "Algorithm 2. Typically, pipleline selection is accomplished\n",
      "Fig. 6. The conditional flow pattern. There is a routing module that controls\n",
      "which RAG flow the query is directed to. Typically, different flows are used for\n",
      "various configurations to meet the general requirements of the RAG system.\n",
      "Fig. 7.\n",
      "Pre-retrieval branching flow pattern.Each branch performs retrieval\n",
      "and generation separately, and then they are aggregated at the end.\n",
      "through a routing module that determines the next module\n",
      "in the flow.\n",
      "Pconditional = {Mi\n",
      "fr\n",
      "−→Mj ∨Mk}\n",
      "(26)\n",
      "Where\n",
      "fr\n",
      "−→represents that based on routing function fr(·), the\n",
      "flow can go to module Mj or Mk.\n",
      "Algorithm 2 Conditional RAG Flow Pattern\n",
      "Require: original query q, documents D, language model\n",
      "LM, retriever R, routing function fr\n",
      "Ensure: final output ˆy\n",
      "1: Initialize:\n",
      "2: q′ ←QueryTransform(q) // Pre-process the initial query\n",
      "if needed\n",
      "3: D′ ←R(q′, D) // Retrieve or update documents related\n",
      "to the query\n",
      "4: Mnext ←fr(q′, D′) // Determine the next module using\n",
      "the routing function\n",
      "5: if Mnext = Mj then\n",
      "6:\n",
      "ˆy ←Mj(q′, D′) // Execute module Mj\n",
      "7: else if Mnext = Mk then\n",
      "8:\n",
      "ˆy ←Mk(q′, D′) Mk\n",
      "9: end if\n",
      "10: return ˆy\n",
      "Pipeline selection is determined by the nature of the ques-\n",
      "tion, directing different flows tailored to specific scenarios. For\n",
      "example, the tolerance for responses generated by LLMs varies\n",
      "across questions related to serious issues, political matters,\n",
      "or entertainment topics. These routing flow often diverge in\n",
      "terms of retrieval sources, retrieval processes, configurations,\n",
      "models, and prompts.\n",
      "11\n",
      "Fig. 8. Post-retrieval branching flow pattern.Only one retrieval performed, and\n",
      "then generation is carried out separately for each retrieved document chunks,\n",
      "followed by aggregation.\n",
      "C. Branching\n",
      "In many cases, the RAG flow system may have multiple\n",
      "parallel running branches , usually to increase the diver-\n",
      "sity of generated results. Assuming multiple branches bi are\n",
      "generated in module B\n",
      "= Msplit(·) = {b1, b2, . . . , bm}.\n",
      "For each branch bi ∈B, the same or different RAG pro-\n",
      "cesses can be executed, passing through multiple processing\n",
      "modules {M1, M2, . . . , Mk} to obtain branch output result\n",
      "pi\n",
      "= Mik(. . . Mi2(Mi1(bi)) . . .). The results of multiple\n",
      "branches are aggregated using an aggregation function to\n",
      "obtain intermediate output results. ˆO = Mmerge({pi | bi ∈\n",
      "B}). However, aggregation is not necessarily the end of the\n",
      "RAG flow, as it can continue to connect to other modules,\n",
      "Mjn(. . . Mj2(Mj1( ˆO)) . . .). For example, after aggregating\n",
      "multiple model responses, they can continue through a val-\n",
      "idation module. Therefore, the entire branch flow pattern can\n",
      "be represented as:\n",
      "Pbranch =Mjn(. . . Mj1(Mmerge({Mik\n",
      "(. . . Mi1(bi) . . .) | bi ∈Msplit(q)})) . . .)\n",
      "(27)\n",
      "Algorithm 3 Pre-retrieval Branching Flow Pattern\n",
      "Require: original query q, documents D, query expand mod-\n",
      "ule Mexpand, retriever Mretrieve, language model LLM,\n",
      "merge module Mmerge\n",
      "Ensure: final output ˆy\n",
      "1: Initialize:\n",
      "2: Q′ ←Mexpand(q) // Expand the original query to multiple\n",
      "sub-queries\n",
      "3: for all q′\n",
      "i ∈Q′ do\n",
      "4:\n",
      "D′\n",
      "i ←Mretrieve(q′\n",
      "i, D) // Retrieve documents for each\n",
      "sub-query\n",
      "5:\n",
      "Gi ←∅// Initialize an empty set for generated results\n",
      "of the sub-query\n",
      "6:\n",
      "for all d′\n",
      "ij ∈D′\n",
      "i do\n",
      "7:\n",
      "yij ←LLM([q′\n",
      "i, d′\n",
      "ij]) // Generate results for each\n",
      "document of the sub-query\n",
      "8:\n",
      "Oi ←Oi ∪{yij} // Add generated results to the set\n",
      "9:\n",
      "end for\n",
      "10:\n",
      "ˆy ←Mmerge(Oi) // Merge generated results of the sub-\n",
      "query into the final result\n",
      "11: end for\n",
      "12: return ˆy\n",
      "The RAG flow with a branching structure differs from\n",
      "the conditional approach in that it involves multiple parallel\n",
      "branches, as opposed to selecting one branch from multiple\n",
      "options in the conditional approach. Structurally, it can be\n",
      "categorized into two types, which are depicted in Figure 7\n",
      "and Figure 8.\n",
      "Pre-Retrieval Branching (Multi-Query, Parallel Retrieval).\n",
      "As shown in Algorithm 3, the process involves initially taking\n",
      "a query q and expanding it through a module Mexpand to gen-\n",
      "erate multiple sub-queries Q′. Each sub-query q′\n",
      "i is then used\n",
      "to retrieve relevant documents via Mretrieve, forming document\n",
      "sets D′\n",
      "i. These document sets, along with the corresponding\n",
      "sub-queries, are fed into a generation module Mgenerate to\n",
      "produce a set of answers Gi. Ultimately, all these generated\n",
      "answers are combined using a merging module Mmerge to\n",
      "form the final result y. This entire flow can be mathematically\n",
      "represented as:\n",
      "Pbranchpre =Mmerge(q′\n",
      "i∈Mexpand(q){Mgenerate(q′\n",
      "i, d′\n",
      "ij) |\n",
      "d′\n",
      "ij ∈Mretrieve(q′\n",
      "i)})\n",
      "(28)\n",
      "Post-Retrieval Branching (Single Query, Parallel Genera-\n",
      "tion). As shown in Algorithm 4, in the post-retrieval branching\n",
      "pattern, the process starts with a single query q which is\n",
      "used to retrieve multiple document chunks through a retrieval\n",
      "module Mretrieve, resulting in a set of documents Dq. Each\n",
      "document dq\n",
      "i from this set is then independently processed by\n",
      "a generation module Mgenerate to produce a set of generated\n",
      "results G. These results are subsequently merged using a\n",
      "merge module Mmerge to form the final result y. The process\n",
      "can be succinctly represented as y = Mmerge(Oi), where Oi is\n",
      "the collection of all generated results from each document dq\n",
      "i\n",
      "in Dq. Therefore, the entire process can be represented as:\n",
      "Pbranchpost = Mmerge({Mgenerate(dq\n",
      "i ) | dq\n",
      "i ∈Mretrieve(q)})\n",
      "(29)\n",
      "Algorithm 4 Post-retrieval Branching Flow Pattern\n",
      "Require: original query q, documents D, retriever R, lan-\n",
      "guage model LLM, merge module Mmerge\n",
      "Ensure: final output ˆy\n",
      "1: Initialize:\n",
      "2: q′ ←fpre(q) // Pre-process the original query\n",
      "3: Dq′ ←R(q′, D) // Retrieve a set of documents based on\n",
      "the pre-processed query\n",
      "4: G ←∅// Initialize an empty set to store generated results\n",
      "5: for all di ∈Dq′ do\n",
      "6:\n",
      "yi ←LLM([q, di]) // Generate results independently\n",
      "for each document chunk using the language model\n",
      "7:\n",
      "Oi ←Oi ∪{yi} // Add the generated result to the set\n",
      "of results\n",
      "8: end for\n",
      "9: ˆy ←Mmerge(Oi) // Merge all generated results using the\n",
      "merge function\n",
      "10: return ˆy\n",
      "REPLUG [55] embodies a classic post-retrieval branching\n",
      "structure, wherein the probability of each token is predicted\n",
      "for each branch. Through weighted possibility ensemble, the\n",
      "different branches are aggregated, and the final generation\n",
      "12\n",
      "Fig. 9. The RAG flow in REPLUG [55], which follows a typical post-retrieval\n",
      "branching pattern. Each retrieved chunks undergoes parallel generation, and\n",
      "then they are aggregated using a weighted probability ensemble.\n",
      "result is used to fine-tune the retriever, known as Contriever,\n",
      "through feedback.\n",
      "D. Loop Pattern\n",
      "The RAG flow with a loop structure, as an important char-\n",
      "acteristic of Modular RAG, involves interdependent retrieval\n",
      "and generation steps. It typically includes a scheduling module\n",
      "for flow control. The modular RAG system can be abstracted\n",
      "as a directed graph G = (V, E), where V is the set of vertices\n",
      "representing the various modules Mi in the system, and E is\n",
      "the set of edges representing the control flow or data flow be-\n",
      "tween modules. If there is a vertex sequence Mi1, Mi2, ..., Min\n",
      "such that Min can reach Mi1 (i.e., Min →Mi1), then this\n",
      "RAG system forms a loop. If Mj is the successor module of\n",
      "Mi and Mi decides whether to return to Mj or a previous\n",
      "module Mk through a Judge module, it can be represented\n",
      "as: Mi\n",
      "Judge\n",
      "−−−→Mj\n",
      "or\n",
      "Mi\n",
      "Judge\n",
      "−−−→Mk where Mk is the\n",
      "predecessor module of Mj. If Mi return to Mj, it can be\n",
      "represented as: ∃Judge(Mi, Mj)\n",
      "s.t.\n",
      "(Mi, Mj) ∈E\n",
      "and\n",
      "Judge(Mi, Mj) = true. If the Judge module not to return\n",
      "to any previous module, it can be represented as: ∀Mi ∈\n",
      "V,\n",
      "Judge(Mi, Mj) = false for all Mj that are predecessors\n",
      "of Mi. Loop pattern can be further categorized into iterative,\n",
      "recursive, and adaptive (active) retrieval approaches.\n",
      "Iterative retrieval At times, a single retrieval and genera-\n",
      "tion may not effectively address complex questions requiring\n",
      "extensive knowledge. Therefore, an iterative approach can be\n",
      "used in RAG (see Algorithm 5), typically involving a fixed\n",
      "number of iterations for retrieval. At step t, given the query\n",
      "qt and the previous output sequence y<t = [y0, . . . , yt−1] ,\n",
      "iterations proceed under the condition that t is less than the\n",
      "maximum allowed iterations T. In each loop, it retrieves a\n",
      "document chunks Dt−1 using the last output yt−1 and the\n",
      "current query qt. Subsequently, a new output yt is generated.\n",
      "The continuation of the iteration is determined by a Judge\n",
      "module, which makes its decision based on the yt, y<t, qt,\n",
      "and the Dt−1.\n",
      "An\n",
      "exemplary\n",
      "case\n",
      "of\n",
      "iterative\n",
      "retrieval\n",
      "is\n",
      "ITER-\n",
      "RETGEN [56] (Figure 11), which iterates retrieval-augmented\n",
      "generation and generation-augmented retrieval. Retrieval-\n",
      "augmented generation outputs a response to a task input based\n",
      "on all retrieved knowledge. In each iteration, ITER-RETGEN\n",
      "leverages the model output from the previous iteration as a\n",
      "specific context to help retrieve more relevant knowledge.\n",
      "Fig. 10. Loop flow pattern. Typically, a RAG system performs multiple rounds\n",
      "of retrieval and generation. It can be categorized into three forms: iterative,\n",
      "recursive, and adaptive.\n",
      "Algorithm 5 Iterative RAG Flow Pattern\n",
      "Require: original query q, documents D, maximum iterative\n",
      "times T, language model LLM, retriever R, initial output\n",
      "y<1 = ∅\n",
      "Ensure: final output ˆy\n",
      "1: Initialize:\n",
      "2: qt ←q // Initialize query for the first iteration\n",
      "3: y<1 ←∅// Initialize previous outputs as empty\n",
      "4: t ←1 // Initialize iteration step\n",
      "5: while t ≤T do\n",
      "6:\n",
      "qt ←QueryTransform(y<t−1, qt−1) // Generate query\n",
      "based on previous output and original query\n",
      "7:\n",
      "Dt ←R(yt−1||qt, D) // Retrieve or update documents\n",
      "related to the current query\n",
      "8:\n",
      "yt ←LLM([y<t−1, qt, Dt]) // Generate output using\n",
      "the language model\n",
      "9:\n",
      "y<t ←[y<t−1, yt] // Update the list of previous outputs\n",
      "10:\n",
      "if Judge(yt, q) = false then\n",
      "11:\n",
      "break\n",
      "12:\n",
      "end if\n",
      "13:\n",
      "t ←t + 1 // Increment iteration step\n",
      "14: end while\n",
      "15: yfinal = synthesizeOutput(y≤t) // Synthesize final output\n",
      "from the list of outputs\n",
      "16: return ˆy\n",
      "13\n",
      "Fig. 11. ITER-RETGEN [56] is a typical iterative structure. Multiple rounds\n",
      "of retrieval and generation are performed within the limit of the maximum\n",
      "number of iterations.\n",
      "Termination of the loop is determined by a predefined number\n",
      "of iterations.\n",
      "Recursive retrieval The characteristic feature of recursive\n",
      "retrieval (see Algorithm 6), as opposed to iterative retrieval, is\n",
      "its clear dependency on the previous step and its continuous\n",
      "deepening of retrieval. Typically, it follows a tree-like structure\n",
      "and there is a clear termination mechanism as an exit condition\n",
      "for recursive retrieval. In RAG systems, recursive retrieval usu-\n",
      "ally involves query transform, relying on the newly rewritten\n",
      "query for each retrieval.\n",
      "Algorithm 6 Recursive RAG Flow Pattern\n",
      "Require: initial query q, document D, retriever R, language\n",
      "model LM, maximum recursive depth Kmax\n",
      "Ensure: final output ˆy\n",
      "1: Initialize:\n",
      "2:\n",
      "Q ←{q}\n",
      "3:\n",
      "k ←0 // Initialize recursion depth\n",
      "4: while Q ̸= ∅and k < Kmax do\n",
      "5:\n",
      "Q′ ←∅// To store queries for the next recursion level\n",
      "6:\n",
      "for all q ∈Q do\n",
      "7:\n",
      "Dq ←R(q, D) // Retrieve or update documents\n",
      "related to the current query\n",
      "8:\n",
      "Y\n",
      "←LM([q, Dq]) // Generate outputs using the\n",
      "language model\n",
      "9:\n",
      "Q′′ ←deriveNewQueries(q, Dq, Y ) // Derive new\n",
      "queries from generated outputs\n",
      "10:\n",
      "for all q′ ∈Q′′ do\n",
      "11:\n",
      "if q′ /∈Q′ and q′ /∈Q then\n",
      "12:\n",
      "Q′ ←Q′ ∪{q′}\n",
      "13:\n",
      "end if\n",
      "14:\n",
      "end for\n",
      "15:\n",
      "end for\n",
      "16:\n",
      "Q ←Q′ // Update the set of queries for the next\n",
      "recursion\n",
      "17:\n",
      "k ←k + 1 // Increment recursion depth\n",
      "18: end while\n",
      "19: ˆy = synthesizeOutput(Y ) // Synthesize final output from\n",
      "generated outputs\n",
      "20: return ˆy\n",
      "A typical implementation of recursive retrieval, such as\n",
      "ToC [13] (see Figure 12 ), involves recursively executing RAC\n",
      "(Recursive Augmented Clarification) to gradually insert sub-\n",
      "nodes into the clarification tree from the initial ambiguous\n",
      "question (AQ). At each expansion step, paragraph re-ranking\n",
      "is performed based on the current query to generate a disam-\n",
      "Fig. 12.\n",
      "RAG flow of ToC [13]. A typical characteristic of this process is\n",
      "that each recursive retrieval uses the new query generated from the previous\n",
      "step, thereby progressively deepening analysis of the original complex query.\n",
      "biguous Question (DQ). The exploration of the tree concludes\n",
      "upon reaching the maximum number of valid nodes or the\n",
      "maximum depth. Once the clarification tree is constructed,\n",
      "ToC gathers all valid nodes and generates a comprehensive\n",
      "long-text answer to address AQ.\n",
      "Adaptive (Active) retrieval With the advancement of RAG,\n",
      "there has been a gradual shift beyond passive retrieval to the\n",
      "emergence of adaptive retrieval (see Algorithm 7) , also known\n",
      "as active retrieval, which is partly attributed to the powerful\n",
      "capabilities of LLM. This shares a core concept with LLM\n",
      "Agent [57]. RAG systems can actively determine the timing\n",
      "of retrieval and decide when to conclude the entire process and\n",
      "produce the final result. Based on the criteria for judgment,\n",
      "this can be further categorized into Prompt-base and Tuning-\n",
      "base approaches.\n",
      "Algorithm 7 Active RAG Flow Pattern\n",
      "Require: original query Q, documents D, maximum iterative\n",
      "times T, language model LLM, retriever R\n",
      "Ensure: final output ˆy\n",
      "1: Initialize:\n",
      "2: t ←1 // Initialize loop step\n",
      "3: qt ←q // Initialize query for the first iteration\n",
      "4: y<1 ←∅// Initialize previous outputs as empty\n",
      "5: while t ≤T do\n",
      "6:\n",
      "Qt ←QueryTransform(y<t−1, qt−1) // Derive new\n",
      "query from previous output and query\n",
      "7:\n",
      "if Evaluate(Qt, y<t−1) then\n",
      "8:\n",
      "Dt ←R(qt, D) // Retrieve documents based on the\n",
      "new query\n",
      "9:\n",
      "yt ←LLM([qt, Dt]) // Generate output using the\n",
      "language model\n",
      "10:\n",
      "else\n",
      "11:\n",
      "yt ←∅// Set output as empty if query evaluation is\n",
      "false\n",
      "12:\n",
      "end if\n",
      "13:\n",
      "y<t ←[y<t−1, yt] // Update the list of previous outputs\n",
      "14:\n",
      "if isOutputAcceptable(yt, y<t, qt) = false then\n",
      "15:\n",
      "break // Break if the output is not acceptable\n",
      "16:\n",
      "end if\n",
      "17:\n",
      "t ←t + 1 // Increment iteration step\n",
      "18: end while\n",
      "19: ˆy = synthesizeOutput(y≤t) // Synthesize final output from\n",
      "the list of outputs\n",
      "20: return ˆy\n",
      "Prompt-base. The prompt-base approach involves control-\n",
      "ling the flow using Prompt Engineering to direct LLM. A\n",
      "14\n",
      "Fig. 13. RAG flow of FLARE [14]. The generated provisional answer will\n",
      "undergo confidence assessment. If it does not meet the required confidence\n",
      "level, the process will return to the retrieval stage and generate anew. The\n",
      "assessment criteria are implemented through prompt\n",
      "Fig. 14.\n",
      "RAG flow of SELF-RAG [28]. First, it prompt GPT-4 to obtain\n",
      "a suitable instruct fine-tuning dataset to fine-tune the deployed open-source\n",
      "LLM. This allows the model to output four specific tokens during generation,\n",
      "which are used to control the RAG process.\n",
      "typical implementation example is FLARE [14]. Its core\n",
      "concept is that LLMs should only retrieve when essential\n",
      "knowledge is lacking, to avoid unnecessary or inappropriate\n",
      "retrieval in an enhanced LM. FLARE iteratively generates the\n",
      "next provisional sentence and checks for the presence of low-\n",
      "probability tokens. If found, the system retrieves relevant docu-\n",
      "ments and regenerates the sentence. Tuning-base. The tuning-\n",
      "based approach involves fine-tuning LLM to generate special\n",
      "tokens, thereby triggering retrieval or generation. This concept\n",
      "can be traced back to Toolformer [50], where the generation of\n",
      "specific content assists in invoking tools. In RAG systems, this\n",
      "approach is used to control both retrieval and generation steps.\n",
      "A typical case is Self-RAG [28](see Figure 14). Given an\n",
      "input prompt and the preceding generation result, first predict\n",
      "whether the special token Retrieve is helpful for enhancing\n",
      "the continued generation through retrieval. Then, if retrieval\n",
      "is needed, the model generates a critique token to evaluate the\n",
      "retrieved passage’s relevance. and a critique token to evaluate\n",
      "if the information in the response is supported by the retrieved\n",
      "passage. Finally, a critique token evaluates the overall utility of\n",
      "the response and selects the optimal result as the final output.\n",
      "E. Tuning Pattern\n",
      "RAG is continuously integrating with more LLM-related\n",
      "technologies. In Modular RAG, many components are com-\n",
      "posed of trainable language models. Through fine-tuning, the\n",
      "performance of the components and the compatibility with\n",
      "the overall flow can be further optimized. This section will\n",
      "introduce three main patterns of fine-tuning stages, namely\n",
      "retriever fine-tuning, generator fine-tuning, and dual fine-\n",
      "tuning.\n",
      "Fig. 15.\n",
      "Retriever fine-tuning pattern, mainly includes direct SFT, adding\n",
      "trainable adapter, LM-supervised retrieval and LLM Reward RL.\n",
      "1) Retriever FT: In the RAG flow, common methods for\n",
      "fine-tuning the retriever is shown in Figure 15 ,which include:\n",
      "• Direct supervised fine-tuning of the retriever. Construct-\n",
      "ing a specialized dataset for retrieval and fine-tuning the\n",
      "dense retriever. For example, using open-source retrieval\n",
      "datasets or constructing one based on domain-specific\n",
      "data.\n",
      "• Adding trainable adapter modules. Sometimes, direct\n",
      "fine-tuning of the API-base embedding model (e.g., Ope-\n",
      "nAI Ada-002 and Cohere) is not feasible. Incorporating\n",
      "an adapter module can enhance the representation of\n",
      "your data. Additionally, the adapter module facilitates\n",
      "better alignment with downstream tasks, whether for task-\n",
      "specific (e.g., PRCA [42]) or general purposes (e.g.,\n",
      "AAR [58]).\n",
      "• LM-supervised Retrieval (LSR). Fine-tuning the retriever\n",
      "based on the results generated by LLM.\n",
      "• LLM Reward RL. Still using the LLM output results as\n",
      "the supervisory signal. Employing reinforcement learning\n",
      "to align the retriever with the generator. The whole re-\n",
      "trieval process is disassembled in the form of a generative\n",
      "Markov chain.\n",
      "2) Generator FT: The primary methods for fine-tuning a\n",
      "generator in RAG flow is shown in Figure 16, which include:\n",
      "• Direct supervised fine-tuning. Fine-tuning through an\n",
      "external dataset can supplement the generator with ad-\n",
      "ditional knowledge. Another benefit is the ability to\n",
      "customize input and output formats. By setting the Q&A\n",
      "format, LLM can understand specific data formats and\n",
      "output according to instructions.\n",
      "• Distillation. When using on-premise deployment of open-\n",
      "source models, a simple and effective Optimization\n",
      "method is to use GPT-4 to batch construct fine-tuning\n",
      "data to enhance the capabilities of the open-source model.\n",
      "• RL from LLM/human feedback. Reinforcement learning\n",
      "based on feedback from the final generated answers. In\n",
      "addition to using human evaluations, powerful LLMs can\n",
      "also serve as an evaluative judge.\n",
      "3) Dual FT: In the RAG system, fine-tuning both the\n",
      "retriever and the generator simultaneously is a unique feature\n",
      "of the RAG system. It is important to note that the emphasis\n",
      "of system fine-tuning is on the coordination between the\n",
      "retriever and the generator. An exemplary implementation is\n",
      "RA-DIT [27], which fine-tunes both the LLM and the retriever.\n",
      "The LM-ft component updates the LLM to maximize the\n",
      "15\n",
      "Fig. 16.\n",
      "Generator fine-tuning pattern, The main methods include SFT,\n",
      "distillation and RL from LLM/human feedback.\n",
      "Fig. 17.\n",
      "Dual fine-tuning pattern. In this mode, both the retriever and\n",
      "generator participate in fine-tuning, and their preferences will be aligned.\n",
      "likelihood of the correct answer given the retrieval-augmented\n",
      "instructions while the R-ft component updates the retriever\n",
      "to minimize the KL-Divergence between the retriever score\n",
      "distribution and the LLM preference.\n",
      "VI. DISCUSSION\n",
      "In this chapter, we explore the innovative horizons opened\n",
      "by the modular RAG paradigm. We examine its compatibility\n",
      "with cutting-edge methodologies in the progression of RAG\n",
      "technology, emphasizing its scalability. It not only fosters a\n",
      "fertile ground for model innovation but also paves the way for\n",
      "seamless adaptation to the dynamic requirements of various\n",
      "applications.\n",
      "A. Opportunities in Modular RAG\n",
      "The benefits of Modular RAG are evident, providing a\n",
      "fresh and comprehensive perspective on existing RAG-related\n",
      "work. Through modular organization, relevant technologies\n",
      "and methods are clearly summarized.\n",
      "From a research perspective. Modular RAG is highly\n",
      "scalable, it empowers researchers to introduce innovative mod-\n",
      "ules and operators, leveraging a deep understanding of RAG’s\n",
      "evolving landscape. This flexibility enables the exploration of\n",
      "new theoretical and practical dimensions in the field.\n",
      "From an application perspective. The modularity of RAG\n",
      "systems simplifies their design and implementation. Users can\n",
      "tailor RAG flows to fit their specific data, use cases, and\n",
      "downstream tasks, enhancing the adaptability of the system\n",
      "to diverse requirements. Developers can draw from existing\n",
      "flow architectures and innovate by defining new flows and\n",
      "patterns that are tailored to various application contexts and\n",
      "domains. This approach not only streamlines the development\n",
      "process but also enriches the functionality and versatility of\n",
      "RAG applications.\n",
      "B. Compatibility with new methods\n",
      "Modular RAG paradigm demonstrates exceptional compati-\n",
      "bility with new developments. To gain a deeper understanding\n",
      "of this, we list three typical scalability cases, which clearly\n",
      "shows that Modular RAG paradigm provides robust support\n",
      "and flexibility for the innovation and development of RAG\n",
      "technology.\n",
      "1) Recombination of the current modules: In this scenario,\n",
      "no new modules or operators are proposed; rather, specific\n",
      "problems are addressed through the combination of existing\n",
      "modules.DR-RAG [59] employs a two-stage retrieval strategy\n",
      "and classifier selection mechanism, incorporating a branching\n",
      "retrieval structure. In the first stage, retrieving chunks relevant\n",
      "to the query. In the second stage, the query is combined\n",
      "individually with each chunk retrieved in the first stage, and a\n",
      "parallel secondary retrieval is conducted. The retrieved content\n",
      "is then input into a classifier to filter out the most relevant\n",
      "dynamic documents. This ensures that the retrieved documents\n",
      "are highly relevant to the query while reducing redundant\n",
      "information. DR-RAG improved retrieval method significantly\n",
      "enhances the accuracy and efficiency of answers, bolstering\n",
      "RAG’s performance in multi-hop question-answering scenar-\n",
      "ios.\n",
      "2) New flow without adding new operators.: This refers\n",
      "to redesigning the processes for retrieval and generation to\n",
      "address more complex scenarios without proposing new mod-\n",
      "ules. The core idea of PlanRAG [18] lies in its introduction of\n",
      "a preliminary planning stage, a crucial step that occurs before\n",
      "retrieval and generation. Initially, the system employs a judge\n",
      "module to assess whether the current context necessitates the\n",
      "formulation of a new plan or adjustments to an existing one.\n",
      "When encountering a problem for the first time, the system\n",
      "initiates the planning process, while in subsequent interactions,\n",
      "it decides whether to execute re-planning based on previous\n",
      "plans and retrieved data.\n",
      "Next, the system devises an execution plan tailored to the\n",
      "query, treating this process as a logical decomposition of\n",
      "complex queries. Specifically, PlanRAG uses a query expan-\n",
      "sion module to extend and refine the query. For each derived\n",
      "sub-query, the system conducts targeted retrieval. Following\n",
      "retrieval, another judge module evaluates the current results to\n",
      "decide whether further retrieval is required or if it should return\n",
      "to the planning stage for re-planning. Through this strategy,\n",
      "PlanRAG is able to handle complex decision-making problems\n",
      "that require multi-step data analysis more efficiently.\n",
      "3) New flow derived from new operators.: New operators\n",
      "often introduce novel flow design, exemplified by Multi-Head\n",
      "RAG [60]. Existing RAG solutions do not focus on queries that\n",
      "may require retrieving multiple documents with significantly\n",
      "different content. Such queries are common but difficult to\n",
      "handle because embeddings of these documents may be far\n",
      "apart in the embedding space. Multi-Head RAG addresses this\n",
      "by designing a new retriever that uses the activations of the\n",
      "multi-head attention layers of the Transformer, rather than the\n",
      "decoder layers, as keys for retrieving multifaceted documents.\n",
      "Different attention heads can learn to capture different aspects\n",
      "of the data. By using the corresponding activation results,\n",
      "embeddings that represent different aspects of the data items\n",
      "and the query can be generated, thereby enhancing the retrieval\n",
      "accuracy for complex queries.\n",
      "16\n",
      "VII. CONCLUSION\n",
      "RAG is emerging as a pivotal technology for LLM applica-\n",
      "tions. As technological landscapes evolve and the intricacies of\n",
      "application requirements escalate, RAG systems are being en-\n",
      "hanced by integrating a diverse suite of technologies, thereby\n",
      "achieving a higher level of complexity and functionality. This\n",
      "paper introduces the innovative paradigm of Modular RAG.\n",
      "This approach systematically disassembles the complex archi-\n",
      "tecture of RAG systems into well-defined, discrete functional\n",
      "modules. Each module is meticulously characterized by its\n",
      "specific operational functions, ensuring clarity and precision.\n",
      "Therefore, the entire system is composed of those modules\n",
      "and operators, akin to Lego bricks. By conducting an in-\n",
      "depth analysis of numerous studies, the paper also distills\n",
      "common RAG design patterns and scrutinizes key case studies\n",
      "to illustrate these patterns in practice.\n",
      "Modular RAG not only offers a structured framework for\n",
      "the design and application of RAG systems but also en-\n",
      "ables a scenario-based customization of these systems. The\n",
      "modularity inherent in this design facilitates ease of tracking\n",
      "and debugging, significantly enhancing the maintainability and\n",
      "scalability of RAG systems. Furthermore, Modular RAG opens\n",
      "up new avenues for the future progression of RAG technology.\n",
      "It encourages the innovation of novel functional modules and\n",
      "the crafting of innovative workflows, thereby driving forward\n",
      "the frontiers of RAG systems.\n",
      "REFERENCES\n",
      "[1] Y. Zhang, Y. Li, L. Cui, D. Cai, L. Liu, T. Fu, X. Huang, E. Zhao,\n",
      "Y. Zhang, Y. Chen et al., “Siren’s song in the ai ocean: A survey on hal-\n",
      "lucination in large language models,” arXiv preprint arXiv:2309.01219,\n",
      "2023.\n",
      "[2] Y. Gao, Y. Xiong, X. Gao, K. Jia, J. Pan, Y. Bi, Y. Dai, J. Sun, and\n",
      "H. Wang, “Retrieval-augmented generation for large language models:\n",
      "A survey,” arXiv preprint arXiv:2312.10997, 2023.\n",
      "[3] Z. Xu, M. J. Cruz, M. Guevara, T. Wang, M. Deshpande, X. Wang,\n",
      "and Z. Li, “Retrieval-augmented generation with knowledge graphs\n",
      "for customer service question answering,” in Proceedings of the 47th\n",
      "International ACM SIGIR Conference on Research and Development in\n",
      "Information Retrieval, 2024, pp. 2905–2909.\n",
      "[4] C. Zhang, S. Wu, H. Zhang, T. Xu, Y. Gao, Y. Hu, and E. Chen,\n",
      "“Notellm: A retrievable large language model for note recommendation,”\n",
      "in Companion Proceedings of the ACM on Web Conference 2024, 2024,\n",
      "pp. 170–179.\n",
      "[5] R. Anantha, T. Bethi, D. Vodianik, and S. Chappidi, “Context tuning\n",
      "for retrieval augmented generation,” arXiv preprint arXiv:2312.05708,\n",
      "2023.\n",
      "[6] Y. Gao, T. Sheng, Y. Xiang, Y. Xiong, H. Wang, and J. Zhang, “Chat-\n",
      "rec: Towards interactive and explainable llms-augmented recommender\n",
      "system,” arXiv preprint arXiv:2303.14524, 2023.\n",
      "[7] J. Liu, “Building production-ready rag applications,” https://www.ai.\n",
      "engineer/summit/schedule/building-production-ready-rag-applications,\n",
      "2023.\n",
      "[8] D. S. Asudani, N. K. Nagwani, and P. Singh, “Impact of word embedding\n",
      "models on text analytics in deep learning environment: a review,”\n",
      "Artificial intelligence review, vol. 56, no. 9, pp. 10 345–10 425, 2023.\n",
      "[9] F. Cuconasu, G. Trappolini, F. Siciliano, S. Filice, C. Campagnano,\n",
      "Y. Maarek, N. Tonellotto, and F. Silvestri, “The power of noise:\n",
      "Redefining retrieval for rag systems,” arXiv preprint arXiv:2401.14887,\n",
      "2024.\n",
      "[10] W. Peng, G. Li, Y. Jiang, Z. Wang, D. Ou, X. Zeng, E. Chen et al.,\n",
      "“Large language model based long-tail query rewriting in taobao search,”\n",
      "arXiv preprint arXiv:2311.03758, 2023.\n",
      "[11] Y. Xi, J. Lin, W. Liu, X. Dai, W. Zhang, R. Zhang, R. Tang, and\n",
      "Y. Yu, “A bird’s-eye view of reranking: from list level to page level,”\n",
      "in Proceedings of the Sixteenth ACM International Conference on Web\n",
      "Search and Data Mining, 2023, pp. 1075–1083.\n",
      "[12] Z. Feng, X. Feng, D. Zhao, M. Yang, and B. Qin, “Retrieval-\n",
      "generation synergy augmented large language models,” arXiv preprint\n",
      "arXiv:2310.05149, 2023.\n",
      "[13] G. Kim, S. Kim, B. Jeon, J. Park, and J. Kang, “Tree of clarifica-\n",
      "tions: Answering ambiguous questions with retrieval-augmented large\n",
      "language models,” arXiv preprint arXiv:2310.14696, 2023.\n",
      "[14] Z. Jiang, F. F. Xu, L. Gao, Z. Sun, Q. Liu, J. Dwivedi-Yu, Y. Yang,\n",
      "J. Callan, and G. Neubig, “Active retrieval augmented generation,” arXiv\n",
      "preprint arXiv:2305.06983, 2023.\n",
      "[15] D. Edge, H. Trinh, N. Cheng, J. Bradley, A. Chao, A. Mody, S. Truitt,\n",
      "and J. Larson, “From local to global: A graph rag approach to query-\n",
      "focused summarization,” arXiv preprint arXiv:2404.16130, 2024.\n",
      "[16] Q. Leng, K. Uhlenhuth, and A. Polyzotis, “Best practices for\n",
      "llm evaluation of rag applications,” https://www.databricks.com/blog/\n",
      "LLM-auto-eval-best-practices-RAG, 2023.\n",
      "[17] X. Wang, Z. Wang, X. Gao, F. Zhang, Y. Wu, Z. Xu, T. Shi, Z. Wang,\n",
      "S. Li, Q. Qian et al., “Searching for best practices in retrieval-augmented\n",
      "generation,” arXiv preprint arXiv:2407.01219, 2024.\n",
      "[18] M. Lee, S. An, and M.-S. Kim, “Planrag: A plan-then-retrieval aug-\n",
      "mented generation for generative large language models as decision\n",
      "makers,” arXiv preprint arXiv:2406.12430, 2024.\n",
      "[19] D. Arora, A. Kini, S. R. Chowdhury, N. Natarajan, G. Sinha, and\n",
      "A. Sharma, “Gar-meets-rag paradigm for zero-shot information re-\n",
      "trieval,” arXiv preprint arXiv:2310.20158, 2023.\n",
      "[20] P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal,\n",
      "H. K¨uttler, M. Lewis, W.-t. Yih, T. Rockt¨aschel et al., “Retrieval-\n",
      "augmented generation for knowledge-intensive nlp tasks,” Advances in\n",
      "Neural Information Processing Systems, vol. 33, pp. 9459–9474, 2020.\n",
      "[21] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Milli-\n",
      "can, G. B. Van Den Driessche, J.-B. Lespiau, B. Damoc, A. Clark et al.,\n",
      "“Improving language models by retrieving from trillions of tokens,” in\n",
      "International conference on machine learning. PMLR, 2022, pp. 2206–\n",
      "2240.\n",
      "[22] G. Izacard, P. Lewis, M. Lomeli, L. Hosseini, F. Petroni, T. Schick,\n",
      "J. Dwivedi-Yu, A. Joulin, S. Riedel, and E. Grave, “Few-shot\n",
      "learning with retrieval augmented language models,” arXiv preprint\n",
      "arXiv:2208.03299, 2022.\n",
      "[23] H. Trivedi, N. Balasubramanian, T. Khot, and A. Sabharwal, “Interleav-\n",
      "ing retrieval with chain-of-thought reasoning for knowledge-intensive\n",
      "multi-step questions,” arXiv preprint arXiv:2212.10509, 2022.\n",
      "[24] X. Ma, Y. Gong, P. He, H. Zhao, and N. Duan, “Query rewrit-\n",
      "ing for retrieval-augmented large language models,” arXiv preprint\n",
      "arXiv:2305.14283, 2023.\n",
      "[25] N. Anderson, C. Wilson, and S. D. Richardson, “Lingua: Addressing\n",
      "scenarios for live interpretation and automatic dubbing,” in Proceedings\n",
      "of the 15th Biennial Conference of the Association for Machine\n",
      "Translation in the Americas (Volume 2: Users and Providers Track and\n",
      "Government Track), J. Campbell, S. Larocca, J. Marciano, K. Savenkov,\n",
      "and A. Yanishevsky, Eds.\n",
      "Orlando, USA: Association for Machine\n",
      "Translation in the Americas, Sep. 2022, pp. 202–209. [Online].\n",
      "Available: https://aclanthology.org/2022.amta-upg.14\n",
      "[26] L. Luo, Y.-F. Li, G. Haffari, and S. Pan, “Reasoning on graphs: Faith-\n",
      "ful and interpretable large language model reasoning,” arXiv preprint\n",
      "arXiv:2310.01061, 2023.\n",
      "[27] X. V. Lin, X. Chen, M. Chen, W. Shi, M. Lomeli, R. James, P. Rodriguez,\n",
      "J. Kahn, G. Szilvasy, M. Lewis et al., “Ra-dit: Retrieval-augmented dual\n",
      "instruction tuning,” arXiv preprint arXiv:2310.01352, 2023.\n",
      "[28] A. Asai, Z. Wu, Y. Wang, A. Sil, and H. Hajishirzi, “Self-rag: Learning\n",
      "to retrieve, generate, and critique through self-reflection,” arXiv preprint\n",
      "arXiv:2310.11511, 2023.\n",
      "[29] Y. Huang and J. Huang, “A survey on retrieval-augmented text gen-\n",
      "eration for large language models,” arXiv preprint arXiv:2404.10981,\n",
      "2024.\n",
      "[30] Y. Hu and Y. Lu, “Rag and rau: A survey on retrieval-augmented\n",
      "language model in natural language processing,” arXiv preprint\n",
      "arXiv:2404.19543, 2024.\n",
      "[31] Y. Ding, W. Fan, L. Ning, S. Wang, H. Li, D. Yin, T.-S. Chua, and\n",
      "Q. Li, “A survey on rag meets llms: Towards retrieval-augmented large\n",
      "language models,” arXiv preprint arXiv:2405.06211, 2024.\n",
      "[32] P. Zhao, H. Zhang, Q. Yu, Z. Wang, Y. Geng, F. Fu, L. Yang, W. Zhang,\n",
      "and B. Cui, “Retrieval-augmented generation for ai-generated content:\n",
      "A survey,” arXiv preprint arXiv:2402.19473, 2024.\n",
      "[33] S.\n",
      "Yang,\n",
      "“Advanced\n",
      "rag\n",
      "01:\n",
      "Small-to-\n",
      "big\n",
      "retrieval,”\n",
      "https://towardsdatascience.com/\n",
      "advanced-rag-01-small-to-big-retrieval-172181b396d4, 2023.\n",
      "17\n",
      "[34] Y. Wang, N. Lipka, R. A. Rossi, A. Siu, R. Zhang, and T. Derr,\n",
      "“Knowledge graph prompting for multi-document question answering,”\n",
      "arXiv preprint arXiv:2308.11730, 2023.\n",
      "[35] D. Zhou, N. Sch¨arli, L. Hou, J. Wei, N. Scales, X. Wang, D. Schu-\n",
      "urmans, C. Cui, O. Bousquet, Q. Le et al., “Least-to-most prompting\n",
      "enables complex reasoning in large language models,” arXiv preprint\n",
      "arXiv:2205.10625, 2022.\n",
      "[36] S. Dhuliawala, M. Komeili, J. Xu, R. Raileanu, X. Li, A. Celikyilmaz,\n",
      "and J. Weston, “Chain-of-verification reduces hallucination in large\n",
      "language models,” arXiv preprint arXiv:2309.11495, 2023.\n",
      "[37] L. Gao, X. Ma, J. Lin, and J. Callan, “Precise zero-shot dense retrieval\n",
      "without relevance labels,” arXiv preprint arXiv:2212.10496, 2022.\n",
      "[38] H. S. Zheng, S. Mishra, X. Chen, H.-T. Cheng, E. H. Chi, Q. V. Le,\n",
      "and D. Zhou, “Take a step back: Evoking reasoning via abstraction in\n",
      "large language models,” arXiv preprint arXiv:2310.06117, 2023.\n",
      "[39] H. Cao, “Recent advances in text embedding: A comprehensive review\n",
      "of top-performing methods on the mteb benchmark,” arXiv preprint\n",
      "arXiv:2406.01607, 2024.\n",
      "[40] BAAI, “Flagembedding,” https://github.com/FlagOpen/FlagEmbedding,\n",
      "2023.\n",
      "[41] Z. Li, X. Zhang, Y. Zhang, D. Long, P. Xie, and M. Zhang, “Towards\n",
      "general text embeddings with multi-stage contrastive learning,” arXiv\n",
      "preprint arXiv:2308.03281, 2023.\n",
      "[42] H. Yang, Z. Li, Y. Zhang, J. Wang, N. Cheng, M. Li, and J. Xiao,\n",
      "“Prca: Fitting black-box large language models for retrieval question an-\n",
      "swering via pluggable reward-driven contextual adapter,” arXiv preprint\n",
      "arXiv:2310.18347, 2023.\n",
      "[43] N. F. Liu, K. Lin, J. Hewitt, A. Paranjape, M. Bevilacqua, F. Petroni, and\n",
      "P. Liang, “Lost in the middle: How language models use long contexts,”\n",
      "arXiv preprint arXiv:2307.03172, 2023.\n",
      "[44] Y. Lyu, Z. Li, S. Niu, F. Xiong, B. Tang, W. Wang, H. Wu, H. Liu,\n",
      "T. Xu, and E. Chen, “Crud-rag: A comprehensive chinese benchmark\n",
      "for retrieval-augmented generation of large language models,” arXiv\n",
      "preprint arXiv:2401.17043, 2024.\n",
      "[45] L. Xia, J. Xu, Y. Lan, J. Guo, and X. Cheng, “Learning maximal\n",
      "marginal relevance model via directly optimizing diversity evaluation\n",
      "measures,” in Proceedings of the 38th international ACM SIGIR con-\n",
      "ference on research and development in information retrieval, 2015, pp.\n",
      "113–122.\n",
      "[46] Cohere, “Say goodbye to irrelevant search results: Cohere rerank is\n",
      "here,” https://txt.cohere.com/rerank/, 2023.\n",
      "[47] H. Jiang, Q. Wu, X. Luo, D. Li, C.-Y. Lin, Y. Yang, and L. Qiu,\n",
      "“Longllmlingua: Accelerating and enhancing llms in long context sce-\n",
      "narios via prompt compression,” arXiv preprint arXiv:2310.06839, 2023.\n",
      "[48] R. Litman, O. Anschel, S. Tsiper, R. Litman, S. Mazor, and R. Man-\n",
      "matha, “Scatter: selective context attentional scene text recognizer,” in\n",
      "proceedings of the IEEE/CVF conference on computer vision and pattern\n",
      "recognition, 2020, pp. 11 962–11 972.\n",
      "[49] J. Cui, Z. Li, Y. Yan, B. Chen, and L. Yuan, “Chatlaw: Open-source\n",
      "legal large language model with integrated external knowledge bases,”\n",
      "arXiv preprint arXiv:2306.16092, 2023.\n",
      "[50] T. Schick, J. Dwivedi-Yu, R. Dess`ı, R. Raileanu, M. Lomeli, L. Zettle-\n",
      "moyer, N. Cancedda, and T. Scialom, “Toolformer: Language models\n",
      "can teach themselves to use tools,” arXiv preprint arXiv:2302.04761,\n",
      "2023.\n",
      "[51] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin,\n",
      "C. Zhang, S. Agarwal, K. Slama, A. Ray et al., “Training language\n",
      "models to follow instructions with human feedback,” Advances in neural\n",
      "information processing systems, vol. 35, pp. 27 730–27 744, 2022.\n",
      "[52] S. J. Semnani, V. Z. Yao, H. C. Zhang, and M. S. Lam, “Wikichat:\n",
      "Stopping the hallucination of large language model chatbots by few-\n",
      "shot grounding on wikipedia,” arXiv preprint arXiv:2305.14292, 2023.\n",
      "[53] J.\n",
      "Baek,\n",
      "S.\n",
      "Jeong,\n",
      "M.\n",
      "Kang,\n",
      "J.\n",
      "C.\n",
      "Park,\n",
      "and\n",
      "S.\n",
      "J.\n",
      "Hwang,\n",
      "“Knowledge-augmented language model verification,” arXiv preprint\n",
      "arXiv:2310.12836, 2023.\n",
      "[54] G. V. Cormack, C. L. Clarke, and S. Buettcher, “Reciprocal rank\n",
      "fusion outperforms condorcet and individual rank learning methods,”\n",
      "in Proceedings of the 32nd international ACM SIGIR conference on\n",
      "Research and development in information retrieval, 2009, pp. 758–759.\n",
      "[55] W. Shi, S. Min, M. Yasunaga, M. Seo, R. James, M. Lewis, L. Zettle-\n",
      "moyer, and W.-t. Yih, “Replug: Retrieval-augmented black-box language\n",
      "models,” arXiv preprint arXiv:2301.12652, 2023.\n",
      "[56] Z. Shao, Y. Gong, Y. Shen, M. Huang, N. Duan, and W. Chen,\n",
      "“Enhancing retrieval-augmented large language models with iterative\n",
      "retrieval-generation synergy,” arXiv preprint arXiv:2305.15294, 2023.\n",
      "[57] S. Hong, X. Zheng, J. Chen, Y. Cheng, J. Wang, C. Zhang, Z. Wang,\n",
      "S. K. S. Yau, Z. Lin, L. Zhou et al., “Metagpt: Meta programming for\n",
      "multi-agent collaborative framework,” arXiv preprint arXiv:2308.00352,\n",
      "2023.\n",
      "[58] Z. Yu, C. Xiong, S. Yu, and Z. Liu, “Augmentation-adapted retriever\n",
      "improves generalization of language models as generic plug-in,” arXiv\n",
      "preprint arXiv:2305.17331, 2023.\n",
      "[59] Z. Hei, W. Wei, W. Ou, J. Qiao, J. Jiao, Z. Zhu, and G. Song,\n",
      "“Dr-rag: Applying dynamic document relevance to retrieval-augmented\n",
      "generation for question-answering,” arXiv preprint arXiv:2406.07348,\n",
      "2024.\n",
      "[60] M. Besta, A. Kubicek, R. Niggli, R. Gerstenberger, L. Weitzen-\n",
      "dorf, M. Chi, P. Iff, J. Gajda, P. Nyczyk, J. M¨uller et al., “Multi-\n",
      "head rag: Solving multi-aspect problems with llms,” arXiv preprint\n",
      "arXiv:2406.05085, 2024.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb309ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'Entry ID': 'http://arxiv.org/abs/2407.21059v1', 'Published': datetime.date(2024, 7, 26), 'Title': 'Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks', 'Authors': 'Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang'}, page_content='Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\\nof Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\\nincreasing demands of application scenarios have driven the evolution of RAG,\\nleading to the integration of advanced retrievers, LLMs and other complementary\\ntechnologies, which in turn has amplified the intricacy of RAG systems.\\nHowever, the rapid advancements are outpacing the foundational RAG paradigm,\\nwith many methods struggling to be unified under the process of\\n\"retrieve-then-generate\". In this context, this paper examines the limitations\\nof the existing RAG paradigm and introduces the modular RAG framework. By\\ndecomposing complex RAG systems into independent modules and specialized\\noperators, it facilitates a highly reconfigurable framework. Modular RAG\\ntranscends the traditional linear architecture, embracing a more advanced\\ndesign that integrates routing, scheduling, and fusion mechanisms. Drawing on\\nextensive research, this paper further identifies prevalent RAG\\npatterns-linear, conditional, branching, and looping-and offers a comprehensive\\nanalysis of their respective implementation nuances. Modular RAG presents\\ninnovative opportunities for the conceptualization and deployment of RAG\\nsystems. Finally, the paper explores the potential emergence of new operators\\nand paradigms, establishing a solid theoretical foundation and a practical\\nroadmap for the continued evolution and practical deployment of RAG\\ntechnologies.')]\n"
     ]
    }
   ],
   "source": [
    "# 논문 요약만 조회\n",
    "summary_docs = loader.get_summaries_as_docs()\n",
    "print(summary_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fce9a191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Entry ID': 'http://arxiv.org/abs/2407.21059v1',\n",
       " 'Published': datetime.date(2024, 7, 26),\n",
       " 'Title': 'Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks',\n",
       " 'Authors': 'Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdcac9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\n",
      "of Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\n",
      "increasing demands of application scenarios have driven the evolution of RAG,\n",
      "leading to the integration of advanced retrievers, LLMs and other complementary\n",
      "technologies, which in turn has amplified the intricacy of RAG systems.\n",
      "However, the rapid advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process of\n",
      "\"retrieve-then-generate\". In this context, this paper examines the limitations\n",
      "of the existing RAG paradigm and introduces the modular RAG framework. By\n",
      "decomposing complex RAG systems into independent modules and specialized\n",
      "operators, it facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a more advanced\n",
      "design that integrates routing, scheduling, and fusion mechanisms. Drawing on\n",
      "extensive research, this paper further identifies prevalent RAG\n",
      "patterns-linear, conditional, branching, and looping-and offers a comprehensive\n",
      "analysis of their respective implementation nuances. Modular RAG presents\n",
      "innovative opportunities for the conceptualization and deployment of RAG\n",
      "systems. Finally, the paper explores the potential emergence of new operators\n",
      "and paradigms, establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment of RAG\n",
      "technologies.\n"
     ]
    }
   ],
   "source": [
    "print(summary_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a984953e",
   "metadata": {},
   "source": [
    "### Docling\n",
    "- IBM Research에서 개발한 오픈소스 문서처리 도구로 다양한 종류의 문서를 구조화된 데이터로 변환해 생성형 AI에서 활용할 수있도록 지원한다.\n",
    "- **주요기능**\n",
    "  - PDF, DOCX, PPTX, XLSX, HTML, 이미지 등 여러 형식을 지원\n",
    "  - PDF의 **페이지 레이아웃, 읽기 순서, 표 구조, 코드, 수식** 등을 분석하여 정확하게 읽어들인다.\n",
    "  - OCR을 지원하여 스캔된 PDF나 이미지에서 텍스트를 추출할 수있다.\n",
    "  - 읽어들인 내용을 markdown, html, json등 다양한 형식으로 출력해준다.\n",
    "- 설치 : `pip install langchain-docling ipywidgets -qU` \n",
    "- 참조\n",
    "  - docling 사이트: https://github.com/docling-project/docling\n",
    "  - 랭체인-docling https://python.langchain.com/docs/integrations/document_loaders/docling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "406c0672-a932-4b55-bc39-1863e00ef3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for docling-parse \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[45 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m python prefix:  /Users/giwonjun/anaconda3/envs/lang_env\n",
      "  \u001b[31m   \u001b[0m python executable:  /Users/giwonjun/anaconda3/envs/lang_env/bin/python\n",
      "  \u001b[31m   \u001b[0m pybind11_cmake_dir='/private/var/folders/69/bt3_5fns57n_cp5_ydbrhfh80000gn/T/pip-build-env-amkign5y/overlay/lib/python3.12/site-packages/pybind11/share/cmake/pybind11'\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m launch: cmake -B /private/var/folders/69/bt3_5fns57n_cp5_ydbrhfh80000gn/T/pip-install-9hsqglry/docling-parse_2829d61d0ebb4c62a4104b9fc2aa8105/build -DUSE_SYSTEM_DEPS=OFF -DPYTHON_EXECUTABLE=/Users/giwonjun/anaconda3/envs/lang_env/bin/python -Dpybind11_DIR=/private/var/folders/69/bt3_5fns57n_cp5_ydbrhfh80000gn/T/pip-build-env-amkign5y/overlay/lib/python3.12/site-packages/pybind11/share/cmake/pybind11\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/69/bt3_5fns57n_cp5_ydbrhfh80000gn/T/pip-install-9hsqglry/docling-parse_2829d61d0ebb4c62a4104b9fc2aa8105/build.py\", line 73, in <module>\n",
      "  \u001b[31m   \u001b[0m     build_local(num_threads=num_threads)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/69/bt3_5fns57n_cp5_ydbrhfh80000gn/T/pip-install-9hsqglry/docling-parse_2829d61d0ebb4c62a4104b9fc2aa8105/build.py\", line 55, in build_local\n",
      "  \u001b[31m   \u001b[0m     success = run(config_cmd, cwd=ROOT_DIR)\n",
      "  \u001b[31m   \u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/69/bt3_5fns57n_cp5_ydbrhfh80000gn/T/pip-install-9hsqglry/docling-parse_2829d61d0ebb4c62a4104b9fc2aa8105/build.py\", line 31, in run\n",
      "  \u001b[31m   \u001b[0m     message = subprocess.run(cmd, cwd=cwd)\n",
      "  \u001b[31m   \u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/subprocess.py\", line 548, in run\n",
      "  \u001b[31m   \u001b[0m     with Popen(*popenargs, **kwargs) as process:\n",
      "  \u001b[31m   \u001b[0m          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/subprocess.py\", line 1026, in __init__\n",
      "  \u001b[31m   \u001b[0m     self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/subprocess.py\", line 1955, in _execute_child\n",
      "  \u001b[31m   \u001b[0m     raise child_exception_type(errno_num, err_msg, err_filename)\n",
      "  \u001b[31m   \u001b[0m FileNotFoundError: [Errno 2] No such file or directory: 'cmake'\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 389, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 373, in main\n",
      "  \u001b[31m   \u001b[0m     json_out[\"return_val\"] = hook(**hook_input[\"kwargs\"])\n",
      "  \u001b[31m   \u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 280, in build_wheel\n",
      "  \u001b[31m   \u001b[0m     return _build_backend().build_wheel(\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/69/bt3_5fns57n_cp5_ydbrhfh80000gn/T/pip-build-env-amkign5y/overlay/lib/python3.12/site-packages/poetry/core/masonry/api.py\", line 58, in build_wheel\n",
      "  \u001b[31m   \u001b[0m     return WheelBuilder.make_in(\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/69/bt3_5fns57n_cp5_ydbrhfh80000gn/T/pip-build-env-amkign5y/overlay/lib/python3.12/site-packages/poetry/core/masonry/builders/wheel.py\", line 95, in make_in\n",
      "  \u001b[31m   \u001b[0m     wb.build(target_dir=directory)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/69/bt3_5fns57n_cp5_ydbrhfh80000gn/T/pip-build-env-amkign5y/overlay/lib/python3.12/site-packages/poetry/core/masonry/builders/wheel.py\", line 134, in build\n",
      "  \u001b[31m   \u001b[0m     self._build(zip_file)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/69/bt3_5fns57n_cp5_ydbrhfh80000gn/T/pip-build-env-amkign5y/overlay/lib/python3.12/site-packages/poetry/core/masonry/builders/wheel.py\", line 183, in _build\n",
      "  \u001b[31m   \u001b[0m     self._run_build_script(self._package.build_script)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/69/bt3_5fns57n_cp5_ydbrhfh80000gn/T/pip-build-env-amkign5y/overlay/lib/python3.12/site-packages/poetry/core/masonry/builders/wheel.py\", line 304, in _run_build_script\n",
      "  \u001b[31m   \u001b[0m     subprocess.check_call([self.executable.as_posix(), build_script])\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/subprocess.py\", line 413, in check_call\n",
      "  \u001b[31m   \u001b[0m     raise CalledProcessError(retcode, cmd)\n",
      "  \u001b[31m   \u001b[0m subprocess.CalledProcessError: Command '['/Users/giwonjun/anaconda3/envs/lang_env/bin/python', 'build.py']' returned non-zero exit status 1.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for docling-parse\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Failed to build installable wheels for some pyproject.toml based projects (docling-parse)\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-docling ipywidgets -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96e423ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_docling import DoclingLoader\n",
    "from langchain_docling.loader import ExportType\n",
    "\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a639f1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# huggingface-hub 로그인\n",
    "login(os.getenv(\"HUGGINGFACE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "006cd80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n",
      "Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n",
      "/Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages/transformers/models/rt_detr/image_processing_rt_detr.py:1093: UserWarning: MPS: nonzero op is supported natively starting from macOS 14.0. Falling back on CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Indexing.mm:404.)\n",
      "  \"scores\": score[score > threshold],\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"papers/1.pdf\" #문서 경로. local file경로, url\n",
    "path = \"https://arxiv.org/pdf/2506.09669\"\n",
    "\n",
    "loader = DoclingLoader(file_path=path, export_type=ExportType.MARKDOWN)\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6af181e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://arxiv.org/pdf/2506.09669'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c6cd786-947d-49ae-933c-627ca714c06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Query-Level Uncertainty in Large Language Models\n",
       "\n",
       "## Lihu Chen , Gaël Varoquaux 1 2\n",
       "\n",
       "- 1 Imperial College London, UK\n",
       "\n",
       "2 Soda, Inria Saclay, France lihu.chen@imperial.ac.uk gael.varoquaux@inria.fr\n",
       "\n",
       "## Abstract\n",
       "\n",
       "It is important for Large Language Models to be aware of the boundary of their knowledge, the mechanism of identifying known and unknown queries. This type of awareness can help models perform adaptive inference, such as invoking RAG, engaging in slow and deep thinking, or adopting the abstention mechanism, which is beneficial to the development of efficient and trustworthy AI. In this work, we propose a method to detect knowledge boundaries via Query-Level Uncertainty , which aims to determine if the model is able to address a given query without generating any tokens. To this end, we introduce a novel and training-free method called Internal Confidence , which leverages self-evaluations across layers and tokens. Empirical results on both factual QA and mathematical reasoning tasks demonstrate that our internal confidence can outperform several baselines. Furthermore, we showcase that our proposed method can be used for efficient RAG and model cascading, which is able to reduce inference costs while maintaining performance. The code is available at /github https://github.com/tigerchen52/ query\\_level\\_uncertainty\n",
       "\n",
       "## 1 Introduction\n",
       "\n",
       "Large language Models (LLMs) have their knowledge boundaries (Li et al., 2024; Yin et al., 2024; Ren et al., 2025), which means that there are certain problems that they cannot provide accurate outputs. It is crucial for LLMs to be self-aware of their limitations, i.e., know what I know and know what I don't know (Kadavath et al., 2022; Amayuelas et al., 2024).\n",
       "\n",
       "Possessing awareness of knowledge boundaries provides several advantages in developing efficient and trustworthy AI. First, if LLMs can identify known-unknown or simple-hard queries, they can smartly perform adaptive inference to balance the trade-offs between computational cost and out-\n",
       "\n",
       "Figure 1: Illustrating the difference between answerlevel and query-level uncertainty. Query-level uncertainty estimating known or unknown queries ( knowledge boundary ) before generating answers, which is useful for adaptive inference, e.g., efficient RAG and fast-slow reasoning.\n",
       "\n",
       "put quality. For queries beyond their parametric knowledge, they can choose to find relevant external knowledge via RAG (Lewis et al., 2020) or tool calls (Schick et al., 2023). When faced with hard problems, LLMs can engage in slow (or deep) thinking to improve their outputs, which is also known as test-time scaling (Snell et al., 2024; Zhang et al., 2025). Alternatively, another solution is to defer a complex problem to a larger model via model cascading (Dohan et al., 2022; Gupta et al., 2024). This adaptive inference ensures that computational resources are allocated effectively, which reduces costs while maintaining performance. Second, estimating whether a query is answerable enhances the honesty and trustworthiness of LLMs. When LLMs identify uncertain queries, they can use the abstention strategy (Wen et al., 2024) to withhold responses, which is important in high-stakes domains like healthcare (Tomani et al., 2024).\n",
       "\n",
       "In this work, we propose a new concept, QueryLevel Uncertainty , to estimate a model's knowledge with regard to a given query. The research question here is: Given a query, can we determine if the model is able to address it without generating any tokens? Most existing work focus on answerlevel uncertainty, which measures the uncertainty associated with a specific answer, helping us assess the reliability of outputs (Shorinwa et al., 2024; Vashurin et al., 2025). The main distinction here is that we shift from post-generation uncertainty to pre-generation uncertainty, which aims to measure how certain an LLM can solve this query, as shown in Figure 1.\n",
       "\n",
       "Prior studies propose learning a probe on internal states to predict uncertainties of queries (Gottesman and Geva, 2024; Kossen et al., 2024). Another branch of work attempts to teach LLMs to explicitly express 'I don't know' in their responses via fine-tuning methods (Amayuelas et al., 2024; Kapoor et al., 2024; Cohen et al., 2024; Zhang et al., 2024a). One potential issue of these studies is that they often require fine-tuning and training samples, which introduces additional overhead and may limit their generalizability. We aim to introduce a training-free approach to estimate querylevel uncertainty, which is simple yet effective.\n",
       "\n",
       "Our approach relies on self-evaluation across internal layers and tokens, which is called Internal Confidence . The proposed approach is based on a simple assumption: LLMs can self-evaluate their knowledge about a query by answering a yesno question. Inspired by the uncertainty method P(True) (Kadavath et al., 2022), we can compute the probability P(Yes) to indicate the model's confidence. To fully use latent knowledge within LLMs, we compute this kind of P(Yes) at each layer and token position. Following that, we aggregate these signals to obtain the final confidence score. This aggregation is motivated by prior work showing that leveraging logical consistency across layers can improve outputs (Burns et al., 2022; Chuang et al., 2023; Xie et al., 2024). Specifically, we perform a weighted sum across layers and tokens, and the weights are derived from attenuated encoding (Chen et al., 2023), which can control the influence of adjacent units.\n",
       "\n",
       "To validate the effectiveness of our proposed internal confidence, we conduct experiments on three datasets that cover factual QA and mathematical reasoning tasks. For comparison, we adapt the existing answer-level methods to compute the querylevel uncertainty. Experimental results demonstrate that our proposed internal confidence can distinguish known and unknown queries better than various baselines. In terms of applications, we showcase that our proposed method can help efficient\n",
       "\n",
       "RAG and model cascading. On the one hand, internal confidence can guide users to assess the tradeoffs between cost and quality when invoking additional services. On the other hand, it brings a 'benefit region', where inference overhead can be reduced without compromising performance.\n",
       "\n",
       "To conclude, we propose a simple yet effective, training-free method to estimate query-level uncertainty, which can determine if a model can address a given query without generating any tokens.\n",
       "\n",
       "## 2 Related Work\n",
       "\n",
       "## 2.1 Uncertainty Estimation\n",
       "\n",
       "Existing methods mainly focus on estimating the uncertainty of LLM-generated responses, which aim to provide a score to indicate the reliability of a query-answer pair (Geng et al., 2024; Shorinwa et al., 2024; Vashurin et al., 2025). These approaches often rely on internal states (Chen et al., 2024a) or textual responses (Kuhn et al., 2023), and commonly use calibration techniques to mitigate issues such as overconfidence (Zhang et al., 2024b) and biases (Chen et al., 2024b). Notably, these methods assess post-generation reliability, i.e., they evaluate uncertainty about a particular answer. In contrast, there is limited research on quantifying how well a model can address a query prior to token generation. For example, Gottesman and Geva (2024) propose training a lightweight probe on internal representations to estimate the model's knowledge about specific entities. Similarly, Semantic Entropy Probes (Kossen et al., 2024) suggest that internal model states can implicitly encode semantic uncertainty, even before any output is generated. To the best of our knowledge, this work is the first to formally define query-level uncertainty and investigate it systematically.\n",
       "\n",
       "## 2.2 Knowledge Boundary Detection\n",
       "\n",
       "LLMs should faithfully assess their level of confidence in answering a query. This knowledge boundary awareness (Li et al., 2024; Yin et al., 2024; Wang et al., 2024) is essential to build reliable AI systems, particularly in high-stakes domains such as healthcare and law. A pioneering study by Kadavath et al. (2022) explores whether language models can be trained to predict when they 'know' the answer to a given query, introducing the concept of 'I Know' (IK) prediction. Based on this idea, subsequent work has proposed methods to help LLMs become explicitly aware of their knowledge limitations through fine-tuning strategies (Amayuelas et al., 2024; Kapoor et al., 2024). Cohen et al. (2024) further advances this line of research by introducing a special [IDK] (' I don't know ') token into the model's vocabulary, allowing the direct expression of uncertainty in its output. Similarly, RTuning (Zhang et al., 2024a) tunes LLMs to refrain from responding to questions beyond their parametric knowledge. While these abstention-based approaches show benefits in mitigating hallucinations (Wen et al., 2024), they often require additional fine-tuning, which introduces overhead and may limit generalizability across models and tasks. In this work, we propose a training-free method to identify the knowledge boundary of an LLM, which offers a more generalizable and efficient alternative to detect the knowledge boundary of LLMs.\n",
       "\n",
       "## 3 Preliminary\n",
       "\n",
       "## 3.1 Aleatoric and Epistemic Uncertainty\n",
       "\n",
       "Uncertainty in machine learning is commonly categorized into two main types: aleatoric and epistemic uncertainty (Hora, 1996; Der Kiureghian and Ditlevsen, 2009; Hüllermeier and Waegeman, 2021). These distinctions are often overlooked in the context of LLM uncertainty estimation. Aleatoric uncertainty arises from inherent randomness in the data, such as ambiguous inputs or conflicting annotations. This type of uncertainty is irreducible, as it reflects intrinsic noise in the input data. In contrast, epistemic uncertainty stems from a lack of knowledge, often due to insufficient training data and limited model capacity. Unlike aleatoric uncertainty, epistemic uncertainty is reducible with additional data or advanced modeling. In this work, we focus specifically on epistemic uncertainty, with the goal of evaluating whether an LLM possesses sufficient knowledge to answer a given query. Although it is possible that a dataset may contain some ambiguous queries and noisy labels, we assume that the benchmark datasets used in our experiments are well-curated, and have minimal ambiguity. This assumption allows us to reasonably minimize the impact of aleatoric uncertainty, and study the epistemic uncertainty in a clear way.\n",
       "\n",
       "## 3.2 Uncertainty and Confidence\n",
       "\n",
       "In the context of LLMs, the terms uncertainty and confidence are often used interchangeably (antonyms). However, the two concepts have sub- tle differences. As noted by Lin et al. (2023), uncertainty is a holistic property of the entire predictive distribution, while confidence refers to the model's estimated confidence level associated with a specific answer. For example, given a query x = 'What is the capital of France' , estimating uncertainty requires the distribution over all possible answers, e.g., Paris, Toulouse, etc. , as explained by the semantic entropy framework (Kuhn et al., 2023). In contrast, the conditional probability P Y ( = Paris | x ) can serve as a confidence here to indicate the correctness of a specific answer. In the context of query-level uncertainty, we treat uncertainty and confidence as antonyms, as obtaining full probability distributions over all possible queries for a given model is infeasible.\n",
       "\n",
       "## 4 Problem Statement and Method\n",
       "\n",
       "In this section, we describe our problem definition and introduce our method, Internal Confidence , a score that reflects whether an LLM can address a query in its own knowledge, prior to generating tokens.\n",
       "\n",
       "## 4.1 Problem Statement\n",
       "\n",
       "Given a query (including prompt words) x = ( x , . . . , x 1 N ) , we aim to quantify the query-level uncertainty, U ( x ) , without generating an answer y . This is different from existing uncertainty methods that estimate the uncertainty associated with a specific generated answer, denoted as U ( x y , ) . We define that if an LLM can answer a query correctly in greedy decoding, the query falls within the knowledge boundary of the model, and its answer can be reliable. Otherwise, the query falls beyond the model's boundary, and it does not possess sufficient knowledge to answer it. We use this standard to evaluate the estimated query-level uncertainty, i.e., a lower uncertainty indicates a model is more likely to output the correct answer. Although different decoding strategies impact LLM outputs (Song et al., 2024), we aim to measure the internal knowledge of a model in a deterministic way.\n",
       "\n",
       "Here, we focus on queries with definite answers, which have broad applications such as factual QA and mathematical reasoning. While contentious queries with open answers are also important in areas such as politics and philosophy, they are out of the scope of this work.\n",
       "\n",
       "Figure 2: Left: the internal P(Yes) across tokens and layers. Middle: the AUC of P(Yes) across tokens and layers. Right: decay weights with different localities. Model: Llama-8B; Dataset: GSM8K validation set.\n",
       "\n",
       "## 4.2 Method\n",
       "\n",
       "Existing findings reveal that LLMs can express verbalized uncertainty in their responses (Tian et al., 2023; Xiong et al., 2024), which reflects that LLMs can evaluate the answer correctness in their own knowledge. Similarly, we can prompt an LLM to assess its confidence in answering a given query by using a yes-no format: 'Respond only with 'Yes' or 'No' to indicate whether you are capable of answering the {Query} accurately. Answer Yes or No:' . Following that, we can compute the probability P(Yes) at the last token ( x N ):\n",
       "\n",
       "<!-- formula-not-decoded -->\n",
       "\n",
       "where N is the index of the last token in the query, and L is the index of the last layer of the model. h ( L ) N ∈ R d is the hidden state and d is the dimensionality of the hidden representations. W unemb ∈ R |V|× d is the unembedding matrix that maps the hidden state h ( L ) N to logits over the vocabulary V . P(Yes) can serve as a query-level confidence score here, which is somehow correlated with verbalized uncertainty (Tian et al., 2023), but the main difference is that this method only makes a single forward pass of the query without generating any answer tokens.\n",
       "\n",
       "However, P(Yes) does fully use internal states of LLMs, which preserves rich latent information about estimating uncertainty (Azaria and Mitchell, 2023; Chen et al., 2024a). Furthermore, prior work demonstrates that using logical consistency across layers can improve outputs (Burns et al., 2022; Chuang et al., 2023; Xie et al., 2024). Therefore, we propose the Internal Confidence , which leverages latent knowledge across different layers and tokens. Let f θ denote the transformation function for computing hidden states, parameterized by θ . The hidden state for the query x n of the query at layer l is computed as:\n",
       "\n",
       "<!-- formula-not-decoded -->\n",
       "\n",
       "In total, the model contains N × L such latent representations, and we can use Equation 4.2 to compute the P(Yes) for each h ( ) l n .\n",
       "\n",
       "Figure 2a shows the average P(Yes) of Llama-8B on the mathematical queries (the validation set of GSM8K (Cobbe et al., 2021)), across layers and query tokens 1 . We observe that the probability increases gradually from low to high layers and from left to right positions, presenting diverse behaviors. If we treat each P ( Yes | h ( ) l n ) as a confidence score and evaluate Area Under the Curve (AUC), we can obtain an AUC heatmap to show how well the model can distinguish known and unknown queries. As shown in Figure 2b, the top right score is not optimal. Actually, the representation h (27) 5 can achieve the best AUC, and the performance gradually declines in regions surrounding this point. We refer to this optimal point as Decision Center . It is important to note that the location of the Decision Center is sensitive to both model architecture and task type.\n",
       "\n",
       "To improve the naive P(Yes), we can apply a weighted average centering around the decision center, which serves as an ensemble strategy to enhance calibration and expressivity (Zhang et al.,\n",
       "\n",
       "1 Here, we consider tokens after the {Query} , which means that a model has seen the entire query and is able to guess its knowledge gap.\n",
       "\n",
       "Table 1: Overall performances of different query-level uncertainty methods.\n",
       "\n",
       "|                                      | TriviaQA   | TriviaQA   | TriviaQA   | SciQ     | SciQ     | SciQ     | GSM8K    | GSM8K    | GSM8K    | Avg      | Avg      | Avg      |\n",
       "|--------------------------------------|------------|------------|------------|----------|----------|----------|----------|----------|----------|----------|----------|----------|\n",
       "| Method                               | ↑ AUC      | ↑ PRR      | ↓ ECE      | ↑ AUC    | ↑ PRR    | ↓ ECE    | ↑ AUC    | ↑ PRR    | ↓ ECE    | ↑ AUC    | ↑ PRR    | ↓ ECE    |\n",
       "| Phi-3.8B                             | Phi-3.8B   | Phi-3.8B   | Phi-3.8B   | Phi-3.8B | Phi-3.8B | Phi-3.8B | Phi-3.8B | Phi-3.8B | Phi-3.8B | Phi-3.8B | Phi-3.8B | Phi-3.8B |\n",
       "| Max ( - log p )                      | 55.5       | 10.0       | -          | 51.4     | 2.9      | -        | 55.0     | 11.3     | -        | 54.0     | 8.1      | -        |\n",
       "| Predictive Entropy                   | 58.9       | 17.9       | -          | 51.2     | 3.9      | -        | 63.6     | 25.7     | -        | 57.9     | 15.8     | -        |\n",
       "| Min-K Entropy                        | 59.9       | 20.0       | -          | 52.7     | 4.9      | -        | 60.4     | 17.9     | -        | 57.7     | 14.3     | -        |\n",
       "| Attentional Entropy                  | 60.6       | 21.4       | -          | 56.2     | 9.4      | -        | 52.4     | 4.4      | -        | 56.4     | 11.7     | -        |\n",
       "| Perplexity                           | 61.8       | 24.3       | -          | 57.7     | 16.6     | -        | 53.6     | 6.9      | -        | 57.7     | 15.9     | -        |\n",
       "| Internal Semantic Similarity         | 48.7       | -2.4       | 0.3        | 46.9     | -5.9     | 12.2     | 47.9     | -2.6     | 35.2     | 47.8     | -3.6     | 15.9     |\n",
       "| P(Yes)                               | 58.1       | 16.4       | 13.9       | 58.8     | 16.9     | 10.8     | 56.6     | 12.0     | 7.6      | 57.8     | 15.1     | 10.8     |\n",
       "| Internal Confidence ( w/ naive avg ) | 58.8       | 17.3       | 19.9       | 52.4     | 4.5      | 3.3      | 54.7     | 14.7     | 21.7     | 55.3     | 12.2     | 15.0     |\n",
       "| Internal Confidence                  | 56.2       | 13.1       | 13.9       | 57.2     | 15.2     | 8.2      | 57.2     | 12.9     | 6.0      | 56.9     | 13.7     | 9.4      |\n",
       "| Llama-8B                             | Llama-8B   | Llama-8B   | Llama-8B   | Llama-8B | Llama-8B | Llama-8B | Llama-8B | Llama-8B | Llama-8B | Llama-8B | Llama-8B | Llama-8B |\n",
       "| Max ( - log p )                      | 54.9       | 11.1       | -          | 51.4     | 1.9      | -        | 53.3     | 10.4     | -        | 53.2     | 7.8      | -        |\n",
       "| Predictive Entropy                   | 58.5       | 17.7       | -          | 51.4     | 3.2      | -        | 66.1     | 28.0     | -        | 58.7     | 16.3     | -        |\n",
       "| Min-K Entropy                        | 58.1       | 17.4       | -          | 53.5     | 7.9      | -        | 57.5     | 13.2     | -        | 56.4     | 12.8     | -        |\n",
       "| Attentional Entropy                  | 59.4       | 18.7       | -          | 57.7     | 15.2     | -        | 56.1     | 13.5     | -        | 57.7     | 15.8     | -        |\n",
       "| Perplexity                           | 58.6       | 17.1       | -          | 58.3     | 15.1     | -        | 53.2     | 4.3      | -        | 56.7     | 12.2     | -        |\n",
       "| Internal Semantic Similarity         | 44.1       | -14.4      | 24.4       | 46.1     | -7.1     | 30.8     | 52.7     | 6.7      | 45.9     | 47.6     | -4.9     | 33.7     |\n",
       "| P(Yes)                               | 66.4       | 33.0       | 27.5       | 51.3     | 2.4      | 23.7     | 62.2     | 24.8     | 11.6     | 60.0     | 20.1     | 20.9     |\n",
       "| Internal Confidence ( w/ naive avg ) | 67.2       | 34.4       | 14.9       | 58.6     | 15.4     | 21.5     | 59.1     | 18.7     | 29.2     | 61.6     | 22.8     | 21.9     |\n",
       "| Internal Confidence                  | 67.8       | 34.5       | 19.1       | 56.4     | 13.0     | 18.9     | 62.9     | 27.9     | 1.3      | 62.4     | 25.1     | 13.1     |\n",
       "| Qwen-14B                             | Qwen-14B   | Qwen-14B   | Qwen-14B   | Qwen-14B | Qwen-14B | Qwen-14B | Qwen-14B | Qwen-14B | Qwen-14B | Qwen-14B | Qwen-14B | Qwen-14B |\n",
       "| Max ( - log p )                      | 56.5       | 12.4       | -          | 54.1     | 6.9      | -        | 54.3     | 13.5     | -        | 55.0     | 10.9     | -        |\n",
       "| Predictive Entropy                   | 59.3       | 18.9       | -          | 53.2     | 6.9      | -        | 66.4     | 32.6     | -        | 59.6     | 19.5     | -        |\n",
       "| Min-K Entropy                        | 59.9       | 20.0       | -          | 55.7     | 11.3     | -        | 63.0     | 30.9     | -        | 59.5     | 20.7     | -        |\n",
       "| Attentional Entropy                  | 59.1       | 17.2       | -          | 59.4     | 19.2     | -        | 54.9     | 3.1      | -        | 57.8     | 13.2     | -        |\n",
       "| Perplexity                           | 59.1       | 17.8       | -          | 60.1     | 20.7     | -        | 54.0     | 7.3      | -        | 57.7     | 15.3     | -        |\n",
       "| Internal Semantic Similarity         | 51.0       | 2.5        | 2.0        | 45.5     | -7.7     | 14.9     | 47.5     | -4.6     | 33.1     | 48.0     | -3.3     | 16.7     |\n",
       "| P(Yes)                               | 63.2       | 25.8       | 31.9       | 61.0     | 22.4     | 23.9     | 54.7     | 7.5      | 5.8      | 59.6     | 18.6     | 20.5     |\n",
       "| Internal Confidence ( w/ naive avg ) | 63.3       | 27.6       | 8.0        | 60.5     | 20.5     | 15.3     | 61.7     | 28.4     | 36.3     | 61.8     | 25.5     | 19.9     |\n",
       "| Internal Confidence                  | 69.1       | 38.4       | 28.7       | 65.0     | 30.8     | 20.6     | 62.7     | 28.4     | 5.5      | 65.6     | 32.5     | 18.3     |\n",
       "\n",
       "2020; Stickland and Murray, 2020). We refer to this process as Internal Confidence (IC) , which can be denoted as:\n",
       "\n",
       "<!-- formula-not-decoded -->\n",
       "\n",
       "To reflect the observations that AUC performances gradually decay from the decision center, we adopt the Attenuated Encoding to compute the above two weight vectors (Chen et al., 2023)\n",
       "\n",
       "where w ( ) l n is the weight for each h ( ) l n . The equation describes a two-step aggregation process. First, we compute a weighted sum across layers for each individual token. Then, we apply a second weighted average over these token-level aggregated scores. Ideally, this process requires a layer weight matrix W layer ∈ R N × L for the first step and a token weight matrix W token ∈ R 1 × N for the second step. Through this aggregation, we are able to obtain a final confidence score.\n",
       "\n",
       "In a practical implementation, the decision center is static and fixed to the last token and last layer. However, it is possible to use a hold-out set to identify optimal positions tailored to specific models and tasks. We make this simplification to get rid of the requirement of training samples and aim to obtain better generalizability. Additionally, the layer weight vectors are shared across tokens, which means we need only two weight vectors: W layer ∈ R 1 × L and W token ∈ R 1 × N .\n",
       "\n",
       "<!-- formula-not-decoded -->\n",
       "\n",
       "where i is the index of the decision center, d i,j is the relative distance, and w &gt; 0 is a scalar parameter that controls the locality value. Locality is a metric that measures how much the weights of a weight vector are gathered in adjacent positions. Given a weight vector for the i -th position ϵ i = { ϵ i, 1 , ϵ i, 2 , ..., ϵ i,n } , the locality can be denoted as:\n",
       "\n",
       "<!-- formula-not-decoded -->\n",
       "\n",
       "Figure 2c shows the weights computed by Equation 4 with varied localities. This signifies that we can control the influence of neighboring layers and tokens during the averaging process.\n",
       "\n",
       "Our proposed internal confidence is training-free and efficient, as it requires only a single forward pass of a given query. Since model responses are usually longer than input prompts and invoking\n",
       "\n",
       "Figure 3: We use Internal Confidence of Phi-3.8B to predict whether the corresponding can distinguish known and unknown queries.\n",
       "\n",
       "external services like RAG adds significant overhead. We hope this pre-generation uncertainty can support adaptive reasoning.\n",
       "\n",
       "## 5 Experiments\n",
       "\n",
       "## 5.1 Settings\n",
       "\n",
       "Implementations We provide one positive and one negative example to prompt LLMs, and the target model should follow the examples to output answers. All LLMs use greedy decoding to have deterministic results. The decision center is fixed to the last layer and last token, and we set w = 1 0 . (Equation 4) for all models and datasets.\n",
       "\n",
       "edge and it falls in its knowledge boundary. For the first two datasets with short answers, we consider an answer to be correct if its Rouge-L (Lin and Och, 2004) of the ground truth is greater than 0.3, which is consistent with prior work (Kuhn et al., 2023). For the GSM8K dataset, we use an LLM evaluator, Mistal-Large (MistralAI, 2024), to assess both reasoning steps and final answer. After that, we can obtain a binary label for each query, which shows if a model is able to address the query.\n",
       "\n",
       "Models Three different sizes of LLMs are used in experiments: Phi-3-mini-4k-instruct (Abdin et al., 2024), Llama-3.1-8B-Instruct (Grattafiori et al., 2024), and Qwen2.5-14B-Instruct (Team, 2024). We aim to evaluate if internal confidence can be scaled to different model sizes. Note that internal confidence can be used for models without instruction tuning.\n",
       "\n",
       "Datasets We evaluate on two factual QA datasets and one mathematical reasoning dataset: TriviaQA (Joshi et al., 2017), SciQ (Welbl et al., 2017), and GSM8K (Cobbe et al., 2021). The first two tasks aim to assess factual knowledge stored in parameters, while GSM8K requires models to selfevaluate their reasoning capabilities. Ground truth of factual QA tasks is a short answer with some entity facts. GSM8k calls for a short answer, but the intermediate reasoning steps have been evaluated as well, following prior work (Kadavath et al., 2022).\n",
       "\n",
       "We ask a model to generate answers in a greedy decoding way. If the answer is aligned with ground truth, we regard that the model has sufficient knowl-\n",
       "\n",
       "Baselines We adapt existing answer-level methods to quantify the pre-generation uncertainty, e.g., logit-based uncertainty. Given a query (including prompt words) x = ( x , . . . , x 1 N ) , we can obtain a probability for each token P x ( n | x &lt;n ) by performing a forward pass. (1) The baseline Max ( -log p ) measures the query's uncertainty by assessing the least likely token in the query (Manakul et al., 2023). (2) Predictive Entropy is defined as the entropy over the entire query tokens (Malinin and Gales, 2021):\n",
       "\n",
       "<!-- formula-not-decoded -->\n",
       "\n",
       "(3) Min-K Entropy combines the thoughts of the Max ( -log p ) and predictive entropy , which select the top-K of tokens from the query with the minimum token probability (Shi et al., 2024). (4) Attentional Entropy is an adapted version of the predictive entropy by performing a weighted sum:\n",
       "\n",
       "<!-- formula-not-decoded -->\n",
       "\n",
       "where α n is the attentional weights for the token x n . The intuition here is that tokens contribute to the semantic meanings in a different way, and we should\n",
       "\n",
       "Figure 4: Left: We use estimated internal confidence scores to decide whether to invoke RAG. If the internal confidence exceeds a threshold, the model answers the query using its parametric knowledge. Otherwise, it relies on external knowledge for reasoning. The plot shows the accuracy of Phi-3.8B on the TriviaQA dataset under this setting. Right: We implement a model cascading seeting with Phi-3.8B (small) and Llama-8B (large) on the TriviaQA dataset. The internal confidence of the smaller model determines whether it answers the query or defers to the larger model when confidence is low.\n",
       "\n",
       "not treat all tokens equally (Duan et al., 2024). (5) Perplexity reflects how uncertain a model is when predicting the next token:\n",
       "\n",
       "<!-- formula-not-decoded -->\n",
       "\n",
       "(6) Internal Semantic Similarity measures the average similarity among hidden states of different layers { h (1) N , ..., h ( L ) N } , which is inspired by the lexical similarity (Fomicheva et al., 2020). (7) P(Yes) is the probability of self-evaluation, which is described in Equation 4.2. (8) Internal Confidence (w/ naive avg) is a variant of our proposed internal confidence. The distinction is we apply a naive average to aggregate all scores.\n",
       "\n",
       "observe that our proposed internal confidence can distinguish known and unknown queries better than other baselines (based on AUC and PRR) on average, especially for larger models such as Llama-8B and Qwen-14B. For example, the average AUC of Qwen-14B is 65.6, which is significantly higher than other baselines. Regarding the calibration (ECE), internal confidence can achieve lower error across models and tasks consistently. These findings indicate the effectiveness of internal confidence. Second, the variant, Internal Confidence ( w/ naive avg , leads to a decrease in general, which demonstrates that the benefit of using the attenuated encoding to obtain decay weights.\n",
       "\n",
       "Evaluation Metrics We evaluate uncertainty by assessing whether a method can distinguish known and unknown queries, which can be treated as ranking problems, i.e., a lower uncertainty means a model is more likely to know the answer to the query. Following prior work (Manakul et al., 2023; Kuhn et al., 2023), we adopt the metrics Area Under the Curve (AUC) and Prediction Rejection Ratio (PRR) (Malinin et al., 2017) to measure this. Additionally, we use the Expected Calibration Error (ECE) to assess the calibration of different methods.\n",
       "\n",
       "## 5.2 Internal Confidence Can Identify Known and Unknown Queries\n",
       "\n",
       "Table 1 shows the overall performances of various query-level uncertainty methods. First, we can\n",
       "\n",
       "Additionally, Figure 3 shows the how well the internal confidence can distinguish known and unknown queries across three tasks. While the results confirm that our training-free method can predict knowledge boundaries to some extent, there is still considerable room for improvement. We hope this initial effort encourages further research in this direction.\n",
       "\n",
       "## 5.3 Internal Confidence Makes LLM Reasoning More Efficiently\n",
       "\n",
       "Recent studies advance LLM reasoning by introducing additional resources, such as using RAG to obtain external knowledge (Lewis et al., 2020) and inference-time scaling to improve outputs (Snell et al., 2024). However, it is not always necessary to use additional resources, especially for simple queries. Here, we can use our proposed internal\n",
       "\n",
       "Figure 5: Impacts of locality on validation sets.\n",
       "\n",
       "confidence to determine when to invoke RAG, slow thinking, or model cascading.\n",
       "\n",
       "## 5.4 Locality Impacts Uncertainty Performance\n",
       "\n",
       "We conduct experiments for two scenarios: (1) Efficient RAG. Basically, the internal confidence can serve as a signal of the knowledge gaps of a model. If the score is greater than a threshold, the model is confidence to address the query. Otherwise, it requires the call of RAG. We use the TriviaQA dataset for evaluation. This dataset provides web search results for a query, which can be used as retrieved contexts for RAG. (2) Model Cascading. This task aims to achieve cost-performance trade-offs by coordinating small and large models (Dohan et al., 2022; Gupta et al., 2024). Smaller models is responsible for easy missions. If they are aware that the mission is hard to complete, it invokes a larger model. We use a two-model cascade setting with Phi-3.8B and Llama-8B on the TriviaQA dataset. Likewise, if the internal confidence of the smaller model is high, we do not invoke the larger model. Otherwise, the hard query is deferred to the larger model.\n",
       "\n",
       "Figure 4 shows the results of efficient RAG and model cascading. The trade-off region means that we can carefully select a threshold to control the call of external services, which helps strike a balance between efficiency and performance. The benefit region indicates scenarios where the use of additional resources can be reduced without compromising performance. Results across the two tasks further confirm the effectiveness of Internal Confidence in identifying knowledge gaps. Our method offers practical benefits by reducing inference overhead, which is correlated with computation time and monetary cost.\n",
       "\n",
       "We introduce attenuated encodings to aggregate probabilities centering around a decision point. The locality of the encoding may impact the performance of estimated uncertainties. To study the influence of the locality, we vary the w in Equation 4 to obtain encoding with different localities and observe how they can impact the estimations. Figure 5 shows the AUC across different datasets and models. We can observe that the locality is correlated with task types and model architecture. For example, Phi-3.8B prefers an extreme locality (1.0) while Qwen-14B has a certain optimal value around 0.8. Regarding different datasets, the influence of locality values displays slightly different behaviors. Although we may need to search an optimal locality for a specific task, we show that an empirical value with ( w = 1 0 . , Locality=0.72) can achieve competitive performances across models and datasets.\n",
       "\n",
       "## 6 Conclusion\n",
       "\n",
       "In this work, we propose a new concept called query-level uncertainty, which aims to assess whether a model can address a query without generating any tokens. To this end, we propose the approach, internal confidence, which leverages latent self-evaluation to identify the boundary of a model's knowledge. Experimental results verify the effectiveness of our approach in factual QA and mathematical reasoning. Furthermore, we apply internal confidence to two practical scenarios of adaptive inference, efficient RAG and model cascading. Our findings reveal that our method can identify two regions: a trade-off region and a benefit region. The former means that users can strike a balance between cost and quality by carefully selecting a threshold of confidence scores. The latter means that users can reduce inference overhead without compromising performance. Although our method can serve as a strong baseline for estimating querylevel uncertainty, there is still considerable room for improvement. We hope this study can stimulate future studies in this area.\n",
       "\n",
       "## References\n",
       "\n",
       "Marah Abdin, Jyoti Aneja, Hany Awadalla, Ahmed Awadallah, Ammar Ahmad Awan, Nguyen Bach, Amit Bahree, Arash Bakhtiari, Jianmin Bao, Harkirat Behl, and 1 others. 2024. Phi-3 technical report: A highly capable language model locally on your phone. arXiv preprint arXiv:2404.14219 .\n",
       "\n",
       "Alfonso Amayuelas, Kyle Wong, Liangming Pan, Wenhu Chen, and William Yang Wang. 2024. Knowledge of knowledge: Exploring known-unknowns uncertainty with large language models. In Findings of the Association for Computational Linguistics ACL 2024 , pages 6416-6432.\n",
       "\n",
       "Amos Azaria and Tom Mitchell. 2023. The internal state of an llm knows when it's lying. In Findings of the Association for Computational Linguistics: EMNLP 2023 , pages 967-976.\n",
       "\n",
       "Collin Burns, Haotian Ye, Dan Klein, and Jacob Steinhardt. 2022. Discovering latent knowledge in language models without supervision. In The Eleventh International Conference on Learning Representations .\n",
       "\n",
       "Chao Chen, Kai Liu, Ze Chen, Yi Gu, Yue Wu, Mingyuan Tao, Zhihang Fu, and Jieping Ye. 2024a. Inside: Llms' internal states retain the power of hallucination detection. In ICLR .\n",
       "\n",
       "Lihu Chen, Alexandre Perez-Lebel, Fabian Suchanek, and Gaël Varoquaux. 2024b. Reconfidencing llms from the grouping loss perspective. In Findings of the Association for Computational Linguistics: EMNLP 2024 , pages 1567-1581.\n",
       "\n",
       "Lihu Chen, Gael Varoquaux, and Fabian Suchanek. 2023. The locality and symmetry of positional encodings. In Findings of the Association for Computational Linguistics: EMNLP 2023 , pages 1431314331.\n",
       "\n",
       "Yung-Sung Chuang, Yujia Xie, Hongyin Luo, Yoon Kim, James R Glass, and Pengcheng He. 2023. Dola: Decoding by contrasting layers improves factuality in large language models. In The Twelfth International Conference on Learning Representations .\n",
       "\n",
       "Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, and 1 others. 2021. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168 .\n",
       "\n",
       "Roi Cohen, Konstantin Dobler, Eden Biran, and Gerard de Melo. 2024. I don't know: Explicit modeling of uncertainty with an [idk] token. Advances in Neural Information Processing Systems , 37:10935-10958.\n",
       "\n",
       "Armen Der Kiureghian and Ove Ditlevsen. 2009. Aleatory or epistemic? does it matter? Structural safety , 31(2):105-112.\n",
       "\n",
       "David Dohan, Winnie Xu, Aitor Lewkowycz, Jacob Austin, David Bieber, Raphael Gontijo Lopes, Yuhuai Wu, Henryk Michalewski, Rif A Saurous, Jascha Sohl-Dickstein, and 1 others. 2022. Language model cascades. arXiv preprint arXiv:2207.10342 .\n",
       "\n",
       "Jinhao Duan, Hao Cheng, Shiqi Wang, Alex Zavalny, Chenan Wang, Renjing Xu, Bhavya Kailkhura, and Kaidi Xu. 2024. Shifting attention to relevance: Towards the predictive uncertainty quantification of freeform large language models. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages 5050-5063.\n",
       "\n",
       "Marina Fomicheva, Shuo Sun, Lisa Yankovskaya, Frédéric Blain, Francisco Guzmán, Mark Fishel, Nikolaos Aletras, Vishrav Chaudhary, and Lucia Specia. 2020. Unsupervised quality estimation for neural machine translation. Transactions of the Association for Computational Linguistics , 8:539-555.\n",
       "\n",
       "Jiahui Geng, Fengyu Cai, Yuxia Wang, Heinz Koeppl, Preslav Nakov, and Iryna Gurevych. 2024. A survey of confidence estimation and calibration in large language models. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers) , pages 6577-6595.\n",
       "\n",
       "Daniela Gottesman and Mor Geva. 2024. Estimating knowledge in large language models without generating a single token. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing , pages 3994-4019.\n",
       "\n",
       "Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad AlDahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, and 1 others. 2024. The llama 3 herd of models. arXiv preprint arXiv:2407.21783 .\n",
       "\n",
       "Neha Gupta, Harikrishna Narasimhan, Wittawat Jitkrittum, Ankit Singh Rawat, Aditya Krishna Menon, and Sanjiv Kumar. 2024. Language model cascades: Token-level uncertainty and beyond. In The Twelfth International Conference on Learning Representations .\n",
       "\n",
       "Stephen C Hora. 1996. Aleatory and epistemic uncertainty in probability elicitation with an example from hazardous waste management. Reliability Engineering &amp; System Safety , 54(2-3):217-223.\n",
       "\n",
       "Eyke Hüllermeier and Willem Waegeman. 2021. Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and methods. Machine learning , 110(3):457-506.\n",
       "\n",
       "Mandar Joshi, Eunsol Choi, Daniel S Weld, and Luke Zettlemoyer. 2017. Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages 1601-1611.\n",
       "\n",
       "Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli Tran-Johnson, and 1 others. 2022. Language models (mostly) know what they know. arXiv preprint arXiv:2207.05221 .\n",
       "\n",
       "Sanyam Kapoor, Nate Gruver, Manley Roberts, Katherine M Collins, Arka Pal, Umang Bhatt, Adrian Weller, Samuel Dooley, Micah Goldblum, and Andrew Gordon Wilson. 2024. Large language models must be taught to know what they don't know. In The Thirtyeighth Annual Conference on Neural Information Processing Systems .\n",
       "\n",
       "Jannik Kossen, Jiatong Han, Muhammed Razzak, Lisa Schut, Shreshth Malik, and Yarin Gal. 2024. Semantic entropy probes: Robust and cheap hallucination detection in llms. arXiv preprint arXiv:2406.15927 .\n",
       "\n",
       "Lorenz Kuhn, Yarin Gal, and Sebastian Farquhar. 2023. Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation. In The Eleventh International Conference on Learning Representations .\n",
       "\n",
       "Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, and 1 others. 2020. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in neural information processing systems , 33:94599474.\n",
       "\n",
       "Moxin Li, Yong Zhao, Yang Deng, Wenxuan Zhang, Shuaiyi Li, Wenya Xie, See-Kiong Ng, and Tat-Seng Chua. 2024. Knowledge boundary of large language models: A survey. arXiv preprint arXiv:2412.12472 .\n",
       "\n",
       "Chin-Yew Lin and Franz Josef Och. 2004. Automatic evaluation of machine translation quality using longest common subsequence and skip-bigram statistics. In Proceedings of the 42nd annual meeting of the association for computational linguistics (ACL04) , pages 605-612.\n",
       "\n",
       "Zhen Lin, Shubhendu Trivedi, and Jimeng Sun. 2023. Generating with confidence: Uncertainty quantification for black-box large language models. Transactions on Machine Learning Research .\n",
       "\n",
       "Andrey Malinin and Mark Gales. 2021. Uncertainty estimation in autoregressive structured prediction. In International Conference on Learning Representations .\n",
       "\n",
       "Andrey Malinin, Anton Ragni, Kate Knill, and Mark Gales. 2017. Incorporating uncertainty into deep learning for spoken language assessment. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) , pages 45-50.\n",
       "\n",
       "Potsawee Manakul, Adian Liusie, and Mark Gales. 2023. Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing , pages 9004-9017.\n",
       "\n",
       "MistralAI. 2024. Mistral large: A general-purpose language model. https://mistral.ai/news/ mistral-large-2407/ .\n",
       "\n",
       "Ruiyang Ren, Yuhao Wang, Yingqi Qu, Wayne Xin Zhao, Jing Liu, Hua Wu, Ji-Rong Wen, and Haifeng Wang. 2025. Investigating the factual knowledge boundary of large language models with retrieval augmentation. In Proceedings of the 31st International Conference on Computational Linguistics , pages 3697-3715.\n",
       "\n",
       "Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. 2023. Toolformer: Language models can teach themselves to use tools. Advances in Neural Information Processing Systems , 36:68539-68551.\n",
       "\n",
       "Weijia Shi, Anirudh Ajith, Mengzhou Xia, Yangsibo Huang, Daogao Liu, Terra Blevins, Danqi Chen, and Luke Zettlemoyer. 2024. Detecting pretraining data from large language models. In The Twelfth International Conference on Learning Representations .\n",
       "\n",
       "Ola Shorinwa, Zhiting Mei, Justin Lidard, Allen Z Ren, and Anirudha Majumdar. 2024. A survey on uncertainty quantification of large language models: Taxonomy, open research challenges, and future directions. arXiv preprint arXiv:2412.05563 .\n",
       "\n",
       "Charlie Snell, Jaehoon Lee, Kelvin Xu, and Aviral Kumar. 2024. Scaling llm test-time compute optimally can be more effective than scaling model parameters. arXiv preprint arXiv:2408.03314 .\n",
       "\n",
       "Yifan Song, Guoyin Wang, Sujian Li, and Bill Yuchen Lin. 2024. The good, the bad, and the greedy: Evaluation of llms should not ignore non-determinism. arXiv preprint arXiv:2407.10457 .\n",
       "\n",
       "Asa Cooper Stickland and Iain Murray. 2020. Diverse ensembles improve calibration. arXiv preprint arXiv:2007.04206 .\n",
       "\n",
       "Qwen Team. 2024. Qwen2.5: A party of foundation models.\n",
       "\n",
       "Katherine Tian, Eric Mitchell, Allan Zhou, Archit Sharma, Rafael Rafailov, Huaxiu Yao, Chelsea Finn, and Christopher D Manning. 2023. Just ask for calibration: Strategies for eliciting calibrated confidence scores from language models fine-tuned with human feedback. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing , pages 5433-5442.\n",
       "\n",
       "Christian Tomani, Kamalika Chaudhuri, Ivan Evtimov, Daniel Cremers, and Mark Ibrahim. 2024. Uncertainty-based abstention in llms improves safety and reduces hallucinations. arXiv preprint arXiv:2404.10960 .\n",
       "\n",
       "Roman Vashurin, Ekaterina Fadeeva, Artem Vazhentsev, Lyudmila Rvanova, Daniil Vasilev, Akim Tsvigun, Sergey Petrakov, Rui Xing, Abdelrahman Sadallah, Kirill Grishchenkov, and 1 others. 2025. Benchmarking uncertainty quantification methods for large language models with lm-polygraph. Transactions of the Association for Computational Linguistics , 13:220-248.\n",
       "\n",
       "Hongru Wang, Boyang Xue, Baohang Zhou, Tianhua Zhang, Cunxiang Wang, Huimin Wang, Guanhua Chen, and Kam-fai Wong. 2024. Self-dc: When to reason and when to act? self divide-and-conquer for compositional unknown questions. arXiv preprint arXiv:2402.13514 .\n",
       "\n",
       "Johannes Welbl, Nelson F Liu, and Matt Gardner. 2017. Crowdsourcing multiple choice science questions. In Proceedings of the 3rd Workshop on Noisy Usergenerated Text , pages 94-106.\n",
       "\n",
       "Bingbing Wen, Jihan Yao, Shangbin Feng, Chenjun Xu, Yulia Tsvetkov, Bill Howe, and Lucy Lu Wang. 2024. Know your limits: A survey of abstention in large language models. arXiv preprint arXiv:2407.18418 .\n",
       "\n",
       "Zhihui Xie, Jizhou Guo, Tong Yu, and Shuai Li. 2024. Calibrating reasoning in language models with internal consistency. In The Thirty-eighth Annual Conference on Neural Information Processing Systems .\n",
       "\n",
       "Miao Xiong, Zhiyuan Hu, Xinyang Lu, YIFEI LI, Jie Fu, Junxian He, and Bryan Hooi. 2024. Can llms express their uncertainty? an empirical evaluation of confidence elicitation in llms. In The Twelfth International Conference on Learning Representations .\n",
       "\n",
       "Xunjian Yin, Xu Zhang, Jie Ruan, and Xiaojun Wan. 2024. Benchmarking knowledge boundary for large language models: A different perspective on model evaluation. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages 2270-2286.\n",
       "\n",
       "Hanning Zhang, Shizhe Diao, Yong Lin, Yi Fung, Qing Lian, Xingyao Wang, Yangyi Chen, Heng Ji, and Tong Zhang. 2024a. R-tuning: Instructing large language models to say 'i don't know'. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers) , pages 7106-7132.\n",
       "\n",
       "Jize Zhang, Bhavya Kailkhura, and T Yong-Jin Han. 2020. Mix-n-match: Ensemble and compositional methods for uncertainty calibration in deep learning. In International conference on machine learning , pages 11117-11128. PMLR.\n",
       "\n",
       "Mozhi Zhang, Mianqiu Huang, Rundong Shi, Linsen Guo, Chong Peng, Peng Yan, Yaqian Zhou, and Xipeng Qiu. 2024b. Calibrating the confidence of large language models by eliciting fidelity. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing , pages 29592979.\n",
       "\n",
       "Qiyuan Zhang, Fuyuan Lyu, Zexu Sun, Lei Wang, Weixu Zhang, Wenyue Hua, Haolun Wu, Zhihan Guo, Yufei Wang, Niklas Muennighoff, and 1 others. 2025. A survey on test-time scaling in large language models: What, how, where, and how well? arXiv preprint arXiv:2503.24235 .\n",
       "\n",
       "## A Example Appendix\n",
       "\n",
       "This is an appendix."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(docs[0].page_content)\n",
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d0d3eb-8af4-432f-a207-728ff62358ee",
   "metadata": {},
   "source": [
    "### UnstructuredLoader\n",
    "- 다양한 비정형 문서들을 읽어 오는 Unstrctured 를 사용해, 다양한 형식의 문서들을 load 해 RAG, 모델 파인튜닝에 적용할 수있게 한다.\n",
    "  - 지원 파일 형식: \"csv\", \"doc\", \"docx\", \"epub\", \"image\", \"md\", \"msg\", \"odt\", \"org\", \"pdf\", \"ppt\", \"pptx\", \"rtf\", \"rst\", \"tsv\", \"xlsx\"\n",
    "- **다양한 형식의 파일로 부터 text를 로딩**해야 할 경우 유용하다. \n",
    "- Local에 library를 설치해서 사용하거나,  Unstructured 가 제공하는 API service를 사용할 수 있다.\n",
    "  - https://docs.unstructured.io\n",
    "- 텍스트 파일, PDF, 이미지, HTML, XML, ms-office(word, ppt), epub 등 다양한 비정형 데이터 파일을 처리할 수 있다.\n",
    "  - 설치, 지원 문서: https://docs.unstructured.io/open-source/installation/full-installation\n",
    "  - Langchain 문서: https://python.langchain.com/docs/integrations/document_loaders/unstructured_file\n",
    "\n",
    "> - UnstructuredLoader PDF Load 시 Document 분할 기준\n",
    ">     -  문서의 구조와 콘텐츠를 기반으로 텍스트를 분할해 Document에 넣는다.\n",
    ">     -  분할 기준\n",
    ">        - 헤더(Header): 문서의 제목이나 섹션 제목 등\n",
    ">        - 본문 텍스트(NarrativeText): 일반적인 문단이나 설명문\n",
    ">        - 표(Table): 데이터가 표 형식으로 구성된 부분\n",
    ">        - 리스트(List): 순서가 있거나 없는 목록\n",
    ">        - 이미지(Image): 사진이나 그래픽 요소"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87686d9-03d9-401a-9573-d57a2aacf965",
   "metadata": {},
   "source": [
    "#### 설치할 프로그램\n",
    "- poppler\n",
    "  - pdf 파일을 text로 변환하기 위해 필요한 프로그램\n",
    "  - windows: https://github.com/oschwartz10612/poppler-windows/releases/ 에서 최신 버전 다운로드 후 압축 풀어서 설치.\n",
    "    - 환경변수 Path에 \"설치경로\\Library\\bin\" 을 추가. (설치 후 IDE를 다시 시작한다.)\n",
    "  - macOS: `brew install poppler`\n",
    "  - Linux: `sudo apt-get install poppler-utils`\n",
    "- tesseract-ocr\n",
    "  - OCR 라이브러리로 pdf 이미지를 text로 변환하기 위해 필요한 프로그램 \n",
    "  - windows: https://github.com/UB-Mannheim/tesseract/wiki 에서 다운받아 설치. \n",
    "    - 환경변수 Path에 설치 경로(\"C:\\Program Files\\Tesseract-OCR\") 추가 한다. (설치 후 IDE를 다시 시작한다.)\n",
    "  - macOS: `brew install tesseract`\n",
    "  - linux(unbuntu): `sudo apt install tesseract-ocr`\n",
    "- 설치 할 패키지\n",
    "  - **libmagic 설치**\n",
    "      - windows: `pip install python-magic-bin -qU`\n",
    "      - macOS: `brew install libmagic`\n",
    "      - linux(ubuntu): `sudo apt-get install libmagic-dev`\n",
    "  - `pip install \"unstructured[pdf]\" -qU`\n",
    "      - 문서 형식별로 sub module을 설치한다. (pdf, docx ..)\n",
    "      - 모든 sub module 설치: `pip install unstructured[all-docs]`\n",
    "      - https://docs.unstructured.io/open-source/installation/full-installation\n",
    "  - `pip install langchain-unstructured -qU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d98a32d3-b64c-427f-8663-86e00ee88f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-unstructured in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (0.1.6)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-unstructured) (0.3.63)\n",
      "Requirement already satisfied: onnxruntime<=1.19.2,>=1.17.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-unstructured) (1.19.2)\n",
      "Requirement already satisfied: unstructured-client<1,>=0.27.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-unstructured) (0.36.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (0.3.44)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (4.14.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (2.11.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (0.16.0)\n",
      "Requirement already satisfied: coloredlogs in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (25.2.10)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (2.2.6)\n",
      "Requirement already satisfied: protobuf in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (6.31.1)\n",
      "Requirement already satisfied: sympy in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (1.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (2.4.0)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured) (24.1.0)\n",
      "Requirement already satisfied: cryptography>=3.1 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured) (45.0.4)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured) (1.6.0)\n",
      "Requirement already satisfied: pypdf>=4.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured) (5.6.0)\n",
      "Requirement already satisfied: cffi>=1.14 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from cryptography>=3.1->unstructured-client<1,>=0.27.0->langchain-unstructured) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from cffi>=1.14->cryptography>=3.1->unstructured-client<1,>=0.27.0->langchain-unstructured) (2.22)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from coloredlogs->onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from sympy->onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-unstructured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324e4182",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e95e735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured\n",
      "  Using cached unstructured-0.17.2-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting chardet (from unstructured)\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: filetype in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured) (1.2.0)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Using cached python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: lxml in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured) (5.4.0)\n",
      "Collecting nltk (from unstructured)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: requests in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured) (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured) (4.13.4)\n",
      "Collecting emoji (from unstructured)\n",
      "  Using cached emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: dataclasses-json in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured) (0.6.7)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Using cached python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Using cached langdetect-1.0.9-py3-none-any.whl\n",
      "Requirement already satisfied: numpy in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured) (2.2.6)\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Using cached rapidfuzz-3.13.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting backoff (from unstructured)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: typing-extensions in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured) (4.14.0)\n",
      "Requirement already satisfied: unstructured-client in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured) (0.36.0)\n",
      "Collecting wrapt (from unstructured)\n",
      "  Using cached wrapt-1.17.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: tqdm in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured) (4.67.1)\n",
      "Requirement already satisfied: psutil in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured) (7.0.0)\n",
      "Collecting python-oxmsg (from unstructured)\n",
      "  Using cached python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting html5lib (from unstructured)\n",
      "  Using cached html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from beautifulsoup4->unstructured) (2.7)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from dataclasses-json->unstructured) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (24.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from html5lib->unstructured) (1.17.0)\n",
      "Collecting webencodings (from html5lib->unstructured)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: click in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from nltk->unstructured) (8.2.1)\n",
      "Requirement already satisfied: joblib in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from nltk->unstructured) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from nltk->unstructured) (2024.11.6)\n",
      "Collecting olefile (from python-oxmsg->unstructured)\n",
      "  Using cached olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from requests->unstructured) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from requests->unstructured) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from requests->unstructured) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from requests->unstructured) (2025.4.26)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured-client->unstructured) (24.1.0)\n",
      "Requirement already satisfied: cryptography>=3.1 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured-client->unstructured) (45.0.4)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured-client->unstructured) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured-client->unstructured) (1.6.0)\n",
      "Requirement already satisfied: pydantic>=2.11.2 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured-client->unstructured) (2.11.5)\n",
      "Requirement already satisfied: pypdf>=4.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured-client->unstructured) (5.6.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured-client->unstructured) (1.0.0)\n",
      "Requirement already satisfied: cffi>=1.14 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from cffi>=1.14->cryptography>=3.1->unstructured-client->unstructured) (2.22)\n",
      "Requirement already satisfied: anyio in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (0.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.3.1)\n",
      "Using cached unstructured-0.17.2-py3-none-any.whl (1.8 MB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Using cached emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "Using cached html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
      "Using cached python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Using cached python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
      "Using cached olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Using cached rapidfuzz-3.13.0-cp312-cp312-macosx_11_0_arm64.whl (1.4 MB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Using cached wrapt-1.17.2-cp312-cp312-macosx_11_0_arm64.whl (38 kB)\n",
      "Installing collected packages: webencodings, wrapt, rapidfuzz, python-magic, python-iso639, olefile, nltk, langdetect, html5lib, emoji, chardet, backoff, python-oxmsg, unstructured\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/14\u001b[0m [unstructured][0m [unstructured]\n",
      "\u001b[1A\u001b[2KSuccessfully installed backoff-2.2.1 chardet-5.2.0 emoji-2.14.1 html5lib-1.1 langdetect-1.0.9 nltk-3.9.1 olefile-0.47 python-iso639-2025.2.18 python-magic-0.4.27 python-oxmsg-0.0.2 rapidfuzz-3.13.0 unstructured-0.17.2 webencodings-0.5.1 wrapt-1.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install unstructured\n",
    "# brew install qpdf  -> 실행 필요 -> pip install \"unstructured[pdf]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a51647fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: pikepdf C++ to Python logger bridge initialized\n"
     ]
    }
   ],
   "source": [
    "from langchain_unstructured import UnstructuredLoader\n",
    "# path = \"data/olympic.txt\"\n",
    "# path = \"papers/1.pdf\"\n",
    "path = [\"data/olympic.txt\", \"papers/1.pdf\"]\n",
    "loader = UnstructuredLoader(path)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b20ea58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef294226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'papers/1.pdf',\n",
       " 'coordinates': {'points': ((70.866, 338.5113216),\n",
       "   (70.866, 403.26892159999994),\n",
       "   (290.7855161390001, 403.26892159999994),\n",
       "   (290.7855161390001, 338.5113216)),\n",
       "  'system': 'PixelSpace',\n",
       "  'layout_width': 595.276,\n",
       "  'layout_height': 841.89},\n",
       " 'file_directory': 'papers',\n",
       " 'filename': '1.pdf',\n",
       " 'languages': ['eng'],\n",
       " 'last_modified': '2025-06-13T08:55:22',\n",
       " 'page_number': 10,\n",
       " 'parent_id': 'c0ff9d37ae73259855ed24d509a77b06',\n",
       " 'filetype': 'application/pdf',\n",
       " 'category': 'NarrativeText',\n",
       " 'element_id': 'e1d2951b77c3895facdfdac2c0f93dec'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[300].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bc7e7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'각 올림픽 종목들은 IOC로부터 승인을 받은 국제경기연맹의 관리를 받는다. 35개의 연맹이 IOC에서 승인을 받았으며, 승인을 받았지만 현재 정식종목이 아닌 종목을 감독하는 연맹도 있다. IOC의 승인을 받았지만 올림픽 종목이 아닌 스포츠들은 올림픽 종목으로 고려되지는 않으나, 올림픽이 끝난 후 처음으로 열리는 IOC총회 때마다 정식종목이 되도록 신청을 할 수는 있다. IOC 총회 때 정식종목 선정은 총회에 참석중인 IOC위원들의 투표를 통해 이루어지며, 재적 위원 수의 과반수 이상 찬성표를 얻어야 정식종목으로 인정을 받는다. IOC의 승인을 받은 스포츠이나 찬성표를 받지 못해 정식종목이 되지 못한 스포츠로는 체스와 서핑과 같은 것이 있다.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[10].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8efaff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4acfcbe1-cc26-4e87-8c41-d6fa7d461701",
   "metadata": {},
   "source": [
    "### Directory 내의 문서파일들 로딩\n",
    "- DirectoryLoader 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b8eb4d8-3c1d-418d-a499-ee181d54b759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    \"data\", # 읽어들일 문서들이 있는 디렉토리.\n",
    "    recursive=True, # 하위디렉토리까지 검색할지 여부.\n",
    ")\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10ebc232-48ae-4cd2-ab3a-f6e26bd95ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1\\n\\n배따라기\\n\\nExported from Wikisource on 2024년 11월 24일\\n\\n2\\n\\n🙝🙟\\n\\n좋은 일기이다.\\n\\n좋은 일기라도, 하늘에 구름 한 점 없는 - 우리 ‘사람’으로서 는 감히 접근 못할 위엄을 가지고, 높이서 우리 조그만 ‘사 람’을 비웃는 듯이 내려다보는, 그런 교만한 하늘은 아니고, 가장 우리 ‘사람’의 이해자인 듯이 낮추 뭉글뭉글 엉기는 분 홍빛 구름으로서 우리와 서로 손목을 잡자는 그런 하늘이다. 사랑의 하늘이다.\\n\\n나는 잠시도 멎지 않고, 푸른 물을 황해로 부어 내리는 대동 강을 향한, 모란봉 기슭 새파랗게 돋아나는 풀 위에 뒹굴고 있었다.\\n\\n이날은 삼월 삼질, 대동강에 첫 뱃놀이하는 날이다. 까맣게 내려다보이는 물 위에는, 결결이 반짝이는 물결을 푸른 놀잇 배들이 타고 넘으며, 거기서는 봄 향기에 취한 형형색색의 선율이, 우단보다도 부드러운 봄 공기를 흔들면서 날아온다.\\n\\n그리고 거기서 기생들의 노래와 함께 날아오는 조선 아악 (雅樂)은 느리게, 길게, 유장하게, 부드럽게, 그리고 또 애처 롭게, 모든 봄의 정다움과 끝까지 조화하지 않고는 안두겠다 는 듯이 대동강에 흐르는 시꺼먼 봄 물, 청류벽에 돋아나는 푸르른 푸러음, 심지어 사람의 가슴속에 봄에 뛰노는 불붙는 핏줄기까지라도, 습기 많은 봄 공기를 다리 놓고 떨리지 않 고는 두지 않는다.\\n\\n봄이다. 봄이 왔다.\\n\\n3\\n\\n부드럽게 부는 조그만 바람이, 시꺼먼 조선 솔을 꿰며, 또는 돋아나는 풀을 스치고 지나갈 때의 그 음악은, 다른 데서는 듣지 못할 아름다운 음악이다.\\n\\n아아, 사람을 취케 하는 푸르른 봄의 아름다움이여! 열 다섯 살부터의 동경(東京) 생활에, 마음껏 이런 봄을 보지 못하였 던 나는, 늘 이것을 보는 사람보다 곱 이상의 감명을 여기서 받지 않을 수 없다.\\n\\n평양성 내에는, 겨우 툭툭 터진 땅을 헤치면 파릇파릇 돋아 나는 나무새기와 돋아나려는 버들의 어음으로 봄이 온 줄 알 뿐, 아직 완전히 봄이 안 이르렀지만, 이 모란봉 일대와 대동 강을 넘어 보이는 가나안 옥토를 연상시키는 장림(⻑林)에 는 마음껏 봄의 정다움이 이르렀다.\\n\\n그리고 또 꽤 자란 밀 보리들로 새파랗게 장식한 장림의 그 푸른 빛. 만족한 웃음을 띠고 그 벌에 서서 내다보는 농부의 모양은, 보지 않아도 생각할 수가 있다.\\n\\n구름은 자꾸 하늘을 날아다니는 모양이다. 그 밀 위에 비치 었던 구름의 그림자는 그 구름과 함께 저편으로 물러가며, 거기는 세계를 아까 만들어놓은 것 같은 새로운 녹빛이 퍼져 나간다. 바람이나 조금 부는 때는 그 잘 자란 밀들은 물결같 이 누웠다 일어났다, 일록 일청으로 춤을 춘다. 그리고 봄의 한가함을 찬송하는 솔개들은, 높은 하늘에서 동그라미를 그 리면서 더욱 더 아름다운 봄에 향그러운 정취를 더한다.\\n\\n“다스한 봄 정에 솟아나리다. 다스한 봄 정에 솟아나리다.”\\n\\n4\\n\\n나는 두어 번 소리나게 읊은 뒤에 담배를 붙여 물었다. 담뱃 내는 무럭무럭 하늘로 올라간다. 하늘에도 봄이 왔다.\\n\\n하늘은 낮았다. 모란봉 꼭대기에 올라가면 넉넉히 만질 수가 있으리만큼 하늘은 낮다. 그리고 그 낮은 하늘보다는 오히려 더 높이 있는 듯한 분홍빛 구름은, 뭉글뭉글 엉기면서 이리 저리 날아다닌다.\\n\\n나는 이러한 아름다운 봄 경치에 이렇게 마음껏 봄의 속삭임 을 들을 때는, 언제든 유토피아를 아니 생각할 수 없다. 우리 가 시시각각으로 애를 쓰며 수고하는 것은 - 그 목적은 무엇 인가? 역시 유토피아 건설에 있지 않을까? 유토피아를 생각 할 때는 언제든 그 ‘위대한 인격의 소유자’며 ‘사람의 위대함 을 끝까지 즐긴’ 진나라 시황(秦始皇)을 생각지 않을 수 없 다.\\n\\n우리가 어찌하면 죽지를 아니할까 하여, 소년 삼백을 배를 태워 불사약을 구하러 떠나보내며, 예술의 사치를 다하여 아 방궁을 지으며 매일 신하 몇 천 명과 잔치로써 즐기며, 이리 하여 여기 한 유토피아를 세우려던 시황은, 몇만의 역사가가 어떻다고 욕을 하든, 그는 정말로 인생의 향락자며 역사 이 후의 제일 큰 위인이라고 할 수가 있다. 그만한 순전한 용기 있는 사람이 있고야 우리 인류의 역사는 끝이 날지라도 한 ‘사람’을 가졌었다고 할 수 있다.\\n\\n“큰사람이었었다.”\\n\\n하면서 나는 머리를 들었다.\\n\\n5\\n\\n이때다. 기자묘 근처에서 무슨 슬픈 음률이, 봄 공기를 진동 시키며 날아오는 것이 들렸다.\\n\\n나는 무심코 귀를 기울였다.\\n\\n‘영유 배따라기’다. 그것도 웬만한 광대나 기생은 발꿈치에 도 미치지 못하리만큼 - 그만큼 그 배따라기의 주인은 잘 부 르는 사람이었다.\\n\\n비나이다, 비나이다. 산천후토 일월성신 하나님전 비나이다. 실낱같은 우리목숨 살려달라 비나이다. 에에야, 어그여지야.\\n\\n여기까지 이르렀을 때에 저편 아래 물에서 장고 소리와 함께 기생의 노래가 울리어오며 배따라기는 그만 안 들리게 되었 다. 나는 이년 전 한여름을 영유서 지내본 일이 있다. 배따라 기의 본고장인 영유를 몇 달 있어본 사람은 그 배따라기에 대하여 언제든 한 속절없는 애처로움을 깨달을 것이다.\\n\\n영유, 이름은 모르지만 산에 올라가서 내려다보면 앞은 망망 한 황해이니, 그곳 저녁때의 경치는 한번 본 사람은 영구히 잊을 수가 없으리라. 불덩이 같은 커다란 시뻘건 해가, 남실 남실 넘치는 바다에 도로 빠질 듯, 도로 솟아오를 듯 춤을 추 며, 거기서 때때로 보이지 않는 배에서 배따라기만 슬프게 날아오는 것을 들을 때엔 눈물 많은 나는 때때로 눈물을 흘 렸다. 이로 보아서, 어떤 원의 아내가 자기의 모든 영화를 낡 은 신같이 내어 던지고 뱃사람과 정처 없는 물길을 떠났다 함도 믿지 못할 말이랄 수가 없다.\\n\\n6\\n\\n영유서 돌아온 뒤에도 그 배따라기는 내 마음에 깊이 새기어 져 잊을 수가 없었고 언제 한번 다시 영유를 가서 그 노래를 한번 더 들어보고 그 경치를 다시 한번 보고 싶은 생각이 늘 떠나지를 않았다.\\n\\n장고소리와 기생의 노래는 멎고 배따라기만 구슬프게 날아 온다. 결결이 부는 바람으로 말미암아 때때로는 들을 수가 없으되, 나의 기억과 곡조를 종합하여 들은 배따라기는 이 대목이다.\\n\\n강변에 나왔다가 나를 보더니만, 혼비백산하여 꿈인지 생시인지 와르륵 달려들어 섬섬옥수로 부처잡고, 호천망극 하는 말이 ‘하늘로서 떨어지며 땅으로서 솟아났나. 바람결에 묻어오고 구름길에 쌔여왔나.’ 이리 서로 붙들고 울음 울 제, 인리 제인이며 일가 친척이 모두 모여,\\n\\n여기까지 들은 나는 마침내 참지 못하고 벌떡 일어서서 소나 무가지에 걸었던 모자를 내려쓰고, 그곳을 찾으러 모란봉 꼭 대기에 올라섰다. 꼭대기는 좀더 노래 소리가 잘 들린다. 그 는 배따라기의 맨 마지막, 여기를 부른다.\\n\\n7\\n\\n밥을 빌어서 죽을 쑬지라도 제발덕분에 뱃놈 노릇은 하지 말아. 에에야 어그여지야\\n\\n🙝🙟 그의 소리로써 방향을 찾으려던 나는, 그만 그 자리에 섰다.\\n\\n‘어딘가? 기자묘? 혹은 을밀대?’\\n\\n그러나 나는 오래 서 있을 수가 없었다. 어떻든 찾아보자 하 고, 현무문으로 가서 문 밖에 썩 나섰다. 기자묘의 깊은 솔밭 은 눈앞에 쫙 퍼진다.\\n\\n‘어딘가?’\\n\\n나는 또 물어보았다.\\n\\n이때에 그는 또다시 배따라기를 시초부터 부른다. 그 소리는 왼편에서 온다.\\n\\n왼편이구나 하면서, 소리 나는 곳을 더듬어서 소나무 틈으로 한참 돌다가, 겨우 기자묘 치고는 그중 하늘이 넓고 밝은 곳 에, 혼자서 뒹굴고 있는 그를 찾아내었다. 나의 생각한 바와 같은 얼굴이다. 얼굴, 코, 입, 눈, 몸집이 모두 네모나고 - 그 의 이마의 굵은 주름살과 시꺼먼 눈썹은, 고생 많이 함과 순 진한 성격을 나타낸다.\\n\\n8\\n\\n그는 어떤 신사가 자기를 들여다보는 것을 보고, 노래를 그 치고 일어나 앉는다.\\n\\n“왜? 그냥 하지요.”\\n\\n하면서 나는 그의 곁에 가 앉았다.\\n\\n“머…”\\n\\n한 뿐 그는 눈을 들어서 터진 하늘을 쳐다본다.\\n\\n좋은 눈이었다. 바다의 넓고 큼이, 유감없이 그의 눈에 나타 나 있다. 그는 뱃사람이라 나는 짐작하였다.\\n\\n“고향이 영유요?”\\n\\n“예, 머, 영유서 나기는 했디만, 한 이십 년 영윤 가보디두 않 았이요.”\\n\\n“왜, 이십 년씩 고향엘 안가요?”\\n\\n“사람의 일이라니, 마음대로 됩데까?”\\n\\n그는 왜 그러는지, 한숨을 짓는다.\\n\\n“거저, 운명이 데일 힘셉디다.”\\n\\n운명의 힘이 제일 세다는 그의 소리는 삭이지 못할 원한과 뉘우침이 섞여 있다.\\n\\n“그래요?”\\n\\n9\\n\\n나는 다만 그를 건너다볼 뿐이다.\\n\\n한참 잠잠하니 있다가 나는 다시 말하였다.\\n\\n“자 노형의 경험담이나 한번 들어봅시다. 감출 일이 아니면 한번 이야기해보소.”\\n\\n“머, 감출 일은…”\\n\\n“그럼, 어디 들어봅시다그려.”\\n\\n그는 다시 하늘을 쳐다보았다. 그러나 좀 있다가,\\n\\n“하디요.”\\n\\n하면서 내가 담배를 붙이는 것을 보고 자기도 담배를 붙여물 고 이야기를 꺼낸다.\\n\\n“잊히디두 않는 십 구 년 전 팔월 열 하룻날 일인데요.”\\n\\n하면서 그가 이야기한 바는 대략 이와 같은 것이다.\\n\\n그의 살던 마을은 영유 고을서 한 이십 리 떠나 있는 바다를 향한 조그만 어촌이다. 그의 살던 조그만 마을(설흔 집쯤 되 는)에서는 그는 꽤 유명한 사람이었다.\\n\\n그의 부모는 모두 열댓에 났을 때 돌아갔고, 남은 사람이라 고는 곁집에 딴살림하는 그의 아우 부처와 그 자기 부처뿐이 었다. 그들 형제가 그 마을에서 제일 부자이고 또 제일 고기 잡이를 잘하였고, 그중 글이 있었고 배따라기도 그 마을에서\\n\\n10\\n\\n빼나게 그 형제가 잘 불렀다. 말하자면 그 형제가 그 동네의 대표적 사람이었다.\\n\\n팔월 보름은 추석명절이다. 팔월 열 하룻날 그는 명절에 쓸 장도 볼 겸, 그의 아내가 늘 부러워하는 거울도 하나 사올 겸, 장으로 향하였다.\\n\\n“당손네 집에 있는 것보다 큰 거이요 잊디 말구요.”\\n\\n그의 아내는 길까지 따라나오면서 잊지 않도록 부탁하였다.\\n\\n“안 잊어.”\\n\\n하면서 그는 떠오르는 새빨간 햇빛을 앞으로 받으면서 자기 마을을 나섰다.\\n\\n그는 아내를(이렇게 말하기는 우습지만) 고와했다. 그의 아 내는 촌에서는 드물도록 연연하고도 예쁘게 생겼다(그는 나 에게 이렇게 말하였다).\\n\\n“성내(평양) 덴줏골(갈보촌)을 가두 그만한 거 쉽디 않갔이 요.”\\n\\n그러니까 촌에서는, 그리고 그 당시에는 남에게 우습게 보이 도록 그 내외의 사이는 좋았다. 늙은이들은 계집에게 혹하지 말라고 흔히 그에게 권고하였다.\\n\\n부처의 사이는 좋았지만 - 아니, 오히려 좋으므로 그는 아내 에게 샘을 많이 하였다. 그리고 그의 아내는 시기를 받을 일 을 많이 하였다. 품행이 나쁘다는 것이 아니라, 그의 아내는\\n\\n11\\n\\n대단히 천진스럽고 쾌활한 성질로서 아무에게나 말 잘하고 애교를 잘 부렸다.\\n\\n🙝🙟 그 동네에서는 무슨 명절이나 되면, 집이 그중 정결함을 핑 계삼아 젊은이들은 모두 그의 집에 모이고 하였다. 그 젊은 이들은 모두 그의 아내에게 ‘아즈마니’라 부르고, 그의 아내 는 아내라 ‘아즈바니 아즈바니’ 하며 그들과 지껄이고 즐기 며 그 웃기 잘하는 입에는 늘 웃음을 흘리고 있었다.\\n\\n그럴 때마다 그는 한편 구석에서 눈만 할끈거리며 있다가 젊 은이들이 돌아간 뒤에는 불문곡직하고 아내에게 덤비어들 어, 발길로 차고 때리며, 이전에 사다주었던 것을 모두 걷어 올린다. 싸움을 할 때에는 언제든 곁집에 있는 아우 부처가 말리러 오며, 그렇게 되면 언제든 그는 아우 부처까지 때려 주었다.\\n\\n그가 아우에게 그렇게 구는 데는 이유가 있었다. 그의 아우 는 시골 사람에게는 쉽지 않도록 늠름한 위엄이 있었고, 매 일 바닷바람을 쏘였지만 얼굴이 희었다. 이것 뿐으로도 시기 가 된다 하면 되지만, 특별히 아내가 그의 아우에게 친절히 하는 데는, 그는 속이 끓어 못 견디었다.\\n\\n그가 영유를 떠나기 반년 전쯤 ? 다시 말하자면 그가 거울을 사러 장에 갈 때부터 반년 전쯤 그의 생일날이었다. 그의 집 에서는 음식을 차려서 잘 먹었는데, 그에게는 괴상한 버릇이 있었으니, 맛있는 음식은 남겨두었다가 좀 있다 먹고 하는 것이 습관이었다.\\n\\n12\\n\\n그의 아내도 이 버릇은 잘 알 터인데 그의 아우가 점심때쯤 오니까, 아까 그가 아껴서 남겨두었던 그 음식을 아우에게 주려 하였다. 그는 눈을 부릅뜨고 ‘못 주리라’고 암호하였지 만 아내는 그것을 보았는지 못 보았는지 그의 아우에게 주어 버렸다. 그는 마음속이 자못 편치 못하였다. 트집만 있으면 이년을…, 그는 마음먹었다.\\n\\n그의 아내는 시아우에게 상을 준 뒤에 물러오다가 그만 그의 발을 조금 밟았다.\\n\\n“이년!”\\n\\n그는 힘껏 발을 들어서 아내를 냅다 찼다. 그의 아내는 상 위 에 꺼꾸러졌다가 일어난다.\\n\\n“이년, 사나이 발을 짓밟는 년이 어디 있어!”\\n\\n“거 좀 밟아서 발이 부러텟쉐까?”\\n\\n아내는 낯이 새빨개져서 울음 섞인 소리로 고함친다.\\n\\n“이년! 말대답이…”\\n\\n그는 일어서서 아내의 머리채를 휘어잡았다.\\n\\n“형님! 왜 이리십니까?”\\n\\n아우가 일어서면서 그를 붙잡았다.\\n\\n“가만 있거라, 이놈의 자식.”\\n\\n13\\n\\n하며, 그는 아우를 밀친 뒤에 아내를 되는대로 내리찧었다.\\n\\n“죽일 년, 이년! 나가거라!”\\n\\n“죽여라, 죽여라! 난, 죽어도 이 집에선 못 나가!”\\n\\n“못 나가?”\\n\\n“못 나가디 않구. 뉘 집이게…”\\n\\n이때다. 그의 마음에는 그 '못 나가겠다'는 아내의 마음이 폭 들이박혔다. 그 이상 때리기가 싫었다. 우두커니 눈만 흘기 고 있다가 그는,\\n\\n“망할 년, 그럼 내가 나갈라.”\\n\\n하고 그만 문 밖으로 뛰어나와서,\\n\\n“형님, 어디 갑니까?”\\n\\n하는 아우의 말에는 대답도 안하고, 곁 동네 탁주 집으로 뒤 도 안 돌아보고 가서, 거기 있는 술 파는 계집과 술상 앞에 마주앉았다.\\n\\n그날 저녁, 얼근히 취한 그는 아내를 위하여 떡을 한 돈어치 사 가지고 집으로 돌아왔다. 이리하여 또 서너 달은 평화가 이르렀다. 그러나 이 평화가 언제까지든 계속될 수가 없었 다. 그의 아우로 말미암아 또 평화는 쪼개져나갔다.\\n\\n14\\n\\n오월 초승부터 영유 고을 출입이 잦던 그의 아우는 오월 그 믐께부터는 고을서 며칠씩 묵어오는 일이 많았다. 함께, 고 을에 첩을 얻어두었다는 소문이 퍼졌다. 이 소문이 있은 뒤 는 아내는 그의 아우가 고을 들어가는 것을 벌레보다도 더 싫어하고, 며칠 묵어서 오는 때면 곧 아우의 집으로 가서 그 와 담판을 하며 심지어 동서 되는 아우의 처에까지 못 가게 하지 않는다고 싸우는 일이 있었다.\\n\\n칠월 초승께 그의 아우는 고을에 들어가서 열흘쯤 묵어온 일 이 있었다. 이때도 전과 같이 그의 아내는 그의 아우며 계수 와 싸우다 못하여, 마침내 그에게까지 와서 아우가 그런 못 된 데를 다니는 것을 그냥 둔다고, 해보자 한다. 그 꼴을 곱 게 보지 않았던 그는 첫마디로 고함을 쳤다.\\n\\n“네게 상관이 무에가? 듣기 싫다.”\\n\\n“못난둥이. 아우가 그런 델 댕기는 걸 말리디두 못하고!”\\n\\n분김에 이렇게 그의 아내는 고함쳤다.\\n\\n“이년, 무얼?”\\n\\n그는 벌떡 일어섰다.\\n\\n“못난둥이!”\\n\\n그 말이 채 끝나기 전에 그의 아내는 악 소리와 함께 그 자리 에 꺼꾸러졌다.\\n\\n“이년! 사나이게 그따윗 말버릇 어디서 배완!”\\n\\n15\\n\\n“에미네 때리는 건 어디서 배왔노? 못난둥이!”\\n\\n그의 아내는 울음소리로 부르짖었다.\\n\\n“상년 그냥? 나갈! 우리 집에 있디 말구 나갈!”\\n\\n그는 내리찧으면서 부르짖었다. 그리고 아내를 문을 열고 밀 쳤다.\\n\\n“나가디 않으리.”\\n\\n하고 그의 아내는 울면서 뛰어나갔다.\\n\\n“망한 년!”\\n\\n토하는 듯이 중얼거리고 그는 그 자리에 주저앉았다.\\n\\n그의 아내는 해가 져서 어두워져도 돌아오지 않았다. 일단 내어쫓기는 하였지만, 그는 아내의 돌아옴을 기다리고 있었 다. 어두워져서도 그는 불도 안 켜고, 성이 나서 우들우들 떨 면서 아내의 돌아오기를 기다렸다. 그러나 그의 아내의 참 기쁜 듯이 웃는 소리가 그의 아우의 집에서 밤새도록 울리었 다. 그는 움쩍도 안하고 그 자리에 앉아서 밤을 새운 뒤에, 새벽 동터올 때 아내와 아우를 죽이려고 부엌에 가서 식칼을 가지고 들어와서 문을 벌컥 열었다.\\n\\n그의 아내로서 만약 근심스러운 얼굴을 하고 그 문 밖에 우 두커니 서서 문을 들여다보고 있지 않았더면, 그는 아내와 아우를 죽이고야 말았으리라.\\n\\n16\\n\\n🙝🙟 그는 아내를 보는 순간, 마음에 가득 차는 사랑을 깨달으면 서, 칼을 내던지고 뛰어나가서 아내의 머리채를 휘어잡고 이 년 하면서 들어와서 뺨을 물어뜯으면서 함께 이리저리 자빠 져서 뒹굴었다.\\n\\n그런 이야기는 다 하려면 끝이 없으되 다만 ‘그’ ‘그의 아내’ ‘그의 아우’ 세 사람의 삼각 관계는 대략 이와 같았다….\\n\\n거울은 마침 장에 마음에 맞는 것이 있었다. 지금 것과 대보 면, 어떤 때는 코도 크게 보이고 입이 작게도 보이는 것이지 만, 그 당시에는 그리고 그런 촌에서는 둘도 없는 귀물이었 다. 거울을 사 가지고 장을 본 뒤에 그는 이 거울을 아내에게 주면 그 기뻐할 모양을 생각하며, 새빨간 저녁 햇빛을 받는, 넘치는 듯한 바다를 안고 자기 집으로, 늘 들러오던 탁주 집 에도 안 들러서 돌아왔다.\\n\\n그러나 그가 그의 집 방안에 들어설 때에는, 뜻도 안 하였던 광경이 그의 눈에 벌어져 있었다.\\n\\n방 가운데는 떡 상이 있고, 그의 아우는 수건이 벗어져서 목 뒤로 늘어지고, 저고리 고름이 모두 풀어져 가지고 한편 모 퉁이에 서 있고, 아내도 머리채가 모두 뒤로 늘어지고, 치마 가 배꼽 아래로 늘어지도록 되어 있으며, 그의 아내와 아우 는 그를 보고, 어찌할 줄을 모르는 듯이, 움찍도 안하고 서 있었다.\\n\\n세 사람은 한참 동안 어이가 없어서 서 있었다. 그러나 좀 있 다가 마침내 그의 아우가 겨우 말했다.\\n\\n17\\n\\n“그놈의 쥐 어디 갔니?”\\n\\n“흥! 쥐? 훌륭한 쥐 잡댔구나!”\\n\\n그는 말을 끝내지도 않고, 짐을 벗어던지고, 뛰어가서 아우 의 멱살을 끌어잡았다.\\n\\n“형님! 정말 쥐가…”\\n\\n“쥐? 이놈! 형수하고 그런 쥐 잡는 놈이 어디 있니?”\\n\\n그는 아우를 따귀를 몇 대 때린 뒤에 등을 밀어서 문 밖에 내 어던졌다. 그런 뒤에 이제 자기에게 이를 매를 생각하고, 우 들우들 떨면서 아랫목에 서 있는 아내에게 달려들었다.\\n\\n“이년! 시아우와 그런 쥐 잡는 년이 어디 있어?”\\n\\n그는 아내를 꺼꾸러뜨리고 함부로 내리찧었다.\\n\\n“정말 쥐가… 아이 죽겠다.”\\n\\n“이년! 너두 쥐? 죽어라!”\\n\\n그의 팔다리는 함부로 아내의 몸에 오르내렸다.\\n\\n“아이 죽갔다. 정말 아까 적으니(시아우) 왔기에 떡 자시라 구 내놓았더니…”\\n\\n“듣기 싫다! 시아우 붙은 년이, 무슨 잔소릴…”\\n\\n“아이, 아이, 정말이야요. 쥐가 한 마리 나…”\\n\\n18\\n\\n“그냥 쥐?”\\n\\n“쥐 잡을래다가…”\\n\\n“샹년! 죽어라! 물에래두 빠데 죽얼!”\\n\\n그는 실컷 때린 뒤에, 아내도 아우처럼 등을 밀어 쫓았다. 그 뒤에 그의 등으로,\\n\\n“고기 배때기에 장사해라!”\\n\\n토하였다.\\n\\n분풀이는 실컷 하였지만, 그래도 마음속이 자못 편치 못하였 다. 그는 아랫목으로 가서, 바람벽을 의지하고 실신한 사람 같이 우두커니 서서 떡 상만 들여다보고 있었다.\\n\\n한 시간… 두 시간….\\n\\n서편으로 바다를 향한 마을이라, 다른 곳보다는 늦게 어둡지 만, 그래도 술시(戌時) 쯤 되어서는 깜깜하니 어두웠다. 그 는 불을 켜려고 바람벽에서 떠나 성냥을 찾으러 돌아갔다.\\n\\n성냥은 늘 있던 자리에 있지 않았다. 그래서 여기저기 뒤적 이노라니까, 어떤 낡은 옷 뭉치를 들칠 때에 문득 쥐 소리가 나면서 무엇이 후더덕 튀어나온다. 그리하여 저편으로 기어 서 도망한다.\\n\\n“역시 쥐댔구나!”\\n\\n19\\n\\n그는 조그만 소리로 부르짖었다. 그리고 그만 그 자리에 맥 없이 덜썩 주저앉았다.\\n\\n아까 그가 보지 못한 때의 광경이, 활동사진과 같이 그의 머 리에 지나갔다.\\n\\n아우가 집에를 온다. 아우에게 친절한 아내는 떡을 먹으라고 아우에게 떡 상을 내놓는다. 그때에 어디선가 쥐가 한 마리 뛰어나온다. 둘(아우와 아내)이서는 쥐를 잡느라고 돌아간 다. 한참 성화시키던 쥐는 어느 구석에 숨어버린다. 그들은 쥐를 찾느라고 두룩거린다. 그럴 때에 그가 집에 들어선 것 이다.\\n\\n“상년. 좀 있으믄 안 들어오리…”\\n\\n그는 억지로 마음먹고 그 자리에 드러누웠다.\\n\\n그러나 아내는 밤이 가고 날이 밝기는커녕, 해가 중천에 올 라도 돌아오지를 않았다. 그는 차차 걱정이 나서 찾아보러 나섰다.\\n\\n아우의 집에도 없었다. 동네를 모두 찾아보아도 본 사람도 없다 한다.\\n\\n그리하여, 낮쯤 한 삼사 리 내려가서 바닷가에서 겨우 아내 를 찾기는 찾았지만, 그 아내는 이전 같은 생기로 찬 산 아내 가 아니요, 몸은 물에 불어서 곱이나 크게 되고, 이전에 늘 웃음을 흘리던 예쁜 입에는 거품을 잔뜩 물은, 죽은 아내였 다.\\n\\n20\\n\\n그는 아내를 업고 집으로 돌아오기까지 정신이 없었다.\\n\\n이튿날 간단하게 장사를 하였다. 뒤에 따라오는 아우의 얼굴 에는,\\n\\n‘형님, 이게 웬일이오니까?’\\n\\n하는 듯한 원망이 있었다.\\n\\n🙝🙟 장사를 지낸 이튿날부터 아우는 그 조그만 마을에서 없어졌 다. 하루 이틀은 심상히 지냈지만, 닷새가 지나도 아우는 돌 아오지 않았다. 그래서 알아보니까, 꼭 그의 아우같이 생긴 사람이 오륙 일 전에 멧산자 보따리를 하여 진 뒤에, 시뻘건 저녁 해를 등으로 받고 더벅더벅 동쪽으로 가더라 한다. 그 리하여 열흘이 지나고 스무날이 지났지만, 한번 떠난 그의 아우는 돌아올 길이 없고, 혼자 남은 아우의 아내는 매일 한 숨으로 세월을 보내게 되었다.\\n\\n그도 이것을 잠자코 보고 있을 수가 없었다. 그 불행의 모든 죄는 죄 그에게 있었다.\\n\\n그도 마침내 뱃사람이 되어, 적으나마 아내를 삼킨 바다와 늘 접근하며, 가는 곳마다 아우의 소식을 알아보려고, 어떤 배를 얻어 타고 물길을 나섰다.\\n\\n그는 가는 곳마다 아우의 이름과 모습을 말하여 물었으나, 아우의 소식은 알 수가 없었다.\\n\\n21\\n\\n이리하여 꿈결같이 십 년을 지내서 구년 전 가을, 탁탁히 낀 안개를 꿰며 연안(延安) 바다를 지나가던 그의 배는, 몹시 부는 바람으로 말미암아 파선을 하여 벗 몇 사람은 죽고, 그 는 정신을 잃고 물위에 떠돌고 있었다.\\n\\n그가 정신을 차린 때는 밤이었다. 그리고 어느덧 그는 뭍 위 에 올라와 있었고 그를 말리우느라고 새빨갛게 피워놓은 불 빛으로 자기를 간호하는 아우를 보았다.\\n\\n그는 이상히도 놀라지 않고, 천연하게 물었다.\\n\\n“너, 어ㅅ개(어떻게) 여기 완?”\\n\\n아우는 잠자코 한참 있다가 겨우 대답하였다.\\n\\n“형님, 거저 다 운명이왼다.”\\n\\n따뜻한 불기운에 깜빡 잠이 들려다가 그는 화닥닥 깨면서 또 말했다.\\n\\n“십 년 동안에 되게 파랬구나.”\\n\\n“형님, 나두 변했거니와 형님도 몹시 늙으셨쉐다.”\\n\\n이 말을 꿈결같이 들으면서 그는 또 혼혼히 잠이 들었다. 그 리하여 두어 시간, 꿀보다도 단 잠을 잔 뒤에 깨어보니, 아까 같이 빨간 불은 피어 있지만 아우는 어디로 갔는지 없어졌 다. 곁의 사람에게 물어보니까 아까 아우는 형의 얼굴을 물 끄러미 한참 들여다보고 있다가, 새빨간 불빛을 등으로 받으\\n\\n22\\n\\n면서, 더벅더벅 아무말 없이 어두움 가운데로 사라졌다 한 다.\\n\\n이튿날 아무리 알아보아야 그의 아우는 종적이 없어지고 알 수 없으므로, 그는 하릴없이 다른 배를 얻어 타고 또 물길을 떠났다. 그리하여 그의 배가 해주에 이르렀을 때, 그는 해주 장에 들어가서 무엇을 사려다가, 저편 맞은편 가게에 걸핏 그의 아우 같은 사람이 있으므로 뛰어가서 보니 그는 벌써 없어졌다. 배가 해주에는 오래 머물지 않으므로 그는 마음은 해주에 남겨두고, 또다시 바닷길을 떠났다.\\n\\n그 뒤에 삼 년을 이리저리 돌아다녔어도 아우는 다시 볼 수 가 없었다.\\n\\n그리하여 삼 년을 지내서 지금부터 육 년 전에, 그의 탄 배가 강화도를 지날 날에, 바다를 향한 가파로운 뫼켠에서 바다를 향하여 날아오는 배따라기를 들었다. 그것도 어떤 구절과 곡 조는 그의 아우 특식으로 변경된 - 그의 아우가 아니면 부를 사람이 없는, 그 배따라기이다.\\n\\n배가 강화도에는 머무르지 않아서 거저 지나갔으나, 인천서 열흘쯤 머무르게 되었으므로, 그는 곧 내려서 강화도로 건너 가 보았다. 거기서 이리저리 찾아다니다가, 어떤 조그만 객 주집에서 물어보니, 이름도 그의 아우요, 생긴 모습도 그의 아우인 사람이 묵어 있기는 하였으나, 사나흘 전에 도로 인 천으로 갔다 한다. 그는 곧 돌아서서 인천으로 건너와서 찾 아보았지만, 그 조그만 인천서도 그의 아우를 찾을 바이 없 었다.\\n\\n23\\n\\n그 뒤에 눈 오고 비 오며, 육년이 지났지만, 그는 다시 아우 를 만나보지 못하고 아우의 생사까지도 알 수가 없다.\\n\\n말을 끝낸 그의 눈에는 저녁 해에 반사하여 몇 방울의 눈물 이 반짝인다.\\n\\n나는 한참 있다가 겨우 물었다.\\n\\n“노형 계수는?”\\n\\n“모르디오. 이십 년을 영유는 안가봤으니낀요.”\\n\\n“노형은 이제 어디루 갈 테요?”\\n\\n“것두 모르디요. 덩처가 있나요? 바람 부는 대로 몰려댕기디 오.”\\n\\n그는 다시 한번 나를 위하여 배따라기를 불렀다. 아아, 그 속 에 잠겨 있는 삭이지 못할 뉘우침, 바다에 대한 애처로운 그 리움.\\n\\n노래를 끝낸 다음에 그는 일어서서 시뻘건 저녁 해를 잔뜩 등으로 받고, 을밀대로 향하여 더벅더벅 걸어간다. 나는 그 를 말릴 힘이 없어서, 멀거니 그의 등만 바라보고 앉아 있었 다.\\n\\n그날 밤, 집에 돌아와서도 그 배따라기와 그의 숙명적 경험 담이 귀에 쟁쟁히 울리어서 잠을 못 이루고, 이튿날 아침 깨 어서 조반도 안먹고 기자묘로 뛰어가서 또다시 그를 찾아보 았다. 그가 어제 깔고 앉았던 풀은 모두 한편으로 누워서 그\\n\\n24\\n\\n가 다녀감을 기념하되, 그는 그 근처에 보이지 않았다. 그러 나 - 그러나 배따라기는 어디선가 쟁쟁히 울리어서 모든 소 나무들을 떨리지 않고는 안 두겠다는 듯이 날아온다.\\n\\n“모란봉(牡丹峰)이다. 모란봉에 있다.”\\n\\n하고 나는 한숨에 모란봉으로 뛰어갔다. 모란봉에는 사람이 하나도 없다. 부벽루(浮碧樓)에도 없다.\\n\\n“을밀대(⼄密臺)다.”\\n\\n하고 나는 다시 을밀대로 갔다. 을밀대에선 부벽루를 연한, 지옥까지 연한 듯한 골짜기에 물 한 방울을 안 새이리라고 빽빽이 난 소나무의 그 모든 잎잎은 떨리는 배따라기를 부르 고 있지만, 그는 여기도 있지 않다. 기자묘의, 하늘을 향하여 퍼져나간 그 모든 소나무의 천만의 잎잎도, 그 아래쪽 퍼진 천만의 풀들도, 모두 그 배따라기를 슬프게 부르고 있지만, 그는 이 조그만 모란봉 일대에서 찾을 수가 없었다.\\n\\n강가에 나가서 알아보니, 그의 배는 오늘 새벽에 떠났다 한 다. 그 뒤에 여름과 가을이 가고 일년이 지나서 다시 봄이 이 르렀으되, 잠깐 평양을 다녀간 그는 그 숙명적 경험담과 슬 픈 배따라기를 두었을 뿐, 다시 조그만 모란봉에 나타나지 않는다.\\n\\n모란봉과 기자묘에 다시 봄이 이르러서, 작년에 그가 깔고 앉아서 부러졌던 풀들도 다시 곧게 대가 나서 자주빛 꽃이 피려 하지만 끝없는 뉘우침을 다만 한낱 배따라기로 하소연 하는 그는, 이 조그만 모란봉과 기자묘에서 다시 볼 수가 없\\n\\n25\\n\\n었다. 다만 그가 남기고 간 배따라기만 추억하는 듯이 모든 잎잎이 속삭이고 있을 따름이다.\\n\\n26\\n\\n이 저작물은 저자가 사망한 지 50년이 넘었으므 로, 저자가 사망한 후 50년(또는 그 이하)이 지나 면 저작권이 소멸하는 국가에서 퍼블릭 도메인입 니다.\\n\\n1929년에서 1977년 사이에 출판되었다면 미국에서 퍼블 릭 도메인이 아닐 수도 있습니다. 미국에서 퍼블릭 도메인 인 저작에는 {{PD-1996}}를 사용하십시오.\\n\\n주의\\n\\n27\\n\\nAbout this digital edition\\n\\nThis e-book comes from the online library Wikisource[1]. This multilingual digital library, built by volunteers, is committed to developing a free accessible collection of publications of every kind: novels, poems, magazines, letters...\\n\\nWe distribute our books for free, starting from works not copyrighted or published under a free license. You are free to use our e-books for any purpose (including commercial exploitation), under the terms of the Creative Commons Attribution-ShareAlike 3.0 Unported[2] license or, at your choice, those of the GNU FDL[3].\\n\\nWikisource is constantly looking for new members. During the realization of this book, it's possible that we made some errors. You can report them at this page[4].\\n\\nThe following users contributed to this book:\\n\\nCaﬀelice~kowikisource Mineralsab Salamander724 Kwamikagami Tene~commonswiki Rocket000\\n\\n28\\n\\nBastique Andux Amgine Boris23 KABALINI Bromskloss AzaToth Bender235 PatríciaR\\n\\n1. ↑ https://wikisource.org 2. ↑ https://www.creativecommons.org/licenses/by-sa/3.0 3. ↑ https://www.gnu.org/copyleft/fdl.html 4. ↑ https://wikisource.org/wiki/Wikisource:Scriptorium\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 13\n",
    "docs[idx].metadata\n",
    "docs[idx].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04a1e8eb-2569-43f3-a458-dd020a322c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DirectoryLoader(\n",
    "    \"data\", # 읽어들일 문서들이 있는 디렉토리.\n",
    "    glob=[\"*.txt\"],   # 읽을 파일들의 확장자를 지정.\n",
    "    recursive=False, # 하위디렉토리까지 검색할지 여부.\n",
    ")\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "606579fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d910f155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data/olympic.txt'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[2].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de26ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275ba5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8314a70c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15823c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "300bddc2",
   "metadata": {},
   "source": [
    "# Chunking (문서 분할)\n",
    "\n",
    "![rag_split](figures/rag_split.png)\n",
    "\n",
    "- Load 한 문서를 지정한 기준의 덩어리(chunk)로 나누는 작업을 진행한다.\n",
    "\n",
    "## 나누는 이유\n",
    "1. **임베딩 모델의 컨텍스트 길이 제한**\n",
    "    - 대부분의 언어 모델은 한 번에 처리할 수 있는 토큰 수에 제한이 있다. 전체 문서를 통째로 입력하면 이 제한을 초과할 수 있어 처리가 불가능해진다.\n",
    "2. **검색 정확도 향상**\n",
    "    - 큰 문서 전체보다는 특정 주제나 내용을 다루는 작은 chunk가 사용자 질문과 더 정확하게 매칭된다. 예를 들어, 100페이지 매뉴얼에서 특정 기능에 대한 질문이 있을 때, 해당 기능을 설명하는 몇 개의 문단만 검색되는 것이 더 효과적이다.\n",
    "    - 사용자 질문에 대해 문서의 모든 내용이 다 관련있는 것은 아니다. Chunking을 통해 가장 관련성 높은 부분만 선별적으로 활용할 수 있어 답변의 품질이 향상된다.\n",
    "    - 전체 문서에는 질문과 무관한 내용들이 많이 포함되어 있어 모델이 혼란을 겪을 수 있다. 적절한 크기의 chunk는 이런 노이즈를 줄여준다.\n",
    "3. **계산 효율성**\n",
    "    - 벡터 유사도 계산, 임베딩 생성 등의 작업이 작은 chunk 단위로 수행될 때 더 빠르고 효율적이다. 메모리 사용량도 줄일 수 있다.\n",
    "\n",
    "## 주요 Spliter\n",
    "- https://api.python.langchain.com/en/latest/text_splitters_api_reference.html\n",
    "\n",
    "### CharacterTextSplitter\n",
    "가장  기본적인 Text spliter\n",
    "- 한개의 구분자를 기준으로 분리한다. (default: \"\\n\\n\")\n",
    "    - 분리된 조각이 chunk size 보다 작으면 다음 조각과 합칠 수 있다.\n",
    "        - 합쳤을때 chuck_size 보다 크면 안 합친다. chuck_size 이내면 합친다.\n",
    "    - 나누는 기준은 구분자이기 때문에 chunk_size 보다 글자수가 많을 수 있다.\n",
    "- chunk size: 분리된 문서(chunk) 글자수 이내에서 분리되도록 한다.\n",
    "    -  구분자를 기준으로 분리한다. 구분자를 기준으로 분리한 문서 조각이 chunk size 보다 크더라도 그대로 유지한다. 즉 chunk_size가 우선이 아니라 **seperator** 가 우선이다.\n",
    "- 주요 파라미터\n",
    "    - chunk_size: 각 조각의 최대 길이를 지정.\n",
    "    - seperator: 구분 문자열을 지정. (default: '\\n\\n')\n",
    "- CharacterTextSplitter는 단순 스플리터로 overlap기능을 지원하지는 않는다. 단 seperator가 빈문자열(\"\") 일 경우에는 overlap 기능을 지원한다. overlap이란 각 이전 청크의 뒷부분의 문자열을 앞에 붙여 문맥을 유지하는 것을 말한다.\n",
    "  \n",
    "### RecursiveCharacterTextSplitter\n",
    "- RecursiveCharacterTextSplitter는 **긴 텍스트를 지정된 최대 길이(chunk_size) 이하로 나누는 데 효과적인 텍스트 분할기**(splitter)이다.\n",
    "- 여러 **구분자(separators)를 순차적으로 적용**하여, 가능한 한 자연스러운 문단/문장/단어 단위로 분할하고, 최종적으로는 크기 제한을 만족시킨다.\n",
    "- 분할 기준 문자\n",
    "    1. 두 개의 줄바꿈 문자 (\"\\n\\n\")\n",
    "    2. 한 개의 줄바꿈 문자 (\"\\n\")\n",
    "    3. 공백 문자 (\" \")\n",
    "    4. 빈 문자열 (\"\")\n",
    "- 작동 방식\n",
    "    1. 먼저 가장 높은 우선순위의 구분자(\"\\n\\n\")로 분할을 시도한다.\n",
    "    2. 분할된 조각 중 **chunk_size를 초과하는 조각**에 대해 다음 우선순위 구분자(\"\\n\" → \" \" → \"\")로 재귀적으로 재분할한다.\n",
    "    3. 이 과정을 통해 모든 조각(chunk)이 chunk_size를 초과하지 않도록 만든다.  \n",
    "- 주요 파라미터\n",
    "    - chunk_size: 각 조각의 최대 길이를 지정.\n",
    "    - chunk_overlap: 연속된 청크들 간의 겹치는 문자 수를 설정. 새로운 청크 생성 시 이전 청크의 마지막 부분에서 지정된 수만큼의 문자를 가져와서 새 청크의 앞부분에 포함시켜, 청크 경계에서 문맥의 연속성을 유지한다.\n",
    "      - 구분자에 의해 청크가 나눠지면 정상적인 분리이므로 overlap이 적용되지 않는다.\n",
    "      - 정상적 구분자로 나눌 수 없어 chunk_size에 맞춰 잘라진 경우 문맥의 연결성을 위애 overlap을 적용한다.\n",
    "    - separators(list): 구분자를 지정한다. 지정하면 기본 구분자가 지정한 것으로 변경된다.\n",
    "\n",
    "#### 메소드\n",
    "- `split_documents(Iterable[Document]) : List[Document]`\n",
    "    - Document 목록을 받아 split 처리한다.\n",
    "- `split_text(str) : List[str]`\n",
    "    - string text를 받아서 split 처리한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35a08d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"가각간갇갈갉갊감갑값갓갔강갖갗같갚갛개객갠갤갬갭갯갰\n",
    "\n",
    "aadlskfjadklsfjakldfjadklsjadfskl갸갹갼걀걋걍걔걘걜거걱건걷걸걺검겁것겉겊겋게겐\n",
    "\n",
    "띱띳띵라락란랄람랍랏랐\n",
    "\n",
    "랑랒랖랗래랙랜랠램랩랫랬랭랴략랸럇량러럭런럴럼럽럿렀렁렇레렉렌렐렘렙렛렝나낙낚ASDFFGHJJKKLLLQWE\n",
    "\n",
    "멨멩며 \n",
    "\n",
    "멱면멸몃몄명몇몌모목몫몬몰몲몸몹못몽뫄뫈뫘뫙뫼묀묄묍묏묑묘묜묠묩묫무묵묶문묻물묽묾뭄뭅뭇뭉뭍뭏ABCDEFGHIJ\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3725f8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "# chunk_size > chunk_overlap   =>   국룰\n",
    "spliter = CharacterTextSplitter(\n",
    "    chunk_size = 60,                                    # 60글자로 자름\n",
    "    chunk_overlap = 10,                                 # 겹치는 문자 수 지정\n",
    "    # separator = \"\"                                      # defaul : \"\\n\\n\"\n",
    ")\n",
    "docs = spliter.split_text(text)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee0c8840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "가각간갇갈갉갊감갑값갓갔강갖갗같갚갛개객갠갤갬갭갯갰\n",
      "56\n",
      "aadlskfjadklsfjakldfjadklsjadfskl갸갹갼걀걋걍걔걘걜거걱건걷걸걺검겁것겉겊겋게겐\n",
      "11\n",
      "띱띳띵라락란랄람랍랏랐\n",
      "56\n",
      "랑랒랖랗래랙랜랠램랩랫랬랭랴략랸럇량러럭런럴럼럽럿렀렁렇레렉렌렐렘렙렛렝나낙낚ASDFFGHJJKKLLLQWE\n",
      "3\n",
      "멨멩며\n",
      "57\n",
      "멱면멸몃몄명몇몌모목몫몬몰몲몸몹못몽뫄뫈뫘뫙뫼묀묄묍묏묑묘묜묠묩묫무묵묶문묻물묽묾뭄뭅뭇뭉뭍뭏ABCDEFGHIJ\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(len(doc))\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c57ae7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 6, langchain_core.documents.base.Document)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "document = Document(page_content=text)\n",
    "docs2 = spliter.split_documents([document])\n",
    "type(docs2), len(docs2), type(docs2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed5b25cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='가각간갇갈갉갊감갑값갓갔강갖갗같갚갛개객갠갤갬갭갯갰'\n",
      "page_content='aadlskfjadklsfjakldfjadklsjadfskl갸갹갼걀걋걍걔걘걜거걱건걷걸걺검겁것겉겊겋게겐'\n",
      "page_content='띱띳띵라락란랄람랍랏랐'\n",
      "page_content='랑랒랖랗래랙랜랠램랩랫랬랭랴략랸럇량러럭런럴럼럽럿렀렁렇레렉렌렐렘렙렛렝나낙낚ASDFFGHJJKKLLLQWE'\n",
      "page_content='멨멩며'\n",
      "page_content='멱면멸몃몄명몇몌모목몫몬몰몲몸몹못몽뫄뫈뫘뫙뫼묀묄묍묏묑묘묜묠묩묫무묵묶문묻물묽묾뭄뭅뭇뭉뭍뭏ABCDEFGHIJ'\n"
     ]
    }
   ],
   "source": [
    "for d in docs2:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb96813e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 9\n"
     ]
    }
   ],
   "source": [
    "spliter2 = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 50,\n",
    "    chunk_overlap = 10\n",
    "    # ,separators=[\"첫번쨰 구분자\", \"두번째 구분자\", ...]\n",
    ")\n",
    "\n",
    "result = spliter2.split_text(text)\n",
    "print(type(result), len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5cd8206f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26||가각간갇갈갉갊감갑값갓갔강갖갗같갚갛개객갠갤갬갭갯갰\n",
      "======================================================================\n",
      "49||aadlskfjadklsfjakldfjadklsjadfskl갸갹갼걀걋걍걔걘걜거걱건걷걸걺검\n",
      "======================================================================\n",
      "17||걔걘걜거걱건걷걸걺검겁것겉겊겋게겐\n",
      "======================================================================\n",
      "11||띱띳띵라락란랄람랍랏랐\n",
      "======================================================================\n",
      "49||랑랒랖랗래랙랜랠램랩랫랬랭랴략랸럇량러럭런럴럼럽럿렀렁렇레렉렌렐렘렙렛렝나낙낚ASDFFGHJJK\n",
      "======================================================================\n",
      "17||ASDFFGHJJKKLLLQWE\n",
      "======================================================================\n",
      "3||멨멩며\n",
      "======================================================================\n",
      "49||멱면멸몃몄명몇몌모목몫몬몰몲몸몹못몽뫄뫈뫘뫙뫼묀묄묍묏묑묘묜묠묩묫무묵묶문묻물묽묾뭄뭅뭇뭉뭍뭏AB\n",
      "======================================================================\n",
      "18||묽묾뭄뭅뭇뭉뭍뭏ABCDEFGHIJ\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "for r in result:\n",
    "    print(len(r), r, sep=\"||\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12edb31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='가각간갇갈갉갊감갑값갓갔강갖갗같갚갛개객갠갤갬갭갯갰'),\n",
       " Document(metadata={}, page_content='aadlskfjadklsfjakldfjadklsjadfskl갸갹갼걀걋걍걔걘걜거걱건걷걸걺검'),\n",
       " Document(metadata={}, page_content='걔걘걜거걱건걷걸걺검겁것겉겊겋게겐'),\n",
       " Document(metadata={}, page_content='띱띳띵라락란랄람랍랏랐'),\n",
       " Document(metadata={}, page_content='랑랒랖랗래랙랜랠램랩랫랬랭랴략랸럇량러럭런럴럼럽럿렀렁렇레렉렌렐렘렙렛렝나낙낚ASDFFGHJJK'),\n",
       " Document(metadata={}, page_content='ASDFFGHJJKKLLLQWE'),\n",
       " Document(metadata={}, page_content='멨멩며'),\n",
       " Document(metadata={}, page_content='멱면멸몃몄명몇몌모목몫몬몰몲몸몹못몽뫄뫈뫘뫙뫼묀묄묍묏묑묘묜묠묩묫무묵묶문묻물묽묾뭄뭅뭇뭉뭍뭏AB'),\n",
       " Document(metadata={}, page_content='묽묾뭄뭅뭇뭉뭍뭏ABCDEFGHIJ')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = spliter2.split_documents([document])\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4461fa92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "# olympic.txt를 읽어서 split 처리\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 1. 문서 Load\n",
    "path = \"data/olympic.txt\"\n",
    "loader = TextLoader(path, encoding=\"utf-8\")\n",
    "docs = loader.load()\n",
    "\n",
    "# 2. load한 문서를 split\n",
    "spliter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "split_docs = spliter.split_documents(docs)\n",
    "print(len(split_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "05193ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 498,\n",
       " 403,\n",
       " 414,\n",
       " 239,\n",
       " 262,\n",
       " 5,\n",
       " 496,\n",
       " 222,\n",
       " 270,\n",
       " 338,\n",
       " 310,\n",
       " 434,\n",
       " 456,\n",
       " 498,\n",
       " 5,\n",
       " 496,\n",
       " 135,\n",
       " 446,\n",
       " 413,\n",
       " 4,\n",
       " 498,\n",
       " 120,\n",
       " 356,\n",
       " 233,\n",
       " 400,\n",
       " 392,\n",
       " 310,\n",
       " 221,\n",
       " 496,\n",
       " 226,\n",
       " 428,\n",
       " 362,\n",
       " 495,\n",
       " 379,\n",
       " 311,\n",
       " 355,\n",
       " 268,\n",
       " 405,\n",
       " 2,\n",
       " 495,\n",
       " 495,\n",
       " 242,\n",
       " 362,\n",
       " 493,\n",
       " 374,\n",
       " 236,\n",
       " 329,\n",
       " 297,\n",
       " 459,\n",
       " 498,\n",
       " 154,\n",
       " 401,\n",
       " 444,\n",
       " 466,\n",
       " 352,\n",
       " 499,\n",
       " 111,\n",
       " 10,\n",
       " 498,\n",
       " 217]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_list = [len(d.page_content) for d in split_docs]                        # split된 문서들의 글자수\n",
    "len_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "89bf463f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "올림픽(영어: Olympic Games, 프랑스어: Jeux olympiques)은 전 세계 각 대륙 각국에서 모인 수천 명의 선수가 참가해 여름과 겨울에 스포츠 경기를 하는 국제적인 대회이다. 전 세계에서 가장 큰 지구촌 최대의 스포츠 축제인 올림픽은 세계에서 가장 인지도있는 국제 행사이다. 올림픽은 2년마다 하계 올림픽과 동계 올림픽이 번갈아 열리며, 국제 올림픽 위원회(IOC)가 감독하고 있다. 또한 오늘날의 올림픽은 기원전 8세기부터 서기 5세기에 이르기까지 고대 그리스 올림피아에서 열렸던 올림피아 제전에서 비롯되었다. 그리고 19세기 말에 피에르 드 쿠베르탱 남작이 고대 올림피아 제전에서 영감을 얻어, 근대 올림픽을 부활시켰다. 이를 위해 쿠베르탱 남작은 1894년에 IOC를 창설했으며, 2년 뒤인 1896년에 그리스 아테네에서 제 1회 올림픽이 열렸다. 이때부터 IOC는 올림픽 운동의 감독 기구가 되었으며, 조직과 활동은 올림픽 헌장을 따른다. 오늘날 전 세계 대부분의\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print(split_docs[idx].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "639cce29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# 문서 로드\n",
    "path = \"data/novel/메밀꽃_필_무렵_이효석.pdf\"\n",
    "loader = PyPDFLoader(path)\n",
    "docs = loader.load()\n",
    "\n",
    "# split\n",
    "split_docs = spliter.split_documents(docs)\n",
    "len(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a4329ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "메밀꽃  필  무렵\n",
      "Exported from Wikisource on 2024 년  11 월  24 일\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "print(split_docs[idx].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf15e35c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed87439d",
   "metadata": {},
   "source": [
    "## Token 수 기준으로 나누기\n",
    "\n",
    "- LLM 언어 모델들은 입력 토큰 수 제한이 있어서 요청시 제한 토큰수 이상의 프롬프트는 전송할 수 없다.\n",
    "- 따라서 텍스트를 chunk로 분할할 때는 글자수 보다 **토큰 수를 기준으로 크기를 지정하는 것**이 좋다.  \n",
    "- 토큰기반 분할은 텍스트의 의미를 유지하면서 분할하는 방식이므로 문자 기반 분할과 같이 단어가 중간잘리는 것들을 방지할 수 있다. \n",
    "- 토큰 수 계산할 때는 사용하는 언어 모델에 사용된 것과 동일한 tokenizer를 사용하는 것이 좋다.\n",
    "  - 예를 들어 OpenAI의 GPT 모델을 사용할 경우 tiktoken 라이브러리를 활용하여 토큰 수를 정확하게 계산할 수 있다.\n",
    "\n",
    "### [tiktoken](https://github.com/openai/tiktoken) tokenizer 기반 분할\n",
    "- OpenAI에서 GPT 모델을 학습할 때 사용한 `BPE` 방식의 tokenizer. **OpenAI 언어모델을 사용할 경우 이것을 사용하는 것이 좀 더 정확하게  토큰dmf 계산할 수 있다.**\n",
    "- Splitter.from_tiktoken_encoder() 메소드를 이용해 생성\n",
    "  - `RecursiveCharacterTextSplitter.from_tiktoken_encoder()`\n",
    "  - `CharacterTextSplitter.from_tiktoken_encoder()`\n",
    "- 파라미터\n",
    "  - encode_name: 인코딩 방식(토큰화 규칙)을 지정. OpenAI는 GPT 모델들 마다 다른 방식을 사용했다. 그래서 사용하려는 모델에 맞는 인코딩 방식을 지정해야 한다.\n",
    "    - `cl100k_base`: GPT-4 및 GPT-3.5-Turbo 모델에서 사용된 방식.\n",
    "    - `r50k_base:` GPT-3 모델에서 사용된 방식 \n",
    "  - chunk_size, chunk_overlap, separators 파라미터 (위와 동일)\n",
    "- tiktoken 설치\n",
    "  - `pip install tiktoken`\n",
    "\n",
    "### HuggingFace Tokenizer\n",
    "- HuggingFace 모델을 사용할 경우 그 모델이 사용한 tokenizer를 이용해 토큰 기반으로 분할 한다.\n",
    "  - 다른 tokenizer를 이용해 분할 할 경우 토큰 수 계산이 다르게 될 수있다.\n",
    "- `from_huggingface_tokenizer()` 메소드를 이용.\n",
    "  - 파라미터\n",
    "    - tokenizer: HuggingFace tokenizer 객체\n",
    "    - chunk_size, chunk_overlap, separators 파라미터 (위와 동일)\n",
    "- `transformers` 라이브러리를 설치해야 한다.\n",
    "  - `pip install transformers` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d99796ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = TextLoader(\"data/olympic.txt\", encoding=\"utf-8\")\n",
    "\n",
    "spliter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    model_name=\"gpt-4o-mini\",                                       # 지정한 모델을 학습할 때 사용한 tokenizer를 사용\n",
    "    chunk_size=200,                                                 # 토큰수 기준\n",
    "    chunk_overlap=0\n",
    ")\n",
    "docs = loader.load_and_split(spliter)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aa6dba29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "올림픽(영어: Olympic Games, 프랑스어: Jeux olympiques)은 전 세계 각 대륙 각국에서 모인 수천 명의 선수가 참가해 여름과 겨울에 스포츠 경기를 하는 국제적인 대회이다. 전 세계에서 가장 큰 지구촌 최대의 스포츠 축제인 올림픽은 세계에서 가장 인지도있는 국제 행사이다. 올림픽은 2년마다 하계 올림픽과 동계 올림픽이 번갈아 열리며, 국제 올림픽 위원회(IOC)가 감독하고 있다. 또한 오늘날의 올림픽은 기원전 8세기부터 서기 5세기에 이르기까지 고대 그리스 올림피아에서 열렸던 올림피아 제전에서 비롯되었다. 그리고 19세기 말에 피에르 드 쿠베르탱 남작이 고대 올림피아\n"
     ]
    }
   ],
   "source": [
    "print(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30b4d3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huggingface Tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "model_id = \"beomi/kcbert-base\"                      # 사용할 LLM 모델의 ID\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dbf9ddbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spliter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer=tokenizer,\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "docs = loader.load_and_split(spliter)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591dc456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
