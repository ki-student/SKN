{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "227316ea",
   "metadata": {},
   "source": [
    "# RAG(Retrieval Augmented Generation)\n",
    "- [RAG](https://python.langchain.com/v0.1/docs/modules/data_connection/)ì€ *Retrieval Augmented Generation*ì˜ ì•½ìë¡œ, **ê²€ìƒ‰ ê¸°ë°˜ ìƒì„± ê¸°ë²•**ì„ ì˜ë¯¸í•œë‹¤. ì´ ê¸°ë²•ì€ LLMì´ íŠ¹ì • ë¬¸ì„œì— ê¸°ë°˜í•˜ì—¬ ë³´ë‹¤ ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ìˆë„ë¡ ë•ëŠ”ë‹¤.     \n",
    "- ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ìì²´ì ìœ¼ë¡œ êµ¬ì¶•í•œ ë°ì´í„°ë² ì´ìŠ¤(DB)ë‚˜ ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³ , ì´ë¥¼ ì§ˆë¬¸ê³¼ í•¨ê»˜ LLMì— ì „ë‹¬í•œë‹¤.\n",
    "- LLMì€ ê°™ì´ ì „ë‹¬ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•œë‹¤. \n",
    "- ì´ë¥¼ í†µí•´ LLMì´ í•™ìŠµí•˜ì§€ ì•Šì€ ë‚´ìš©ë„ ë‹¤ë£° ìˆ˜ ìˆìœ¼ë©°, ì˜ëª»ëœ ì •ë³´ë¥¼ ìƒì„±í•˜ëŠ” í™˜ê° í˜„ìƒ(*hallucination*)ì„ ì¤„ì¼ ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "## RAGì™€ íŒŒì¸íŠœë‹(Fine Tuning) ë¹„êµ\n",
    "\n",
    "### íŒŒì¸íŠœë‹(Fine Tuning)\n",
    "\n",
    "- **ì •ì˜**: ì‚¬ì „ í•™ìŠµ(pre-trained)ëœ LLMì— íŠ¹ì • ë„ë©”ì¸ì˜ ë°ì´í„°ë¥¼ ì¶”ê°€ë¡œ í•™ìŠµì‹œì¼œ í•´ë‹¹ ë„ë©”ì¸ì— íŠ¹í™”ëœ ë§ì¶¤í˜• ëª¨ë¸ë¡œ ë§Œë“œëŠ” ë°©ì‹ì´ë‹¤.\n",
    "- **ì¥ì **\n",
    "  - íŠ¹ì • ë„ë©”ì¸ì— ìµœì í™”ë˜ì–´ ë†’ì€ ì •í™•ë„ì™€ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìˆë‹¤.\n",
    "- **ë‹¨ì **\n",
    "  - ëª¨ë¸ ì¬í•™ìŠµì— ë§ì€ ì‹œê°„ê³¼ ìì›ì´ í•„ìš”í•˜ë‹¤.\n",
    "  - ìƒˆë¡œìš´ ì •ë³´ê°€ ë°˜ì˜ë˜ì§€ ì•Šìœ¼ë©°, ì´ë¥¼ ìœ„í•´ì„œëŠ” ë‹¤ì‹œ í•™ìŠµí•´ì•¼ í•œë‹¤.\n",
    "\n",
    "### RAG\n",
    "\n",
    "- **ì •ì˜**: ëª¨ë¸ì„ ë‹¤ì‹œ í•™ìŠµì‹œí‚¤ì§€ ì•Šê³ , ì™¸ë¶€ ì§€ì‹ ê¸°ë°˜ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì‹¤ì‹œê°„ìœ¼ë¡œ ë‹µë³€ì— í™œìš©í•˜ëŠ” ë°©ì‹ì´ë‹¤.\n",
    "- **ì¥ì **\n",
    "  - ìµœì‹  ì •ë³´ë¥¼ ì‰½ê²Œ ë°˜ì˜í•  ìˆ˜ ìˆë‹¤.\n",
    "  - ëª¨ë¸ì„ ìˆ˜ì •í•˜ì§€ ì•Šì•„ë„ ë˜ë¯€ë¡œ íš¨ìœ¨ì ì´ë‹¤.\n",
    "- **ë‹¨ì **\n",
    "  - ê²€ìƒ‰ëœ ë¬¸ì„œì˜ í’ˆì§ˆì— ë”°ë¼ ë‹µë³€ì˜ ì •í™•ì„±ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆë‹¤.\n",
    "  - ê²€ìƒ‰ ì‹œìŠ¤í…œ êµ¬ì¶•ì´ í•„ìš”í•˜ë‹¤.\n",
    "\n",
    "## ì •ë¦¬\n",
    "\n",
    "| í•­ëª©       | íŒŒì¸íŠœë‹ | RAG |\n",
    "| -------- | ---- | --- |\n",
    "| ë„ë©”ì¸ ìµœì í™”  | ê°€ëŠ¥   | ì œí•œì  |\n",
    "| ìµœì‹  ì •ë³´ ë°˜ì˜ | ë¶ˆê°€ëŠ¥  | ê°€ëŠ¥  |\n",
    "| êµ¬í˜„ ë‚œì´ë„   | ë†’ìŒ   | ë³´í†µ  |\n",
    "| ìœ ì—°ì„±      | ë‚®ìŒ   | ë†’ìŒ  |\n",
    "\n",
    "- LLMì€ í•™ìŠµ ë‹¹ì‹œì˜ ë°ì´í„°ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ë™í•˜ë¯€ë¡œ ìµœì‹  ì •ë³´ë‚˜ ê¸°ì—… ë‚´ë¶€ ìë£Œì™€ ê°™ì€ íŠ¹ì •í•œ ì§€ì‹ ê¸°ë°˜ì— ì ‘ê·¼í•  ìˆ˜ ì—†ë‹¤.\n",
    "- íŒŒì¸íŠœë‹ì€ ì‹œê°„ê³¼ ë¹„ìš©ì´ ë§ì´ ë“¤ê³  ìœ ì§€ë³´ìˆ˜ê°€ ì–´ë µë‹¤.\n",
    "-\të°˜ë©´, RAGëŠ” ê¸°ì¡´ LLMì„ ë³€ê²½í•˜ì§€ ì•Šê³ ë„ ì™¸ë¶€ ë¬¸ì„œë¥¼ í†µí•´ ê·¸ í•œê³„ë¥¼ ë³´ì™„í•  ìˆ˜ ìˆë‹¤.\n",
    "- RAGëŠ” íŠ¹íˆ ë¹ ë¥´ê²Œ ë³€í™”í•˜ëŠ” ì •ë³´ë¥¼ ë‹¤ë£¨ëŠ” ë¶„ì•¼(ì˜ˆ: ê¸°ìˆ  ì§€ì›, ë‰´ìŠ¤, ë²•ë¥  ë“±)ì—ì„œ ìœ ìš©í•˜ê²Œ í™œìš©ëœë‹¤. ë°˜ë©´, ì •ì ì¸ ì •ë³´ì— ëŒ€í•´ ë†’ì€ ì •í™•ë„ê°€ í•„ìš”í•œ ê²½ìš°ì—ëŠ” íŒŒì¸íŠœë‹ì´ íš¨ê³¼ì ì´ë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9017ca94-32e0-4460-8937-90a8d92ca07b",
   "metadata": {},
   "source": [
    "## RAG ì‘ë™ ë‹¨ê³„\n",
    "- í¬ê²Œ \"**ì •ë³´ ì €ì¥(ì¸ë±ì‹±)**\", \"**ê²€ìƒ‰**, **ìƒì„±**\"ì˜ ë‹¨ê³„ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆë‹¤.\n",
    "  \n",
    "### 1. ì •ë³´ ì €ì¥(ì¸ë±ì‹±)\n",
    "RAGëŠ” ì‚¬ì „ì— ì •ë³´ë¥¼ ê°€ê³µí•˜ì—¬ **ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤**(Vector ì €ì¥ì†Œ)ì— ì €ì¥í•´ ë‘ê³ , ë‚˜ì¤‘ì— ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ ì¤€ë¹„í•œë‹¤. ì´ ë‹¨ê³„ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê³¼ì •ìœ¼ë¡œ ì´ë£¨ì–´ì§„ë‹¤.\n",
    "\n",
    "1. **Load (ë¶ˆëŸ¬ì˜¤ê¸°)**\n",
    "   - ë‹µë³€ì‹œ ì°¸ì¡°í•  ì‚¬ì „ ì •ë³´ë¥¼ ê°€ì§„ ë°ì´í„°ë“¤ì„ ë¶ˆëŸ¬ì˜¨ë‹¤.\n",
    "2. **Split/Chunking (ë¬¸ì„œ ë¶„í• )**\n",
    "   - ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì¼ì •í•œ ê¸¸ì´ì˜ ì‘ì€ ë©ì–´ë¦¬(*chunk*)ë¡œ ë‚˜ëˆˆë‹¤.\n",
    "   - ì´ë ‡ê²Œ í•´ì•¼ ê²€ìƒ‰ê³¼ ìƒì„±ì˜ ì •í™•ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆë‹¤.\n",
    "3. **Embedding (ì„ë² ë”©)**\n",
    "   - ê° í…ìŠ¤íŠ¸ ì¡°ê°ì„ **ì„ë² ë”© ë²¡í„°**ë¡œ ë³€í™˜í•œë‹¤.\n",
    "   - ì„ë² ë”© ë²¡í„°ëŠ” ê·¸ ë¬¸ì„œì˜ ì˜ë¯¸ë¥¼ ë²¡í„°í™” í•œ ê²ƒìœ¼ë¡œ ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ì°¾ì„ ë•Œ ì¸ë±ìŠ¤ë¡œ ì‚¬ìš©ëœë‹¤.\n",
    "4. **Store (ì €ì¥)**\n",
    "   - ì„ë² ë”©ëœ ë²¡í„°ë¥¼ **ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤**(ë²¡í„° ì €ì¥ì†Œ)ì— ì €ì¥í•œë‹¤.\n",
    "   - ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ëŠ” ìœ ì‚¬í•œ ì§ˆë¬¸ì´ë‚˜ ë¬¸ì¥ì„ ë¹ ë¥´ê²Œ ì°¾ì„ ìˆ˜ ìˆë„ë¡ íŠ¹í™”ëœ ë°ì´í„° ì €ì¥ì†Œì´ë‹¤.\n",
    "   \n",
    "![rag](figures/rag1.png)\n",
    "\n",
    "### 2. ê²€ìƒ‰, ìƒì„±\n",
    "\n",
    "ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì ˆì°¨ë¡œ ë‹µë³€ì´ ìƒì„±ëœë‹¤.\n",
    "1. **Retrieve (ê²€ìƒ‰)**\n",
    "   - ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì„ë² ë”©í•œ í›„, ì´ ì§ˆë¬¸ ë²¡í„°ì™€ ìœ ì‚¬í•œ context ë²¡í„°ë¥¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰í•˜ì—¬ ì°¾ëŠ”ë‹¤.\n",
    "2. **Query (ì§ˆì˜ ìƒì„±)**\n",
    "   - ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰ëœ ë¬¸ì„œ ì¡°ê°ê³¼ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ í•¨ê»˜ **í”„ë¡¬í”„íŠ¸**(prompt)ë¡œ êµ¬ì„±í•˜ì—¬ LLMì— ì „ë‹¬í•œë‹¤.\n",
    "3. **Generation (ì‘ë‹µ ìƒì„±)**\n",
    "   - LLMì€ ë°›ì€ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ì‘ë‹µì„ ìƒì„±í•œë‹¤.\n",
    "   \n",
    "- **RAG íë¦„**\n",
    "  \n",
    "![Retrieve and Generation](figures/rag2.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7e3d03-2250-4c79-aa83-7faf709ba4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21f6fd91-e3de-4f9d-9c8a-9c21de7a768c",
   "metadata": {},
   "source": [
    "# Document Loader\n",
    "- LLMì—ê²Œ ì§ˆì˜í•  ë•Œ ê°™ì´ ì œê³µí•  Dataë“¤ì„ ì €ì¥í•˜ê¸° ìœ„í•´ ë¨¼ì € ì½ì–´ë“¤ì¸ë‹¤.(Load)\n",
    "- ë°ì´í„° ResouceëŠ” ë‹¤ì–‘í•˜ë‹¤.\n",
    "    - ë°ì´í„°ë¥¼ ë¡œë“œ(load)í•˜ëŠ” ë°©ì‹ì€ ì €ì¥ëœ ìœ„ì¹˜ì™€ í˜•ì‹ì— ë”°ë¼ ë‹¤ì–‘í•˜ë‹¤. \n",
    "      - ë¡œì»¬ ì»´í“¨í„°(Local Computer)ì— ì €ì¥ëœ ë¬¸ì„œ\n",
    "        - ì˜ˆ: CSV, Excel, JSON, TXT íŒŒì¼ ë“±\n",
    "      - ë°ì´í„°ë² ì´ìŠ¤(Database)ì— ì €ì¥ëœ ë°ì´í„°ì…‹\n",
    "      - ì¸í„°ë„·ì— ì¡´ì¬í•˜ëŠ” ë°ì´í„°\n",
    "        - ì˜ˆ: ì›¹ì— ê³µê°œëœ API, ì›¹ í˜ì´ì§€ì— ìˆëŠ” ë°ì´í„°, í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ì— ì €ì¥ëœ íŒŒì¼ ë“±\n",
    "\n",
    "![rag_load](figures/rag_load.png)\n",
    "\n",
    "- ë‹¤ì–‘í•œ ë¬¸ì„œ í˜•ì‹(format)ì— ë§ì¶° ì½ì–´ì˜¤ëŠ” ë‹¤ì–‘í•œ **document loader** ë“¤ì„ Langchainì—ì„œ ì§€ì›í•œë‹¤.\n",
    "    - ë‹¤ì–‘í•œ Resourceë“¤ë¡œ ë¶€í„° ë°ì´í„°ë¥¼ ì½ê¸° ìœ„í•´ì„œëŠ” ë‹¤ì–‘í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•´ ì„œë¡œ ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì½ì–´ì•¼ í•œë‹¤.\n",
    "    - Langchainì€ ë°ì´í„°ë¥¼ ì½ëŠ” ë‹¤ì–‘í•œ ë°©ì‹ì˜ ì½”ë“œë¥¼ í•˜ë‚˜ì˜ interfaceë¡œ ì‚¬ìš© í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•œë‹¤.\n",
    "        - https://python.langchain.com/docs/how_to/#document-loaders\n",
    "    - ë‹¤ì–‘í•œ 3rd party library(ppt, github ë“±ë“± ë‹¤ì–‘í•œ 3rd party libë„ ìˆìŒ. )ë“¤ê³¼ ì—°ë™í•´ ë‹¤ì–‘í•œ Resourceë¡œ ë¶€í„° ë°ì´í„°ë¥¼ Loading í•  ìˆ˜ ìˆë‹¤.\n",
    "        - https://python.langchain.com/docs/integrations/document_loaders/\n",
    "- **ëª¨ë“  document loaderëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë™ì¼í•œ interface(ì‚¬ìš©ë²•)ë¡œ í˜¸ì¶œí•  ìˆ˜ìˆë‹¤.**\n",
    "- **ë°˜í™˜íƒ€ì…**\n",
    "    - **list[Document]**\n",
    "    - Load í•œ ë¬¸ì„œëŠ” Documentê°ì²´ì— ì •ë³´ë“¤ì„ ë„£ëŠ”ë‹¤. ì—¬ëŸ¬ ë¬¸ì„œë¥¼ ì½ì„ ìˆ˜ ìˆê¸° ëŒ€ë¬¸ì— listì— ë¬¶ì–´ì„œ ë°˜í™˜í•œë‹¤.\n",
    "        - **Document ì†ì„±**\n",
    "            - page_content: ë¬¸ì„œì˜ ë‚´ìš©\n",
    "            - metadata(option): ë¬¸ì„œì— ëŒ€í•œ ë©”íƒ€ë°ì´í„°(ì •ë³´)ë¥¼ dict í˜•íƒœë¡œ ì €ì¥í•œë‹¤. \n",
    "            - id(option): ë¬¸ì„œì˜ ê³ ìœ  id\n",
    "     \n",
    "- **ì£¼ì˜**\n",
    "    - Langchainì„ ì´ìš©í•´ RAGë¥¼ êµ¬í˜„í•  ë•Œ **ê¼­ Langchainì˜ DocumentLoaderë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ëŠ” ê²ƒì€ ì•„ë‹ˆë‹¤.**\n",
    "    - DocumentLoaderëŠ” ë°ì´í„°ë¥¼ ì½ì–´ì˜¤ëŠ” ê²ƒì„ ë„ì™€ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì¼ ë¿ì´ë‹¤. ë‹¤ë¥¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•´ì„œ ì½ì–´ ë“¤ì—¬ë„ ìƒê´€ì—†ë‹¤. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f25589-24a2-4f1f-9e8c-41e0594b6ce1",
   "metadata": {},
   "source": [
    "## ì£¼ìš” Document Loader\n",
    "\n",
    "### Text file\n",
    "- TextLoader ì´ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40998e95-a607-45d5-a3f6-2bb598b1aa19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 1\n",
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "path = \"data/olympic.txt\"\n",
    "\n",
    "# with open(path, 'rt') as f:\n",
    "#     doc = f.read()\n",
    "\n",
    "# 1. ê°ì²´ ìƒì„± -> ì½ì–´ì˜¬ ìì›ì˜ ì •ë³´(ê²½ë¡œ)ë¥¼ ì œê³µ.\n",
    "loader = TextLoader(path, encoding=\"utf-8\")\n",
    "\n",
    "# 2. ì½ì–´ ì˜¤ê¸°(Loading)\n",
    "docs = loader.load()  # lazy_load() -> ë¬¸ì„œë¥¼ ì‚¬ìš©í•˜ëŠ” ì‹œì ì— ì½ì–´ì˜¨ë‹¤.\n",
    "\n",
    "print(type(docs), len(docs))\n",
    "print(type(docs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ec8523a-e87c-4214-aee9-c1aa8d1745c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¬¸ì„œì˜ ì •ë³´-metadata: {'source': 'data/olympic.txt'}\n",
      "ë¬¸ì„œì‹ë³„ì(ID): None\n",
      "ë¬¸ì„œë‚´ìš©:\n",
      "ì˜¬ë¦¼í”½\n",
      "ì˜¬ë¦¼í”½(ì˜ì–´: Olympic Games, í”„ë‘ìŠ¤ì–´: Jeux olympiques)ì€ ì „ ì„¸ê³„ ê° ëŒ€ë¥™ ê°êµ­ì—ì„œ ëª¨ì¸ ìˆ˜ì²œ ëª…ì˜ ì„ ìˆ˜ê°€ ì°¸ê°€í•´ ì—¬ë¦„ê³¼ ê²¨ìš¸ì— ìŠ¤í¬ì¸  ê²½ê¸°ë¥¼ í•˜\n"
     ]
    }
   ],
   "source": [
    "# Document ê°ì²´ ì†ì„±\n",
    "doc = docs[0]\n",
    "print(\"ë¬¸ì„œì˜ ì •ë³´-metadata:\", doc.metadata)\n",
    "print(\"ë¬¸ì„œì‹ë³„ì(ID):\", doc.id)\n",
    "print(\"ë¬¸ì„œë‚´ìš©:\")\n",
    "print(doc.page_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "591ae197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "with open(path, 'rt') as f:\n",
    "    load_doc = f.read()\n",
    "\n",
    "d = Document(page_content=load_doc, metadata={\"category\":\"ì˜¬ë¦¼í”½\", \"path\":path})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bbbd08-6afc-4f2f-985b-c96da7c3b943",
   "metadata": {},
   "source": [
    "### PDF\n",
    "- PyPDF, Pymupdf ë“± ë‹¤ì–‘í•œ PDF ë¬¸ì„œë¥¼ ì½ì–´ë“¤ì´ëŠ” íŒŒì´ì¬ì˜  3rd party libraryë“¤ì„ ì´ìš©í•´ pdf ë¬¸ì„œë¥¼ Load í•œë‹¤.\n",
    "    - https://python.langchain.com/docs/integrations/document_loaders/#pdfs\n",
    "- ê° PDF Loader íŠ¹ì§•\n",
    "    -  PyMuPDFLoader\n",
    "        -   í…ìŠ¤íŠ¸ ë¿ ì•„ë‹ˆë¼ ì´ë¯¸ì§€, ì£¼ì„ë“±ì˜ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ”ë° ì„±ëŠ¥ì´ ì¢‹ë‹¤.\n",
    "        -   PyMuPDF ë¼ì´ë¸ŒëŸ¬ë¦¬ ê¸°ë°˜\n",
    "    - PyPDFLoader\n",
    "        - í…ìŠ¤íŠ¸ë¥¼ ë¹ ë¥´ê²Œ ì¶”ì¶œ í•  ìˆ˜ìˆë‹¤.\n",
    "        - PyPDF2 ë¼ì´ë¸ŒëŸ¬ë¦¬ ê¸°ë°˜. ê²½ëŸ‰ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ë¹ ë¥´ê³  í° íŒŒì¼ë„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•œë‹¤.\n",
    "    - PDFPlumberLoader\n",
    "        - í‘œì™€ ê°™ì€ ë³µì¡í•œ êµ¬ì¡°ì˜ ë°ì´í„° ì²˜ë¦¬í•˜ëŠ”ë° ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤€ë‹¤. í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, í‘œ ë“±ì„ ëª¨ë‘ ì¶”ì¶œí•  ìˆ˜ ìˆë‹¤. \n",
    "        - PDFPlumber ë¼ì´ë¸ŒëŸ¬ë¦¬ ê¸°ë°˜\n",
    "- ì„¤ì¹˜ íŒ¨í‚¤ì§€\n",
    "    - DocumentLoaderì™€ ì—°ë™í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ì„¤ì¹˜ í•´ì•¼ í•œë‹¤.\n",
    "    - `pip install pypdf -qU`\n",
    "    - `pip install pymupdf -qU`\n",
    "    - `pip install pdfplumber -qU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6378f01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# 1. ê°ì²´ ìƒì„± -> raw ë°ì´í„° ì—°ê²°\n",
    "path = \"data/novel/ê¸ˆ_ë”°ëŠ”_ì½©ë°­_ê¹€ìœ ì •.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(path)\n",
    "\n",
    "docs = loader.load()  # List[Document]\n",
    "len(docs)  # í˜ì´ì§€ë‹¹ í•˜ë‚˜ì˜ ë¬¸ì„œ(Document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9647515-7c2d-447d-a4e4-d70a18e4e025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 \n",
      "ìœ„í‚¤ë°±ê³¼\n",
      "ìœ„í‚¤ë°±ê³¼ì—  ì´  ê¸€\n",
      "ê³¼  ê´€ë ¨ëœ \n",
      "ìë£Œê°€  ìˆìŠµë‹ˆë‹¤ .\n",
      "ê¸ˆ  ë”°ëŠ”  ì½©ë°­\n",
      "ğŸ™ ğŸ™Ÿ \n",
      "ë•…ì†  ì €  ë°‘ì€  ëŠ˜  ìŒì¹¨í•˜\n",
      "ë‹¤ .\n",
      "ê³ ë‹¬í”ˆ  ê°„ë“œë ›ë¶ˆ , ë§¥ì—†ì´\n",
      "í‘¸ë¥´ë¼í•˜ë‹¤ .\n",
      "ë°¤ê³¼  ë‹¬ë¼ì„œ  ë‚®ì—”  ë˜ìš°  íë¦¿í•˜ì˜€ë‹¤ .\n",
      "ê²‰ìœ¼ë¡œ  í™©í†   ì¥ë²½ìœ¼ë¡œ  ì•ë’¤ì¢Œìš°ê°€  ì½•  ë§‰íŒ  ì¢ì§í•œ  êµ¬ë…ì´ .\n",
      "í¡ì‚¬íˆ  ë¬´ë¤  ì†ê°™ì´  ê·€ì¤‘ì¤‘í•˜ë‹¤ . ì‹¸ëŠ˜í•œ  ì¹¨ë¬µ , ì¿ ë”ë¸Œë ˆí•œ\n",
      "í™ë‚´ì™€  ì§•ê·¸ëŸ¬ìš´  ëƒ‰ê¸°ë§Œì´  ê·¸  ì†ì—  ììš±í•˜ë‹¤ .\n",
      "ê³¡ê´­ì´ëŠ”  ë»”ì§ˆ  í™ì„  ì´ë¥´ì§‘ëŠ”ë‹¤ . ì•”íŒ¡ìŠ¤ëŸ¬ì´  ë‚´ë ¤ìª¼ë©° ,\n",
      "í½  í½  í¼ì–µ .\n",
      "ì´ë ‡ê²Œ  ë©”ë–¨ì–´ì§„  ì†Œë¦¬ë¿ . ê·¸ëŸ¬ë‚˜  ê°„ê°„  ìš°ìˆ˜ìˆ˜  í•˜ê³   ë²½ì´  í—\n",
      "ë¦°ë‹¤ .\n",
      "ì˜ì‹ì´ëŠ”  ì¼ì†ì„  ë†“ê³   ì†Œë§·ìë½ì„  ëŒì–´ë‹¹ê¸°ì–´  ì–¼êµ´ì˜  ë•€ì„\n",
      "í›‘ëŠ”ë‹¤ . ì´ë†ˆì˜  ì¤„ì´  ì–¸ì œë‚˜  ì¡íëŠ”ì§€  ê¸°ê°€  ì°¼ë‹¤ . í™  í•œì¤Œì„\n",
      "ì§‘ì–´  ì½”ë°‘ì—  ë°”ì§  ë“¤ì—¬ëŒ€ê³   ì†ê°€ë½ìœ¼ë¡œ  ìƒ…ìƒ…ì´  ë’¤ì ¸ë³¸ë‹¤ . ì™„\n",
      "ì—°íˆ  ë²„ë ¥ì€  ì¢€  ë³€í•œ  ë“¯ì‹¶ë‹¤ . ê·¸ëŸ¬ë‚˜  ë¶ˆí†µë²„ë ¥ì´  ì•„ì£¼  ë‹¤  í’€\n",
      "ë¦°  ê²ƒë„  ì•„ë‹ˆì—ˆë‹¤ . ë°€ë˜¥ë²„ë ¥ì´ë¼ì•¼  ê¸ˆì´  ì˜¨ë‹¤ëŠ”ë°  ì™œ  ì´ë¦¬\n",
      "ì•ˆ  ë‚˜ì˜¤ëŠ”ì§€ .\n",
      "ê³¡ê´­ì´ë¥¼  ë‹¤ì‹œ  ì§‘ì–´ë“ ë‹¤ . ë•…ì—  ë¬´ë¦ì„  ê¿‡ê³   ê¶ë…ì´ë¥¼  ë²ˆì©\n",
      "ë“   ì±„  ì‹ì‹ê±°ë¦°ë‹¤ . ê³¡ê´­ì´ëŠ”  ë¬´ì‘ì •  ë‚´ë ¤ì°ëŠ”ë‹¤ . ë°”ë‹¥ì—ì„œ\n"
     ]
    }
   ],
   "source": [
    "print(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdbd7f13-c4d5-4db7-b5d7-27de7984624f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'Wikisource',\n",
       " 'creator': 'Wikisource',\n",
       " 'creationdate': '2024-11-24T07:05:35+00:00',\n",
       " 'author': 'Unknown',\n",
       " 'moddate': '2024-11-24T07:05:37+00:00',\n",
       " 'title': 'ê¸ˆ ë”°ëŠ” ì½©ë°­',\n",
       " 'source': 'data/novel/ê¸ˆ_ë”°ëŠ”_ì½©ë°­_ê¹€ìœ ì •.pdf',\n",
       " 'total_pages': 23,\n",
       " 'page': 1,\n",
       " 'page_label': '2'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bed2776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24aef24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdf\n",
      "  Using cached pymupdf-1.26.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (3.4 kB)\n",
      "Downloading pymupdf-1.26.1-cp39-abi3-macosx_11_0_arm64.whl (22.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m22.4/22.4 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pymupdf\n",
      "Successfully installed pymupdf-1.26.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3db535f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "loader = PyMuPDFLoader(path)\n",
    "\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "904bf667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "ìœ„í‚¤ë°±ê³¼\n",
      "ìœ„í‚¤ë°±ê³¼ì— ì´ ê¸€\n",
      "ê³¼ ê´€ë ¨ëœ\n",
      "ìë£Œê°€ ìˆìŠµë‹ˆë‹¤.\n",
      "ê¸ˆ ë”°ëŠ” ì½©ë°­\n",
      "ğŸ™ğŸ™Ÿ\n",
      "ë•…ì† ì € ë°‘ì€ ëŠ˜ ìŒì¹¨í•˜\n",
      "ë‹¤.\n",
      "ê³ ë‹¬í”ˆ ê°„ë“œë ›ë¶ˆ, ë§¥ì—†ì´\n",
      "í‘¸ë¥´ë¼í•˜ë‹¤.\n",
      "ë°¤ê³¼ ë‹¬ë¼ì„œ ë‚®ì—” ë˜ìš° íë¦¿í•˜ì˜€ë‹¤.\n",
      "ê²‰ìœ¼ë¡œ í™©í†  ì¥ë²½ìœ¼ë¡œ ì•ë’¤ì¢Œìš°ê°€ ì½• ë§‰íŒ ì¢ì§í•œ êµ¬ë…ì´.\n",
      "í¡ì‚¬íˆ ë¬´ë¤ ì†ê°™ì´ ê·€ì¤‘ì¤‘í•˜ë‹¤. ì‹¸ëŠ˜í•œ ì¹¨ë¬µ, ì¿ ë”ë¸Œë ˆí•œ\n",
      "í™ë‚´ì™€ ì§•ê·¸ëŸ¬ìš´ ëƒ‰ê¸°ë§Œì´ ê·¸ ì†ì— ììš±í•˜ë‹¤.\n",
      "ê³¡ê´­ì´ëŠ” ë»”ì§ˆ í™ì„ ì´ë¥´ì§‘ëŠ”ë‹¤. ì•”íŒ¡ìŠ¤ëŸ¬ì´ ë‚´ë ¤ìª¼ë©°,\n",
      "í½ í½ í¼ì–µ.\n",
      "ì´ë ‡ê²Œ ë©”ë–¨ì–´ì§„ ì†Œë¦¬ë¿. ê·¸ëŸ¬ë‚˜ ê°„ê°„ ìš°ìˆ˜ìˆ˜ í•˜ê³  ë²½ì´ í—\n",
      "ë¦°ë‹¤.\n",
      "ì˜ì‹ì´ëŠ” ì¼ì†ì„ ë†“ê³  ì†Œë§·ìë½ì„ ëŒì–´ë‹¹ê¸°ì–´ ì–¼êµ´ì˜ ë•€ì„\n",
      "í›‘ëŠ”ë‹¤. ì´ë†ˆì˜ ì¤„ì´ ì–¸ì œë‚˜ ì¡íëŠ”ì§€ ê¸°ê°€ ì°¼ë‹¤. í™ í•œì¤Œì„\n",
      "ì§‘ì–´ ì½”ë°‘ì— ë°”ì§ ë“¤ì—¬ëŒ€ê³  ì†ê°€ë½ìœ¼ë¡œ ìƒ…ìƒ…ì´ ë’¤ì ¸ë³¸ë‹¤. ì™„\n",
      "ì—°íˆ ë²„ë ¥ì€ ì¢€ ë³€í•œ ë“¯ì‹¶ë‹¤. ê·¸ëŸ¬ë‚˜ ë¶ˆí†µë²„ë ¥ì´ ì•„ì£¼ ë‹¤ í’€\n",
      "ë¦° ê²ƒë„ ì•„ë‹ˆì—ˆë‹¤. ë°€ë˜¥ë²„ë ¥ì´ë¼ì•¼ ê¸ˆì´ ì˜¨ë‹¤ëŠ”ë° ì™œ ì´ë¦¬\n",
      "ì•ˆ ë‚˜ì˜¤ëŠ”ì§€.\n",
      "ê³¡ê´­ì´ë¥¼ ë‹¤ì‹œ ì§‘ì–´ë“ ë‹¤. ë•…ì— ë¬´ë¦ì„ ê¿‡ê³  ê¶ë…ì´ë¥¼ ë²ˆì©\n",
      "ë“  ì±„ ì‹ì‹ê±°ë¦°ë‹¤. ê³¡ê´­ì´ëŠ” ë¬´ì‘ì • ë‚´ë ¤ì°ëŠ”ë‹¤. ë°”ë‹¥ì—ì„œ\n"
     ]
    }
   ],
   "source": [
    "print(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a9baec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'Wikisource',\n",
       " 'creator': 'Wikisource',\n",
       " 'creationdate': '2024-11-24T07:05:35+00:00',\n",
       " 'source': 'data/novel/ê¸ˆ_ë”°ëŠ”_ì½©ë°­_ê¹€ìœ ì •.pdf',\n",
       " 'file_path': 'data/novel/ê¸ˆ_ë”°ëŠ”_ì½©ë°­_ê¹€ìœ ì •.pdf',\n",
       " 'total_pages': 23,\n",
       " 'format': 'PDF 1.4',\n",
       " 'title': 'ê¸ˆ ë”°ëŠ” ì½©ë°­',\n",
       " 'author': 'Unknown',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2024-11-24T07:05:37+00:00',\n",
       " 'trapped': '',\n",
       " 'modDate': \"D:20241124070537+00'00'\",\n",
       " 'creationDate': \"D:20241124070535+00'00'\",\n",
       " 'page': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196a703e-dd86-4cb5-82bf-8b6726aea0e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b507b334-e33b-435f-8a50-7dd31fa6da6b",
   "metadata": {},
   "source": [
    "### Web\n",
    "\n",
    "- WebBaseLoader ì´ìš©\n",
    "  - ì…ë ¥ë°›ì€ URLì˜ ì›¹ ë¬¸ì„œë¥¼ ì½ì–´ ë¬¸ì„œë¡œ ë¡œë“œí•œë‹¤. ì›¹ í¬ë¡¤ë§ì‘ì—… ì—†ì´ ì›¹ìƒì˜ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ìˆë‹¤.\n",
    "  - ë‚´ë¶€ì ìœ¼ë¡œ BeautifulSoupì„ ì´ìš©í•´ ì›¹ë¬¸ì„œë¥¼ parsingí•œë‹¤.\n",
    "- https://python.langchain.com/docs/how_to/document_loader_web/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94e5a711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Using cached bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting beautifulsoup4 (from bs4)\n",
      "  Using cached beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->bs4)\n",
      "  Using cached soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from beautifulsoup4->bs4) (4.14.0)\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Using cached beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Using cached soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3/3\u001b[0m [bs4]\n",
      "\u001b[1A\u001b[2KSuccessfully installed beautifulsoup4-4.13.4 bs4-0.0.2 soupsieve-2.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a44adf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "url = [\n",
    "    \"https://m.sports.naver.com/wfootball/article/421/0008308548\",\n",
    "    \"https://m.sports.naver.com/wfootball/article/450/0000131435\"\n",
    "]\n",
    "\n",
    "my_user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36\"\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_path=url, # ê°œë³„ í˜ì´ì§€ -> str, ì—¬ëŸ¬í˜ì´ì§€ -> list[str]\n",
    "    header_template={\n",
    "        \"user-agent\":my_user_agent\n",
    "    }\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b580ba5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://m.sports.naver.com/wfootball/article/421/0008308548',\n",
       " 'title': '[ë‹¨ë…]ì¿ íŒ¡í”Œë ˆì´, ìŠ¤í¬ì¸ íŒ¨ìŠ¤ ì²« ê°€ê²© ì›” 1ë§Œì›â€¦15ì¼ë¶€í„° ì‹œí–‰',\n",
       " 'language': 'ko'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794e412b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da98b0ba-97ac-445d-85c8-1e000299f926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ë‹¨ë…]ì¿ íŒ¡í”Œë ˆì´, ìŠ¤í¬ì¸ íŒ¨ìŠ¤ ì²« ê°€ê²© ì›” 1ë§Œì›â€¦15ì¼ë¶€í„° ì‹œí–‰NAVERìŠ¤í¬ì¸ ë©”ë‰´í™ˆì•¼êµ¬í•´ì™¸ì•¼êµ¬ì¶•êµ¬í•´ì™¸ì¶•êµ¬ë†êµ¬ë°°êµ¬Nê³¨í”„ì¼ë°˜eìŠ¤í¬ì¸ ì•„ì›ƒë„ì–´NEWë‰´ìŠ¤ì˜ìƒì¼ì •ìˆœìœ„í¬í† í™ˆ ë°”ë¡œê°€ê¸°NAVERìŠ¤í¬ì¸ ë§ˆì´íŒ€íŒ€ ì¶”ê°€ì‘ì›í•˜ëŠ” íŒ€ì„ êµ¬ë…í•´ë³´ì„¸ìš”!ìŠ¤í¬ì¸ ì•¼êµ¬í•´ì™¸ì•¼êµ¬ì¶•êµ¬í•´ì™¸ì¶•êµ¬ë†êµ¬ë°°êµ¬Nê³¨í”„ì¼ë°˜eìŠ¤í¬ì¸ ì•„ì›ƒë„ì–´ì½˜í…ì¸ ì˜¤ëŠ˜ì˜ ê²½ê¸°ìŠ¹ë¶€ì˜ˆì¸¡ì—°ì¬ì´ìŠˆí†¡ëŒ€í•™ìŠ¤í¬ì¸ ë­í‚¹ê¸°íƒ€ê³ ê°ì„¼í„°ê³µì‹ ë¸”ë¡œê·¸ë©”ë‰´ ë‹«ê¸°ë³¸ë¬¸ ë°”ë¡œê°€ê¸°[ë‹¨ë…]ì¿ íŒ¡í”Œë ˆì´, ìŠ¤í¬ì¸ íŒ¨ìŠ¤ ì²« ê°€ê²© ì›” 1ë§Œì›â€¦15ì¼ë¶€í„° ì‹œí–‰ì…ë ¥2025.06.12. ì˜¤í›„ 2:00ìˆ˜ì •2025.06.12. ì˜¤í›„ 3:39ê¸°ì‚¬ì›ë¬¸ê¹€ì •í˜„ ê¸°ìì–‘ìƒˆë¡¬ ê¸°ìê³µê°ì¢‹ì•„ìš”0ìŠ¬í¼ìš”0í™”ë‚˜ìš”0íŒ¬ì´ì—ìš”0í›„ì†ê¸°ì‚¬ ì›í•´ìš”0í…ìŠ¤íŠ¸ ìŒì„± ë³€í™˜ ì„œë¹„ìŠ¤ë³¸ë¬¸ ë“£ê¸°ë¥¼ ì¢…ë£Œí•˜ì˜€ìŠµë‹ˆë‹¤.ê¸€ì í¬ê¸° ë³€ê²½ê³µìœ í•˜ê¸°ì¿ íŒ¡ ì™€ìš° íšŒì›, ì›” ì´ ìš”ê¸ˆ  '1ë§Œ 7890ì›'(ì¿ íŒ¡í”Œë ˆì´ ê°ˆë¬´ë¦¬)/ë‰´ìŠ¤1(ì„œìš¸=ë‰´ìŠ¤1) ê¹€ì •í˜„ ì–‘ìƒˆë¡¬ ê¸°ì = ì¿ íŒ¡í”Œë ˆì´ê°€ ë¶€ê°€ì„œë¹„ìŠ¤ì¸ 'ìŠ¤í¬ì¸  íŒ¨ìŠ¤'ì˜ ê¸ˆì•¡ì„ ì›” 1ë§Œ ì›ìœ¼ë¡œ í™•ì •í–ˆë‹¤.12ì¼ ì—…ê³„ì— ë”°ë¥´ë©´ ì¿ íŒ¡í”Œë ˆì´ëŠ” ì˜¤ëŠ” 15ì¼ í•´ì™¸ ìŠ¤í¬ì¸  ë“±ì˜ ì½˜í…ì¸ ë¥¼ ìœ ë£Œ ë¶€ê°€ ì„œë¹„ìŠ¤ë¡œ ì œê³µí•˜ëŠ” ìŠ¤í¬ì¸  íŒ¨ìŠ¤ì˜ ìš”ê¸ˆì„ ì›” 1ë§Œ ì›ìœ¼ë¡œ ê²°ì •í–ˆë‹¤. ê³µì‹ ê°€ê²©ì€ 1ë§Œ 2000ì›ì´ë‚˜, ì¶œì‹œ í• ì¸ê°€ë¡œ ì¶”ì •ëœë‹¤.ì¿ íŒ¡ ì™€ìš° ë©¤ë²„ì‹­ êµ¬ë…ë£Œì¸ ì›” 7890ì›ì— ìŠ¤í¬ì¸ íŒ¨ìŠ¤ ê¸ˆì•¡ì„ ë”í•˜ë©´ ì›” ì´ìš©ê¸ˆì•¡ì€ 1ë§Œ 7890ì›ì´ ëœë‹¤. í• ì¸ê°€ê°€ ì¢…ë£Œë  ê²½ìš° ì›” êµ¬ë…ë£Œë§Œ 2ë§Œ ì› ìˆ˜ì¤€ì´ë‹¤.ì´ë²ˆ íŒ¨ìŠ¤ë¥¼ í†µí•´ ë³¼ìˆ˜ ìˆëŠ” ìŠ¤í¬ì¸  ë¦¬ê·¸ëŠ” â–³FIFAëŒ€íšŒ(FIFAí´ëŸ½ì›”ë“œì»µ)â–³ìœ ëŸ½ì¶•êµ¬ë¦¬ê·¸(í”„ë¦¬ë¯¸ì–´ë¦¬ê·¸ 2025~2026 ì‹œì¦Œ, ë¼ë¦¬ê°€, ë¶„ë°ìŠ¤ë¦¬ê°€, ë¶„ë°ìŠ¤ë¦¬ê°€2, ë¦¬ê·¸1, EFL ì±”í”¼ì–¸ì‹­ EFLë¦¬ê·¸ì›, ì—ë ˆë””ë¹„ì‹œ) â–³ìœ ëŸ½ì¶•êµ¬ í† ë„ˆë¨¼íŠ¸(FAì»µ, ì¹´ë¼ë°”ì˜¤ì»µ, ì»¤ë®¤ë‹ˆí‹°ì‰´ë“œ, ì½”íŒŒ ë¸ë ˆì´, ìˆ˜í˜ë¥´ì½”íŒŒë° ì—ìŠ¤íŒŒëƒ, DFB-í¬ì¹¼, DFL-ìŠˆí¼ì»µ, ì¿ í”„ë“œí”„ë‘ìŠ¤, íŠ¸ë¡œí˜ë° ìƒ¹í”¼ì˜¹, ë²„íˆ¬íŠ¸ë¡œí”¼) â–³ì•„ì‹œì•„ì¶•êµ¬(AFCì•„ì‹œì•ˆì»µ, AFCì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸ ì—˜ë¦¬íŠ¸, AFCì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸2, ê¸°íƒ€AFCì£¼ê´€ êµ­ì œ ëŒ€íšŒ) â–³ì„¸ê³„ì¶•êµ¬(ì›”ë“œì»µë‚¨ë¯¸ ì˜ˆì„ , í´ëŸ½ ì¹œì„ ê²½ê¸°, í•´ì™¸ êµ­ê°€ ì¹œì„ ê²½ê¸°) ë“±ì´ë‹¤.ì¶•êµ¬ ì™¸ì—ë„ â–³ë ˆì´ì‹±(F1, F1 ì•„ì¹´ë°ë¯¸, ë‚˜ìŠ¤ì¹´) â–³ê³¨í”„(LIV ê³¨í”„) â–³ë†êµ¬(ë‚¨ì ë†êµ¬ ì•„ì‹œì•„ì»µ, ì—¬ì ë†êµ¬ ì•„ì‹œì•„ì»µ) â–³ë¯¸ì‹ ì¶•êµ¬(NFL) ë“±ë„ ìŠ¤í¬ì¸  íŒ¨ìŠ¤ë¥¼ ë³„ë„ êµ¬ë…í•´ì•¼ ì‹œì²­ ê°€ëŠ¥í•˜ë‹¤. ì˜¬ ê°€ì„ë¶€í„°ëŠ” NBA ê²½ê¸°ë„ ë…ì  ì œê³µí•  ì˜ˆì •ì´ë‹¤.ì¿ íŒ¡í”Œë ˆì´ëŠ” ëŒ€í•œë¯¼êµ­ ì¶•êµ¬ ëŒ€í‘œíŒ€, í•œêµ­ í”„ë¡œ ì¶•êµ¬, ì´ë²¤íŠ¸ ë§¤ì¹˜(ì¿ íŒ¡í”Œë ˆì´ ì‹œë¦¬ì¦ˆ)ëŠ” ë³„ë„ íŒ¨ìŠ¤ ê°€ì… ì—†ì´ ì™€ìš° íšŒì›ë“¤ì´ ì‹œì²­í•  ìˆ˜ ìˆë„ë¡ í•  ì˜ˆì •ì´ë‹¤. (ì¿ íŒ¡í”Œë ˆì´ í™ˆí˜ì´ì§€ ê°ˆë¬´ë¦¬) /ë‰´ìŠ¤1ì´ê°™ì€ ì •ë³´ëŠ” ì¿ íŒ¡í”Œë ˆì´ ê³µì‹ í™ˆí˜ì´ì§€ë¥¼ í†µí•´ 'ìŠ¤í¬ì¸  íŒ¨ìŠ¤' í˜ì´ì§€ê°€ ë…¸ì¶œë˜ë©° ì•Œë ¤ì¡Œë‹¤.2ë§Œ ì›ì— ìœ¡ë°•í•˜ëŠ” ê°€ê²© ì •ë³´ê°€ ì•Œë ¤ì§€ì êµ­ë‚´ ìŠ¤í¬ì¸  ì»¤ë®¤ë‹ˆí‹°ì—ì„œëŠ” \"ì¶•êµ¬ë§Œ ë³´ëŠ”ë° ê´€ì‹¬ì—†ëŠ” ì¤‘ê³„ë„ ë¬¶ì–´ì„œ ë¹„ì‹¸ê²Œ íŒë§¤í•˜ëŠ” ëŒ€ì‹  ì„ íƒ í­ì„ ëŠ˜ë ¸ìœ¼ë©´ í•œë‹¤\", \"ëˆ ë°›ëŠ” ê±´ ì¢‹ì€ë° í™”ì§ˆ ê°œì„ ì— ëŒ€í•œ ì´ì•¼ê¸°ëŠ” ì—†ë‚˜\" ë“±ì˜ ë°˜ì‘ì„ ë³´ì´ê³  ìˆë‹¤.ì¿ íŒ¡í”Œë ˆì´ ê´€ê³„ìëŠ” \"í•´ë‹¹ ê°€ê²© ì •ë³´ëŠ” ì‚¬ì‹¤ê³¼ ë‹¤ë¥´ë©°, ìŠ¤í¬ì¸  íŒ¨ìŠ¤ì˜ ê³µì‹ ê°€ê²© ë° ì„¸ë¶€ ë‚´ìš©ì€ ì¶”í›„ ì¿ íŒ¡í”Œë ˆì´ë¥¼ í†µí•´ ì •í™•íˆ ì•ˆë‚´ë“œë¦´ ì˜ˆì •\"ì´ë¼ê³  ë§í–ˆë‹¤.í•œí¸ ì¿ íŒ¡í”Œë ˆì´ëŠ” ì„ íƒí˜• ë¶€ê°€ì„œë¹„ìŠ¤ 'íŒ¨ìŠ¤(PASS)'ë¥¼ 6ì›” ì¤‘ ë„ì…í•œë‹¤ê³  ë°íŒ ë°” ìˆë‹¤.ê¹€ì •í˜„ ê¸°ìêµ¬ë…êµ¬ë…ì 0ì‘ì›ìˆ˜ 0í•´í‚¹ ìˆ¨ê²¼ë˜ ì˜ˆìŠ¤24, ê±°ì§“ë§í•˜ë‹¤ ë˜ ì ë°œâ€¦KISA \"í˜‘ì¡° ì—†ì–´\"ì‚¼ì„± ê°¤ëŸ­ì‹œZí´ë“œ7 '3ì°¨ í‹°ì €' ê³µê°œâ€¦ì¹´ë©”ë¼ ì—…ê·¸ë ˆì´ë“œ ì•”ì‹œì–‘ìƒˆë¡¬ ê¸°ìêµ¬ë…êµ¬ë…ì 0ì‘ì›ìˆ˜ 0SKT, ìœ ì‹¬ êµì²´ì˜ˆì•½ ì™„ë£Œê¹Œì§€ ì—´í˜ ë‚¨ì•˜ëŠ”ë°â€¦52ë§Œ ëª… ì´íƒˆSKT ìœ ì‹¬êµì²´ 700ë§Œ ëª… ì™„ë£Œâ€¦ì”ì—¬ì˜ˆì•½ì 264ë§Œ ëª…Copyright â“’ ë‰´ìŠ¤1. All rights reserved. ë¬´ë‹¨ ì „ì¬ ë° ì¬ë°°í¬,  AIí•™ìŠµ ì´ìš© ê¸ˆì§€.ê¸°ì‚¬ ì„¹ì…˜ ë¶„ë¥˜ ê°€ì´ë“œê¸°ì‚¬ ì„¹ì…˜ ë¶„ë¥˜ ì•ˆë‚´ìŠ¤í¬ì¸  ê¸°ì‚¬ ì„¹ì…˜(ì¢…ëª©) ì •ë³´ëŠ” ì–¸ë¡ ì‚¬ ë¶„ë¥˜ì™€ ê¸°ìˆ  ê¸°ë°˜ì˜ ìë™ ë¶„ë¥˜ ì‹œìŠ¤í…œì„ ë”°ë¥´ê³  ìˆìŠµë‹ˆë‹¤. ì˜¤ë¶„ë¥˜ì— ëŒ€í•œ ê±´ì€ ë„¤ì´ë²„ìŠ¤í¬ì¸ ë¡œ ì œë³´ ë¶€íƒë“œë¦½ë‹ˆë‹¤.ì˜¤ë¶„ë¥˜ ì œë³´í•˜ê¸°ë‹«ê¸°KíŒÂ·KíŠ¸ë¡¯ íŒ¬ë“¤ì˜ ë†€ì´í„°, ìŠ¤íƒ€1í”½ì„¸ìƒì— ì´ëŸ° ì¼ì´...[ì‚¬ê±´ì˜ ì¬êµ¬ì„±]ì£¼ìš”ë‰´ìŠ¤í•´ë‹¹ ì–¸ë¡ ì‚¬ì—ì„œ ì„ ì •í•˜ë©° ì–¸ë¡ ì‚¬ í˜ì´ì§€(ì•„ì›ƒë§í¬)ë¡œ ì´ë™í•´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.ìƒê°„ë…€ì˜ 'ì—­ê³µ'â€¦\"ë‚¨í¸ ë°”ëŒë‚˜ë©´ ì´ìœ  ìˆëŠ” ê²ƒ\"\"ê³ ì—½ì œë¡œ ê±°ë™ë„ ë¶ˆí¸í•œë°\"â€¦ì°¸ì „ ìš©ì‚¬ í­í–‰ ì¶©ê²©\"'ë‹ˆë„¤ ì§‘ ëª‡ í‰ì´ì•¼?' ì‘ìœ¼ë©´ ë¬´ì‹œâ€¦ì• ë“¤ì´ ì´ì‚¬ ê°€ì í•˜ë„¤ìš”\"\"KTX ì–‘ë§ ë²—ê³  ëƒ„ìƒˆ ë§¡ê³  í¼ë•\"â€¦ì˜†ìë¦¬ ìŠ¹ê° ê²°êµ­ì€ì§€ì›, '9ì„¸ ì—°í•˜' ë³¸ì¸ ìŠ¤íƒ€ì¼ë¦¬ìŠ¤íŠ¸ì™€ ì¬í˜¼â€¦ê°€ì¡±ë“¤ë§Œ ì´ˆëŒ€ 'ìŠ¤ëª° ì›¨ë”©'ì¢‹ì•„ìš”0ìŠ¬í¼ìš”0í™”ë‚˜ìš”0íŒ¬ì´ì—ìš”0í›„ì†ê¸°ì‚¬ ì›í•´ìš”0ê¸°ì‚¬ ê³µìœ í•˜ê¸°\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb94a006",
   "metadata": {},
   "source": [
    "- í˜ì´ì§€ì˜ ì¼ë¶€ë¶„ë§Œ ê°€ì ¸ì˜¤ê¸°.\n",
    "- BeautifulSoupì˜ SoupStrainer ë¥¼ ì´ìš©.\n",
    "    - BeautifulSoup(\"htmlë¬¸ì„œ\", parse_only=Strainerê°ì²´)\n",
    "        - Strainerê°ì²´ì— ì§€ì •ëœ ì˜ì—­ì—ì„œë§Œ ë‚´ìš© ì°¾ëŠ”ë‹¤.\n",
    "    - Strainer(\"íƒœê·¸ëª…\") -> ì§€ì •í•œ íƒœê·¸ ë‚´ì—ì„œë§Œ ì°¾ëŠ”ë‹¤.\n",
    "    - Strainer(name=\"íƒœê·¸ëª…\", attrs={ì†ì„±ëª…:ì†ì„±ê°’}) -> ì§€ì •í•œ íƒœê·¸ ì¤‘ ì†ì„±ëª…=ì†ì„±ê°’ì¸ ê²ƒ ë‚´ì—ì„œë§Œ ì°¾ëŠ”ë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be21355c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_path=url,\n",
    "    # WebBaseLoaderê°€ bs4ë¥¼ ì‚¬ìš©. bs4ì— ì „ë‹¬í•  íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •í•˜ëŠ” ë³€ìˆ˜\n",
    "    bs_kwargs={\n",
    "        \"parse_only\":bs4.SoupStrainer(attrs={\"class\":\"_article_content\"})\n",
    "    }\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "facaa491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¿ íŒ¡ ì™€ìš° íšŒì›, ì›” ì´ ìš”ê¸ˆ  '1ë§Œ 7890ì›'(ì¿ íŒ¡í”Œë ˆì´ ê°ˆë¬´ë¦¬)/ë‰´ìŠ¤1(ì„œìš¸=ë‰´ìŠ¤1) ê¹€ì •í˜„ ì–‘ìƒˆë¡¬ ê¸°ì = ì¿ íŒ¡í”Œë ˆì´ê°€ ë¶€ê°€ì„œë¹„ìŠ¤ì¸ 'ìŠ¤í¬ì¸  íŒ¨ìŠ¤'ì˜ ê¸ˆì•¡ì„ ì›” 1ë§Œ ì›ìœ¼ë¡œ í™•ì •í–ˆë‹¤.12ì¼ ì—…ê³„ì— ë”°ë¥´ë©´ ì¿ íŒ¡í”Œë ˆì´ëŠ” ì˜¤ëŠ” 15ì¼ í•´ì™¸ ìŠ¤í¬ì¸  ë“±ì˜ ì½˜í…ì¸ ë¥¼ ìœ ë£Œ ë¶€ê°€ ì„œë¹„ìŠ¤ë¡œ ì œê³µí•˜ëŠ” ìŠ¤í¬ì¸  íŒ¨ìŠ¤ì˜ ìš”ê¸ˆì„ ì›” 1ë§Œ ì›ìœ¼ë¡œ ê²°ì •í–ˆë‹¤. ê³µì‹ ê°€ê²©ì€ 1ë§Œ 2000ì›ì´ë‚˜, ì¶œì‹œ í• ì¸ê°€ë¡œ ì¶”ì •ëœë‹¤.ì¿ íŒ¡ ì™€ìš° ë©¤ë²„ì‹­ êµ¬ë…ë£Œì¸ ì›” 7890ì›ì— ìŠ¤í¬ì¸ íŒ¨ìŠ¤ ê¸ˆì•¡ì„ ë”í•˜ë©´ ì›” ì´ìš©ê¸ˆì•¡ì€ 1ë§Œ 7890ì›ì´ ëœë‹¤. í• ì¸ê°€ê°€ ì¢…ë£Œë  ê²½ìš° ì›” êµ¬ë…ë£Œë§Œ 2ë§Œ ì› ìˆ˜ì¤€ì´ë‹¤.ì´ë²ˆ íŒ¨ìŠ¤ë¥¼ í†µí•´ ë³¼ìˆ˜ ìˆëŠ” ìŠ¤í¬ì¸  ë¦¬ê·¸ëŠ” â–³FIFAëŒ€íšŒ(FIFAí´ëŸ½ì›”ë“œì»µ)â–³ìœ ëŸ½ì¶•êµ¬ë¦¬ê·¸(í”„ë¦¬ë¯¸ì–´ë¦¬ê·¸ 2025~2026 ì‹œì¦Œ, ë¼ë¦¬ê°€, ë¶„ë°ìŠ¤ë¦¬ê°€, ë¶„ë°ìŠ¤ë¦¬ê°€2, ë¦¬ê·¸1, EFL ì±”í”¼ì–¸ì‹­ EFLë¦¬ê·¸ì›, ì—ë ˆë””ë¹„ì‹œ) â–³ìœ ëŸ½ì¶•êµ¬ í† ë„ˆë¨¼íŠ¸(FAì»µ, ì¹´ë¼ë°”ì˜¤ì»µ, ì»¤ë®¤ë‹ˆí‹°ì‰´ë“œ, ì½”íŒŒ ë¸ë ˆì´, ìˆ˜í˜ë¥´ì½”íŒŒë° ì—ìŠ¤íŒŒëƒ, DFB-í¬ì¹¼, DFL-ìŠˆí¼ì»µ, ì¿ í”„ë“œí”„ë‘ìŠ¤, íŠ¸ë¡œí˜ë° ìƒ¹í”¼ì˜¹, ë²„íˆ¬íŠ¸ë¡œí”¼) â–³ì•„ì‹œì•„ì¶•êµ¬(AFCì•„ì‹œì•ˆì»µ, AFCì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸ ì—˜ë¦¬íŠ¸, AFCì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸2, ê¸°íƒ€AFCì£¼ê´€ êµ­ì œ ëŒ€íšŒ) â–³ì„¸ê³„ì¶•êµ¬(ì›”ë“œì»µë‚¨ë¯¸ ì˜ˆì„ , í´ëŸ½ ì¹œì„ ê²½ê¸°, í•´ì™¸ êµ­ê°€ ì¹œì„ ê²½ê¸°) ë“±ì´ë‹¤.ì¶•êµ¬ ì™¸ì—ë„ â–³ë ˆì´ì‹±(F1, F1 ì•„ì¹´ë°ë¯¸, ë‚˜ìŠ¤ì¹´) â–³ê³¨í”„(LIV ê³¨í”„) â–³ë†êµ¬(ë‚¨ì ë†êµ¬ ì•„ì‹œì•„ì»µ, ì—¬ì ë†êµ¬ ì•„ì‹œì•„ì»µ) â–³ë¯¸ì‹ ì¶•êµ¬(NFL) ë“±ë„ ìŠ¤í¬ì¸  íŒ¨ìŠ¤ë¥¼ ë³„ë„ êµ¬ë…í•´ì•¼ ì‹œì²­ ê°€ëŠ¥í•˜ë‹¤. ì˜¬ ê°€ì„ë¶€í„°ëŠ” NBA ê²½ê¸°ë„ ë…ì  ì œê³µí•  ì˜ˆì •ì´ë‹¤.ì¿ íŒ¡í”Œë ˆì´ëŠ” ëŒ€í•œë¯¼êµ­ ì¶•êµ¬ ëŒ€í‘œíŒ€, í•œêµ­ í”„ë¡œ ì¶•êµ¬, ì´ë²¤íŠ¸ ë§¤ì¹˜(ì¿ íŒ¡í”Œë ˆì´ ì‹œë¦¬ì¦ˆ)ëŠ” ë³„ë„ íŒ¨ìŠ¤ ê°€ì… ì—†ì´ ì™€ìš° íšŒì›ë“¤ì´ ì‹œì²­í•  ìˆ˜ ìˆë„ë¡ í•  ì˜ˆì •ì´ë‹¤. (ì¿ íŒ¡í”Œë ˆì´ í™ˆí˜ì´ì§€ ê°ˆë¬´ë¦¬) /ë‰´ìŠ¤1ì´ê°™ì€ ì •ë³´ëŠ” ì¿ íŒ¡í”Œë ˆì´ ê³µì‹ í™ˆí˜ì´ì§€ë¥¼ í†µí•´ 'ìŠ¤í¬ì¸  íŒ¨ìŠ¤' í˜ì´ì§€ê°€ ë…¸ì¶œë˜ë©° ì•Œë ¤ì¡Œë‹¤.2ë§Œ ì›ì— ìœ¡ë°•í•˜ëŠ” ê°€ê²© ì •ë³´ê°€ ì•Œë ¤ì§€ì êµ­ë‚´ ìŠ¤í¬ì¸  ì»¤ë®¤ë‹ˆí‹°ì—ì„œëŠ” \"ì¶•êµ¬ë§Œ ë³´ëŠ”ë° ê´€ì‹¬ì—†ëŠ” ì¤‘ê³„ë„ ë¬¶ì–´ì„œ ë¹„ì‹¸ê²Œ íŒë§¤í•˜ëŠ” ëŒ€ì‹  ì„ íƒ í­ì„ ëŠ˜ë ¸ìœ¼ë©´ í•œë‹¤\", \"ëˆ ë°›ëŠ” ê±´ ì¢‹ì€ë° í™”ì§ˆ ê°œì„ ì— ëŒ€í•œ ì´ì•¼ê¸°ëŠ” ì—†ë‚˜\" ë“±ì˜ ë°˜ì‘ì„ ë³´ì´ê³  ìˆë‹¤.ì¿ íŒ¡í”Œë ˆì´ ê´€ê³„ìëŠ” \"í•´ë‹¹ ê°€ê²© ì •ë³´ëŠ” ì‚¬ì‹¤ê³¼ ë‹¤ë¥´ë©°, ìŠ¤í¬ì¸  íŒ¨ìŠ¤ì˜ ê³µì‹ ê°€ê²© ë° ì„¸ë¶€ ë‚´ìš©ì€ ì¶”í›„ ì¿ íŒ¡í”Œë ˆì´ë¥¼ í†µí•´ ì •í™•íˆ ì•ˆë‚´ë“œë¦´ ì˜ˆì •\"ì´ë¼ê³  ë§í–ˆë‹¤.í•œí¸ ì¿ íŒ¡í”Œë ˆì´ëŠ” ì„ íƒí˜• ë¶€ê°€ì„œë¹„ìŠ¤ 'íŒ¨ìŠ¤(PASS)'ë¥¼ 6ì›” ì¤‘ ë„ì…í•œë‹¤ê³  ë°íŒ ë°” ìˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd26b68d",
   "metadata": {},
   "source": [
    "### ArxivLoader\n",
    "- https://github.com/lukasschwab/arxiv.py\n",
    "- [arXiv-ì•„ì¹´ì´ë¸Œ](https://arxiv.org/) ëŠ” ë¯¸êµ­ ì½”ë ëŒ€í•™ì—ì„œ ìš´ì˜í•˜ëŠ” **ë¬´ë£Œ ë…¼ë¬¸ ì €ì¥ì†Œ**ë¡œ, ë¬¼ë¦¬í•™, ìˆ˜í•™, ì»´í“¨í„° ê³¼í•™, ìƒë¬¼í•™, ê¸ˆìœµ, ê²½ì œ ë“± **ê³¼í•™, ê¸ˆìœµ ë¶„ì•¼ì˜ ë…¼ë¬¸**ë“¤ì„ ê³µìœ í•œë‹¤.\n",
    "- `ArxivLoader` ë¥¼ ì‚¬ìš©í•´ ì›í•˜ëŠ” ì£¼ì œì˜ ë…¼ë¬¸ë“¤ì„ arXivì—ì„œ ê°€ì ¸ì™€ loadí•  ìˆ˜ ìˆë‹¤.\n",
    "- **arXiv API**ë¥¼ ì‚¬ìš©í•´ ë…¼ë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ìˆë‹¤.\n",
    "  - https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.arxiv.ArxivLoader.html\n",
    "- ì„¤ì¹˜\n",
    "  - `pip install langchain-community -qU`\n",
    "  - `pip install arxiv -qU`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "495aa934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting arxiv\n",
      "  Using cached arxiv-2.2.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: langchain-community in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (0.3.24)\n",
      "Collecting feedparser~=6.0.10 (from arxiv)\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: requests~=2.32.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from arxiv) (2.32.3)\n",
      "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from requests~=2.32.0->arxiv) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from requests~=2.32.0->arxiv) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from requests~=2.32.0->arxiv) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from requests~=2.32.0->arxiv) (2025.4.26)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-community) (0.3.63)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-community) (0.3.25)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-community) (2.0.41)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-community) (3.12.9)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-community) (2.9.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-community) (0.3.44)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-community) (2.2.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (2.11.5)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (4.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
      "Downloading arxiv-2.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "Building wheels for collected packages: sgmllib3k\n",
      "\u001b[33m  DEPRECATION: Building 'sgmllib3k' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'sgmllib3k'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for sgmllib3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6089 sha256=4780037acfa2f0ada97612c0d655d45592c8478d0481ee839d46901662d754fd\n",
      "  Stored in directory: /Users/giwonjun/Library/Caches/pip/wheels/03/f5/1a/23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, feedparser, arxiv\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3/3\u001b[0m [arxiv]\n",
      "\u001b[1A\u001b[2KSuccessfully installed arxiv-2.2.0 feedparser-6.0.11 sgmllib3k-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install arxiv langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f45cfa67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'itertools.islice'>\n"
     ]
    }
   ],
   "source": [
    "import arxiv \n",
    "\n",
    "# ê²€ìƒ‰ ê¸°ì¤€ ì„¤ì •.\n",
    "search = arxiv.Search(\n",
    "    query=\"RAG\", # ê²€ìƒ‰ì–´\n",
    "    max_results=2, # ê²€ìƒ‰ ê²°ê³¼ ìµœëŒ€ ê°œìˆ˜.\n",
    "    sort_by=arxiv.SortCriterion.Relevance\n",
    ")\n",
    "# ì •ë ¬ê¸°ì¤€ - Relevance: ê²€ìƒ‰ì–´ ê´€ë ¨ì„±ì´ ë†’ì€ ìˆœì„œ\n",
    "#          - LastUpdatedDate: ë…¼ë¬¸ì´ ë§ˆì§€ë§‰ìœ¼ë¡œ ìˆ˜ì •ëœ ë‚ ì§œ ê¸°ì¤€.\n",
    "#          - SubmittedDate: ì²˜ìŒ ì œì¶œëœ ë‚ ì§œ ê¸°ì¤€.\n",
    "\n",
    "# ê²€ìƒ‰\n",
    "client = arxiv.Client()\n",
    "result = client.results(search)\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6072b39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = next(result)  # ì²«ë²ˆì§¸ ë¬¸ì„œ for page in result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a491e5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë…¼ë¬¸ì œëª©: Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks\n",
      "ì €ì: [arxiv.Result.Author('Yunfan Gao'), arxiv.Result.Author('Yun Xiong'), arxiv.Result.Author('Meng Wang'), arxiv.Result.Author('Haofen Wang')]\n",
      "ë…¼ë¬¸ PDF URL: http://arxiv.org/pdf/2407.21059v1\n"
     ]
    }
   ],
   "source": [
    "print(\"ë…¼ë¬¸ì œëª©:\", doc1.title)\n",
    "print(\"ì €ì:\", doc1.authors)\n",
    "# print(\"ìš”ì•½: \", doc1.summary)\n",
    "print(\"ë…¼ë¬¸ PDF URL:\", doc1.pdf_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "297d24d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¤ìš´ë¡œë“œ\n",
    "import os\n",
    "os.makedirs(\"papers\", exist_ok=True)\n",
    "\n",
    "client = arxiv.Client()\n",
    "result = client.results(search)\n",
    "\n",
    "for idx, paper in enumerate(result, start=10):\n",
    "    paper.download_pdf(\"papers\", f\"{idx}.pdf\")\n",
    "# doc1.download_pdf(ë‹¤ìš´ë°›ì„ ë””ë ‰í† ë¦¬, íŒŒì¼ëª…ëª…)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f14dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fitz in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (0.0.1.dev2)\n",
      "Requirement already satisfied: pymupdf in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (1.26.1)\n",
      "Requirement already satisfied: configobj in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from fitz) (5.0.9)\n",
      "Requirement already satisfied: configparser in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from fitz) (7.2.0)\n",
      "Requirement already satisfied: httplib2 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from fitz) (0.22.0)\n",
      "Requirement already satisfied: nibabel in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from fitz) (5.3.2)\n",
      "Requirement already satisfied: nipype in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from fitz) (1.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from fitz) (2.2.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from fitz) (2.3.0)\n",
      "Requirement already satisfied: pyxnat in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from fitz) (1.6.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from fitz) (1.15.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from httplib2->fitz) (3.2.3)\n",
      "Requirement already satisfied: packaging>=20 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nibabel->fitz) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nibabel->fitz) (4.14.0)\n",
      "Requirement already satisfied: click>=6.6.0 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nipype->fitz) (8.2.1)\n",
      "Requirement already satisfied: networkx>=2.5 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nipype->fitz) (3.5)\n",
      "Requirement already satisfied: prov>=1.5.2 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nipype->fitz) (2.0.2)\n",
      "Requirement already satisfied: pydot>=1.2.3 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nipype->fitz) (4.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nipype->fitz) (2.9.0.post0)\n",
      "Requirement already satisfied: rdflib>=5.0.0 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nipype->fitz) (7.1.4)\n",
      "Requirement already satisfied: simplejson>=3.8.0 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nipype->fitz) (3.20.1)\n",
      "Requirement already satisfied: traits>=6.2 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nipype->fitz) (7.0.2)\n",
      "Requirement already satisfied: filelock>=3.0.0 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nipype->fitz) (3.18.0)\n",
      "Requirement already satisfied: acres in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nipype->fitz) (0.5.0)\n",
      "Requirement already satisfied: etelemetry>=0.3.1 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nipype->fitz) (0.3.1)\n",
      "Requirement already satisfied: looseversion!=1.2 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nipype->fitz) (1.3.0)\n",
      "Requirement already satisfied: puremagic in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from nipype->fitz) (1.29)\n",
      "Requirement already satisfied: colorama in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from click>=6.6.0->nipype->fitz) (0.4.6)\n",
      "Requirement already satisfied: requests in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from etelemetry>=0.3.1->nipype->fitz) (2.32.3)\n",
      "Requirement already satisfied: ci-info>=0.2 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from etelemetry>=0.3.1->nipype->fitz) (0.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from python-dateutil>=2.2->nipype->fitz) (1.17.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from pandas->fitz) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from pandas->fitz) (2025.2)\n",
      "Requirement already satisfied: lxml>=4.3 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from pyxnat->fitz) (5.4.0)\n",
      "Requirement already satisfied: pathlib>=1.0 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from pyxnat->fitz) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from requests->etelemetry>=0.3.1->nipype->fitz) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from requests->etelemetry>=0.3.1->nipype->fitz) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from requests->etelemetry>=0.3.1->nipype->fitz) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\playdata\\miniconda3\\envs\\lang_env\\lib\\site-packages (from requests->etelemetry>=0.3.1->nipype->fitz) (2025.4.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5acac658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import ArxivLoader\n",
    "\n",
    "loader = ArxivLoader(\n",
    "    query=\"Advanced RAG\", \n",
    "    top_k_results=1, # ëª‡ê°œ ê²€ìƒ‰í• ì§€ ì§€ì •.\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e761a39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Published': '2024-07-26',\n",
       " 'Title': 'Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks',\n",
       " 'Authors': 'Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang',\n",
       " 'Summary': 'Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\\nof Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\\nincreasing demands of application scenarios have driven the evolution of RAG,\\nleading to the integration of advanced retrievers, LLMs and other complementary\\ntechnologies, which in turn has amplified the intricacy of RAG systems.\\nHowever, the rapid advancements are outpacing the foundational RAG paradigm,\\nwith many methods struggling to be unified under the process of\\n\"retrieve-then-generate\". In this context, this paper examines the limitations\\nof the existing RAG paradigm and introduces the modular RAG framework. By\\ndecomposing complex RAG systems into independent modules and specialized\\noperators, it facilitates a highly reconfigurable framework. Modular RAG\\ntranscends the traditional linear architecture, embracing a more advanced\\ndesign that integrates routing, scheduling, and fusion mechanisms. Drawing on\\nextensive research, this paper further identifies prevalent RAG\\npatterns-linear, conditional, branching, and looping-and offers a comprehensive\\nanalysis of their respective implementation nuances. Modular RAG presents\\ninnovative opportunities for the conceptualization and deployment of RAG\\nsystems. Finally, the paper explores the potential emergence of new operators\\nand paradigms, establishing a solid theoretical foundation and a practical\\nroadmap for the continued evolution and practical deployment of RAG\\ntechnologies.'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2111ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Modular RAG: Transforming RAG Systems into\n",
      "LEGO-like Reconfigurable Frameworks\n",
      "Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\n",
      "Abstractâ€”Retrieval-augmented\n",
      "Generation\n",
      "(RAG)\n",
      "has\n",
      "markedly enhanced the capabilities of Large Language Models\n",
      "(LLMs) in tackling knowledge-intensive tasks. The increasing\n",
      "demands of application scenarios have driven the evolution\n",
      "of RAG, leading to the integration of advanced retrievers,\n",
      "LLMs and other complementary technologies, which in turn\n",
      "has amplified the intricacy of RAG systems. However, the rapid\n",
      "advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process\n",
      "of â€œretrieve-then-generateâ€. In this context, this paper examines\n",
      "the limitations of the existing RAG paradigm and introduces\n",
      "the modular RAG framework. By decomposing complex RAG\n",
      "systems into independent modules and specialized operators, it\n",
      "facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a\n",
      "more advanced design that integrates routing, scheduling, and\n",
      "fusion mechanisms. Drawing on extensive research, this paper\n",
      "further identifies prevalent RAG patternsâ€”linear, conditional,\n",
      "branching, and loopingâ€”and offers a comprehensive analysis\n",
      "of their respective implementation nuances. Modular RAG\n",
      "presents\n",
      "innovative\n",
      "opportunities\n",
      "for\n",
      "the\n",
      "conceptualization\n",
      "and deployment of RAG systems. Finally, the paper explores\n",
      "the potential emergence of new operators and paradigms,\n",
      "establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment\n",
      "of RAG technologies.\n",
      "Index Termsâ€”Retrieval-augmented generation, large language\n",
      "model, modular system, information retrieval\n",
      "I. INTRODUCTION\n",
      "L\n",
      "ARGE Language Models (LLMs) have demonstrated\n",
      "remarkable capabilities, yet they still face numerous\n",
      "challenges, such as hallucination and the lag in information up-\n",
      "dates [1]. Retrieval-augmented Generation (RAG), by access-\n",
      "ing external knowledge bases, provides LLMs with important\n",
      "contextual information, significantly enhancing their perfor-\n",
      "mance on knowledge-intensive tasks [2]. Currently, RAG, as\n",
      "an enhancement method, has been widely applied in various\n",
      "practical application scenarios, including knowledge question\n",
      "answering, recommendation systems, customer service, and\n",
      "personal assistants. [3]â€“[6]\n",
      "During the nascent stages of RAG , its core framework is\n",
      "constituted by indexing, retrieval, and generation, a paradigm\n",
      "referred to as Naive RAG [7]. However, as the complexity\n",
      "of tasks and the demands of applications have escalated, the\n",
      "Yunfan Gao is with Shanghai Research Institute for Intelligent Autonomous\n",
      "Systems, Tongji University, Shanghai, 201210, China.\n",
      "Yun Xiong is with Shanghai Key Laboratory of Data Science, School of\n",
      "Computer Science, Fudan University, Shanghai, 200438, China.\n",
      "Meng Wang and Haofen Wang are with College of Design and Innovation,\n",
      "Tongji University, Shanghai, 20092, China. (Corresponding author: Haofen\n",
      "Wang. E-mail: carter.whfcarter@gmail.com)\n",
      "limitations of Naive RAG have become increasingly apparent.\n",
      "As depicted in Figure 1, it predominantly hinges on the\n",
      "straightforward similarity of chunks, result in poor perfor-\n",
      "mance when confronted with complex queries and chunks with\n",
      "substantial variability. The primary challenges of Naive RAG\n",
      "include: 1) Shallow Understanding of Queries. The semantic\n",
      "similarity between a query and document chunk is not always\n",
      "highly consistent. Relying solely on similarity calculations\n",
      "for retrieval lacks an in-depth exploration of the relationship\n",
      "between the query and the document [8]. 2) Retrieval Re-\n",
      "dundancy and Noise. Feeding all retrieved chunks directly\n",
      "into LLMs is not always beneficial. Research indicates that\n",
      "an excess of redundant and noisy information may interfere\n",
      "with the LLMâ€™s identification of key information, thereby\n",
      "increasing the risk of generating erroneous and hallucinated\n",
      "responses. [9]\n",
      "To overcome the aforementioned limitations, Advanced\n",
      "RAG paradigm focuses on optimizing the retrieval phase,\n",
      "aiming to enhance retrieval efficiency and strengthen the\n",
      "utilization of retrieved chunks. As shown in Figure 1 ,typical\n",
      "strategies involve pre-retrieval processing and post-retrieval\n",
      "processing. For instance, query rewriting is used to make\n",
      "the queries more clear and specific, thereby increasing the\n",
      "accuracy of retrieval [10], and the reranking of retrieval results\n",
      "is employed to enhance the LLMâ€™s ability to identify and\n",
      "utilize key information [11].\n",
      "Despite the improvements in the practicality of Advanced\n",
      "RAG, there remains a gap between its capabilities and real-\n",
      "world application requirements. On one hand, as RAG tech-\n",
      "nology advances, user expectations rise, demands continue to\n",
      "evolve, and application settings become more complex. For\n",
      "instance, the integration of heterogeneous data and the new\n",
      "demands for system transparency, control, and maintainability.\n",
      "On the other hand, the growth in application demands has\n",
      "further propelled the evolution of RAG technology.\n",
      "As shown in Figure 2, to achieve more accurate and efficient\n",
      "task execution, modern RAG systems are progressively inte-\n",
      "grating more sophisticated function, such as organizing more\n",
      "refined index base in the form of knowledge graphs, integrat-\n",
      "ing structured data through query construction methods, and\n",
      "employing fine-tuning techniques to enable encoders to better\n",
      "adapt to domain-specific documents.\n",
      "In terms of process design, the current RAG system has\n",
      "surpassed the traditional linear retrieval-generation paradigm.\n",
      "Researchers use iterative retrieval [12] to obtain richer con-\n",
      "text, recursive retrieval [13] to handle complex queries, and\n",
      "adaptive retrieval [14] to provide overall autonomy and flex-\n",
      "ibility. This flexibility in the process significantly enhances\n",
      "arXiv:2407.21059v1  [cs.CL]  26 Jul 2024\n",
      "2\n",
      "Fig. 1. Cases of Naive RAG and Advanced RAG.When faced with complex\n",
      "questions, both encounter limitations and struggle to provide satisfactory\n",
      "answers. Despite the fact that Advanced RAG improves retrieval accuracy\n",
      "through hierarchical indexing, pre-retrieval, and post-retrieval processes, these\n",
      "relevant documents have not been used correctly.\n",
      "the expressive power and adaptability of RAG systems, en-\n",
      "abling them to better adapt to various application scenarios.\n",
      "However, this also makes the orchestration and scheduling of\n",
      "workflows more complex, posing greater challenges to system\n",
      "design. Specifically, RAG currently faces the following new\n",
      "challenges:\n",
      "Complex data sources integration. RAG are no longer\n",
      "confined to a single type of unstructured text data source but\n",
      "have expanded to include various data types, such as semi-\n",
      "structured data like tables and structured data like knowledge\n",
      "graphs [15]. Access to heterogeneous data from multiple\n",
      "sources can provide the system with a richer knowledge\n",
      "background, and more reliable knowledge verification capa-\n",
      "bilities [16].\n",
      "New demands for system interpretability, controllability,\n",
      "Fig. 2.\n",
      "Case of current Modular RAG.The system integrates diverse data\n",
      "and more functional components. The process is no longer confined to linear\n",
      "but is controlled by multiple control components for retrieval and generation,\n",
      "making the entire system more flexible and complex.\n",
      "3\n",
      "and maintainability. With the increasing complexity of sys-\n",
      "tems, system maintenance and debugging have become more\n",
      "challenging. Additionally, when issues arise, it is essential to\n",
      "quickly pinpoint the specific components that require opti-\n",
      "mization.\n",
      "Component selection and optimization. More neural net-\n",
      "works are involved in the RAG system, necessitating the\n",
      "selection of appropriate components to meet the needs of spe-\n",
      "cific tasks and resource configurations. Moreover, additional\n",
      "components enhance the effectiveness of RAG but also bring\n",
      "new collaborative work requirements [17]. Ensuring that these\n",
      "models perform as intended and work efficiently together to\n",
      "enhance the overall system performance is crucial.\n",
      "Workflow orchestration and scheduling. Components\n",
      "may need to be executed in a specific order, processed in paral-\n",
      "lel under certain conditions, or even judged by the LLM based\n",
      "on different outputs. Reasonable planning of the workflow is\n",
      "essential for improving system efficiency and achieving the\n",
      "desired outcomes [18].\n",
      "To address the design, management, and maintenance chal-\n",
      "lenges posed by the increasing complexity of RAG systems,\n",
      "and to meet the ever-growing and diverse demands and ex-\n",
      "pectations, this paper proposes Modular RAG architecture.\n",
      "In modern computing systems, modularization is becoming\n",
      "a trend. It can enhance the systemâ€™s scalability and maintain-\n",
      "ability and achieve efficient task execution through process\n",
      "control.\n",
      "The Modular RAG system consists of multiple independent\n",
      "yet tightly coordinated modules, each responsible for handling\n",
      "specific functions or tasks. This architecture is divided into\n",
      "three levels: the top level focuses on the critical stages of\n",
      "RAG, where each stage is treated as an independent module.\n",
      "This level not only inherits the main processes from the\n",
      "Advanced RAG paradigm but also introduces an orchestration\n",
      "module to control the coordination of RAG processes. The\n",
      "middle level is composed of sub-modules within each module,\n",
      "further refining and optimizing the functions. The bottom level\n",
      "consists of basic units of operationâ€”operators. Within the\n",
      "Modular RAG framework, RAG systems can be represented\n",
      "in the form of computational graphs, where nodes represent\n",
      "specific operators. The comparison of the three paradigms is\n",
      "shown in the Figure 3. Modular RAG evolves based on the\n",
      "previous development of RAG. The relationships among these\n",
      "three paradigms are ones of inheritance and development.\n",
      "Advanced RAG is a special case of Modular RAG, while Naive\n",
      "RAG is a special case of Advanced RAG.\n",
      "The advantages of Modular RAG are significant, as it\n",
      "enhances the flexibility and scalability of RAG systems. Users\n",
      "can flexibly combine different modules and operators accord-\n",
      "ing to the requirements of data sources and task scenarios. In\n",
      "summary, the contributions of this paper are as follows:\n",
      "â€¢ This paper proposes a new paradigm called modular\n",
      "RAG, which employs a three-tier architectural design\n",
      "comprising modules, sub-modules, and operators to de-\n",
      "fine the RAG system in a unified and structured manner.\n",
      "This design not only enhances the systemâ€™s flexibility and\n",
      "scalability but also, through the independent design of\n",
      "operators, strengthens the systemâ€™s maintainability and\n",
      "comprehensibility.\n",
      "â€¢ Under the framework of Modular RAG, the orchestration\n",
      "of modules and operators forms the RAG Flow, which\n",
      "can flexibly express current RAG methods. This paper has\n",
      "further summarized six typical flow patterns and specific\n",
      "methods have been analyzed to reveal the universality of\n",
      "modular RAG in practical scenarios.\n",
      "â€¢ The Modular RAG framework offers exceptional flexi-\n",
      "bility and extensibility. This paper delves into the new\n",
      "opportunities brought by Modular RAG and provides a\n",
      "thorough discussion on the adaptation and expansion of\n",
      "new methods in different application scenarios, offering\n",
      "guidance for future research directions and practical ex-\n",
      "ploration.\n",
      "II. RELATED WORK\n",
      "The development of RAG technology can be summarized\n",
      "in three stages. Initially, retrieval-augmented techniques were\n",
      "introduced to improve the performance of pre-trained lan-\n",
      "guage models on knowledge-intensive tasks [19], [20]. In\n",
      "specific implementations, Retro [21] optimized pre-trained\n",
      "autoregressive models through retrieval augmentation, while\n",
      "Atlas [22] utilized a retrieval-augmented few-shot fine-tuning\n",
      "method, enabling language models to adapt to diverse tasks.\n",
      "IRCOT [23] further enriched the reasoning process during\n",
      "the inference phase by combining chain-of-thought and multi-\n",
      "step retrieval processes. Entering the second stage, as the\n",
      "language processing capabilities of LLMs significantly im-\n",
      "proved, retrieval-augmented techniques began to serve as a\n",
      "means of supplementing additional knowledge and providing\n",
      "references, aiming to reduce the hallucination. For instance,\n",
      "RRR [24] improved the rewriting phase, and LLMlingua [25]\n",
      "removed redundant tokens in retrieved document chunks.\n",
      "With the continuous progress of RAG technology, research\n",
      "has become more refined and focused, while also achieving\n",
      "innovative integration with other technologies such as graph\n",
      "neural networks [26] and fine-tuning techniques [27]. The\n",
      "overall pipeline has also become more flexible, such as using\n",
      "LLMs to proactively determine the timing of retrieval and\n",
      "generation [14], [28].\n",
      "The development of RAG technology has been acceler-\n",
      "ated by LLM technology and practical application needs.\n",
      "Researchers are examining and organizing the RAG frame-\n",
      "work and development pathways from different perspectives.\n",
      "Building upon the enhanced stages of RAG, Gao et al., [2] sub-\n",
      "divided RAG into enhancement during pre-training, inference,\n",
      "and fine-tuning stages. Based on the main processes of RAG,\n",
      "relevant works on RAG were organized from the perspectives\n",
      "of retrieval, generation, and augmentation methods. Huang\n",
      "et al., [29] categorize RAG methods into four main classes:\n",
      "pre-retrieval, retrieval, post-retrieval, generation, and provide\n",
      "a detailed discussion of the methods and techniques within\n",
      "each class. Hu et al., [30] discuss Retrieval-Augmented Lan-\n",
      "guage Models (RALMs) form three key components, including\n",
      "retrievers, language models, augmentations, and how their\n",
      "interactions lead to different model structures and applications.\n",
      "4\n",
      "Fig. 3. Comparison between three RAG paradigms. Modular RAG has evolved from previous paradigms and aligns with the current practical needs of RAG\n",
      "systems.\n",
      "They emphasize the importance of considering robustness,\n",
      "accuracy, and relevance when evaluating RALMs and pro-\n",
      "pose several evaluation methods. Ding et al., [31] provide a\n",
      "comprehensive review from the perspectives of architecture,\n",
      "training strategies, and applications. They specifically discuss\n",
      "four training methods of RALMs: training-free methods, in-\n",
      "dependent training methods, sequence training methods, and\n",
      "joint training methods, and compare their advantages and\n",
      "disadvantages. Zhao et al., [32]analyze the applications of\n",
      "RAG technology in various fields such as text generation,\n",
      "code generation, image generation, and video generation from\n",
      "the perspective of augmented intelligence with generative\n",
      "capabilities.\n",
      "The current collation of RAG systems primarily focuses\n",
      "on methods with a fixed process, mainly concerned with\n",
      "optimizing the retrieval and generation stages. However, it has\n",
      "not turned its attention to the new characteristics that RAG\n",
      "research is continuously evolving, namely the characteristics\n",
      "of process scheduling and functional componentization. There\n",
      "is currently a lack of comprehensive analysis of the overall\n",
      "RAG system, which has led to research on paradigms lagging\n",
      "behind the development of RAG technology.\n",
      "III. FRAMEWORK AND NOTATION\n",
      "For query Q = {qi}, a typical RAG system mainly consists\n",
      "of three key components. 1) Indexing. Given documents D =\n",
      "{d1, d2, . . . , dn} , where di represents the document chunk.\n",
      "Indexing is the process of converting di into vectors through\n",
      "an embedding model fe(Â·) , and then store vectors in vector\n",
      "database.\n",
      "I = {e1, e2, . . . , en}\n",
      "and\n",
      "ei = fe(di) âˆˆRd\n",
      "(1)\n",
      "Notation\n",
      "Description\n",
      "q\n",
      "The original query\n",
      "y\n",
      "The output of LLM\n",
      "D\n",
      "A document retrieval repository composed of chunks di.\n",
      "R(q, D)\n",
      "Retriever,find similar chunks from D based on q.\n",
      "F\n",
      "RAG Flow\n",
      "P\n",
      "RAG Flow pattern\n",
      "fqe\n",
      "Query expansion function\n",
      "fqc\n",
      "Query transform function\n",
      "fcomp\n",
      "Chunk compression function\n",
      "fsel\n",
      "Chunk selection function\n",
      "fr\n",
      "Routing function\n",
      "M\n",
      "Module in modular RAG\n",
      "op\n",
      "The specific operators within the Module.\n",
      "TABLE I\n",
      "IMPORTANT NOTATION\n",
      "2) Retrieval . Transform the query into a vector using the\n",
      "same encoding model, and then filter out the top k document\n",
      "chunks that are most similar based on vector similarity.\n",
      "R : topk\n",
      "diâˆˆD\n",
      "Sim(q, di) â†’Dq\n",
      "(2)\n",
      "Dq = {d1, d2, . . . , dk} represents the relevant documents for\n",
      "question q. The similarity function Sim(Â·) commonly used are\n",
      "dot product or cosine similarity.\n",
      "Sim(q, di) = eq Â· edi\n",
      "or\n",
      "eq Â· edi\n",
      "âˆ¥eqâˆ¥Â· âˆ¥ediâˆ¥\n",
      "(3)\n",
      "3) Generation. After getting the relevant documents. The\n",
      "query q and the retrieved document Dq chunks are inputted\n",
      "together to the LLM to generate the final answer, where [Â·, Â·]\n",
      "stands for concatenation.\n",
      "y = LLM([Dq, q])\n",
      "(4)\n",
      "5\n",
      "With the evolution of RAG technology, more and more func-\n",
      "tional components are being integrated into systems. Modular\n",
      "RAG paradigm includes three levels, ranging from large to\n",
      "small:\n",
      "L1 Module (M = {Ms}). The core process in RAG\n",
      "system.\n",
      "L2 Sub-module (Ms = {Op}).The functional modules in\n",
      "module.\n",
      "L3 Operator (Op = {fÎ¸i}). The the specific functional\n",
      "implementation in a module or sub-module. As a result, a\n",
      "Modular RAG system can be represented as:\n",
      "G = {q, D, M, {Ms}, {Op}}\n",
      "(5)\n",
      "The arrangement between modules and operators constitutes\n",
      "the RAG Flow F = (MÏ•1, . . . , MÏ•n) where Ï• stands for\n",
      "the set of module parameters. A modular rag flow can be\n",
      "decomposed into a graph of sub-functions. In the simplest\n",
      "case,the graph is a linear chain.\n",
      "NaiveRAG : q\n",
      "R(q,D)\n",
      "âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’\n",
      "T extâˆ’Embedding Dq\n",
      "LLM([q,Dq])\n",
      "âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’\n",
      "OpenAI/GP T âˆ’4 y\n",
      "(6)\n",
      "IV. MODULE AND OPERATOR\n",
      "This chapter will specifically introduce modules and op-\n",
      "erators under the Modular RAG framework. Based on the\n",
      "current stage of RAG development, we have established\n",
      "six main modules: Indexing, Pre-retrieval, Retrieval, Post-\n",
      "retrieval, Generation, and Orchestration.\n",
      "A. Indexing\n",
      "Indexing is the process of split document into manageable\n",
      "chunks and it is a key step in organizing a system. Indexing\n",
      "faces three main challenges. 1) Incomplete content represen-\n",
      "tation.The semantic information of chunks is influenced by the\n",
      "segmentation method, resulting in the loss or submergence of\n",
      "important information within longer contexts. 2) Inaccurate\n",
      "chunk similarity search. As data volume increases, noise in\n",
      "retrieval grows, leading to frequent matching with erroneous\n",
      "data, making the retrieval system fragile and unreliable. 3)\n",
      "Unclear reference trajectory. The retrieved chunks may orig-\n",
      "inate from any document, devoid of citation trails, potentially\n",
      "resulting in the presence of chunks from multiple different\n",
      "documents that, despite being semantically similar, contain\n",
      "content on entirely different topics.\n",
      "1) Chunk Optimization: The size of the chunks and the\n",
      "overlap between the chunks play a crucial role in the overall\n",
      "effectiveness of the RAG system. Given a chunk di, its chunk\n",
      "size is denoted as Li = |di|, and the overlap is denoted as\n",
      "Lo\n",
      "i = |di âˆ©di+1|. Larger chunks can capture more context,\n",
      "but they also generate more noise, requiring longer processing\n",
      "time and higher costs. While smaller chunks may not fully\n",
      "convey the necessary context, they do have less noise [17].\n",
      "Sliding Window using overlapping chunks in a sliding win-\n",
      "dow enhances semantic transitions. However, it has limitations\n",
      "such as imprecise context size control, potential truncation of\n",
      "words or sentences, and lacking semantic considerations.\n",
      "Metadata Attachment. Chunks can be enriched with meta-\n",
      "data like page number, file name, author, timestamp, sum-\n",
      "mary, or relevant questions. This metadata allows for filtered\n",
      "retrieval, narrowing the search scope.\n",
      "Small-to-Big [33] separate the chunks used for retrieval\n",
      "from those used for synthesis. Smaller chunks enhance re-\n",
      "trieval accuracy, while larger chunks provide more context.\n",
      "One approach is to retrieve smaller summarized chunks and\n",
      "reference their parent larger chunks. Alternatively, individual\n",
      "sentences could be retrieved along with their surrounding text.\n",
      "2) Structure Organization: One effective method for en-\n",
      "hancing information retrieval is to establish a hierarchical\n",
      "structure for the documents. By constructing chunks structure,\n",
      "RAG system can expedite the retrieval and processing of\n",
      "pertinent data.\n",
      "Hierarchical Index. In the hierarchical structure of docu-\n",
      "ments, nodes are arranged in parent-child relationships, with\n",
      "chunks linked to them. Data summaries are stored at each\n",
      "node, aiding in the swift traversal of data and assisting the\n",
      "RAG system in determining which chunks to extract. This\n",
      "approach can also mitigate the illusion caused by chunk\n",
      "extraction issues. The methods for constructing a structured\n",
      "index primarily include: 1) Structural awareness based on\n",
      "paragraph and sentence segmentation in docs. 2) Content\n",
      "awareness based on inherent structure in PDF, HTML, and\n",
      "Latex. 3) Semantic awareness based on semantic recognition\n",
      "and segmentation of text.\n",
      "KG Index [34]. Using Knowledge Graphs (KGs) to struc-\n",
      "ture documents helps maintain consistency by clarifying con-\n",
      "nections between concepts and entities, reducing the risk of\n",
      "mismatch errors. KGs also transform information retrieval\n",
      "into instructions intelligible to language models, improving re-\n",
      "trieval accuracy and enabling contextually coherent responses.\n",
      "This enhances the overall efficiency of the RAG system.\n",
      "For example, organizing a corpus in the format of graph\n",
      "G = {V, E, X}, where node V = {vi}n\n",
      "i=1 represent document\n",
      "structures (e.g.passage, pages, table) , edge E âŠ‚V Ã— V rep-\n",
      "resent semantic or lexical similarity and belonging relations,\n",
      "and node features X = {Xi}n\n",
      "i=1 represent text or markdown\n",
      "content for passage.\n",
      "B. Pre-retrieval\n",
      "One of the primary challenges with Naive RAG is its\n",
      "direct reliance on the userâ€™s original query as the basis for\n",
      "retrieval. Formulating a precise and clear question is difficult,\n",
      "and imprudent queries result in subpar retrieval effectiveness.\n",
      "The primary challenges in this module include: 1) Poorly\n",
      "worded queries. The question itself is complex, and the\n",
      "language is not well-organized. 2) Language complexity and\n",
      "ambiguity. Language models often struggle when dealing\n",
      "with specialized vocabulary or ambiguous abbreviations with\n",
      "multiple meanings. For instance, they may not discern whether\n",
      "LLM refers to Large Language Model or a Master of Laws in\n",
      "a legal context.\n",
      "1) Query Expansion : Expanding a single query into mul-\n",
      "tiple queries enriches the content of the query, providing\n",
      "6\n",
      "further context to address any lack of specific nuances, thereby\n",
      "ensuring the optimal relevance of the generated answers.\n",
      "fqe(q) = {q1, q2, . . . , qn}\n",
      "âˆ€qi âˆˆ{q1, q2, . . . , qn}, qi /âˆˆQ\n",
      "(7)\n",
      "Multi-Query uses prompt engineering to expand queries\n",
      "via LLMs, allowing for parallel execution. These expansions\n",
      "are meticulously designed to ensure diversity and coverage.\n",
      "However, this approach can dilute the userâ€™s original intent.\n",
      "To mitigate this, the model can be instructed to assign greater\n",
      "weight to the original query.\n",
      "Sub-Query. By decomposing and planning for complex\n",
      "problems, multiple sub-problems are generated. Specifically,\n",
      "least-to-most prompting [35] can be employed to decom-\n",
      "pose the complex problem into a series of simpler sub-\n",
      "problems. Depending on the structure of the original problem,\n",
      "the generated sub-problems can be executed in parallel or\n",
      "sequentially. Another approach involves the use of the Chain-\n",
      "of-Verification (CoVe) [36]. The expanded queries undergo\n",
      "validation by LLM to achieve the effect of reducing hallu-\n",
      "cinations.\n",
      "2) Query Transformation: Retrieve and generate based on\n",
      "a transformed query instead of the userâ€™s original query.\n",
      "fqt(q) = qâ€²\n",
      "(8)\n",
      "Rewrite. Original queries often fall short for retrieval in\n",
      "real-world scenarios. To address this, LLMs can be prompted\n",
      "to rewrite. Specialized smaller models can also be employed\n",
      "for this purpose [24]. The implementation of the query rewrite\n",
      "method in Taobao has significantly improved recall effective-\n",
      "ness for long-tail queries, leading to an increase in GMV [10].\n",
      "HyDE [37]. In order to bridge the semantic gap between\n",
      "questions and answers, it constructs hypothetical documents\n",
      "(assumed answers) when responding to queries instead of\n",
      "directly searching the query. It focuses on embedding simi-\n",
      "larity from answer to answer rather than seeking embedding\n",
      "similarity for the problem or query. In addition, it also in-\n",
      "cludes reverse HyDE, which generate hypothetical query for\n",
      "each chunks and focuses on retrieval from query to query.\n",
      "Step-back Prompting [38]. The original query is abstracted\n",
      "into a high-level concept question (step-back question). In the\n",
      "RAG system, both the step-back question and the original\n",
      "query are used for retrieval, and their results are combined\n",
      "to generate the language modelâ€™s answer.\n",
      "3) Query Construction: In addition to text data, an in-\n",
      "creasing amount of structured data, such as tables and graph\n",
      "data, is being integrated into RAG systems. To accommodate\n",
      "various data types, it is necessary to restructure the userâ€™s\n",
      "query. This involve converting the query into another query\n",
      "language to access alternative data sources, with common\n",
      "methods including Text-to-SQL or Text-to-Cypher . In many\n",
      "scenarios, structured query languages (e.g., SQL, Cypher)\n",
      "are often used in conjunction with semantic information and\n",
      "metadata to construct more complex queries.\n",
      "fqc(q) = qâˆ—, qâˆ—âˆˆQâˆ—= {SQL, Cypher, . . . }\n",
      "(9)\n",
      "C. Retrieval\n",
      "The retrieval process is pivotal in RAG systems. By lever-\n",
      "aging powerful embedding models, queries and text can be\n",
      "efficiently represented in latent spaces, which facilitates the\n",
      "establishment of semantic similarity between questions and\n",
      "documents, thereby enhancing retrieval. Three main consider-\n",
      "ations that need to be addressed include retrieval efficiency,\n",
      "quality, and the alignment of tasks, data and models.\n",
      "1) Retriever Selection: With the widespread adoption of\n",
      "RAG technology, the development of embedding models has\n",
      "been in full swing. In addition to traditional models based\n",
      "on statistics and pre-trained models based on the encoder\n",
      "structure, embedding models fine-tuned on LLMs have also\n",
      "demonstrated powerful capabilities [39]. However, they often\n",
      "come with more parameters, leading to weaker inference\n",
      "and retrieval efficiency. Therefore, it is crucial to select the\n",
      "appropriate retriever based on different task scenarios.\n",
      "Sparse Retriever uses statistical methods to convert queries\n",
      "and documents into sparse vectors. Its advantage lies in its\n",
      "efficiency in handling large datasets, focusing only on non-zero\n",
      "elements. However, it may be less effective than dense vectors\n",
      "in capturing complex semantics. Common methods include\n",
      "TF-IDF and BM25.\n",
      "Dense Retriever employs pre-trained language models\n",
      "(PLMs) to provide dense representations of queries and doc-\n",
      "uments. Despite higher computational and storage costs, it\n",
      "offers more complex semantic representations. Typical models\n",
      "include BERT structure PLMs, like ColBERT, and multi-task\n",
      "fine-tuned models like BGE [40] and GTE [41].\n",
      "Hybrid Retriever is to use both sparse and dense retrievers\n",
      "simultaneously. Two embedding techniques complement each\n",
      "other to enhance retrieval effectiveness. Sparse retriever can\n",
      "provide initial screening results. Additionally, sparse models\n",
      "enhance the zero-shot retrieval capabilities of dense models,\n",
      "particularly in handling queries with rare entities, thereby\n",
      "increasing system robustness.\n",
      "2) Retriever Fine-tuning: In cases where the context may\n",
      "diverge from pre-trained corpus, particularly in highly special-\n",
      "ized fields like healthcare, law, and other domains abundant in\n",
      "proprietary terminology. While this adjustment demands addi-\n",
      "tional effort, it can substantially enhance retrieval efficiency\n",
      "and domain alignment.\n",
      "Supervised Fine-Tuning (SFT). Fine-tuning a retrieval\n",
      "model based on labeled domain data is typically done using\n",
      "contrastive learning. This involves reducing the distance be-\n",
      "tween positive samples while increasing the distance between\n",
      "negative samples. The commonly used loss calculation is\n",
      "shown in the following:\n",
      "L(DR) = âˆ’1\n",
      "T\n",
      "T\n",
      "X\n",
      "i=1\n",
      "log\n",
      "e(sim(qi,d+\n",
      "i ))\n",
      "e(sim(qi,d+\n",
      "i )) + PN\n",
      "j=1 e(sim(qi,dâˆ’\n",
      "i ))\n",
      "(10)\n",
      "where d+\n",
      "i is the positive sample document corresponding to\n",
      "the i-th query, dâˆ’\n",
      "i\n",
      "is several negative sample, T is the total\n",
      "number of queries, N is the number of negative samples, and\n",
      "DR is the fine-tuning dataset.\n",
      "LM-supervised Retriever (LSR). In contrast to directly\n",
      "constructing a fine-tuning dataset from the dataset, LSR uti-\n",
      "7\n",
      "lizes the LM-generated results as supervisory signals to fine-\n",
      "tune the embedding model during the RAG process.\n",
      "PLSR(d|q, y) =\n",
      "ePLM(y|d,q)/Î²\n",
      "P\n",
      "dâ€²âˆˆD ePLM(y|d,q)/Î²)\n",
      "(11)\n",
      "PLM(y|d, q) is LM probability of the ground truth output y\n",
      "given the input context d and query q, and Î² is a hyper-\n",
      "paramter.\n",
      "Adapter. At times, fine-tuning a large retriever can be\n",
      "costly, especially when dealing with retrievers based on LLMs\n",
      "like gte-Qwen. In such cases, it can mitigate this by incorpo-\n",
      "rating an adapter module and conducting fine-tuning. Another\n",
      "benefit of adding an adapter is the ability to achieve better\n",
      "alignment with specific downstream tasks [42].\n",
      "D. Post-retrieval\n",
      "Feeding all retrieved chunks directly into the LLM is not an\n",
      "optimal choice. Post-processing the chunks can aid in better\n",
      "leveraging the contextual information. The primary challenges\n",
      "include: 1) Lost in the middle. Like humans, LLM tends\n",
      "to remember only the beginning or the end of long texts,\n",
      "while forgetting the middle portion [43]. 2) Noise/anti-fact\n",
      "chunks. Retrieved noisy or factually contradictory documents\n",
      "can impact the final retrieval generation [44].\n",
      "3) Context\n",
      "Window. Despite retrieving a substantial amount of relevant\n",
      "content, the limitation on the length of contextual information\n",
      "in large models prevents the inclusion of all this content.\n",
      "1) Rerank: Rerank the retrieved chunks without altering\n",
      "their content or length, to enhance the visibility of the more\n",
      "crucial document chunks. Given the retrieved set Dq and a\n",
      "re-ranking method frerank to obtain the re-ranked set:\n",
      "Dq\n",
      "r = frerank(q, Dq) = {dâ€²\n",
      "1, dâ€²\n",
      "2, . . . , dâ€²\n",
      "k}\n",
      "wheref(dâ€²\n",
      "1) â‰¥f(dâ€²\n",
      "2) â‰¥. . . â‰¥f(dâ€²\n",
      "k).\n",
      "(12)\n",
      "Rule-base rerank. Metrics are calculated to rerank chunks\n",
      "according to certain rules. Common metrics include: diversity,\n",
      "relevance and MRR (Maximal Marginal Relevance) [45]. The\n",
      "idea is to reduce redundancy and increase result diversity.\n",
      "MMR selects phrases for the final key phrase list based on a\n",
      "combined criterion of query relevance and information novelty.\n",
      "Model-base rerank. Utilize a language model to reorder the\n",
      "document chunks, commonly based on the relevance between\n",
      "the chunks and the query. Rerank models have become an\n",
      "important component of RAG systems, and relevant model\n",
      "technologies are also being iteratively upgraded. The scope\n",
      "reordering has also been extended to multimodal data such as\n",
      "tables and images [46].\n",
      "2) Compression: A common misconception in the RAG\n",
      "process is the belief that retrieving as many relevant docu-\n",
      "ments as possible and concatenating them to form a lengthy\n",
      "retrieval prompt is beneficial. However, excessive context can\n",
      "introduce more noise, diminishing the LLMâ€™s perception of\n",
      "key information. A common approach to address this is to\n",
      "compress and select the retrieved content.\n",
      "Dq\n",
      "c = fcomp(q, Dq),\n",
      "where|dqc\n",
      "i | < |dq\n",
      "i |\n",
      "âˆ€dq\n",
      "i âˆˆDq\n",
      "(13)\n",
      "(Long)LLMLingua [47]. By utilizing aligned and trained\n",
      "small language models, such as GPT-2 Small or LLaMA-\n",
      "7B, the detection and removal of unimportant tokens from\n",
      "the prompt is achieved, transforming it into a form that is\n",
      "challenging for humans to comprehend but well understood by\n",
      "LLMs. This approach presents a direct and practical method\n",
      "for prompt compression, eliminating the need for additional\n",
      "training of LLMs while balancing language integrity and\n",
      "compression ratio.\n",
      "3) Selection: Unlike compressing the content of document\n",
      "chunks, Selection directly removes irrelevant chunks.\n",
      "Dq\n",
      "s = fsel(Dq) = {di âˆˆD | Â¬P(di)}\n",
      "(14)\n",
      "Where fsel is the function for deletion operation and P(di) is\n",
      "a conditional predicate indicating that document (di) satisfies\n",
      "a certain condition. If document (di) satisfies (P(di)), it will\n",
      "be deleted. Conversely, documents for which (Â¬P(di)) is true\n",
      "will be retained.\n",
      "Selective Context. By identifying and removing redundant\n",
      "content in the input context, the input is refined, thus improv-\n",
      "ing the language modelâ€™s reasoning efficiency. In practice, se-\n",
      "lective context assesses the information content of lexical units\n",
      "based on the self-information computed by the base language\n",
      "model. By retaining content with higher self-information, this\n",
      "method offers a more concise and efficient textual representa-\n",
      "tion, without compromising their performance across diverse\n",
      "applications. However, it overlooks the interdependence be-\n",
      "tween compressed content and the alignment between the\n",
      "targeted language model and the small language model utilized\n",
      "for prompting compression [48].\n",
      "LLM-Critique. Another straightforward and effective ap-\n",
      "proach involves having the LLM evaluate the retrieved content\n",
      "before generating the final answer. This allows the LLM\n",
      "to filter out documents with poor relevance through LLM\n",
      "critique. For instance, in Chatlaw [49], the LLM is prompted\n",
      "to self-suggestion on the referenced legal provisions to assess\n",
      "their relevance.\n",
      "E. Generation\n",
      "Utilize the LLM to generate answers based on the userâ€™s\n",
      "query and the retrieved contextual information. Select an\n",
      "appropriate model based on the task requirements, considering\n",
      "factors such as the need for fine-tuning, inference efficiency,\n",
      "and privacy protection.\n",
      "1) Generator Fine-tuning: In addition to direct LLM usage,\n",
      "targeted fine-tuning based on the scenario and data character-\n",
      "istics can yield better results. This is also one of the greatest\n",
      "advantages of using an on-premise setup LLMs.\n",
      "Instruct-Tuning. When LLMs lack data in a specific do-\n",
      "main, additional knowledge can be provided to the LLM\n",
      "through fine-tuning. General fine-tuning dataset can also be\n",
      "used as an initial step. Another benefit of fine-tuning is the\n",
      "ability to adjust the modelâ€™s input and output. For example, it\n",
      "can enable LLM to adapt to specific data formats and generate\n",
      "responses in a particular style as instructed [50].\n",
      "Reinforcement learning. Aligning LLM outputs with hu-\n",
      "man or retriever preferences through reinforcement learning is\n",
      "8\n",
      "a potential approach [51]. For instance, manually annotating\n",
      "the final generated answers and then providing feedback\n",
      "through reinforcement learning. In addition to aligning with\n",
      "human preferences, it is also possible to align with the\n",
      "preferences of fine-tuned models and retrievers.\n",
      "Dual Fine-tuing Fine-tuning both generator and retriever\n",
      "simultaneously to align their preferences. A typical approach,\n",
      "such as RA-DIT [27], aligns the scoring functions between\n",
      "retriever and generator using KL divergence. Retrieval likeli-\n",
      "hood of each retrieved document d is calculated as :\n",
      "PR(d|q) =\n",
      "e(sim(d,q))/Î³\n",
      "P\n",
      "dâˆˆDq e(sim(d,q)/Î³\n",
      "(15)\n",
      "PLM(y|d, q) is the LM probability of the ground truth output y\n",
      "given the input context d, question q, and Î³ is a hyperparamter.\n",
      "The overall loss is calculated as:\n",
      "L = 1\n",
      "|T|\n",
      "T\n",
      "X\n",
      "i=1\n",
      "KL(PR(d|q)||PLSR(d|q, y|))\n",
      "(16)\n",
      "2) Verification : Although RAG enhances the reliability\n",
      "of LLM-generated answers, in many scenarios, it requires to\n",
      "minimize the probability of hallucinations. Therefore, it can\n",
      "filter out responses that do not meet the required standards\n",
      "through additional verification module. Common verification\n",
      "methods include knowledge-base and model-base .\n",
      "yk = fverify(q, Dq, y)\n",
      "(17)\n",
      "Knowledge-base verification refers to directly validating the\n",
      "responses generated by LLMs through external knowledge.\n",
      "Generally, it extracts specific statements or triplets from re-\n",
      "sponse first. Then, relevant evidence is retrieved from verified\n",
      "knowledge base such as Wikipedia or specific knowledge\n",
      "graphs. Finally, each statement is incrementally compared with\n",
      "the evidence to determine whether the statement is supported,\n",
      "refuted, or if there is insufficient information [52].\n",
      "Model-based verification refers to using a small language\n",
      "model to verify the responses generated by LLMs [53].\n",
      "Given the input question, the retrieved knowledge, and the\n",
      "generated answer, a small language model is trained to de-\n",
      "termine whether the generated answer correctly reflects the\n",
      "retrieved knowledge. This process is framed as a multiple-\n",
      "choice question, where the verifier needs to judge whether the\n",
      "answer reflects correct answer . If the generated answer does\n",
      "not correctly reflect the retrieved knowledge, the answer can\n",
      "be iteratively regenerated until the verifier confirms that the\n",
      "answer is correct.\n",
      "F. Orchestration\n",
      "Orchestration pertains to the control modules that govern the\n",
      "RAG process. Unlike the traditional, rigid approach of a fixed\n",
      "process, RAG now incorporates decision-making at pivotal\n",
      "junctures and dynamically selects subsequent steps contingent\n",
      "upon the previous outcomes. This adaptive and modular ca-\n",
      "pability is a hallmark of modular RAG, distinguishing it from\n",
      "the more simplistic Naive and Advance RAG paradigm.\n",
      "1) Routing: In response to diverse queries, the RAG system\n",
      "routes to specific pipelines tailored for different scenario, a\n",
      "feature essential for a versatile RAG architecture designed\n",
      "to handle a wide array of situations. A decision-making\n",
      "mechanism is necessary to ascertain which modules will be\n",
      "engaged, based on the input from the model or supplementary\n",
      "metadata. Different routes are employed for distinct prompts\n",
      "or components. This routing mechanism is executed through\n",
      "a function, denoted as fr(Â·), which assigns a score Î±i to\n",
      "each module. These scores dictate the selection of the active\n",
      "subset of modules. Mathematically, the routing function is\n",
      "represented as:\n",
      "fr : Q â†’F\n",
      "(18)\n",
      "where fr(Â·) maps the identified query to its corresponding\n",
      "RAG flow.\n",
      "Metadata routing involves extracting key terms, or entities,\n",
      "from the query, applying a filtration process that uses these\n",
      "keywords and associated metadata within the chunks to refine\n",
      "the routing parameters. For a specific RAG flow, denoted as\n",
      "Fi, the pre-defined routing keywords are represented as the\n",
      "set Ki = {ki1, ki2, . . . , kin}. The keyword identified within\n",
      "the query qi is designated as Kâ€²\n",
      "i. The matching process for\n",
      "the query q is quantified by the key score equation:\n",
      "scorekey(qi, Fj) =\n",
      "1\n",
      "|Kâ€²\n",
      "j||Ki âˆ©Kâ€²\n",
      "j|\n",
      "(19)\n",
      "This equation calculates the overlap between the pre-defined\n",
      "keywords and those identified in the query, normalized by the\n",
      "count of keywords in Kâ€²\n",
      "j. The final step is to determine the\n",
      "most relevant flow for the query q:\n",
      "Fi(q) = argmaxFjâˆˆFscore(q, Fj)\n",
      "(20)\n",
      "Semantic routing routes to different modules based on the\n",
      "semantic information of the query. Given a pre-defined intent\n",
      "Î˜ = {Î¸1, Î¸2, . . . , Î¸n}, the possibility of intent for query q is\n",
      "PÎ˜(Î¸|q) =\n",
      "ePLM (Î¸|q)\n",
      "P\n",
      "Î¸âˆˆÎ˜ ePLM (Î¸|q)) . Routing to specific RAG flow is\n",
      "determined by the semantic score:\n",
      "socresemantic(q, Fj) = argmaxÎ¸jâˆˆÎ˜P(Î˜)\n",
      "(21)\n",
      "The function Î´(Â·) serves as a mapping function that assigns\n",
      "an intent to a distinct RAG flow Fi = Î´(Î¸i)\n",
      "Hybrid Routing can be implemented to improve query\n",
      "routing by integrating both semantic analysis and metadata-\n",
      "based approaches, which can be defined as follows:\n",
      "Î±i = aÂ·scorekey(q, Fj)+(1âˆ’Î±)Â·maxÎ¸jâˆˆÎ˜socresemantic(q, Fj)\n",
      "(22)\n",
      "a is a weighting factor that balances the contribution of the\n",
      "key-based score and the semantic score.\n",
      "2) Scheduling: The RAG system evolves in complexity\n",
      "and adaptability, with the ability to manage processes through\n",
      "a sophisticated scheduling module. The scheduling module\n",
      "plays a crucial role in the modular RAG , identifying critical\n",
      "junctures that require external data retrieval, assessing the\n",
      "adequacy of the responses, and deciding on the necessity for\n",
      "further investigation. It is commonly utilized in scenarios that\n",
      "involve recursive, iterative, and adaptive retrieval, ensuring\n",
      "9\n",
      "that the system makes informed decisions on when to cease\n",
      "generation or initiate a new retrieval loop.\n",
      "Rule judge. The subsequent steps are dictated by a set of\n",
      "established rules. Typically, the system evaluates the quality of\n",
      "generated answers through scoring mechanisms. The decision\n",
      "to proceed or halt the process is contingent upon whether these\n",
      "scores surpass certain predetermined thresholds, often related\n",
      "to the confidence levels of individual tokens, which can be\n",
      "defined as follow:\n",
      "yt =\n",
      "(\n",
      "Ë†st\n",
      "if all tokens of Ë†st have probs â‰¥Ï„\n",
      "st = LM([Dqt, x, y<t])\n",
      "otherwise\n",
      "Here, Ë†st represents the tentative answer, and st is the output\n",
      "from the language model. The condition for accepting Ë†st is that\n",
      "all tokens within it must have associated probabilities greater\n",
      "than or equal to the threshold Ï„. If this condition is not met,\n",
      "the system reverts to generating a new answer.\n",
      "LLM judge. The LLM independently determines the sub-\n",
      "sequent course of action. Two primary approaches facilitate\n",
      "this capability. The first method leverages LLM â€™s in-context\n",
      "learning capability, and make judgments through prompt\n",
      "engineering. A significant advantage of this method is the\n",
      "elimination of model fine-tuning. Nonetheless, the format of\n",
      "the judgment output is contingent upon the LLMâ€™s adherence\n",
      "to the provided instructions.\n",
      "The second approach involves the LLM generating specific\n",
      "tokens that initiate targeted actions through fine-tuning. This\n",
      "technique, with roots in the Toolformer [50], has been inte-\n",
      "grated into frameworks like Self-RAG [28]. This allows for a\n",
      "more direct control mechanism over the LLMâ€™s actions, en-\n",
      "hancing the systemâ€™s responsiveness to specific triggers within\n",
      "the conversational context. However, it requires generating a\n",
      "large number of compliant instruction sets to fine-tune LLM.\n",
      "Knowledge-guide scheduling. Beyond the confines of rule-\n",
      "based methods and the complete reliance on LLMs for process\n",
      "control, a more adaptable intermediate approach emerges with\n",
      "knowledge-guided scheduling [26]. These methods harness\n",
      "the power of knowledge graphs, to steer the retrieval and\n",
      "generation processes. Specifically, it involves extracting infor-\n",
      "mation relevant to the question from a knowledge graph and\n",
      "constructing a reasoning chain. This reasoning chain consists\n",
      "of a series of logically interconnected nodes, each containing\n",
      "critical information for the problem-solving process. Based\n",
      "on the information from the nodes in this reasoning chain,\n",
      "information retrieval and content generation can be performed\n",
      "separately. By integrating this approach, it enhance not only\n",
      "the efficacy and precision of problem-solving but also the\n",
      "clarity of the explanations provided.\n",
      "3) Fusion: As RAG process has evolved beyond a linear\n",
      "pipeline, it frequently necessitates broadening the retrieval\n",
      "scope or enhancing diversity by exploring multiple pipelines.\n",
      "Consequently, after the expansion into various branches, the\n",
      "fusion module effectively integrates the information, ensuring\n",
      "a comprehensive and coherent response. The fusion moduleâ€™s\n",
      "reliance is not just for merging answers but also for ensuring\n",
      "that the final output is both rich in content and reflective of\n",
      "the multifaceted nature of the inquiry.\n",
      "LLM fusion.One of the most straightforward methods for\n",
      "multi-branch aggregation is to leverage the powerful capa-\n",
      "bilities of LLMs to analyze and integrate information from\n",
      "different branches. However, this approach also faces some\n",
      "challenges, particularly when dealing with long answers that\n",
      "exceeds the LLMâ€™s context window limitation. To mitigate this\n",
      "issue, it is common practice to first summarize each branchâ€™s\n",
      "answer, extracting the key information before inputting it into\n",
      "the LLM, thus ensuring that the most important content is\n",
      "retained even within length constraints.\n",
      "Weighted ensemble\n",
      "is based on the weighted values of\n",
      "different tokens generated from multiple branches, leading to\n",
      "the comprehensive selection of the final output. This approach\n",
      "can be calculated as :\n",
      "p(y|q, Dq) =\n",
      "X\n",
      "dâˆˆDq\n",
      "p(y|d, q) Â· Î»(d, q)\n",
      "(23)\n",
      "The weight Î»(d, q) is determined by the similarity score\n",
      "between the document d and the input query q. This weight is\n",
      "calculated using the softmax function, which ensures that the\n",
      "weights are normalized and sum up to one.\n",
      "Î»(d, q) =\n",
      "es(d,q)\n",
      "P\n",
      "dâˆˆDq es(d,q)\n",
      "(24)\n",
      "RRF (Reciprocal Rank Fusion) is an ensemble technique\n",
      "that synthesizes multiple retrieval result rankings into a co-\n",
      "hesive, unified list [54]. It employs a tailored weighted aver-\n",
      "aging approach to enhance collective predictive performance\n",
      "and ranking precision. The methodâ€™s strength is its dynamic\n",
      "weight assignment, which is informed by the interplay among\n",
      "branches. RRF is especially potent in scenarios characterized\n",
      "by model or source heterogeneity, where it can markedly\n",
      "amplify the accuracy of predictions.\n",
      "V. RAG FLOW AND FLOW PATTERN\n",
      "The collaboration between operators forms the workflow\n",
      "of the module, which we refer to as RAG flow F\n",
      "=\n",
      "(MÏ•1, . . . , MÏ•n), where Ï• stands for the set of module param-\n",
      "eters. A modular rag flow can be decomposed into a graph of\n",
      "sub-functions. Through control logic, the operators can execute\n",
      "in a predetermined pipeline, while also performing conditional,\n",
      "branching or looping when necessary. In the simplest case. the\n",
      "graph is a linear chain.\n",
      "After conducting an in-depth analysis of current RAG meth-\n",
      "ods, we have identified a set of common RAG flow patterns,\n",
      "denoted as P. These patterns transcend various application\n",
      "domains and demonstrate a high level of consistency and\n",
      "reusability, revealing the prevalent structures and behaviors in\n",
      "process design. A RAG flow pattern can be defined as P =\n",
      "{MÏ•1 : {Op1} â†’MÏ•2 : {Op2} â†’. . . â†’MÏ•n : {Opn}}\n",
      "A. Linear Pattern\n",
      "The modules in the modular RAG system are organized in\n",
      "a linear way, and can be described as Algorithm 1.\n",
      "Plinear = {M1 â†’M2 â†’. . . â†’Mn}\n",
      "(25)\n",
      "10\n",
      "Fig. 4.\n",
      "Linear RAG flow pattern. Each module is processed in a fixed\n",
      "sequential order.\n",
      "Fig. 5. RRR [24] is a typical linear flow that introduces a learnable query\n",
      "rewrite module before retrieval. This module employs reinforcement based on\n",
      "the output results of the LLM.\n",
      "The linear flow pattern is the simplest and most com-\n",
      "monly used pattern. As shown in Figure 4, the full linear\n",
      "RAG flow pattern mainly includes pre-retrieval processing,\n",
      "retrieval, post-retrieval processing, and generation modules.\n",
      "Plinearfull\n",
      "= {Mindexing\n",
      "â†’Mpre-retrieval\n",
      "â†’Mretrieval\n",
      "â†’\n",
      "Mpost-retrieval â†’Mgenerate}. If there are no pre-retrieval and\n",
      "post-retrieval modules, it follows the Naive RAG paradigm.\n",
      "Algorithm 1 Linear RAG Flow Pattern\n",
      "Require: original query q, documents D, retriever R, lan-\n",
      "guage model LLM, pre-processing function fpre, post-\n",
      "processing function fpost\n",
      "Ensure: final output Ë†y\n",
      "1: Initialize:\n",
      "2: qâ€² â†fpre(q) // Pre-process the original query\n",
      "3: Dqâ€² â†R(qâ€², D) // Retrieve documents related to the pre-\n",
      "processed query\n",
      "4: Ë†Dqâ€² â†fpost(qâ€², Dqâ€²) // Post-process the retrieved docu-\n",
      "ments\n",
      "5: Ë†y â†LLM([q, Ë†Dqâ€²]) // Generate output using the lan-\n",
      "guage model with the original query and post-processed\n",
      "documents\n",
      "6: return Ë†y // Return the final output\n",
      "Common linear RAG flow involves a query transform\n",
      "module (such as rewrite or HyDE operators) at the pre-retrieval\n",
      "stage and utilize rerank at the post-retrieval stage. Rewrite-\n",
      "Retrieve-Read (RRR) [24] is a typical linear structure. As\n",
      "illustrated in Figure 5, the query rewrite module frewrite is a\n",
      "smaller trainable language model fine-tuned on T5-large, and\n",
      "in the context of reinforcement learning, the optimization of\n",
      "the rewriter is formalized as a Markov decision process, with\n",
      "the final output of the LLM serving as the reward. The retriever\n",
      "utilizes a sparse encoding model, BM25.\n",
      "B. Conditional Pattern\n",
      "The RAG flow with conditional structure involves select-\n",
      "ing different RAG pipeline based on different conditions,\n",
      "as illustrated in Figure 6. A detailed definition is shown in\n",
      "Algorithm 2. Typically, pipleline selection is accomplished\n",
      "Fig. 6. The conditional flow pattern. There is a routing module that controls\n",
      "which RAG flow the query is directed to. Typically, different flows are used for\n",
      "various configurations to meet the general requirements of the RAG system.\n",
      "Fig. 7.\n",
      "Pre-retrieval branching flow pattern.Each branch performs retrieval\n",
      "and generation separately, and then they are aggregated at the end.\n",
      "through a routing module that determines the next module\n",
      "in the flow.\n",
      "Pconditional = {Mi\n",
      "fr\n",
      "âˆ’â†’Mj âˆ¨Mk}\n",
      "(26)\n",
      "Where\n",
      "fr\n",
      "âˆ’â†’represents that based on routing function fr(Â·), the\n",
      "flow can go to module Mj or Mk.\n",
      "Algorithm 2 Conditional RAG Flow Pattern\n",
      "Require: original query q, documents D, language model\n",
      "LM, retriever R, routing function fr\n",
      "Ensure: final output Ë†y\n",
      "1: Initialize:\n",
      "2: qâ€² â†QueryTransform(q) // Pre-process the initial query\n",
      "if needed\n",
      "3: Dâ€² â†R(qâ€², D) // Retrieve or update documents related\n",
      "to the query\n",
      "4: Mnext â†fr(qâ€², Dâ€²) // Determine the next module using\n",
      "the routing function\n",
      "5: if Mnext = Mj then\n",
      "6:\n",
      "Ë†y â†Mj(qâ€², Dâ€²) // Execute module Mj\n",
      "7: else if Mnext = Mk then\n",
      "8:\n",
      "Ë†y â†Mk(qâ€², Dâ€²) Mk\n",
      "9: end if\n",
      "10: return Ë†y\n",
      "Pipeline selection is determined by the nature of the ques-\n",
      "tion, directing different flows tailored to specific scenarios. For\n",
      "example, the tolerance for responses generated by LLMs varies\n",
      "across questions related to serious issues, political matters,\n",
      "or entertainment topics. These routing flow often diverge in\n",
      "terms of retrieval sources, retrieval processes, configurations,\n",
      "models, and prompts.\n",
      "11\n",
      "Fig. 8. Post-retrieval branching flow pattern.Only one retrieval performed, and\n",
      "then generation is carried out separately for each retrieved document chunks,\n",
      "followed by aggregation.\n",
      "C. Branching\n",
      "In many cases, the RAG flow system may have multiple\n",
      "parallel running branches , usually to increase the diver-\n",
      "sity of generated results. Assuming multiple branches bi are\n",
      "generated in module B\n",
      "= Msplit(Â·) = {b1, b2, . . . , bm}.\n",
      "For each branch bi âˆˆB, the same or different RAG pro-\n",
      "cesses can be executed, passing through multiple processing\n",
      "modules {M1, M2, . . . , Mk} to obtain branch output result\n",
      "pi\n",
      "= Mik(. . . Mi2(Mi1(bi)) . . .). The results of multiple\n",
      "branches are aggregated using an aggregation function to\n",
      "obtain intermediate output results. Ë†O = Mmerge({pi | bi âˆˆ\n",
      "B}). However, aggregation is not necessarily the end of the\n",
      "RAG flow, as it can continue to connect to other modules,\n",
      "Mjn(. . . Mj2(Mj1( Ë†O)) . . .). For example, after aggregating\n",
      "multiple model responses, they can continue through a val-\n",
      "idation module. Therefore, the entire branch flow pattern can\n",
      "be represented as:\n",
      "Pbranch =Mjn(. . . Mj1(Mmerge({Mik\n",
      "(. . . Mi1(bi) . . .) | bi âˆˆMsplit(q)})) . . .)\n",
      "(27)\n",
      "Algorithm 3 Pre-retrieval Branching Flow Pattern\n",
      "Require: original query q, documents D, query expand mod-\n",
      "ule Mexpand, retriever Mretrieve, language model LLM,\n",
      "merge module Mmerge\n",
      "Ensure: final output Ë†y\n",
      "1: Initialize:\n",
      "2: Qâ€² â†Mexpand(q) // Expand the original query to multiple\n",
      "sub-queries\n",
      "3: for all qâ€²\n",
      "i âˆˆQâ€² do\n",
      "4:\n",
      "Dâ€²\n",
      "i â†Mretrieve(qâ€²\n",
      "i, D) // Retrieve documents for each\n",
      "sub-query\n",
      "5:\n",
      "Gi â†âˆ…// Initialize an empty set for generated results\n",
      "of the sub-query\n",
      "6:\n",
      "for all dâ€²\n",
      "ij âˆˆDâ€²\n",
      "i do\n",
      "7:\n",
      "yij â†LLM([qâ€²\n",
      "i, dâ€²\n",
      "ij]) // Generate results for each\n",
      "document of the sub-query\n",
      "8:\n",
      "Oi â†Oi âˆª{yij} // Add generated results to the set\n",
      "9:\n",
      "end for\n",
      "10:\n",
      "Ë†y â†Mmerge(Oi) // Merge generated results of the sub-\n",
      "query into the final result\n",
      "11: end for\n",
      "12: return Ë†y\n",
      "The RAG flow with a branching structure differs from\n",
      "the conditional approach in that it involves multiple parallel\n",
      "branches, as opposed to selecting one branch from multiple\n",
      "options in the conditional approach. Structurally, it can be\n",
      "categorized into two types, which are depicted in Figure 7\n",
      "and Figure 8.\n",
      "Pre-Retrieval Branching (Multi-Query, Parallel Retrieval).\n",
      "As shown in Algorithm 3, the process involves initially taking\n",
      "a query q and expanding it through a module Mexpand to gen-\n",
      "erate multiple sub-queries Qâ€². Each sub-query qâ€²\n",
      "i is then used\n",
      "to retrieve relevant documents via Mretrieve, forming document\n",
      "sets Dâ€²\n",
      "i. These document sets, along with the corresponding\n",
      "sub-queries, are fed into a generation module Mgenerate to\n",
      "produce a set of answers Gi. Ultimately, all these generated\n",
      "answers are combined using a merging module Mmerge to\n",
      "form the final result y. This entire flow can be mathematically\n",
      "represented as:\n",
      "Pbranchpre =Mmerge(qâ€²\n",
      "iâˆˆMexpand(q){Mgenerate(qâ€²\n",
      "i, dâ€²\n",
      "ij) |\n",
      "dâ€²\n",
      "ij âˆˆMretrieve(qâ€²\n",
      "i)})\n",
      "(28)\n",
      "Post-Retrieval Branching (Single Query, Parallel Genera-\n",
      "tion). As shown in Algorithm 4, in the post-retrieval branching\n",
      "pattern, the process starts with a single query q which is\n",
      "used to retrieve multiple document chunks through a retrieval\n",
      "module Mretrieve, resulting in a set of documents Dq. Each\n",
      "document dq\n",
      "i from this set is then independently processed by\n",
      "a generation module Mgenerate to produce a set of generated\n",
      "results G. These results are subsequently merged using a\n",
      "merge module Mmerge to form the final result y. The process\n",
      "can be succinctly represented as y = Mmerge(Oi), where Oi is\n",
      "the collection of all generated results from each document dq\n",
      "i\n",
      "in Dq. Therefore, the entire process can be represented as:\n",
      "Pbranchpost = Mmerge({Mgenerate(dq\n",
      "i ) | dq\n",
      "i âˆˆMretrieve(q)})\n",
      "(29)\n",
      "Algorithm 4 Post-retrieval Branching Flow Pattern\n",
      "Require: original query q, documents D, retriever R, lan-\n",
      "guage model LLM, merge module Mmerge\n",
      "Ensure: final output Ë†y\n",
      "1: Initialize:\n",
      "2: qâ€² â†fpre(q) // Pre-process the original query\n",
      "3: Dqâ€² â†R(qâ€², D) // Retrieve a set of documents based on\n",
      "the pre-processed query\n",
      "4: G â†âˆ…// Initialize an empty set to store generated results\n",
      "5: for all di âˆˆDqâ€² do\n",
      "6:\n",
      "yi â†LLM([q, di]) // Generate results independently\n",
      "for each document chunk using the language model\n",
      "7:\n",
      "Oi â†Oi âˆª{yi} // Add the generated result to the set\n",
      "of results\n",
      "8: end for\n",
      "9: Ë†y â†Mmerge(Oi) // Merge all generated results using the\n",
      "merge function\n",
      "10: return Ë†y\n",
      "REPLUG [55] embodies a classic post-retrieval branching\n",
      "structure, wherein the probability of each token is predicted\n",
      "for each branch. Through weighted possibility ensemble, the\n",
      "different branches are aggregated, and the final generation\n",
      "12\n",
      "Fig. 9. The RAG flow in REPLUG [55], which follows a typical post-retrieval\n",
      "branching pattern. Each retrieved chunks undergoes parallel generation, and\n",
      "then they are aggregated using a weighted probability ensemble.\n",
      "result is used to fine-tune the retriever, known as Contriever,\n",
      "through feedback.\n",
      "D. Loop Pattern\n",
      "The RAG flow with a loop structure, as an important char-\n",
      "acteristic of Modular RAG, involves interdependent retrieval\n",
      "and generation steps. It typically includes a scheduling module\n",
      "for flow control. The modular RAG system can be abstracted\n",
      "as a directed graph G = (V, E), where V is the set of vertices\n",
      "representing the various modules Mi in the system, and E is\n",
      "the set of edges representing the control flow or data flow be-\n",
      "tween modules. If there is a vertex sequence Mi1, Mi2, ..., Min\n",
      "such that Min can reach Mi1 (i.e., Min â†’Mi1), then this\n",
      "RAG system forms a loop. If Mj is the successor module of\n",
      "Mi and Mi decides whether to return to Mj or a previous\n",
      "module Mk through a Judge module, it can be represented\n",
      "as: Mi\n",
      "Judge\n",
      "âˆ’âˆ’âˆ’â†’Mj\n",
      "or\n",
      "Mi\n",
      "Judge\n",
      "âˆ’âˆ’âˆ’â†’Mk where Mk is the\n",
      "predecessor module of Mj. If Mi return to Mj, it can be\n",
      "represented as: âˆƒJudge(Mi, Mj)\n",
      "s.t.\n",
      "(Mi, Mj) âˆˆE\n",
      "and\n",
      "Judge(Mi, Mj) = true. If the Judge module not to return\n",
      "to any previous module, it can be represented as: âˆ€Mi âˆˆ\n",
      "V,\n",
      "Judge(Mi, Mj) = false for all Mj that are predecessors\n",
      "of Mi. Loop pattern can be further categorized into iterative,\n",
      "recursive, and adaptive (active) retrieval approaches.\n",
      "Iterative retrieval At times, a single retrieval and genera-\n",
      "tion may not effectively address complex questions requiring\n",
      "extensive knowledge. Therefore, an iterative approach can be\n",
      "used in RAG (see Algorithm 5), typically involving a fixed\n",
      "number of iterations for retrieval. At step t, given the query\n",
      "qt and the previous output sequence y<t = [y0, . . . , ytâˆ’1] ,\n",
      "iterations proceed under the condition that t is less than the\n",
      "maximum allowed iterations T. In each loop, it retrieves a\n",
      "document chunks Dtâˆ’1 using the last output ytâˆ’1 and the\n",
      "current query qt. Subsequently, a new output yt is generated.\n",
      "The continuation of the iteration is determined by a Judge\n",
      "module, which makes its decision based on the yt, y<t, qt,\n",
      "and the Dtâˆ’1.\n",
      "An\n",
      "exemplary\n",
      "case\n",
      "of\n",
      "iterative\n",
      "retrieval\n",
      "is\n",
      "ITER-\n",
      "RETGEN [56] (Figure 11), which iterates retrieval-augmented\n",
      "generation and generation-augmented retrieval. Retrieval-\n",
      "augmented generation outputs a response to a task input based\n",
      "on all retrieved knowledge. In each iteration, ITER-RETGEN\n",
      "leverages the model output from the previous iteration as a\n",
      "specific context to help retrieve more relevant knowledge.\n",
      "Fig. 10. Loop flow pattern. Typically, a RAG system performs multiple rounds\n",
      "of retrieval and generation. It can be categorized into three forms: iterative,\n",
      "recursive, and adaptive.\n",
      "Algorithm 5 Iterative RAG Flow Pattern\n",
      "Require: original query q, documents D, maximum iterative\n",
      "times T, language model LLM, retriever R, initial output\n",
      "y<1 = âˆ…\n",
      "Ensure: final output Ë†y\n",
      "1: Initialize:\n",
      "2: qt â†q // Initialize query for the first iteration\n",
      "3: y<1 â†âˆ…// Initialize previous outputs as empty\n",
      "4: t â†1 // Initialize iteration step\n",
      "5: while t â‰¤T do\n",
      "6:\n",
      "qt â†QueryTransform(y<tâˆ’1, qtâˆ’1) // Generate query\n",
      "based on previous output and original query\n",
      "7:\n",
      "Dt â†R(ytâˆ’1||qt, D) // Retrieve or update documents\n",
      "related to the current query\n",
      "8:\n",
      "yt â†LLM([y<tâˆ’1, qt, Dt]) // Generate output using\n",
      "the language model\n",
      "9:\n",
      "y<t â†[y<tâˆ’1, yt] // Update the list of previous outputs\n",
      "10:\n",
      "if Judge(yt, q) = false then\n",
      "11:\n",
      "break\n",
      "12:\n",
      "end if\n",
      "13:\n",
      "t â†t + 1 // Increment iteration step\n",
      "14: end while\n",
      "15: yfinal = synthesizeOutput(yâ‰¤t) // Synthesize final output\n",
      "from the list of outputs\n",
      "16: return Ë†y\n",
      "13\n",
      "Fig. 11. ITER-RETGEN [56] is a typical iterative structure. Multiple rounds\n",
      "of retrieval and generation are performed within the limit of the maximum\n",
      "number of iterations.\n",
      "Termination of the loop is determined by a predefined number\n",
      "of iterations.\n",
      "Recursive retrieval The characteristic feature of recursive\n",
      "retrieval (see Algorithm 6), as opposed to iterative retrieval, is\n",
      "its clear dependency on the previous step and its continuous\n",
      "deepening of retrieval. Typically, it follows a tree-like structure\n",
      "and there is a clear termination mechanism as an exit condition\n",
      "for recursive retrieval. In RAG systems, recursive retrieval usu-\n",
      "ally involves query transform, relying on the newly rewritten\n",
      "query for each retrieval.\n",
      "Algorithm 6 Recursive RAG Flow Pattern\n",
      "Require: initial query q, document D, retriever R, language\n",
      "model LM, maximum recursive depth Kmax\n",
      "Ensure: final output Ë†y\n",
      "1: Initialize:\n",
      "2:\n",
      "Q â†{q}\n",
      "3:\n",
      "k â†0 // Initialize recursion depth\n",
      "4: while Q Ì¸= âˆ…and k < Kmax do\n",
      "5:\n",
      "Qâ€² â†âˆ…// To store queries for the next recursion level\n",
      "6:\n",
      "for all q âˆˆQ do\n",
      "7:\n",
      "Dq â†R(q, D) // Retrieve or update documents\n",
      "related to the current query\n",
      "8:\n",
      "Y\n",
      "â†LM([q, Dq]) // Generate outputs using the\n",
      "language model\n",
      "9:\n",
      "Qâ€²â€² â†deriveNewQueries(q, Dq, Y ) // Derive new\n",
      "queries from generated outputs\n",
      "10:\n",
      "for all qâ€² âˆˆQâ€²â€² do\n",
      "11:\n",
      "if qâ€² /âˆˆQâ€² and qâ€² /âˆˆQ then\n",
      "12:\n",
      "Qâ€² â†Qâ€² âˆª{qâ€²}\n",
      "13:\n",
      "end if\n",
      "14:\n",
      "end for\n",
      "15:\n",
      "end for\n",
      "16:\n",
      "Q â†Qâ€² // Update the set of queries for the next\n",
      "recursion\n",
      "17:\n",
      "k â†k + 1 // Increment recursion depth\n",
      "18: end while\n",
      "19: Ë†y = synthesizeOutput(Y ) // Synthesize final output from\n",
      "generated outputs\n",
      "20: return Ë†y\n",
      "A typical implementation of recursive retrieval, such as\n",
      "ToC [13] (see Figure 12 ), involves recursively executing RAC\n",
      "(Recursive Augmented Clarification) to gradually insert sub-\n",
      "nodes into the clarification tree from the initial ambiguous\n",
      "question (AQ). At each expansion step, paragraph re-ranking\n",
      "is performed based on the current query to generate a disam-\n",
      "Fig. 12.\n",
      "RAG flow of ToC [13]. A typical characteristic of this process is\n",
      "that each recursive retrieval uses the new query generated from the previous\n",
      "step, thereby progressively deepening analysis of the original complex query.\n",
      "biguous Question (DQ). The exploration of the tree concludes\n",
      "upon reaching the maximum number of valid nodes or the\n",
      "maximum depth. Once the clarification tree is constructed,\n",
      "ToC gathers all valid nodes and generates a comprehensive\n",
      "long-text answer to address AQ.\n",
      "Adaptive (Active) retrieval With the advancement of RAG,\n",
      "there has been a gradual shift beyond passive retrieval to the\n",
      "emergence of adaptive retrieval (see Algorithm 7) , also known\n",
      "as active retrieval, which is partly attributed to the powerful\n",
      "capabilities of LLM. This shares a core concept with LLM\n",
      "Agent [57]. RAG systems can actively determine the timing\n",
      "of retrieval and decide when to conclude the entire process and\n",
      "produce the final result. Based on the criteria for judgment,\n",
      "this can be further categorized into Prompt-base and Tuning-\n",
      "base approaches.\n",
      "Algorithm 7 Active RAG Flow Pattern\n",
      "Require: original query Q, documents D, maximum iterative\n",
      "times T, language model LLM, retriever R\n",
      "Ensure: final output Ë†y\n",
      "1: Initialize:\n",
      "2: t â†1 // Initialize loop step\n",
      "3: qt â†q // Initialize query for the first iteration\n",
      "4: y<1 â†âˆ…// Initialize previous outputs as empty\n",
      "5: while t â‰¤T do\n",
      "6:\n",
      "Qt â†QueryTransform(y<tâˆ’1, qtâˆ’1) // Derive new\n",
      "query from previous output and query\n",
      "7:\n",
      "if Evaluate(Qt, y<tâˆ’1) then\n",
      "8:\n",
      "Dt â†R(qt, D) // Retrieve documents based on the\n",
      "new query\n",
      "9:\n",
      "yt â†LLM([qt, Dt]) // Generate output using the\n",
      "language model\n",
      "10:\n",
      "else\n",
      "11:\n",
      "yt â†âˆ…// Set output as empty if query evaluation is\n",
      "false\n",
      "12:\n",
      "end if\n",
      "13:\n",
      "y<t â†[y<tâˆ’1, yt] // Update the list of previous outputs\n",
      "14:\n",
      "if isOutputAcceptable(yt, y<t, qt) = false then\n",
      "15:\n",
      "break // Break if the output is not acceptable\n",
      "16:\n",
      "end if\n",
      "17:\n",
      "t â†t + 1 // Increment iteration step\n",
      "18: end while\n",
      "19: Ë†y = synthesizeOutput(yâ‰¤t) // Synthesize final output from\n",
      "the list of outputs\n",
      "20: return Ë†y\n",
      "Prompt-base. The prompt-base approach involves control-\n",
      "ling the flow using Prompt Engineering to direct LLM. A\n",
      "14\n",
      "Fig. 13. RAG flow of FLARE [14]. The generated provisional answer will\n",
      "undergo confidence assessment. If it does not meet the required confidence\n",
      "level, the process will return to the retrieval stage and generate anew. The\n",
      "assessment criteria are implemented through prompt\n",
      "Fig. 14.\n",
      "RAG flow of SELF-RAG [28]. First, it prompt GPT-4 to obtain\n",
      "a suitable instruct fine-tuning dataset to fine-tune the deployed open-source\n",
      "LLM. This allows the model to output four specific tokens during generation,\n",
      "which are used to control the RAG process.\n",
      "typical implementation example is FLARE [14]. Its core\n",
      "concept is that LLMs should only retrieve when essential\n",
      "knowledge is lacking, to avoid unnecessary or inappropriate\n",
      "retrieval in an enhanced LM. FLARE iteratively generates the\n",
      "next provisional sentence and checks for the presence of low-\n",
      "probability tokens. If found, the system retrieves relevant docu-\n",
      "ments and regenerates the sentence. Tuning-base. The tuning-\n",
      "based approach involves fine-tuning LLM to generate special\n",
      "tokens, thereby triggering retrieval or generation. This concept\n",
      "can be traced back to Toolformer [50], where the generation of\n",
      "specific content assists in invoking tools. In RAG systems, this\n",
      "approach is used to control both retrieval and generation steps.\n",
      "A typical case is Self-RAG [28](see Figure 14). Given an\n",
      "input prompt and the preceding generation result, first predict\n",
      "whether the special token Retrieve is helpful for enhancing\n",
      "the continued generation through retrieval. Then, if retrieval\n",
      "is needed, the model generates a critique token to evaluate the\n",
      "retrieved passageâ€™s relevance. and a critique token to evaluate\n",
      "if the information in the response is supported by the retrieved\n",
      "passage. Finally, a critique token evaluates the overall utility of\n",
      "the response and selects the optimal result as the final output.\n",
      "E. Tuning Pattern\n",
      "RAG is continuously integrating with more LLM-related\n",
      "technologies. In Modular RAG, many components are com-\n",
      "posed of trainable language models. Through fine-tuning, the\n",
      "performance of the components and the compatibility with\n",
      "the overall flow can be further optimized. This section will\n",
      "introduce three main patterns of fine-tuning stages, namely\n",
      "retriever fine-tuning, generator fine-tuning, and dual fine-\n",
      "tuning.\n",
      "Fig. 15.\n",
      "Retriever fine-tuning pattern, mainly includes direct SFT, adding\n",
      "trainable adapter, LM-supervised retrieval and LLM Reward RL.\n",
      "1) Retriever FT: In the RAG flow, common methods for\n",
      "fine-tuning the retriever is shown in Figure 15 ,which include:\n",
      "â€¢ Direct supervised fine-tuning of the retriever. Construct-\n",
      "ing a specialized dataset for retrieval and fine-tuning the\n",
      "dense retriever. For example, using open-source retrieval\n",
      "datasets or constructing one based on domain-specific\n",
      "data.\n",
      "â€¢ Adding trainable adapter modules. Sometimes, direct\n",
      "fine-tuning of the API-base embedding model (e.g., Ope-\n",
      "nAI Ada-002 and Cohere) is not feasible. Incorporating\n",
      "an adapter module can enhance the representation of\n",
      "your data. Additionally, the adapter module facilitates\n",
      "better alignment with downstream tasks, whether for task-\n",
      "specific (e.g., PRCA [42]) or general purposes (e.g.,\n",
      "AAR [58]).\n",
      "â€¢ LM-supervised Retrieval (LSR). Fine-tuning the retriever\n",
      "based on the results generated by LLM.\n",
      "â€¢ LLM Reward RL. Still using the LLM output results as\n",
      "the supervisory signal. Employing reinforcement learning\n",
      "to align the retriever with the generator. The whole re-\n",
      "trieval process is disassembled in the form of a generative\n",
      "Markov chain.\n",
      "2) Generator FT: The primary methods for fine-tuning a\n",
      "generator in RAG flow is shown in Figure 16, which include:\n",
      "â€¢ Direct supervised fine-tuning. Fine-tuning through an\n",
      "external dataset can supplement the generator with ad-\n",
      "ditional knowledge. Another benefit is the ability to\n",
      "customize input and output formats. By setting the Q&A\n",
      "format, LLM can understand specific data formats and\n",
      "output according to instructions.\n",
      "â€¢ Distillation. When using on-premise deployment of open-\n",
      "source models, a simple and effective Optimization\n",
      "method is to use GPT-4 to batch construct fine-tuning\n",
      "data to enhance the capabilities of the open-source model.\n",
      "â€¢ RL from LLM/human feedback. Reinforcement learning\n",
      "based on feedback from the final generated answers. In\n",
      "addition to using human evaluations, powerful LLMs can\n",
      "also serve as an evaluative judge.\n",
      "3) Dual FT: In the RAG system, fine-tuning both the\n",
      "retriever and the generator simultaneously is a unique feature\n",
      "of the RAG system. It is important to note that the emphasis\n",
      "of system fine-tuning is on the coordination between the\n",
      "retriever and the generator. An exemplary implementation is\n",
      "RA-DIT [27], which fine-tunes both the LLM and the retriever.\n",
      "The LM-ft component updates the LLM to maximize the\n",
      "15\n",
      "Fig. 16.\n",
      "Generator fine-tuning pattern, The main methods include SFT,\n",
      "distillation and RL from LLM/human feedback.\n",
      "Fig. 17.\n",
      "Dual fine-tuning pattern. In this mode, both the retriever and\n",
      "generator participate in fine-tuning, and their preferences will be aligned.\n",
      "likelihood of the correct answer given the retrieval-augmented\n",
      "instructions while the R-ft component updates the retriever\n",
      "to minimize the KL-Divergence between the retriever score\n",
      "distribution and the LLM preference.\n",
      "VI. DISCUSSION\n",
      "In this chapter, we explore the innovative horizons opened\n",
      "by the modular RAG paradigm. We examine its compatibility\n",
      "with cutting-edge methodologies in the progression of RAG\n",
      "technology, emphasizing its scalability. It not only fosters a\n",
      "fertile ground for model innovation but also paves the way for\n",
      "seamless adaptation to the dynamic requirements of various\n",
      "applications.\n",
      "A. Opportunities in Modular RAG\n",
      "The benefits of Modular RAG are evident, providing a\n",
      "fresh and comprehensive perspective on existing RAG-related\n",
      "work. Through modular organization, relevant technologies\n",
      "and methods are clearly summarized.\n",
      "From a research perspective. Modular RAG is highly\n",
      "scalable, it empowers researchers to introduce innovative mod-\n",
      "ules and operators, leveraging a deep understanding of RAGâ€™s\n",
      "evolving landscape. This flexibility enables the exploration of\n",
      "new theoretical and practical dimensions in the field.\n",
      "From an application perspective. The modularity of RAG\n",
      "systems simplifies their design and implementation. Users can\n",
      "tailor RAG flows to fit their specific data, use cases, and\n",
      "downstream tasks, enhancing the adaptability of the system\n",
      "to diverse requirements. Developers can draw from existing\n",
      "flow architectures and innovate by defining new flows and\n",
      "patterns that are tailored to various application contexts and\n",
      "domains. This approach not only streamlines the development\n",
      "process but also enriches the functionality and versatility of\n",
      "RAG applications.\n",
      "B. Compatibility with new methods\n",
      "Modular RAG paradigm demonstrates exceptional compati-\n",
      "bility with new developments. To gain a deeper understanding\n",
      "of this, we list three typical scalability cases, which clearly\n",
      "shows that Modular RAG paradigm provides robust support\n",
      "and flexibility for the innovation and development of RAG\n",
      "technology.\n",
      "1) Recombination of the current modules: In this scenario,\n",
      "no new modules or operators are proposed; rather, specific\n",
      "problems are addressed through the combination of existing\n",
      "modules.DR-RAG [59] employs a two-stage retrieval strategy\n",
      "and classifier selection mechanism, incorporating a branching\n",
      "retrieval structure. In the first stage, retrieving chunks relevant\n",
      "to the query. In the second stage, the query is combined\n",
      "individually with each chunk retrieved in the first stage, and a\n",
      "parallel secondary retrieval is conducted. The retrieved content\n",
      "is then input into a classifier to filter out the most relevant\n",
      "dynamic documents. This ensures that the retrieved documents\n",
      "are highly relevant to the query while reducing redundant\n",
      "information. DR-RAG improved retrieval method significantly\n",
      "enhances the accuracy and efficiency of answers, bolstering\n",
      "RAGâ€™s performance in multi-hop question-answering scenar-\n",
      "ios.\n",
      "2) New flow without adding new operators.: This refers\n",
      "to redesigning the processes for retrieval and generation to\n",
      "address more complex scenarios without proposing new mod-\n",
      "ules. The core idea of PlanRAG [18] lies in its introduction of\n",
      "a preliminary planning stage, a crucial step that occurs before\n",
      "retrieval and generation. Initially, the system employs a judge\n",
      "module to assess whether the current context necessitates the\n",
      "formulation of a new plan or adjustments to an existing one.\n",
      "When encountering a problem for the first time, the system\n",
      "initiates the planning process, while in subsequent interactions,\n",
      "it decides whether to execute re-planning based on previous\n",
      "plans and retrieved data.\n",
      "Next, the system devises an execution plan tailored to the\n",
      "query, treating this process as a logical decomposition of\n",
      "complex queries. Specifically, PlanRAG uses a query expan-\n",
      "sion module to extend and refine the query. For each derived\n",
      "sub-query, the system conducts targeted retrieval. Following\n",
      "retrieval, another judge module evaluates the current results to\n",
      "decide whether further retrieval is required or if it should return\n",
      "to the planning stage for re-planning. Through this strategy,\n",
      "PlanRAG is able to handle complex decision-making problems\n",
      "that require multi-step data analysis more efficiently.\n",
      "3) New flow derived from new operators.: New operators\n",
      "often introduce novel flow design, exemplified by Multi-Head\n",
      "RAG [60]. Existing RAG solutions do not focus on queries that\n",
      "may require retrieving multiple documents with significantly\n",
      "different content. Such queries are common but difficult to\n",
      "handle because embeddings of these documents may be far\n",
      "apart in the embedding space. Multi-Head RAG addresses this\n",
      "by designing a new retriever that uses the activations of the\n",
      "multi-head attention layers of the Transformer, rather than the\n",
      "decoder layers, as keys for retrieving multifaceted documents.\n",
      "Different attention heads can learn to capture different aspects\n",
      "of the data. By using the corresponding activation results,\n",
      "embeddings that represent different aspects of the data items\n",
      "and the query can be generated, thereby enhancing the retrieval\n",
      "accuracy for complex queries.\n",
      "16\n",
      "VII. CONCLUSION\n",
      "RAG is emerging as a pivotal technology for LLM applica-\n",
      "tions. As technological landscapes evolve and the intricacies of\n",
      "application requirements escalate, RAG systems are being en-\n",
      "hanced by integrating a diverse suite of technologies, thereby\n",
      "achieving a higher level of complexity and functionality. This\n",
      "paper introduces the innovative paradigm of Modular RAG.\n",
      "This approach systematically disassembles the complex archi-\n",
      "tecture of RAG systems into well-defined, discrete functional\n",
      "modules. Each module is meticulously characterized by its\n",
      "specific operational functions, ensuring clarity and precision.\n",
      "Therefore, the entire system is composed of those modules\n",
      "and operators, akin to Lego bricks. By conducting an in-\n",
      "depth analysis of numerous studies, the paper also distills\n",
      "common RAG design patterns and scrutinizes key case studies\n",
      "to illustrate these patterns in practice.\n",
      "Modular RAG not only offers a structured framework for\n",
      "the design and application of RAG systems but also en-\n",
      "ables a scenario-based customization of these systems. The\n",
      "modularity inherent in this design facilitates ease of tracking\n",
      "and debugging, significantly enhancing the maintainability and\n",
      "scalability of RAG systems. Furthermore, Modular RAG opens\n",
      "up new avenues for the future progression of RAG technology.\n",
      "It encourages the innovation of novel functional modules and\n",
      "the crafting of innovative workflows, thereby driving forward\n",
      "the frontiers of RAG systems.\n",
      "REFERENCES\n",
      "[1] Y. Zhang, Y. Li, L. Cui, D. Cai, L. Liu, T. Fu, X. Huang, E. Zhao,\n",
      "Y. Zhang, Y. Chen et al., â€œSirenâ€™s song in the ai ocean: A survey on hal-\n",
      "lucination in large language models,â€ arXiv preprint arXiv:2309.01219,\n",
      "2023.\n",
      "[2] Y. Gao, Y. Xiong, X. Gao, K. Jia, J. Pan, Y. Bi, Y. Dai, J. Sun, and\n",
      "H. Wang, â€œRetrieval-augmented generation for large language models:\n",
      "A survey,â€ arXiv preprint arXiv:2312.10997, 2023.\n",
      "[3] Z. Xu, M. J. Cruz, M. Guevara, T. Wang, M. Deshpande, X. Wang,\n",
      "and Z. Li, â€œRetrieval-augmented generation with knowledge graphs\n",
      "for customer service question answering,â€ in Proceedings of the 47th\n",
      "International ACM SIGIR Conference on Research and Development in\n",
      "Information Retrieval, 2024, pp. 2905â€“2909.\n",
      "[4] C. Zhang, S. Wu, H. Zhang, T. Xu, Y. Gao, Y. Hu, and E. Chen,\n",
      "â€œNotellm: A retrievable large language model for note recommendation,â€\n",
      "in Companion Proceedings of the ACM on Web Conference 2024, 2024,\n",
      "pp. 170â€“179.\n",
      "[5] R. Anantha, T. Bethi, D. Vodianik, and S. Chappidi, â€œContext tuning\n",
      "for retrieval augmented generation,â€ arXiv preprint arXiv:2312.05708,\n",
      "2023.\n",
      "[6] Y. Gao, T. Sheng, Y. Xiang, Y. Xiong, H. Wang, and J. Zhang, â€œChat-\n",
      "rec: Towards interactive and explainable llms-augmented recommender\n",
      "system,â€ arXiv preprint arXiv:2303.14524, 2023.\n",
      "[7] J. Liu, â€œBuilding production-ready rag applications,â€ https://www.ai.\n",
      "engineer/summit/schedule/building-production-ready-rag-applications,\n",
      "2023.\n",
      "[8] D. S. Asudani, N. K. Nagwani, and P. Singh, â€œImpact of word embedding\n",
      "models on text analytics in deep learning environment: a review,â€\n",
      "Artificial intelligence review, vol. 56, no. 9, pp. 10 345â€“10 425, 2023.\n",
      "[9] F. Cuconasu, G. Trappolini, F. Siciliano, S. Filice, C. Campagnano,\n",
      "Y. Maarek, N. Tonellotto, and F. Silvestri, â€œThe power of noise:\n",
      "Redefining retrieval for rag systems,â€ arXiv preprint arXiv:2401.14887,\n",
      "2024.\n",
      "[10] W. Peng, G. Li, Y. Jiang, Z. Wang, D. Ou, X. Zeng, E. Chen et al.,\n",
      "â€œLarge language model based long-tail query rewriting in taobao search,â€\n",
      "arXiv preprint arXiv:2311.03758, 2023.\n",
      "[11] Y. Xi, J. Lin, W. Liu, X. Dai, W. Zhang, R. Zhang, R. Tang, and\n",
      "Y. Yu, â€œA birdâ€™s-eye view of reranking: from list level to page level,â€\n",
      "in Proceedings of the Sixteenth ACM International Conference on Web\n",
      "Search and Data Mining, 2023, pp. 1075â€“1083.\n",
      "[12] Z. Feng, X. Feng, D. Zhao, M. Yang, and B. Qin, â€œRetrieval-\n",
      "generation synergy augmented large language models,â€ arXiv preprint\n",
      "arXiv:2310.05149, 2023.\n",
      "[13] G. Kim, S. Kim, B. Jeon, J. Park, and J. Kang, â€œTree of clarifica-\n",
      "tions: Answering ambiguous questions with retrieval-augmented large\n",
      "language models,â€ arXiv preprint arXiv:2310.14696, 2023.\n",
      "[14] Z. Jiang, F. F. Xu, L. Gao, Z. Sun, Q. Liu, J. Dwivedi-Yu, Y. Yang,\n",
      "J. Callan, and G. Neubig, â€œActive retrieval augmented generation,â€ arXiv\n",
      "preprint arXiv:2305.06983, 2023.\n",
      "[15] D. Edge, H. Trinh, N. Cheng, J. Bradley, A. Chao, A. Mody, S. Truitt,\n",
      "and J. Larson, â€œFrom local to global: A graph rag approach to query-\n",
      "focused summarization,â€ arXiv preprint arXiv:2404.16130, 2024.\n",
      "[16] Q. Leng, K. Uhlenhuth, and A. Polyzotis, â€œBest practices for\n",
      "llm evaluation of rag applications,â€ https://www.databricks.com/blog/\n",
      "LLM-auto-eval-best-practices-RAG, 2023.\n",
      "[17] X. Wang, Z. Wang, X. Gao, F. Zhang, Y. Wu, Z. Xu, T. Shi, Z. Wang,\n",
      "S. Li, Q. Qian et al., â€œSearching for best practices in retrieval-augmented\n",
      "generation,â€ arXiv preprint arXiv:2407.01219, 2024.\n",
      "[18] M. Lee, S. An, and M.-S. Kim, â€œPlanrag: A plan-then-retrieval aug-\n",
      "mented generation for generative large language models as decision\n",
      "makers,â€ arXiv preprint arXiv:2406.12430, 2024.\n",
      "[19] D. Arora, A. Kini, S. R. Chowdhury, N. Natarajan, G. Sinha, and\n",
      "A. Sharma, â€œGar-meets-rag paradigm for zero-shot information re-\n",
      "trieval,â€ arXiv preprint arXiv:2310.20158, 2023.\n",
      "[20] P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal,\n",
      "H. KÂ¨uttler, M. Lewis, W.-t. Yih, T. RocktÂ¨aschel et al., â€œRetrieval-\n",
      "augmented generation for knowledge-intensive nlp tasks,â€ Advances in\n",
      "Neural Information Processing Systems, vol. 33, pp. 9459â€“9474, 2020.\n",
      "[21] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Milli-\n",
      "can, G. B. Van Den Driessche, J.-B. Lespiau, B. Damoc, A. Clark et al.,\n",
      "â€œImproving language models by retrieving from trillions of tokens,â€ in\n",
      "International conference on machine learning. PMLR, 2022, pp. 2206â€“\n",
      "2240.\n",
      "[22] G. Izacard, P. Lewis, M. Lomeli, L. Hosseini, F. Petroni, T. Schick,\n",
      "J. Dwivedi-Yu, A. Joulin, S. Riedel, and E. Grave, â€œFew-shot\n",
      "learning with retrieval augmented language models,â€ arXiv preprint\n",
      "arXiv:2208.03299, 2022.\n",
      "[23] H. Trivedi, N. Balasubramanian, T. Khot, and A. Sabharwal, â€œInterleav-\n",
      "ing retrieval with chain-of-thought reasoning for knowledge-intensive\n",
      "multi-step questions,â€ arXiv preprint arXiv:2212.10509, 2022.\n",
      "[24] X. Ma, Y. Gong, P. He, H. Zhao, and N. Duan, â€œQuery rewrit-\n",
      "ing for retrieval-augmented large language models,â€ arXiv preprint\n",
      "arXiv:2305.14283, 2023.\n",
      "[25] N. Anderson, C. Wilson, and S. D. Richardson, â€œLingua: Addressing\n",
      "scenarios for live interpretation and automatic dubbing,â€ in Proceedings\n",
      "of the 15th Biennial Conference of the Association for Machine\n",
      "Translation in the Americas (Volume 2: Users and Providers Track and\n",
      "Government Track), J. Campbell, S. Larocca, J. Marciano, K. Savenkov,\n",
      "and A. Yanishevsky, Eds.\n",
      "Orlando, USA: Association for Machine\n",
      "Translation in the Americas, Sep. 2022, pp. 202â€“209. [Online].\n",
      "Available: https://aclanthology.org/2022.amta-upg.14\n",
      "[26] L. Luo, Y.-F. Li, G. Haffari, and S. Pan, â€œReasoning on graphs: Faith-\n",
      "ful and interpretable large language model reasoning,â€ arXiv preprint\n",
      "arXiv:2310.01061, 2023.\n",
      "[27] X. V. Lin, X. Chen, M. Chen, W. Shi, M. Lomeli, R. James, P. Rodriguez,\n",
      "J. Kahn, G. Szilvasy, M. Lewis et al., â€œRa-dit: Retrieval-augmented dual\n",
      "instruction tuning,â€ arXiv preprint arXiv:2310.01352, 2023.\n",
      "[28] A. Asai, Z. Wu, Y. Wang, A. Sil, and H. Hajishirzi, â€œSelf-rag: Learning\n",
      "to retrieve, generate, and critique through self-reflection,â€ arXiv preprint\n",
      "arXiv:2310.11511, 2023.\n",
      "[29] Y. Huang and J. Huang, â€œA survey on retrieval-augmented text gen-\n",
      "eration for large language models,â€ arXiv preprint arXiv:2404.10981,\n",
      "2024.\n",
      "[30] Y. Hu and Y. Lu, â€œRag and rau: A survey on retrieval-augmented\n",
      "language model in natural language processing,â€ arXiv preprint\n",
      "arXiv:2404.19543, 2024.\n",
      "[31] Y. Ding, W. Fan, L. Ning, S. Wang, H. Li, D. Yin, T.-S. Chua, and\n",
      "Q. Li, â€œA survey on rag meets llms: Towards retrieval-augmented large\n",
      "language models,â€ arXiv preprint arXiv:2405.06211, 2024.\n",
      "[32] P. Zhao, H. Zhang, Q. Yu, Z. Wang, Y. Geng, F. Fu, L. Yang, W. Zhang,\n",
      "and B. Cui, â€œRetrieval-augmented generation for ai-generated content:\n",
      "A survey,â€ arXiv preprint arXiv:2402.19473, 2024.\n",
      "[33] S.\n",
      "Yang,\n",
      "â€œAdvanced\n",
      "rag\n",
      "01:\n",
      "Small-to-\n",
      "big\n",
      "retrieval,â€\n",
      "https://towardsdatascience.com/\n",
      "advanced-rag-01-small-to-big-retrieval-172181b396d4, 2023.\n",
      "17\n",
      "[34] Y. Wang, N. Lipka, R. A. Rossi, A. Siu, R. Zhang, and T. Derr,\n",
      "â€œKnowledge graph prompting for multi-document question answering,â€\n",
      "arXiv preprint arXiv:2308.11730, 2023.\n",
      "[35] D. Zhou, N. SchÂ¨arli, L. Hou, J. Wei, N. Scales, X. Wang, D. Schu-\n",
      "urmans, C. Cui, O. Bousquet, Q. Le et al., â€œLeast-to-most prompting\n",
      "enables complex reasoning in large language models,â€ arXiv preprint\n",
      "arXiv:2205.10625, 2022.\n",
      "[36] S. Dhuliawala, M. Komeili, J. Xu, R. Raileanu, X. Li, A. Celikyilmaz,\n",
      "and J. Weston, â€œChain-of-verification reduces hallucination in large\n",
      "language models,â€ arXiv preprint arXiv:2309.11495, 2023.\n",
      "[37] L. Gao, X. Ma, J. Lin, and J. Callan, â€œPrecise zero-shot dense retrieval\n",
      "without relevance labels,â€ arXiv preprint arXiv:2212.10496, 2022.\n",
      "[38] H. S. Zheng, S. Mishra, X. Chen, H.-T. Cheng, E. H. Chi, Q. V. Le,\n",
      "and D. Zhou, â€œTake a step back: Evoking reasoning via abstraction in\n",
      "large language models,â€ arXiv preprint arXiv:2310.06117, 2023.\n",
      "[39] H. Cao, â€œRecent advances in text embedding: A comprehensive review\n",
      "of top-performing methods on the mteb benchmark,â€ arXiv preprint\n",
      "arXiv:2406.01607, 2024.\n",
      "[40] BAAI, â€œFlagembedding,â€ https://github.com/FlagOpen/FlagEmbedding,\n",
      "2023.\n",
      "[41] Z. Li, X. Zhang, Y. Zhang, D. Long, P. Xie, and M. Zhang, â€œTowards\n",
      "general text embeddings with multi-stage contrastive learning,â€ arXiv\n",
      "preprint arXiv:2308.03281, 2023.\n",
      "[42] H. Yang, Z. Li, Y. Zhang, J. Wang, N. Cheng, M. Li, and J. Xiao,\n",
      "â€œPrca: Fitting black-box large language models for retrieval question an-\n",
      "swering via pluggable reward-driven contextual adapter,â€ arXiv preprint\n",
      "arXiv:2310.18347, 2023.\n",
      "[43] N. F. Liu, K. Lin, J. Hewitt, A. Paranjape, M. Bevilacqua, F. Petroni, and\n",
      "P. Liang, â€œLost in the middle: How language models use long contexts,â€\n",
      "arXiv preprint arXiv:2307.03172, 2023.\n",
      "[44] Y. Lyu, Z. Li, S. Niu, F. Xiong, B. Tang, W. Wang, H. Wu, H. Liu,\n",
      "T. Xu, and E. Chen, â€œCrud-rag: A comprehensive chinese benchmark\n",
      "for retrieval-augmented generation of large language models,â€ arXiv\n",
      "preprint arXiv:2401.17043, 2024.\n",
      "[45] L. Xia, J. Xu, Y. Lan, J. Guo, and X. Cheng, â€œLearning maximal\n",
      "marginal relevance model via directly optimizing diversity evaluation\n",
      "measures,â€ in Proceedings of the 38th international ACM SIGIR con-\n",
      "ference on research and development in information retrieval, 2015, pp.\n",
      "113â€“122.\n",
      "[46] Cohere, â€œSay goodbye to irrelevant search results: Cohere rerank is\n",
      "here,â€ https://txt.cohere.com/rerank/, 2023.\n",
      "[47] H. Jiang, Q. Wu, X. Luo, D. Li, C.-Y. Lin, Y. Yang, and L. Qiu,\n",
      "â€œLongllmlingua: Accelerating and enhancing llms in long context sce-\n",
      "narios via prompt compression,â€ arXiv preprint arXiv:2310.06839, 2023.\n",
      "[48] R. Litman, O. Anschel, S. Tsiper, R. Litman, S. Mazor, and R. Man-\n",
      "matha, â€œScatter: selective context attentional scene text recognizer,â€ in\n",
      "proceedings of the IEEE/CVF conference on computer vision and pattern\n",
      "recognition, 2020, pp. 11 962â€“11 972.\n",
      "[49] J. Cui, Z. Li, Y. Yan, B. Chen, and L. Yuan, â€œChatlaw: Open-source\n",
      "legal large language model with integrated external knowledge bases,â€\n",
      "arXiv preprint arXiv:2306.16092, 2023.\n",
      "[50] T. Schick, J. Dwivedi-Yu, R. Dess`Ä±, R. Raileanu, M. Lomeli, L. Zettle-\n",
      "moyer, N. Cancedda, and T. Scialom, â€œToolformer: Language models\n",
      "can teach themselves to use tools,â€ arXiv preprint arXiv:2302.04761,\n",
      "2023.\n",
      "[51] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin,\n",
      "C. Zhang, S. Agarwal, K. Slama, A. Ray et al., â€œTraining language\n",
      "models to follow instructions with human feedback,â€ Advances in neural\n",
      "information processing systems, vol. 35, pp. 27 730â€“27 744, 2022.\n",
      "[52] S. J. Semnani, V. Z. Yao, H. C. Zhang, and M. S. Lam, â€œWikichat:\n",
      "Stopping the hallucination of large language model chatbots by few-\n",
      "shot grounding on wikipedia,â€ arXiv preprint arXiv:2305.14292, 2023.\n",
      "[53] J.\n",
      "Baek,\n",
      "S.\n",
      "Jeong,\n",
      "M.\n",
      "Kang,\n",
      "J.\n",
      "C.\n",
      "Park,\n",
      "and\n",
      "S.\n",
      "J.\n",
      "Hwang,\n",
      "â€œKnowledge-augmented language model verification,â€ arXiv preprint\n",
      "arXiv:2310.12836, 2023.\n",
      "[54] G. V. Cormack, C. L. Clarke, and S. Buettcher, â€œReciprocal rank\n",
      "fusion outperforms condorcet and individual rank learning methods,â€\n",
      "in Proceedings of the 32nd international ACM SIGIR conference on\n",
      "Research and development in information retrieval, 2009, pp. 758â€“759.\n",
      "[55] W. Shi, S. Min, M. Yasunaga, M. Seo, R. James, M. Lewis, L. Zettle-\n",
      "moyer, and W.-t. Yih, â€œReplug: Retrieval-augmented black-box language\n",
      "models,â€ arXiv preprint arXiv:2301.12652, 2023.\n",
      "[56] Z. Shao, Y. Gong, Y. Shen, M. Huang, N. Duan, and W. Chen,\n",
      "â€œEnhancing retrieval-augmented large language models with iterative\n",
      "retrieval-generation synergy,â€ arXiv preprint arXiv:2305.15294, 2023.\n",
      "[57] S. Hong, X. Zheng, J. Chen, Y. Cheng, J. Wang, C. Zhang, Z. Wang,\n",
      "S. K. S. Yau, Z. Lin, L. Zhou et al., â€œMetagpt: Meta programming for\n",
      "multi-agent collaborative framework,â€ arXiv preprint arXiv:2308.00352,\n",
      "2023.\n",
      "[58] Z. Yu, C. Xiong, S. Yu, and Z. Liu, â€œAugmentation-adapted retriever\n",
      "improves generalization of language models as generic plug-in,â€ arXiv\n",
      "preprint arXiv:2305.17331, 2023.\n",
      "[59] Z. Hei, W. Wei, W. Ou, J. Qiao, J. Jiao, Z. Zhu, and G. Song,\n",
      "â€œDr-rag: Applying dynamic document relevance to retrieval-augmented\n",
      "generation for question-answering,â€ arXiv preprint arXiv:2406.07348,\n",
      "2024.\n",
      "[60] M. Besta, A. Kubicek, R. Niggli, R. Gerstenberger, L. Weitzen-\n",
      "dorf, M. Chi, P. Iff, J. Gajda, P. Nyczyk, J. MÂ¨uller et al., â€œMulti-\n",
      "head rag: Solving multi-aspect problems with llms,â€ arXiv preprint\n",
      "arXiv:2406.05085, 2024.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb309ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'Entry ID': 'http://arxiv.org/abs/2407.21059v1', 'Published': datetime.date(2024, 7, 26), 'Title': 'Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks', 'Authors': 'Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang'}, page_content='Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\\nof Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\\nincreasing demands of application scenarios have driven the evolution of RAG,\\nleading to the integration of advanced retrievers, LLMs and other complementary\\ntechnologies, which in turn has amplified the intricacy of RAG systems.\\nHowever, the rapid advancements are outpacing the foundational RAG paradigm,\\nwith many methods struggling to be unified under the process of\\n\"retrieve-then-generate\". In this context, this paper examines the limitations\\nof the existing RAG paradigm and introduces the modular RAG framework. By\\ndecomposing complex RAG systems into independent modules and specialized\\noperators, it facilitates a highly reconfigurable framework. Modular RAG\\ntranscends the traditional linear architecture, embracing a more advanced\\ndesign that integrates routing, scheduling, and fusion mechanisms. Drawing on\\nextensive research, this paper further identifies prevalent RAG\\npatterns-linear, conditional, branching, and looping-and offers a comprehensive\\nanalysis of their respective implementation nuances. Modular RAG presents\\ninnovative opportunities for the conceptualization and deployment of RAG\\nsystems. Finally, the paper explores the potential emergence of new operators\\nand paradigms, establishing a solid theoretical foundation and a practical\\nroadmap for the continued evolution and practical deployment of RAG\\ntechnologies.')]\n"
     ]
    }
   ],
   "source": [
    "# ë…¼ë¬¸ ìš”ì•½ë§Œ ì¡°íšŒ\n",
    "summary_docs = loader.get_summaries_as_docs()\n",
    "print(summary_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fce9a191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Entry ID': 'http://arxiv.org/abs/2407.21059v1',\n",
       " 'Published': datetime.date(2024, 7, 26),\n",
       " 'Title': 'Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks',\n",
       " 'Authors': 'Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdcac9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\n",
      "of Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\n",
      "increasing demands of application scenarios have driven the evolution of RAG,\n",
      "leading to the integration of advanced retrievers, LLMs and other complementary\n",
      "technologies, which in turn has amplified the intricacy of RAG systems.\n",
      "However, the rapid advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process of\n",
      "\"retrieve-then-generate\". In this context, this paper examines the limitations\n",
      "of the existing RAG paradigm and introduces the modular RAG framework. By\n",
      "decomposing complex RAG systems into independent modules and specialized\n",
      "operators, it facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a more advanced\n",
      "design that integrates routing, scheduling, and fusion mechanisms. Drawing on\n",
      "extensive research, this paper further identifies prevalent RAG\n",
      "patterns-linear, conditional, branching, and looping-and offers a comprehensive\n",
      "analysis of their respective implementation nuances. Modular RAG presents\n",
      "innovative opportunities for the conceptualization and deployment of RAG\n",
      "systems. Finally, the paper explores the potential emergence of new operators\n",
      "and paradigms, establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment of RAG\n",
      "technologies.\n"
     ]
    }
   ],
   "source": [
    "print(summary_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a984953e",
   "metadata": {},
   "source": [
    "### Docling\n",
    "- IBM Researchì—ì„œ ê°œë°œí•œ ì˜¤í”ˆì†ŒìŠ¤ ë¬¸ì„œì²˜ë¦¬ ë„êµ¬ë¡œ ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ ë¬¸ì„œë¥¼ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜í•´ ìƒì„±í˜• AIì—ì„œ í™œìš©í•  ìˆ˜ìˆë„ë¡ ì§€ì›í•œë‹¤.\n",
    "- **ì£¼ìš”ê¸°ëŠ¥**\n",
    "  - PDF, DOCX, PPTX, XLSX, HTML, ì´ë¯¸ì§€ ë“± ì—¬ëŸ¬ í˜•ì‹ì„ ì§€ì›\n",
    "  - PDFì˜ **í˜ì´ì§€ ë ˆì´ì•„ì›ƒ, ì½ê¸° ìˆœì„œ, í‘œ êµ¬ì¡°, ì½”ë“œ, ìˆ˜ì‹** ë“±ì„ ë¶„ì„í•˜ì—¬ ì •í™•í•˜ê²Œ ì½ì–´ë“¤ì¸ë‹¤.\n",
    "  - OCRì„ ì§€ì›í•˜ì—¬ ìŠ¤ìº”ëœ PDFë‚˜ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ìˆë‹¤.\n",
    "  - ì½ì–´ë“¤ì¸ ë‚´ìš©ì„ markdown, html, jsonë“± ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ì¤€ë‹¤.\n",
    "- ì„¤ì¹˜ : `pip install langchain-docling ipywidgets -qU` \n",
    "- ì°¸ì¡°\n",
    "  - docling ì‚¬ì´íŠ¸: https://github.com/docling-project/docling\n",
    "  - ë­ì²´ì¸-docling https://python.langchain.com/docs/integrations/document_loaders/docling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "406c0672-a932-4b55-bc39-1863e00ef3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31mÃ—\u001b[0m \u001b[32mBuilding wheel for docling-parse \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31mâ•°â”€>\u001b[0m \u001b[31m[45 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m python prefix:  /Users/giwonjun/anaconda3/envs/lang_env\n",
      "  \u001b[31m   \u001b[0m python executable:  /Users/giwonjun/anaconda3/envs/lang_env/bin/python\n",
      "  \u001b[31m   \u001b[0m pybind11_cmake_dir='/private/var/folders/69/bt3_5fns57n_cp5_ydbrhfh80000gn/T/pip-build-env-amkign5y/overlay/lib/python3.12/site-packages/pybind11/share/cmake/pybind11'\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m launch: cmake -B /private/var/folders/69/bt3_5fns57n_cp5_ydbrhfh80000gn/T/pip-install-9hsqglry/docling-parse_2829d61d0ebb4c62a4104b9fc2aa8105/build -DUSE_SYSTEM_DEPS=OFF -DPYTHON_EXECUTABLE=/Users/giwonjun/anaconda3/envs/lang_env/bin/python -Dpybind11_DIR=/private/var/folders/69/bt3_5fns57n_cp5_ydbrhfh80000gn/T/pip-build-env-amkign5y/overlay/lib/python3.12/site-packages/pybind11/share/cmake/pybind11\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/69/bt3_5fns57n_cp5_ydbrhfh80000gn/T/pip-install-9hsqglry/docling-parse_2829d61d0ebb4c62a4104b9fc2aa8105/build.py\", line 73, in <module>\n",
      "  \u001b[31m   \u001b[0m     build_local(num_threads=num_threads)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/69/bt3_5fns57n_cp5_ydbrhfh80000gn/T/pip-install-9hsqglry/docling-parse_2829d61d0ebb4c62a4104b9fc2aa8105/build.py\", line 55, in build_local\n",
      "  \u001b[31m   \u001b[0m     success = run(config_cmd, cwd=ROOT_DIR)\n",
      "  \u001b[31m   \u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/69/bt3_5fns57n_cp5_ydbrhfh80000gn/T/pip-install-9hsqglry/docling-parse_2829d61d0ebb4c62a4104b9fc2aa8105/build.py\", line 31, in run\n",
      "  \u001b[31m   \u001b[0m     message = subprocess.run(cmd, cwd=cwd)\n",
      "  \u001b[31m   \u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/subprocess.py\", line 548, in run\n",
      "  \u001b[31m   \u001b[0m     with Popen(*popenargs, **kwargs) as process:\n",
      "  \u001b[31m   \u001b[0m          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/subprocess.py\", line 1026, in __init__\n",
      "  \u001b[31m   \u001b[0m     self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/subprocess.py\", line 1955, in _execute_child\n",
      "  \u001b[31m   \u001b[0m     raise child_exception_type(errno_num, err_msg, err_filename)\n",
      "  \u001b[31m   \u001b[0m FileNotFoundError: [Errno 2] No such file or directory: 'cmake'\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 389, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 373, in main\n",
      "  \u001b[31m   \u001b[0m     json_out[\"return_val\"] = hook(**hook_input[\"kwargs\"])\n",
      "  \u001b[31m   \u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 280, in build_wheel\n",
      "  \u001b[31m   \u001b[0m     return _build_backend().build_wheel(\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/69/bt3_5fns57n_cp5_ydbrhfh80000gn/T/pip-build-env-amkign5y/overlay/lib/python3.12/site-packages/poetry/core/masonry/api.py\", line 58, in build_wheel\n",
      "  \u001b[31m   \u001b[0m     return WheelBuilder.make_in(\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/69/bt3_5fns57n_cp5_ydbrhfh80000gn/T/pip-build-env-amkign5y/overlay/lib/python3.12/site-packages/poetry/core/masonry/builders/wheel.py\", line 95, in make_in\n",
      "  \u001b[31m   \u001b[0m     wb.build(target_dir=directory)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/69/bt3_5fns57n_cp5_ydbrhfh80000gn/T/pip-build-env-amkign5y/overlay/lib/python3.12/site-packages/poetry/core/masonry/builders/wheel.py\", line 134, in build\n",
      "  \u001b[31m   \u001b[0m     self._build(zip_file)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/69/bt3_5fns57n_cp5_ydbrhfh80000gn/T/pip-build-env-amkign5y/overlay/lib/python3.12/site-packages/poetry/core/masonry/builders/wheel.py\", line 183, in _build\n",
      "  \u001b[31m   \u001b[0m     self._run_build_script(self._package.build_script)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/69/bt3_5fns57n_cp5_ydbrhfh80000gn/T/pip-build-env-amkign5y/overlay/lib/python3.12/site-packages/poetry/core/masonry/builders/wheel.py\", line 304, in _run_build_script\n",
      "  \u001b[31m   \u001b[0m     subprocess.check_call([self.executable.as_posix(), build_script])\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/subprocess.py\", line 413, in check_call\n",
      "  \u001b[31m   \u001b[0m     raise CalledProcessError(retcode, cmd)\n",
      "  \u001b[31m   \u001b[0m subprocess.CalledProcessError: Command '['/Users/giwonjun/anaconda3/envs/lang_env/bin/python', 'build.py']' returned non-zero exit status 1.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for docling-parse\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Failed to build installable wheels for some pyproject.toml based projects (docling-parse)\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-docling ipywidgets -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96e423ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_docling import DoclingLoader\n",
    "from langchain_docling.loader import ExportType\n",
    "\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a639f1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# huggingface-hub ë¡œê·¸ì¸\n",
    "login(os.getenv(\"HUGGINGFACE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "006cd80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n",
      "Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n",
      "/Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages/transformers/models/rt_detr/image_processing_rt_detr.py:1093: UserWarning: MPS: nonzero op is supported natively starting from macOS 14.0. Falling back on CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Indexing.mm:404.)\n",
      "  \"scores\": score[score > threshold],\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"papers/1.pdf\" #ë¬¸ì„œ ê²½ë¡œ. local fileê²½ë¡œ, url\n",
    "path = \"https://arxiv.org/pdf/2506.09669\"\n",
    "\n",
    "loader = DoclingLoader(file_path=path, export_type=ExportType.MARKDOWN)\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6af181e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://arxiv.org/pdf/2506.09669'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c6cd786-947d-49ae-933c-627ca714c06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Query-Level Uncertainty in Large Language Models\n",
       "\n",
       "## Lihu Chen , GaÃ«l Varoquaux 1 2\n",
       "\n",
       "- 1 Imperial College London, UK\n",
       "\n",
       "2 Soda, Inria Saclay, France lihu.chen@imperial.ac.uk gael.varoquaux@inria.fr\n",
       "\n",
       "## Abstract\n",
       "\n",
       "It is important for Large Language Models to be aware of the boundary of their knowledge, the mechanism of identifying known and unknown queries. This type of awareness can help models perform adaptive inference, such as invoking RAG, engaging in slow and deep thinking, or adopting the abstention mechanism, which is beneficial to the development of efficient and trustworthy AI. In this work, we propose a method to detect knowledge boundaries via Query-Level Uncertainty , which aims to determine if the model is able to address a given query without generating any tokens. To this end, we introduce a novel and training-free method called Internal Confidence , which leverages self-evaluations across layers and tokens. Empirical results on both factual QA and mathematical reasoning tasks demonstrate that our internal confidence can outperform several baselines. Furthermore, we showcase that our proposed method can be used for efficient RAG and model cascading, which is able to reduce inference costs while maintaining performance. The code is available at /github https://github.com/tigerchen52/ query\\_level\\_uncertainty\n",
       "\n",
       "## 1 Introduction\n",
       "\n",
       "Large language Models (LLMs) have their knowledge boundaries (Li et al., 2024; Yin et al., 2024; Ren et al., 2025), which means that there are certain problems that they cannot provide accurate outputs. It is crucial for LLMs to be self-aware of their limitations, i.e., know what I know and know what I don't know (Kadavath et al., 2022; Amayuelas et al., 2024).\n",
       "\n",
       "Possessing awareness of knowledge boundaries provides several advantages in developing efficient and trustworthy AI. First, if LLMs can identify known-unknown or simple-hard queries, they can smartly perform adaptive inference to balance the trade-offs between computational cost and out-\n",
       "\n",
       "Figure 1: Illustrating the difference between answerlevel and query-level uncertainty. Query-level uncertainty estimating known or unknown queries ( knowledge boundary ) before generating answers, which is useful for adaptive inference, e.g., efficient RAG and fast-slow reasoning.\n",
       "\n",
       "put quality. For queries beyond their parametric knowledge, they can choose to find relevant external knowledge via RAG (Lewis et al., 2020) or tool calls (Schick et al., 2023). When faced with hard problems, LLMs can engage in slow (or deep) thinking to improve their outputs, which is also known as test-time scaling (Snell et al., 2024; Zhang et al., 2025). Alternatively, another solution is to defer a complex problem to a larger model via model cascading (Dohan et al., 2022; Gupta et al., 2024). This adaptive inference ensures that computational resources are allocated effectively, which reduces costs while maintaining performance. Second, estimating whether a query is answerable enhances the honesty and trustworthiness of LLMs. When LLMs identify uncertain queries, they can use the abstention strategy (Wen et al., 2024) to withhold responses, which is important in high-stakes domains like healthcare (Tomani et al., 2024).\n",
       "\n",
       "In this work, we propose a new concept, QueryLevel Uncertainty , to estimate a model's knowledge with regard to a given query. The research question here is: Given a query, can we determine if the model is able to address it without generating any tokens? Most existing work focus on answerlevel uncertainty, which measures the uncertainty associated with a specific answer, helping us assess the reliability of outputs (Shorinwa et al., 2024; Vashurin et al., 2025). The main distinction here is that we shift from post-generation uncertainty to pre-generation uncertainty, which aims to measure how certain an LLM can solve this query, as shown in Figure 1.\n",
       "\n",
       "Prior studies propose learning a probe on internal states to predict uncertainties of queries (Gottesman and Geva, 2024; Kossen et al., 2024). Another branch of work attempts to teach LLMs to explicitly express 'I don't know' in their responses via fine-tuning methods (Amayuelas et al., 2024; Kapoor et al., 2024; Cohen et al., 2024; Zhang et al., 2024a). One potential issue of these studies is that they often require fine-tuning and training samples, which introduces additional overhead and may limit their generalizability. We aim to introduce a training-free approach to estimate querylevel uncertainty, which is simple yet effective.\n",
       "\n",
       "Our approach relies on self-evaluation across internal layers and tokens, which is called Internal Confidence . The proposed approach is based on a simple assumption: LLMs can self-evaluate their knowledge about a query by answering a yesno question. Inspired by the uncertainty method P(True) (Kadavath et al., 2022), we can compute the probability P(Yes) to indicate the model's confidence. To fully use latent knowledge within LLMs, we compute this kind of P(Yes) at each layer and token position. Following that, we aggregate these signals to obtain the final confidence score. This aggregation is motivated by prior work showing that leveraging logical consistency across layers can improve outputs (Burns et al., 2022; Chuang et al., 2023; Xie et al., 2024). Specifically, we perform a weighted sum across layers and tokens, and the weights are derived from attenuated encoding (Chen et al., 2023), which can control the influence of adjacent units.\n",
       "\n",
       "To validate the effectiveness of our proposed internal confidence, we conduct experiments on three datasets that cover factual QA and mathematical reasoning tasks. For comparison, we adapt the existing answer-level methods to compute the querylevel uncertainty. Experimental results demonstrate that our proposed internal confidence can distinguish known and unknown queries better than various baselines. In terms of applications, we showcase that our proposed method can help efficient\n",
       "\n",
       "RAG and model cascading. On the one hand, internal confidence can guide users to assess the tradeoffs between cost and quality when invoking additional services. On the other hand, it brings a 'benefit region', where inference overhead can be reduced without compromising performance.\n",
       "\n",
       "To conclude, we propose a simple yet effective, training-free method to estimate query-level uncertainty, which can determine if a model can address a given query without generating any tokens.\n",
       "\n",
       "## 2 Related Work\n",
       "\n",
       "## 2.1 Uncertainty Estimation\n",
       "\n",
       "Existing methods mainly focus on estimating the uncertainty of LLM-generated responses, which aim to provide a score to indicate the reliability of a query-answer pair (Geng et al., 2024; Shorinwa et al., 2024; Vashurin et al., 2025). These approaches often rely on internal states (Chen et al., 2024a) or textual responses (Kuhn et al., 2023), and commonly use calibration techniques to mitigate issues such as overconfidence (Zhang et al., 2024b) and biases (Chen et al., 2024b). Notably, these methods assess post-generation reliability, i.e., they evaluate uncertainty about a particular answer. In contrast, there is limited research on quantifying how well a model can address a query prior to token generation. For example, Gottesman and Geva (2024) propose training a lightweight probe on internal representations to estimate the model's knowledge about specific entities. Similarly, Semantic Entropy Probes (Kossen et al., 2024) suggest that internal model states can implicitly encode semantic uncertainty, even before any output is generated. To the best of our knowledge, this work is the first to formally define query-level uncertainty and investigate it systematically.\n",
       "\n",
       "## 2.2 Knowledge Boundary Detection\n",
       "\n",
       "LLMs should faithfully assess their level of confidence in answering a query. This knowledge boundary awareness (Li et al., 2024; Yin et al., 2024; Wang et al., 2024) is essential to build reliable AI systems, particularly in high-stakes domains such as healthcare and law. A pioneering study by Kadavath et al. (2022) explores whether language models can be trained to predict when they 'know' the answer to a given query, introducing the concept of 'I Know' (IK) prediction. Based on this idea, subsequent work has proposed methods to help LLMs become explicitly aware of their knowledge limitations through fine-tuning strategies (Amayuelas et al., 2024; Kapoor et al., 2024). Cohen et al. (2024) further advances this line of research by introducing a special [IDK] (' I don't know ') token into the model's vocabulary, allowing the direct expression of uncertainty in its output. Similarly, RTuning (Zhang et al., 2024a) tunes LLMs to refrain from responding to questions beyond their parametric knowledge. While these abstention-based approaches show benefits in mitigating hallucinations (Wen et al., 2024), they often require additional fine-tuning, which introduces overhead and may limit generalizability across models and tasks. In this work, we propose a training-free method to identify the knowledge boundary of an LLM, which offers a more generalizable and efficient alternative to detect the knowledge boundary of LLMs.\n",
       "\n",
       "## 3 Preliminary\n",
       "\n",
       "## 3.1 Aleatoric and Epistemic Uncertainty\n",
       "\n",
       "Uncertainty in machine learning is commonly categorized into two main types: aleatoric and epistemic uncertainty (Hora, 1996; Der Kiureghian and Ditlevsen, 2009; HÃ¼llermeier and Waegeman, 2021). These distinctions are often overlooked in the context of LLM uncertainty estimation. Aleatoric uncertainty arises from inherent randomness in the data, such as ambiguous inputs or conflicting annotations. This type of uncertainty is irreducible, as it reflects intrinsic noise in the input data. In contrast, epistemic uncertainty stems from a lack of knowledge, often due to insufficient training data and limited model capacity. Unlike aleatoric uncertainty, epistemic uncertainty is reducible with additional data or advanced modeling. In this work, we focus specifically on epistemic uncertainty, with the goal of evaluating whether an LLM possesses sufficient knowledge to answer a given query. Although it is possible that a dataset may contain some ambiguous queries and noisy labels, we assume that the benchmark datasets used in our experiments are well-curated, and have minimal ambiguity. This assumption allows us to reasonably minimize the impact of aleatoric uncertainty, and study the epistemic uncertainty in a clear way.\n",
       "\n",
       "## 3.2 Uncertainty and Confidence\n",
       "\n",
       "In the context of LLMs, the terms uncertainty and confidence are often used interchangeably (antonyms). However, the two concepts have sub- tle differences. As noted by Lin et al. (2023), uncertainty is a holistic property of the entire predictive distribution, while confidence refers to the model's estimated confidence level associated with a specific answer. For example, given a query x = 'What is the capital of France' , estimating uncertainty requires the distribution over all possible answers, e.g., Paris, Toulouse, etc. , as explained by the semantic entropy framework (Kuhn et al., 2023). In contrast, the conditional probability P Y ( = Paris | x ) can serve as a confidence here to indicate the correctness of a specific answer. In the context of query-level uncertainty, we treat uncertainty and confidence as antonyms, as obtaining full probability distributions over all possible queries for a given model is infeasible.\n",
       "\n",
       "## 4 Problem Statement and Method\n",
       "\n",
       "In this section, we describe our problem definition and introduce our method, Internal Confidence , a score that reflects whether an LLM can address a query in its own knowledge, prior to generating tokens.\n",
       "\n",
       "## 4.1 Problem Statement\n",
       "\n",
       "Given a query (including prompt words) x = ( x , . . . , x 1 N ) , we aim to quantify the query-level uncertainty, U ( x ) , without generating an answer y . This is different from existing uncertainty methods that estimate the uncertainty associated with a specific generated answer, denoted as U ( x y , ) . We define that if an LLM can answer a query correctly in greedy decoding, the query falls within the knowledge boundary of the model, and its answer can be reliable. Otherwise, the query falls beyond the model's boundary, and it does not possess sufficient knowledge to answer it. We use this standard to evaluate the estimated query-level uncertainty, i.e., a lower uncertainty indicates a model is more likely to output the correct answer. Although different decoding strategies impact LLM outputs (Song et al., 2024), we aim to measure the internal knowledge of a model in a deterministic way.\n",
       "\n",
       "Here, we focus on queries with definite answers, which have broad applications such as factual QA and mathematical reasoning. While contentious queries with open answers are also important in areas such as politics and philosophy, they are out of the scope of this work.\n",
       "\n",
       "Figure 2: Left: the internal P(Yes) across tokens and layers. Middle: the AUC of P(Yes) across tokens and layers. Right: decay weights with different localities. Model: Llama-8B; Dataset: GSM8K validation set.\n",
       "\n",
       "## 4.2 Method\n",
       "\n",
       "Existing findings reveal that LLMs can express verbalized uncertainty in their responses (Tian et al., 2023; Xiong et al., 2024), which reflects that LLMs can evaluate the answer correctness in their own knowledge. Similarly, we can prompt an LLM to assess its confidence in answering a given query by using a yes-no format: 'Respond only with 'Yes' or 'No' to indicate whether you are capable of answering the {Query} accurately. Answer Yes or No:' . Following that, we can compute the probability P(Yes) at the last token ( x N ):\n",
       "\n",
       "<!-- formula-not-decoded -->\n",
       "\n",
       "where N is the index of the last token in the query, and L is the index of the last layer of the model. h ( L ) N âˆˆ R d is the hidden state and d is the dimensionality of the hidden representations. W unemb âˆˆ R |V|Ã— d is the unembedding matrix that maps the hidden state h ( L ) N to logits over the vocabulary V . P(Yes) can serve as a query-level confidence score here, which is somehow correlated with verbalized uncertainty (Tian et al., 2023), but the main difference is that this method only makes a single forward pass of the query without generating any answer tokens.\n",
       "\n",
       "However, P(Yes) does fully use internal states of LLMs, which preserves rich latent information about estimating uncertainty (Azaria and Mitchell, 2023; Chen et al., 2024a). Furthermore, prior work demonstrates that using logical consistency across layers can improve outputs (Burns et al., 2022; Chuang et al., 2023; Xie et al., 2024). Therefore, we propose the Internal Confidence , which leverages latent knowledge across different layers and tokens. Let f Î¸ denote the transformation function for computing hidden states, parameterized by Î¸ . The hidden state for the query x n of the query at layer l is computed as:\n",
       "\n",
       "<!-- formula-not-decoded -->\n",
       "\n",
       "In total, the model contains N Ã— L such latent representations, and we can use Equation 4.2 to compute the P(Yes) for each h ( ) l n .\n",
       "\n",
       "Figure 2a shows the average P(Yes) of Llama-8B on the mathematical queries (the validation set of GSM8K (Cobbe et al., 2021)), across layers and query tokens 1 . We observe that the probability increases gradually from low to high layers and from left to right positions, presenting diverse behaviors. If we treat each P ( Yes | h ( ) l n ) as a confidence score and evaluate Area Under the Curve (AUC), we can obtain an AUC heatmap to show how well the model can distinguish known and unknown queries. As shown in Figure 2b, the top right score is not optimal. Actually, the representation h (27) 5 can achieve the best AUC, and the performance gradually declines in regions surrounding this point. We refer to this optimal point as Decision Center . It is important to note that the location of the Decision Center is sensitive to both model architecture and task type.\n",
       "\n",
       "To improve the naive P(Yes), we can apply a weighted average centering around the decision center, which serves as an ensemble strategy to enhance calibration and expressivity (Zhang et al.,\n",
       "\n",
       "1 Here, we consider tokens after the {Query} , which means that a model has seen the entire query and is able to guess its knowledge gap.\n",
       "\n",
       "Table 1: Overall performances of different query-level uncertainty methods.\n",
       "\n",
       "|                                      | TriviaQA   | TriviaQA   | TriviaQA   | SciQ     | SciQ     | SciQ     | GSM8K    | GSM8K    | GSM8K    | Avg      | Avg      | Avg      |\n",
       "|--------------------------------------|------------|------------|------------|----------|----------|----------|----------|----------|----------|----------|----------|----------|\n",
       "| Method                               | â†‘ AUC      | â†‘ PRR      | â†“ ECE      | â†‘ AUC    | â†‘ PRR    | â†“ ECE    | â†‘ AUC    | â†‘ PRR    | â†“ ECE    | â†‘ AUC    | â†‘ PRR    | â†“ ECE    |\n",
       "| Phi-3.8B                             | Phi-3.8B   | Phi-3.8B   | Phi-3.8B   | Phi-3.8B | Phi-3.8B | Phi-3.8B | Phi-3.8B | Phi-3.8B | Phi-3.8B | Phi-3.8B | Phi-3.8B | Phi-3.8B |\n",
       "| Max ( - log p )                      | 55.5       | 10.0       | -          | 51.4     | 2.9      | -        | 55.0     | 11.3     | -        | 54.0     | 8.1      | -        |\n",
       "| Predictive Entropy                   | 58.9       | 17.9       | -          | 51.2     | 3.9      | -        | 63.6     | 25.7     | -        | 57.9     | 15.8     | -        |\n",
       "| Min-K Entropy                        | 59.9       | 20.0       | -          | 52.7     | 4.9      | -        | 60.4     | 17.9     | -        | 57.7     | 14.3     | -        |\n",
       "| Attentional Entropy                  | 60.6       | 21.4       | -          | 56.2     | 9.4      | -        | 52.4     | 4.4      | -        | 56.4     | 11.7     | -        |\n",
       "| Perplexity                           | 61.8       | 24.3       | -          | 57.7     | 16.6     | -        | 53.6     | 6.9      | -        | 57.7     | 15.9     | -        |\n",
       "| Internal Semantic Similarity         | 48.7       | -2.4       | 0.3        | 46.9     | -5.9     | 12.2     | 47.9     | -2.6     | 35.2     | 47.8     | -3.6     | 15.9     |\n",
       "| P(Yes)                               | 58.1       | 16.4       | 13.9       | 58.8     | 16.9     | 10.8     | 56.6     | 12.0     | 7.6      | 57.8     | 15.1     | 10.8     |\n",
       "| Internal Confidence ( w/ naive avg ) | 58.8       | 17.3       | 19.9       | 52.4     | 4.5      | 3.3      | 54.7     | 14.7     | 21.7     | 55.3     | 12.2     | 15.0     |\n",
       "| Internal Confidence                  | 56.2       | 13.1       | 13.9       | 57.2     | 15.2     | 8.2      | 57.2     | 12.9     | 6.0      | 56.9     | 13.7     | 9.4      |\n",
       "| Llama-8B                             | Llama-8B   | Llama-8B   | Llama-8B   | Llama-8B | Llama-8B | Llama-8B | Llama-8B | Llama-8B | Llama-8B | Llama-8B | Llama-8B | Llama-8B |\n",
       "| Max ( - log p )                      | 54.9       | 11.1       | -          | 51.4     | 1.9      | -        | 53.3     | 10.4     | -        | 53.2     | 7.8      | -        |\n",
       "| Predictive Entropy                   | 58.5       | 17.7       | -          | 51.4     | 3.2      | -        | 66.1     | 28.0     | -        | 58.7     | 16.3     | -        |\n",
       "| Min-K Entropy                        | 58.1       | 17.4       | -          | 53.5     | 7.9      | -        | 57.5     | 13.2     | -        | 56.4     | 12.8     | -        |\n",
       "| Attentional Entropy                  | 59.4       | 18.7       | -          | 57.7     | 15.2     | -        | 56.1     | 13.5     | -        | 57.7     | 15.8     | -        |\n",
       "| Perplexity                           | 58.6       | 17.1       | -          | 58.3     | 15.1     | -        | 53.2     | 4.3      | -        | 56.7     | 12.2     | -        |\n",
       "| Internal Semantic Similarity         | 44.1       | -14.4      | 24.4       | 46.1     | -7.1     | 30.8     | 52.7     | 6.7      | 45.9     | 47.6     | -4.9     | 33.7     |\n",
       "| P(Yes)                               | 66.4       | 33.0       | 27.5       | 51.3     | 2.4      | 23.7     | 62.2     | 24.8     | 11.6     | 60.0     | 20.1     | 20.9     |\n",
       "| Internal Confidence ( w/ naive avg ) | 67.2       | 34.4       | 14.9       | 58.6     | 15.4     | 21.5     | 59.1     | 18.7     | 29.2     | 61.6     | 22.8     | 21.9     |\n",
       "| Internal Confidence                  | 67.8       | 34.5       | 19.1       | 56.4     | 13.0     | 18.9     | 62.9     | 27.9     | 1.3      | 62.4     | 25.1     | 13.1     |\n",
       "| Qwen-14B                             | Qwen-14B   | Qwen-14B   | Qwen-14B   | Qwen-14B | Qwen-14B | Qwen-14B | Qwen-14B | Qwen-14B | Qwen-14B | Qwen-14B | Qwen-14B | Qwen-14B |\n",
       "| Max ( - log p )                      | 56.5       | 12.4       | -          | 54.1     | 6.9      | -        | 54.3     | 13.5     | -        | 55.0     | 10.9     | -        |\n",
       "| Predictive Entropy                   | 59.3       | 18.9       | -          | 53.2     | 6.9      | -        | 66.4     | 32.6     | -        | 59.6     | 19.5     | -        |\n",
       "| Min-K Entropy                        | 59.9       | 20.0       | -          | 55.7     | 11.3     | -        | 63.0     | 30.9     | -        | 59.5     | 20.7     | -        |\n",
       "| Attentional Entropy                  | 59.1       | 17.2       | -          | 59.4     | 19.2     | -        | 54.9     | 3.1      | -        | 57.8     | 13.2     | -        |\n",
       "| Perplexity                           | 59.1       | 17.8       | -          | 60.1     | 20.7     | -        | 54.0     | 7.3      | -        | 57.7     | 15.3     | -        |\n",
       "| Internal Semantic Similarity         | 51.0       | 2.5        | 2.0        | 45.5     | -7.7     | 14.9     | 47.5     | -4.6     | 33.1     | 48.0     | -3.3     | 16.7     |\n",
       "| P(Yes)                               | 63.2       | 25.8       | 31.9       | 61.0     | 22.4     | 23.9     | 54.7     | 7.5      | 5.8      | 59.6     | 18.6     | 20.5     |\n",
       "| Internal Confidence ( w/ naive avg ) | 63.3       | 27.6       | 8.0        | 60.5     | 20.5     | 15.3     | 61.7     | 28.4     | 36.3     | 61.8     | 25.5     | 19.9     |\n",
       "| Internal Confidence                  | 69.1       | 38.4       | 28.7       | 65.0     | 30.8     | 20.6     | 62.7     | 28.4     | 5.5      | 65.6     | 32.5     | 18.3     |\n",
       "\n",
       "2020; Stickland and Murray, 2020). We refer to this process as Internal Confidence (IC) , which can be denoted as:\n",
       "\n",
       "<!-- formula-not-decoded -->\n",
       "\n",
       "To reflect the observations that AUC performances gradually decay from the decision center, we adopt the Attenuated Encoding to compute the above two weight vectors (Chen et al., 2023)\n",
       "\n",
       "where w ( ) l n is the weight for each h ( ) l n . The equation describes a two-step aggregation process. First, we compute a weighted sum across layers for each individual token. Then, we apply a second weighted average over these token-level aggregated scores. Ideally, this process requires a layer weight matrix W layer âˆˆ R N Ã— L for the first step and a token weight matrix W token âˆˆ R 1 Ã— N for the second step. Through this aggregation, we are able to obtain a final confidence score.\n",
       "\n",
       "In a practical implementation, the decision center is static and fixed to the last token and last layer. However, it is possible to use a hold-out set to identify optimal positions tailored to specific models and tasks. We make this simplification to get rid of the requirement of training samples and aim to obtain better generalizability. Additionally, the layer weight vectors are shared across tokens, which means we need only two weight vectors: W layer âˆˆ R 1 Ã— L and W token âˆˆ R 1 Ã— N .\n",
       "\n",
       "<!-- formula-not-decoded -->\n",
       "\n",
       "where i is the index of the decision center, d i,j is the relative distance, and w &gt; 0 is a scalar parameter that controls the locality value. Locality is a metric that measures how much the weights of a weight vector are gathered in adjacent positions. Given a weight vector for the i -th position Ïµ i = { Ïµ i, 1 , Ïµ i, 2 , ..., Ïµ i,n } , the locality can be denoted as:\n",
       "\n",
       "<!-- formula-not-decoded -->\n",
       "\n",
       "Figure 2c shows the weights computed by Equation 4 with varied localities. This signifies that we can control the influence of neighboring layers and tokens during the averaging process.\n",
       "\n",
       "Our proposed internal confidence is training-free and efficient, as it requires only a single forward pass of a given query. Since model responses are usually longer than input prompts and invoking\n",
       "\n",
       "Figure 3: We use Internal Confidence of Phi-3.8B to predict whether the corresponding can distinguish known and unknown queries.\n",
       "\n",
       "external services like RAG adds significant overhead. We hope this pre-generation uncertainty can support adaptive reasoning.\n",
       "\n",
       "## 5 Experiments\n",
       "\n",
       "## 5.1 Settings\n",
       "\n",
       "Implementations We provide one positive and one negative example to prompt LLMs, and the target model should follow the examples to output answers. All LLMs use greedy decoding to have deterministic results. The decision center is fixed to the last layer and last token, and we set w = 1 0 . (Equation 4) for all models and datasets.\n",
       "\n",
       "edge and it falls in its knowledge boundary. For the first two datasets with short answers, we consider an answer to be correct if its Rouge-L (Lin and Och, 2004) of the ground truth is greater than 0.3, which is consistent with prior work (Kuhn et al., 2023). For the GSM8K dataset, we use an LLM evaluator, Mistal-Large (MistralAI, 2024), to assess both reasoning steps and final answer. After that, we can obtain a binary label for each query, which shows if a model is able to address the query.\n",
       "\n",
       "Models Three different sizes of LLMs are used in experiments: Phi-3-mini-4k-instruct (Abdin et al., 2024), Llama-3.1-8B-Instruct (Grattafiori et al., 2024), and Qwen2.5-14B-Instruct (Team, 2024). We aim to evaluate if internal confidence can be scaled to different model sizes. Note that internal confidence can be used for models without instruction tuning.\n",
       "\n",
       "Datasets We evaluate on two factual QA datasets and one mathematical reasoning dataset: TriviaQA (Joshi et al., 2017), SciQ (Welbl et al., 2017), and GSM8K (Cobbe et al., 2021). The first two tasks aim to assess factual knowledge stored in parameters, while GSM8K requires models to selfevaluate their reasoning capabilities. Ground truth of factual QA tasks is a short answer with some entity facts. GSM8k calls for a short answer, but the intermediate reasoning steps have been evaluated as well, following prior work (Kadavath et al., 2022).\n",
       "\n",
       "We ask a model to generate answers in a greedy decoding way. If the answer is aligned with ground truth, we regard that the model has sufficient knowl-\n",
       "\n",
       "Baselines We adapt existing answer-level methods to quantify the pre-generation uncertainty, e.g., logit-based uncertainty. Given a query (including prompt words) x = ( x , . . . , x 1 N ) , we can obtain a probability for each token P x ( n | x &lt;n ) by performing a forward pass. (1) The baseline Max ( -log p ) measures the query's uncertainty by assessing the least likely token in the query (Manakul et al., 2023). (2) Predictive Entropy is defined as the entropy over the entire query tokens (Malinin and Gales, 2021):\n",
       "\n",
       "<!-- formula-not-decoded -->\n",
       "\n",
       "(3) Min-K Entropy combines the thoughts of the Max ( -log p ) and predictive entropy , which select the top-K of tokens from the query with the minimum token probability (Shi et al., 2024). (4) Attentional Entropy is an adapted version of the predictive entropy by performing a weighted sum:\n",
       "\n",
       "<!-- formula-not-decoded -->\n",
       "\n",
       "where Î± n is the attentional weights for the token x n . The intuition here is that tokens contribute to the semantic meanings in a different way, and we should\n",
       "\n",
       "Figure 4: Left: We use estimated internal confidence scores to decide whether to invoke RAG. If the internal confidence exceeds a threshold, the model answers the query using its parametric knowledge. Otherwise, it relies on external knowledge for reasoning. The plot shows the accuracy of Phi-3.8B on the TriviaQA dataset under this setting. Right: We implement a model cascading seeting with Phi-3.8B (small) and Llama-8B (large) on the TriviaQA dataset. The internal confidence of the smaller model determines whether it answers the query or defers to the larger model when confidence is low.\n",
       "\n",
       "not treat all tokens equally (Duan et al., 2024). (5) Perplexity reflects how uncertain a model is when predicting the next token:\n",
       "\n",
       "<!-- formula-not-decoded -->\n",
       "\n",
       "(6) Internal Semantic Similarity measures the average similarity among hidden states of different layers { h (1) N , ..., h ( L ) N } , which is inspired by the lexical similarity (Fomicheva et al., 2020). (7) P(Yes) is the probability of self-evaluation, which is described in Equation 4.2. (8) Internal Confidence (w/ naive avg) is a variant of our proposed internal confidence. The distinction is we apply a naive average to aggregate all scores.\n",
       "\n",
       "observe that our proposed internal confidence can distinguish known and unknown queries better than other baselines (based on AUC and PRR) on average, especially for larger models such as Llama-8B and Qwen-14B. For example, the average AUC of Qwen-14B is 65.6, which is significantly higher than other baselines. Regarding the calibration (ECE), internal confidence can achieve lower error across models and tasks consistently. These findings indicate the effectiveness of internal confidence. Second, the variant, Internal Confidence ( w/ naive avg , leads to a decrease in general, which demonstrates that the benefit of using the attenuated encoding to obtain decay weights.\n",
       "\n",
       "Evaluation Metrics We evaluate uncertainty by assessing whether a method can distinguish known and unknown queries, which can be treated as ranking problems, i.e., a lower uncertainty means a model is more likely to know the answer to the query. Following prior work (Manakul et al., 2023; Kuhn et al., 2023), we adopt the metrics Area Under the Curve (AUC) and Prediction Rejection Ratio (PRR) (Malinin et al., 2017) to measure this. Additionally, we use the Expected Calibration Error (ECE) to assess the calibration of different methods.\n",
       "\n",
       "## 5.2 Internal Confidence Can Identify Known and Unknown Queries\n",
       "\n",
       "Table 1 shows the overall performances of various query-level uncertainty methods. First, we can\n",
       "\n",
       "Additionally, Figure 3 shows the how well the internal confidence can distinguish known and unknown queries across three tasks. While the results confirm that our training-free method can predict knowledge boundaries to some extent, there is still considerable room for improvement. We hope this initial effort encourages further research in this direction.\n",
       "\n",
       "## 5.3 Internal Confidence Makes LLM Reasoning More Efficiently\n",
       "\n",
       "Recent studies advance LLM reasoning by introducing additional resources, such as using RAG to obtain external knowledge (Lewis et al., 2020) and inference-time scaling to improve outputs (Snell et al., 2024). However, it is not always necessary to use additional resources, especially for simple queries. Here, we can use our proposed internal\n",
       "\n",
       "Figure 5: Impacts of locality on validation sets.\n",
       "\n",
       "confidence to determine when to invoke RAG, slow thinking, or model cascading.\n",
       "\n",
       "## 5.4 Locality Impacts Uncertainty Performance\n",
       "\n",
       "We conduct experiments for two scenarios: (1) Efficient RAG. Basically, the internal confidence can serve as a signal of the knowledge gaps of a model. If the score is greater than a threshold, the model is confidence to address the query. Otherwise, it requires the call of RAG. We use the TriviaQA dataset for evaluation. This dataset provides web search results for a query, which can be used as retrieved contexts for RAG. (2) Model Cascading. This task aims to achieve cost-performance trade-offs by coordinating small and large models (Dohan et al., 2022; Gupta et al., 2024). Smaller models is responsible for easy missions. If they are aware that the mission is hard to complete, it invokes a larger model. We use a two-model cascade setting with Phi-3.8B and Llama-8B on the TriviaQA dataset. Likewise, if the internal confidence of the smaller model is high, we do not invoke the larger model. Otherwise, the hard query is deferred to the larger model.\n",
       "\n",
       "Figure 4 shows the results of efficient RAG and model cascading. The trade-off region means that we can carefully select a threshold to control the call of external services, which helps strike a balance between efficiency and performance. The benefit region indicates scenarios where the use of additional resources can be reduced without compromising performance. Results across the two tasks further confirm the effectiveness of Internal Confidence in identifying knowledge gaps. Our method offers practical benefits by reducing inference overhead, which is correlated with computation time and monetary cost.\n",
       "\n",
       "We introduce attenuated encodings to aggregate probabilities centering around a decision point. The locality of the encoding may impact the performance of estimated uncertainties. To study the influence of the locality, we vary the w in Equation 4 to obtain encoding with different localities and observe how they can impact the estimations. Figure 5 shows the AUC across different datasets and models. We can observe that the locality is correlated with task types and model architecture. For example, Phi-3.8B prefers an extreme locality (1.0) while Qwen-14B has a certain optimal value around 0.8. Regarding different datasets, the influence of locality values displays slightly different behaviors. Although we may need to search an optimal locality for a specific task, we show that an empirical value with ( w = 1 0 . , Locality=0.72) can achieve competitive performances across models and datasets.\n",
       "\n",
       "## 6 Conclusion\n",
       "\n",
       "In this work, we propose a new concept called query-level uncertainty, which aims to assess whether a model can address a query without generating any tokens. To this end, we propose the approach, internal confidence, which leverages latent self-evaluation to identify the boundary of a model's knowledge. Experimental results verify the effectiveness of our approach in factual QA and mathematical reasoning. Furthermore, we apply internal confidence to two practical scenarios of adaptive inference, efficient RAG and model cascading. Our findings reveal that our method can identify two regions: a trade-off region and a benefit region. The former means that users can strike a balance between cost and quality by carefully selecting a threshold of confidence scores. The latter means that users can reduce inference overhead without compromising performance. Although our method can serve as a strong baseline for estimating querylevel uncertainty, there is still considerable room for improvement. We hope this study can stimulate future studies in this area.\n",
       "\n",
       "## References\n",
       "\n",
       "Marah Abdin, Jyoti Aneja, Hany Awadalla, Ahmed Awadallah, Ammar Ahmad Awan, Nguyen Bach, Amit Bahree, Arash Bakhtiari, Jianmin Bao, Harkirat Behl, and 1 others. 2024. Phi-3 technical report: A highly capable language model locally on your phone. arXiv preprint arXiv:2404.14219 .\n",
       "\n",
       "Alfonso Amayuelas, Kyle Wong, Liangming Pan, Wenhu Chen, and William Yang Wang. 2024. Knowledge of knowledge: Exploring known-unknowns uncertainty with large language models. In Findings of the Association for Computational Linguistics ACL 2024 , pages 6416-6432.\n",
       "\n",
       "Amos Azaria and Tom Mitchell. 2023. The internal state of an llm knows when it's lying. In Findings of the Association for Computational Linguistics: EMNLP 2023 , pages 967-976.\n",
       "\n",
       "Collin Burns, Haotian Ye, Dan Klein, and Jacob Steinhardt. 2022. Discovering latent knowledge in language models without supervision. In The Eleventh International Conference on Learning Representations .\n",
       "\n",
       "Chao Chen, Kai Liu, Ze Chen, Yi Gu, Yue Wu, Mingyuan Tao, Zhihang Fu, and Jieping Ye. 2024a. Inside: Llms' internal states retain the power of hallucination detection. In ICLR .\n",
       "\n",
       "Lihu Chen, Alexandre Perez-Lebel, Fabian Suchanek, and GaÃ«l Varoquaux. 2024b. Reconfidencing llms from the grouping loss perspective. In Findings of the Association for Computational Linguistics: EMNLP 2024 , pages 1567-1581.\n",
       "\n",
       "Lihu Chen, Gael Varoquaux, and Fabian Suchanek. 2023. The locality and symmetry of positional encodings. In Findings of the Association for Computational Linguistics: EMNLP 2023 , pages 1431314331.\n",
       "\n",
       "Yung-Sung Chuang, Yujia Xie, Hongyin Luo, Yoon Kim, James R Glass, and Pengcheng He. 2023. Dola: Decoding by contrasting layers improves factuality in large language models. In The Twelfth International Conference on Learning Representations .\n",
       "\n",
       "Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, and 1 others. 2021. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168 .\n",
       "\n",
       "Roi Cohen, Konstantin Dobler, Eden Biran, and Gerard de Melo. 2024. I don't know: Explicit modeling of uncertainty with an [idk] token. Advances in Neural Information Processing Systems , 37:10935-10958.\n",
       "\n",
       "Armen Der Kiureghian and Ove Ditlevsen. 2009. Aleatory or epistemic? does it matter? Structural safety , 31(2):105-112.\n",
       "\n",
       "David Dohan, Winnie Xu, Aitor Lewkowycz, Jacob Austin, David Bieber, Raphael Gontijo Lopes, Yuhuai Wu, Henryk Michalewski, Rif A Saurous, Jascha Sohl-Dickstein, and 1 others. 2022. Language model cascades. arXiv preprint arXiv:2207.10342 .\n",
       "\n",
       "Jinhao Duan, Hao Cheng, Shiqi Wang, Alex Zavalny, Chenan Wang, Renjing Xu, Bhavya Kailkhura, and Kaidi Xu. 2024. Shifting attention to relevance: Towards the predictive uncertainty quantification of freeform large language models. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages 5050-5063.\n",
       "\n",
       "Marina Fomicheva, Shuo Sun, Lisa Yankovskaya, FrÃ©dÃ©ric Blain, Francisco GuzmÃ¡n, Mark Fishel, Nikolaos Aletras, Vishrav Chaudhary, and Lucia Specia. 2020. Unsupervised quality estimation for neural machine translation. Transactions of the Association for Computational Linguistics , 8:539-555.\n",
       "\n",
       "Jiahui Geng, Fengyu Cai, Yuxia Wang, Heinz Koeppl, Preslav Nakov, and Iryna Gurevych. 2024. A survey of confidence estimation and calibration in large language models. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers) , pages 6577-6595.\n",
       "\n",
       "Daniela Gottesman and Mor Geva. 2024. Estimating knowledge in large language models without generating a single token. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing , pages 3994-4019.\n",
       "\n",
       "Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad AlDahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, and 1 others. 2024. The llama 3 herd of models. arXiv preprint arXiv:2407.21783 .\n",
       "\n",
       "Neha Gupta, Harikrishna Narasimhan, Wittawat Jitkrittum, Ankit Singh Rawat, Aditya Krishna Menon, and Sanjiv Kumar. 2024. Language model cascades: Token-level uncertainty and beyond. In The Twelfth International Conference on Learning Representations .\n",
       "\n",
       "Stephen C Hora. 1996. Aleatory and epistemic uncertainty in probability elicitation with an example from hazardous waste management. Reliability Engineering &amp; System Safety , 54(2-3):217-223.\n",
       "\n",
       "Eyke HÃ¼llermeier and Willem Waegeman. 2021. Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and methods. Machine learning , 110(3):457-506.\n",
       "\n",
       "Mandar Joshi, Eunsol Choi, Daniel S Weld, and Luke Zettlemoyer. 2017. Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages 1601-1611.\n",
       "\n",
       "Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli Tran-Johnson, and 1 others. 2022. Language models (mostly) know what they know. arXiv preprint arXiv:2207.05221 .\n",
       "\n",
       "Sanyam Kapoor, Nate Gruver, Manley Roberts, Katherine M Collins, Arka Pal, Umang Bhatt, Adrian Weller, Samuel Dooley, Micah Goldblum, and Andrew Gordon Wilson. 2024. Large language models must be taught to know what they don't know. In The Thirtyeighth Annual Conference on Neural Information Processing Systems .\n",
       "\n",
       "Jannik Kossen, Jiatong Han, Muhammed Razzak, Lisa Schut, Shreshth Malik, and Yarin Gal. 2024. Semantic entropy probes: Robust and cheap hallucination detection in llms. arXiv preprint arXiv:2406.15927 .\n",
       "\n",
       "Lorenz Kuhn, Yarin Gal, and Sebastian Farquhar. 2023. Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation. In The Eleventh International Conference on Learning Representations .\n",
       "\n",
       "Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich KÃ¼ttler, Mike Lewis, Wen-tau Yih, Tim RocktÃ¤schel, and 1 others. 2020. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in neural information processing systems , 33:94599474.\n",
       "\n",
       "Moxin Li, Yong Zhao, Yang Deng, Wenxuan Zhang, Shuaiyi Li, Wenya Xie, See-Kiong Ng, and Tat-Seng Chua. 2024. Knowledge boundary of large language models: A survey. arXiv preprint arXiv:2412.12472 .\n",
       "\n",
       "Chin-Yew Lin and Franz Josef Och. 2004. Automatic evaluation of machine translation quality using longest common subsequence and skip-bigram statistics. In Proceedings of the 42nd annual meeting of the association for computational linguistics (ACL04) , pages 605-612.\n",
       "\n",
       "Zhen Lin, Shubhendu Trivedi, and Jimeng Sun. 2023. Generating with confidence: Uncertainty quantification for black-box large language models. Transactions on Machine Learning Research .\n",
       "\n",
       "Andrey Malinin and Mark Gales. 2021. Uncertainty estimation in autoregressive structured prediction. In International Conference on Learning Representations .\n",
       "\n",
       "Andrey Malinin, Anton Ragni, Kate Knill, and Mark Gales. 2017. Incorporating uncertainty into deep learning for spoken language assessment. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) , pages 45-50.\n",
       "\n",
       "Potsawee Manakul, Adian Liusie, and Mark Gales. 2023. Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing , pages 9004-9017.\n",
       "\n",
       "MistralAI. 2024. Mistral large: A general-purpose language model. https://mistral.ai/news/ mistral-large-2407/ .\n",
       "\n",
       "Ruiyang Ren, Yuhao Wang, Yingqi Qu, Wayne Xin Zhao, Jing Liu, Hua Wu, Ji-Rong Wen, and Haifeng Wang. 2025. Investigating the factual knowledge boundary of large language models with retrieval augmentation. In Proceedings of the 31st International Conference on Computational Linguistics , pages 3697-3715.\n",
       "\n",
       "Timo Schick, Jane Dwivedi-Yu, Roberto DessÃ¬, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. 2023. Toolformer: Language models can teach themselves to use tools. Advances in Neural Information Processing Systems , 36:68539-68551.\n",
       "\n",
       "Weijia Shi, Anirudh Ajith, Mengzhou Xia, Yangsibo Huang, Daogao Liu, Terra Blevins, Danqi Chen, and Luke Zettlemoyer. 2024. Detecting pretraining data from large language models. In The Twelfth International Conference on Learning Representations .\n",
       "\n",
       "Ola Shorinwa, Zhiting Mei, Justin Lidard, Allen Z Ren, and Anirudha Majumdar. 2024. A survey on uncertainty quantification of large language models: Taxonomy, open research challenges, and future directions. arXiv preprint arXiv:2412.05563 .\n",
       "\n",
       "Charlie Snell, Jaehoon Lee, Kelvin Xu, and Aviral Kumar. 2024. Scaling llm test-time compute optimally can be more effective than scaling model parameters. arXiv preprint arXiv:2408.03314 .\n",
       "\n",
       "Yifan Song, Guoyin Wang, Sujian Li, and Bill Yuchen Lin. 2024. The good, the bad, and the greedy: Evaluation of llms should not ignore non-determinism. arXiv preprint arXiv:2407.10457 .\n",
       "\n",
       "Asa Cooper Stickland and Iain Murray. 2020. Diverse ensembles improve calibration. arXiv preprint arXiv:2007.04206 .\n",
       "\n",
       "Qwen Team. 2024. Qwen2.5: A party of foundation models.\n",
       "\n",
       "Katherine Tian, Eric Mitchell, Allan Zhou, Archit Sharma, Rafael Rafailov, Huaxiu Yao, Chelsea Finn, and Christopher D Manning. 2023. Just ask for calibration: Strategies for eliciting calibrated confidence scores from language models fine-tuned with human feedback. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing , pages 5433-5442.\n",
       "\n",
       "Christian Tomani, Kamalika Chaudhuri, Ivan Evtimov, Daniel Cremers, and Mark Ibrahim. 2024. Uncertainty-based abstention in llms improves safety and reduces hallucinations. arXiv preprint arXiv:2404.10960 .\n",
       "\n",
       "Roman Vashurin, Ekaterina Fadeeva, Artem Vazhentsev, Lyudmila Rvanova, Daniil Vasilev, Akim Tsvigun, Sergey Petrakov, Rui Xing, Abdelrahman Sadallah, Kirill Grishchenkov, and 1 others. 2025. Benchmarking uncertainty quantification methods for large language models with lm-polygraph. Transactions of the Association for Computational Linguistics , 13:220-248.\n",
       "\n",
       "Hongru Wang, Boyang Xue, Baohang Zhou, Tianhua Zhang, Cunxiang Wang, Huimin Wang, Guanhua Chen, and Kam-fai Wong. 2024. Self-dc: When to reason and when to act? self divide-and-conquer for compositional unknown questions. arXiv preprint arXiv:2402.13514 .\n",
       "\n",
       "Johannes Welbl, Nelson F Liu, and Matt Gardner. 2017. Crowdsourcing multiple choice science questions. In Proceedings of the 3rd Workshop on Noisy Usergenerated Text , pages 94-106.\n",
       "\n",
       "Bingbing Wen, Jihan Yao, Shangbin Feng, Chenjun Xu, Yulia Tsvetkov, Bill Howe, and Lucy Lu Wang. 2024. Know your limits: A survey of abstention in large language models. arXiv preprint arXiv:2407.18418 .\n",
       "\n",
       "Zhihui Xie, Jizhou Guo, Tong Yu, and Shuai Li. 2024. Calibrating reasoning in language models with internal consistency. In The Thirty-eighth Annual Conference on Neural Information Processing Systems .\n",
       "\n",
       "Miao Xiong, Zhiyuan Hu, Xinyang Lu, YIFEI LI, Jie Fu, Junxian He, and Bryan Hooi. 2024. Can llms express their uncertainty? an empirical evaluation of confidence elicitation in llms. In The Twelfth International Conference on Learning Representations .\n",
       "\n",
       "Xunjian Yin, Xu Zhang, Jie Ruan, and Xiaojun Wan. 2024. Benchmarking knowledge boundary for large language models: A different perspective on model evaluation. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages 2270-2286.\n",
       "\n",
       "Hanning Zhang, Shizhe Diao, Yong Lin, Yi Fung, Qing Lian, Xingyao Wang, Yangyi Chen, Heng Ji, and Tong Zhang. 2024a. R-tuning: Instructing large language models to say 'i don't know'. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers) , pages 7106-7132.\n",
       "\n",
       "Jize Zhang, Bhavya Kailkhura, and T Yong-Jin Han. 2020. Mix-n-match: Ensemble and compositional methods for uncertainty calibration in deep learning. In International conference on machine learning , pages 11117-11128. PMLR.\n",
       "\n",
       "Mozhi Zhang, Mianqiu Huang, Rundong Shi, Linsen Guo, Chong Peng, Peng Yan, Yaqian Zhou, and Xipeng Qiu. 2024b. Calibrating the confidence of large language models by eliciting fidelity. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing , pages 29592979.\n",
       "\n",
       "Qiyuan Zhang, Fuyuan Lyu, Zexu Sun, Lei Wang, Weixu Zhang, Wenyue Hua, Haolun Wu, Zhihan Guo, Yufei Wang, Niklas Muennighoff, and 1 others. 2025. A survey on test-time scaling in large language models: What, how, where, and how well? arXiv preprint arXiv:2503.24235 .\n",
       "\n",
       "## A Example Appendix\n",
       "\n",
       "This is an appendix."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(docs[0].page_content)\n",
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d0d3eb-8af4-432f-a207-728ff62358ee",
   "metadata": {},
   "source": [
    "### UnstructuredLoader\n",
    "- ë‹¤ì–‘í•œ ë¹„ì •í˜• ë¬¸ì„œë“¤ì„ ì½ì–´ ì˜¤ëŠ” Unstrctured ë¥¼ ì‚¬ìš©í•´, ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë¬¸ì„œë“¤ì„ load í•´ RAG, ëª¨ë¸ íŒŒì¸íŠœë‹ì— ì ìš©í•  ìˆ˜ìˆê²Œ í•œë‹¤.\n",
    "  - ì§€ì› íŒŒì¼ í˜•ì‹: \"csv\", \"doc\", \"docx\", \"epub\", \"image\", \"md\", \"msg\", \"odt\", \"org\", \"pdf\", \"ppt\", \"pptx\", \"rtf\", \"rst\", \"tsv\", \"xlsx\"\n",
    "- **ë‹¤ì–‘í•œ í˜•ì‹ì˜ íŒŒì¼ë¡œ ë¶€í„° textë¥¼ ë¡œë”©**í•´ì•¼ í•  ê²½ìš° ìœ ìš©í•˜ë‹¤. \n",
    "- Localì— libraryë¥¼ ì„¤ì¹˜í•´ì„œ ì‚¬ìš©í•˜ê±°ë‚˜,  Unstructured ê°€ ì œê³µí•˜ëŠ” API serviceë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.\n",
    "  - https://docs.unstructured.io\n",
    "- í…ìŠ¤íŠ¸ íŒŒì¼, PDF, ì´ë¯¸ì§€, HTML, XML, ms-office(word, ppt), epub ë“± ë‹¤ì–‘í•œ ë¹„ì •í˜• ë°ì´í„° íŒŒì¼ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤.\n",
    "  - ì„¤ì¹˜, ì§€ì› ë¬¸ì„œ: https://docs.unstructured.io/open-source/installation/full-installation\n",
    "  - Langchain ë¬¸ì„œ: https://python.langchain.com/docs/integrations/document_loaders/unstructured_file\n",
    "\n",
    "> - UnstructuredLoader PDF Load ì‹œ Document ë¶„í•  ê¸°ì¤€\n",
    ">     -  ë¬¸ì„œì˜ êµ¬ì¡°ì™€ ì½˜í…ì¸ ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ë¶„í• í•´ Documentì— ë„£ëŠ”ë‹¤.\n",
    ">     -  ë¶„í•  ê¸°ì¤€\n",
    ">        - í—¤ë”(Header): ë¬¸ì„œì˜ ì œëª©ì´ë‚˜ ì„¹ì…˜ ì œëª© ë“±\n",
    ">        - ë³¸ë¬¸ í…ìŠ¤íŠ¸(NarrativeText): ì¼ë°˜ì ì¸ ë¬¸ë‹¨ì´ë‚˜ ì„¤ëª…ë¬¸\n",
    ">        - í‘œ(Table): ë°ì´í„°ê°€ í‘œ í˜•ì‹ìœ¼ë¡œ êµ¬ì„±ëœ ë¶€ë¶„\n",
    ">        - ë¦¬ìŠ¤íŠ¸(List): ìˆœì„œê°€ ìˆê±°ë‚˜ ì—†ëŠ” ëª©ë¡\n",
    ">        - ì´ë¯¸ì§€(Image): ì‚¬ì§„ì´ë‚˜ ê·¸ë˜í”½ ìš”ì†Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87686d9-03d9-401a-9573-d57a2aacf965",
   "metadata": {},
   "source": [
    "#### ì„¤ì¹˜í•  í”„ë¡œê·¸ë¨\n",
    "- poppler\n",
    "  - pdf íŒŒì¼ì„ textë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ í•„ìš”í•œ í”„ë¡œê·¸ë¨\n",
    "  - windows: https://github.com/oschwartz10612/poppler-windows/releases/ ì—ì„œ ìµœì‹  ë²„ì „ ë‹¤ìš´ë¡œë“œ í›„ ì••ì¶• í’€ì–´ì„œ ì„¤ì¹˜.\n",
    "    - í™˜ê²½ë³€ìˆ˜ Pathì— \"ì„¤ì¹˜ê²½ë¡œ\\Library\\bin\" ì„ ì¶”ê°€. (ì„¤ì¹˜ í›„ IDEë¥¼ ë‹¤ì‹œ ì‹œì‘í•œë‹¤.)\n",
    "  - macOS: `brew install poppler`\n",
    "  - Linux: `sudo apt-get install poppler-utils`\n",
    "- tesseract-ocr\n",
    "  - OCR ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ pdf ì´ë¯¸ì§€ë¥¼ textë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ í•„ìš”í•œ í”„ë¡œê·¸ë¨ \n",
    "  - windows: https://github.com/UB-Mannheim/tesseract/wiki ì—ì„œ ë‹¤ìš´ë°›ì•„ ì„¤ì¹˜. \n",
    "    - í™˜ê²½ë³€ìˆ˜ Pathì— ì„¤ì¹˜ ê²½ë¡œ(\"C:\\Program Files\\Tesseract-OCR\") ì¶”ê°€ í•œë‹¤. (ì„¤ì¹˜ í›„ IDEë¥¼ ë‹¤ì‹œ ì‹œì‘í•œë‹¤.)\n",
    "  - macOS: `brew install tesseract`\n",
    "  - linux(unbuntu): `sudo apt install tesseract-ocr`\n",
    "- ì„¤ì¹˜ í•  íŒ¨í‚¤ì§€\n",
    "  - **libmagic ì„¤ì¹˜**\n",
    "      - windows: `pip install python-magic-bin -qU`\n",
    "      - macOS: `brew install libmagic`\n",
    "      - linux(ubuntu): `sudo apt-get install libmagic-dev`\n",
    "  - `pip install \"unstructured[pdf]\" -qU`\n",
    "      - ë¬¸ì„œ í˜•ì‹ë³„ë¡œ sub moduleì„ ì„¤ì¹˜í•œë‹¤. (pdf, docx ..)\n",
    "      - ëª¨ë“  sub module ì„¤ì¹˜: `pip install unstructured[all-docs]`\n",
    "      - https://docs.unstructured.io/open-source/installation/full-installation\n",
    "  - `pip install langchain-unstructured -qU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d98a32d3-b64c-427f-8663-86e00ee88f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-unstructured in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (0.1.6)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-unstructured) (0.3.63)\n",
      "Requirement already satisfied: onnxruntime<=1.19.2,>=1.17.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-unstructured) (1.19.2)\n",
      "Requirement already satisfied: unstructured-client<1,>=0.27.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-unstructured) (0.36.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (0.3.44)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (4.14.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (2.11.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (0.16.0)\n",
      "Requirement already satisfied: coloredlogs in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (25.2.10)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (2.2.6)\n",
      "Requirement already satisfied: protobuf in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (6.31.1)\n",
      "Requirement already satisfied: sympy in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (1.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (2.4.0)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured) (24.1.0)\n",
      "Requirement already satisfied: cryptography>=3.1 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured) (45.0.4)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured) (1.6.0)\n",
      "Requirement already satisfied: pypdf>=4.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured) (5.6.0)\n",
      "Requirement already satisfied: cffi>=1.14 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from cryptography>=3.1->unstructured-client<1,>=0.27.0->langchain-unstructured) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from cffi>=1.14->cryptography>=3.1->unstructured-client<1,>=0.27.0->langchain-unstructured) (2.22)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from coloredlogs->onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from sympy->onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-unstructured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324e4182",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e95e735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured\n",
      "  Using cached unstructured-0.17.2-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting chardet (from unstructured)\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: filetype in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured) (1.2.0)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Using cached python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: lxml in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured) (5.4.0)\n",
      "Collecting nltk (from unstructured)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: requests in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured) (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured) (4.13.4)\n",
      "Collecting emoji (from unstructured)\n",
      "  Using cached emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: dataclasses-json in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured) (0.6.7)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Using cached python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Using cached langdetect-1.0.9-py3-none-any.whl\n",
      "Requirement already satisfied: numpy in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured) (2.2.6)\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Using cached rapidfuzz-3.13.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting backoff (from unstructured)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: typing-extensions in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured) (4.14.0)\n",
      "Requirement already satisfied: unstructured-client in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured) (0.36.0)\n",
      "Collecting wrapt (from unstructured)\n",
      "  Using cached wrapt-1.17.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: tqdm in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured) (4.67.1)\n",
      "Requirement already satisfied: psutil in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured) (7.0.0)\n",
      "Collecting python-oxmsg (from unstructured)\n",
      "  Using cached python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting html5lib (from unstructured)\n",
      "  Using cached html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from beautifulsoup4->unstructured) (2.7)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from dataclasses-json->unstructured) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (24.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from html5lib->unstructured) (1.17.0)\n",
      "Collecting webencodings (from html5lib->unstructured)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: click in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from nltk->unstructured) (8.2.1)\n",
      "Requirement already satisfied: joblib in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from nltk->unstructured) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from nltk->unstructured) (2024.11.6)\n",
      "Collecting olefile (from python-oxmsg->unstructured)\n",
      "  Using cached olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from requests->unstructured) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from requests->unstructured) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from requests->unstructured) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from requests->unstructured) (2025.4.26)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured-client->unstructured) (24.1.0)\n",
      "Requirement already satisfied: cryptography>=3.1 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured-client->unstructured) (45.0.4)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured-client->unstructured) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured-client->unstructured) (1.6.0)\n",
      "Requirement already satisfied: pydantic>=2.11.2 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured-client->unstructured) (2.11.5)\n",
      "Requirement already satisfied: pypdf>=4.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured-client->unstructured) (5.6.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from unstructured-client->unstructured) (1.0.0)\n",
      "Requirement already satisfied: cffi>=1.14 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from cffi>=1.14->cryptography>=3.1->unstructured-client->unstructured) (2.22)\n",
      "Requirement already satisfied: anyio in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (0.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/giwonjun/anaconda3/envs/lang_env/lib/python3.12/site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.3.1)\n",
      "Using cached unstructured-0.17.2-py3-none-any.whl (1.8 MB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Using cached emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "Using cached html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
      "Using cached python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Using cached python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
      "Using cached olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Using cached rapidfuzz-3.13.0-cp312-cp312-macosx_11_0_arm64.whl (1.4 MB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Using cached wrapt-1.17.2-cp312-cp312-macosx_11_0_arm64.whl (38 kB)\n",
      "Installing collected packages: webencodings, wrapt, rapidfuzz, python-magic, python-iso639, olefile, nltk, langdetect, html5lib, emoji, chardet, backoff, python-oxmsg, unstructured\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14/14\u001b[0m [unstructured][0m [unstructured]\n",
      "\u001b[1A\u001b[2KSuccessfully installed backoff-2.2.1 chardet-5.2.0 emoji-2.14.1 html5lib-1.1 langdetect-1.0.9 nltk-3.9.1 olefile-0.47 python-iso639-2025.2.18 python-magic-0.4.27 python-oxmsg-0.0.2 rapidfuzz-3.13.0 unstructured-0.17.2 webencodings-0.5.1 wrapt-1.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install unstructured\n",
    "# brew install qpdf  -> ì‹¤í–‰ í•„ìš” -> pip install \"unstructured[pdf]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a51647fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: pikepdf C++ to Python logger bridge initialized\n"
     ]
    }
   ],
   "source": [
    "from langchain_unstructured import UnstructuredLoader\n",
    "# path = \"data/olympic.txt\"\n",
    "# path = \"papers/1.pdf\"\n",
    "path = [\"data/olympic.txt\", \"papers/1.pdf\"]\n",
    "loader = UnstructuredLoader(path)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b20ea58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef294226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'papers/1.pdf',\n",
       " 'coordinates': {'points': ((70.866, 338.5113216),\n",
       "   (70.866, 403.26892159999994),\n",
       "   (290.7855161390001, 403.26892159999994),\n",
       "   (290.7855161390001, 338.5113216)),\n",
       "  'system': 'PixelSpace',\n",
       "  'layout_width': 595.276,\n",
       "  'layout_height': 841.89},\n",
       " 'file_directory': 'papers',\n",
       " 'filename': '1.pdf',\n",
       " 'languages': ['eng'],\n",
       " 'last_modified': '2025-06-13T08:55:22',\n",
       " 'page_number': 10,\n",
       " 'parent_id': 'c0ff9d37ae73259855ed24d509a77b06',\n",
       " 'filetype': 'application/pdf',\n",
       " 'category': 'NarrativeText',\n",
       " 'element_id': 'e1d2951b77c3895facdfdac2c0f93dec'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[300].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bc7e7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ê° ì˜¬ë¦¼í”½ ì¢…ëª©ë“¤ì€ IOCë¡œë¶€í„° ìŠ¹ì¸ì„ ë°›ì€ êµ­ì œê²½ê¸°ì—°ë§¹ì˜ ê´€ë¦¬ë¥¼ ë°›ëŠ”ë‹¤. 35ê°œì˜ ì—°ë§¹ì´ IOCì—ì„œ ìŠ¹ì¸ì„ ë°›ì•˜ìœ¼ë©°, ìŠ¹ì¸ì„ ë°›ì•˜ì§€ë§Œ í˜„ì¬ ì •ì‹ì¢…ëª©ì´ ì•„ë‹Œ ì¢…ëª©ì„ ê°ë…í•˜ëŠ” ì—°ë§¹ë„ ìˆë‹¤. IOCì˜ ìŠ¹ì¸ì„ ë°›ì•˜ì§€ë§Œ ì˜¬ë¦¼í”½ ì¢…ëª©ì´ ì•„ë‹Œ ìŠ¤í¬ì¸ ë“¤ì€ ì˜¬ë¦¼í”½ ì¢…ëª©ìœ¼ë¡œ ê³ ë ¤ë˜ì§€ëŠ” ì•Šìœ¼ë‚˜, ì˜¬ë¦¼í”½ì´ ëë‚œ í›„ ì²˜ìŒìœ¼ë¡œ ì—´ë¦¬ëŠ” IOCì´íšŒ ë•Œë§ˆë‹¤ ì •ì‹ì¢…ëª©ì´ ë˜ë„ë¡ ì‹ ì²­ì„ í•  ìˆ˜ëŠ” ìˆë‹¤. IOC ì´íšŒ ë•Œ ì •ì‹ì¢…ëª© ì„ ì •ì€ ì´íšŒì— ì°¸ì„ì¤‘ì¸ IOCìœ„ì›ë“¤ì˜ íˆ¬í‘œë¥¼ í†µí•´ ì´ë£¨ì–´ì§€ë©°, ì¬ì  ìœ„ì› ìˆ˜ì˜ ê³¼ë°˜ìˆ˜ ì´ìƒ ì°¬ì„±í‘œë¥¼ ì–»ì–´ì•¼ ì •ì‹ì¢…ëª©ìœ¼ë¡œ ì¸ì •ì„ ë°›ëŠ”ë‹¤. IOCì˜ ìŠ¹ì¸ì„ ë°›ì€ ìŠ¤í¬ì¸ ì´ë‚˜ ì°¬ì„±í‘œë¥¼ ë°›ì§€ ëª»í•´ ì •ì‹ì¢…ëª©ì´ ë˜ì§€ ëª»í•œ ìŠ¤í¬ì¸ ë¡œëŠ” ì²´ìŠ¤ì™€ ì„œí•‘ê³¼ ê°™ì€ ê²ƒì´ ìˆë‹¤.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[10].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8efaff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4acfcbe1-cc26-4e87-8c41-d6fa7d461701",
   "metadata": {},
   "source": [
    "### Directory ë‚´ì˜ ë¬¸ì„œíŒŒì¼ë“¤ ë¡œë”©\n",
    "- DirectoryLoader ì´ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b8eb4d8-3c1d-418d-a499-ee181d54b759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING: Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    \"data\", # ì½ì–´ë“¤ì¼ ë¬¸ì„œë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬.\n",
    "    recursive=True, # í•˜ìœ„ë””ë ‰í† ë¦¬ê¹Œì§€ ê²€ìƒ‰í• ì§€ ì—¬ë¶€.\n",
    ")\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10ebc232-48ae-4cd2-ab3a-f6e26bd95ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1\\n\\në°°ë”°ë¼ê¸°\\n\\nExported from Wikisource on 2024ë…„ 11ì›” 24ì¼\\n\\n2\\n\\nğŸ™ğŸ™Ÿ\\n\\nì¢‹ì€ ì¼ê¸°ì´ë‹¤.\\n\\nì¢‹ì€ ì¼ê¸°ë¼ë„, í•˜ëŠ˜ì— êµ¬ë¦„ í•œ ì  ì—†ëŠ” - ìš°ë¦¬ â€˜ì‚¬ëŒâ€™ìœ¼ë¡œì„œ ëŠ” ê°íˆ ì ‘ê·¼ ëª»í•  ìœ„ì—„ì„ ê°€ì§€ê³ , ë†’ì´ì„œ ìš°ë¦¬ ì¡°ê·¸ë§Œ â€˜ì‚¬ ëŒâ€™ì„ ë¹„ì›ƒëŠ” ë“¯ì´ ë‚´ë ¤ë‹¤ë³´ëŠ”, ê·¸ëŸ° êµë§Œí•œ í•˜ëŠ˜ì€ ì•„ë‹ˆê³ , ê°€ì¥ ìš°ë¦¬ â€˜ì‚¬ëŒâ€™ì˜ ì´í•´ìì¸ ë“¯ì´ ë‚®ì¶” ë­‰ê¸€ë­‰ê¸€ ì—‰ê¸°ëŠ” ë¶„ í™ë¹› êµ¬ë¦„ìœ¼ë¡œì„œ ìš°ë¦¬ì™€ ì„œë¡œ ì†ëª©ì„ ì¡ìëŠ” ê·¸ëŸ° í•˜ëŠ˜ì´ë‹¤. ì‚¬ë‘ì˜ í•˜ëŠ˜ì´ë‹¤.\\n\\në‚˜ëŠ” ì ì‹œë„ ë©ì§€ ì•Šê³ , í‘¸ë¥¸ ë¬¼ì„ í™©í•´ë¡œ ë¶€ì–´ ë‚´ë¦¬ëŠ” ëŒ€ë™ ê°•ì„ í–¥í•œ, ëª¨ë€ë´‰ ê¸°ìŠ­ ìƒˆíŒŒë—ê²Œ ë‹ì•„ë‚˜ëŠ” í’€ ìœ„ì— ë’¹êµ´ê³  ìˆì—ˆë‹¤.\\n\\nì´ë‚ ì€ ì‚¼ì›” ì‚¼ì§ˆ, ëŒ€ë™ê°•ì— ì²« ë±ƒë†€ì´í•˜ëŠ” ë‚ ì´ë‹¤. ê¹Œë§£ê²Œ ë‚´ë ¤ë‹¤ë³´ì´ëŠ” ë¬¼ ìœ„ì—ëŠ”, ê²°ê²°ì´ ë°˜ì§ì´ëŠ” ë¬¼ê²°ì„ í‘¸ë¥¸ ë†€ì‡ ë°°ë“¤ì´ íƒ€ê³  ë„˜ìœ¼ë©°, ê±°ê¸°ì„œëŠ” ë´„ í–¥ê¸°ì— ì·¨í•œ í˜•í˜•ìƒ‰ìƒ‰ì˜ ì„ ìœ¨ì´, ìš°ë‹¨ë³´ë‹¤ë„ ë¶€ë“œëŸ¬ìš´ ë´„ ê³µê¸°ë¥¼ í”ë“¤ë©´ì„œ ë‚ ì•„ì˜¨ë‹¤.\\n\\nê·¸ë¦¬ê³  ê±°ê¸°ì„œ ê¸°ìƒë“¤ì˜ ë…¸ë˜ì™€ í•¨ê»˜ ë‚ ì•„ì˜¤ëŠ” ì¡°ì„  ì•„ì•… (é›…æ¨‚)ì€ ëŠë¦¬ê²Œ, ê¸¸ê²Œ, ìœ ì¥í•˜ê²Œ, ë¶€ë“œëŸ½ê²Œ, ê·¸ë¦¬ê³  ë˜ ì• ì²˜ ë¡­ê²Œ, ëª¨ë“  ë´„ì˜ ì •ë‹¤ì›€ê³¼ ëê¹Œì§€ ì¡°í™”í•˜ì§€ ì•Šê³ ëŠ” ì•ˆë‘ê² ë‹¤ ëŠ” ë“¯ì´ ëŒ€ë™ê°•ì— íë¥´ëŠ” ì‹œêº¼ë¨¼ ë´„ ë¬¼, ì²­ë¥˜ë²½ì— ë‹ì•„ë‚˜ëŠ” í‘¸ë¥´ë¥¸ í‘¸ëŸ¬ìŒ, ì‹¬ì§€ì–´ ì‚¬ëŒì˜ ê°€ìŠ´ì†ì— ë´„ì— ë›°ë…¸ëŠ” ë¶ˆë¶™ëŠ” í•ì¤„ê¸°ê¹Œì§€ë¼ë„, ìŠµê¸° ë§ì€ ë´„ ê³µê¸°ë¥¼ ë‹¤ë¦¬ ë†“ê³  ë–¨ë¦¬ì§€ ì•Š ê³ ëŠ” ë‘ì§€ ì•ŠëŠ”ë‹¤.\\n\\në´„ì´ë‹¤. ë´„ì´ ì™”ë‹¤.\\n\\n3\\n\\në¶€ë“œëŸ½ê²Œ ë¶€ëŠ” ì¡°ê·¸ë§Œ ë°”ëŒì´, ì‹œêº¼ë¨¼ ì¡°ì„  ì†”ì„ ê¿°ë©°, ë˜ëŠ” ë‹ì•„ë‚˜ëŠ” í’€ì„ ìŠ¤ì¹˜ê³  ì§€ë‚˜ê°ˆ ë•Œì˜ ê·¸ ìŒì•…ì€, ë‹¤ë¥¸ ë°ì„œëŠ” ë“£ì§€ ëª»í•  ì•„ë¦„ë‹¤ìš´ ìŒì•…ì´ë‹¤.\\n\\nì•„ì•„, ì‚¬ëŒì„ ì·¨ì¼€ í•˜ëŠ” í‘¸ë¥´ë¥¸ ë´„ì˜ ì•„ë¦„ë‹¤ì›€ì´ì—¬! ì—´ ë‹¤ì„¯ ì‚´ë¶€í„°ì˜ ë™ê²½(æ±äº¬) ìƒí™œì—, ë§ˆìŒê» ì´ëŸ° ë´„ì„ ë³´ì§€ ëª»í•˜ì˜€ ë˜ ë‚˜ëŠ”, ëŠ˜ ì´ê²ƒì„ ë³´ëŠ” ì‚¬ëŒë³´ë‹¤ ê³± ì´ìƒì˜ ê°ëª…ì„ ì—¬ê¸°ì„œ ë°›ì§€ ì•Šì„ ìˆ˜ ì—†ë‹¤.\\n\\ní‰ì–‘ì„± ë‚´ì—ëŠ”, ê²¨ìš° íˆ­íˆ­ í„°ì§„ ë•…ì„ í—¤ì¹˜ë©´ íŒŒë¦‡íŒŒë¦‡ ë‹ì•„ ë‚˜ëŠ” ë‚˜ë¬´ìƒˆê¸°ì™€ ë‹ì•„ë‚˜ë ¤ëŠ” ë²„ë“¤ì˜ ì–´ìŒìœ¼ë¡œ ë´„ì´ ì˜¨ ì¤„ ì•Œ ë¿, ì•„ì§ ì™„ì „íˆ ë´„ì´ ì•ˆ ì´ë¥´ë €ì§€ë§Œ, ì´ ëª¨ë€ë´‰ ì¼ëŒ€ì™€ ëŒ€ë™ ê°•ì„ ë„˜ì–´ ë³´ì´ëŠ” ê°€ë‚˜ì•ˆ ì˜¥í† ë¥¼ ì—°ìƒì‹œí‚¤ëŠ” ì¥ë¦¼(â»‘æ—)ì— ëŠ” ë§ˆìŒê» ë´„ì˜ ì •ë‹¤ì›€ì´ ì´ë¥´ë €ë‹¤.\\n\\nê·¸ë¦¬ê³  ë˜ ê½¤ ìë€ ë°€ ë³´ë¦¬ë“¤ë¡œ ìƒˆíŒŒë—ê²Œ ì¥ì‹í•œ ì¥ë¦¼ì˜ ê·¸ í‘¸ë¥¸ ë¹›. ë§Œì¡±í•œ ì›ƒìŒì„ ë ê³  ê·¸ ë²Œì— ì„œì„œ ë‚´ë‹¤ë³´ëŠ” ë†ë¶€ì˜ ëª¨ì–‘ì€, ë³´ì§€ ì•Šì•„ë„ ìƒê°í•  ìˆ˜ê°€ ìˆë‹¤.\\n\\nêµ¬ë¦„ì€ ìê¾¸ í•˜ëŠ˜ì„ ë‚ ì•„ë‹¤ë‹ˆëŠ” ëª¨ì–‘ì´ë‹¤. ê·¸ ë°€ ìœ„ì— ë¹„ì¹˜ ì—ˆë˜ êµ¬ë¦„ì˜ ê·¸ë¦¼ìëŠ” ê·¸ êµ¬ë¦„ê³¼ í•¨ê»˜ ì €í¸ìœ¼ë¡œ ë¬¼ëŸ¬ê°€ë©°, ê±°ê¸°ëŠ” ì„¸ê³„ë¥¼ ì•„ê¹Œ ë§Œë“¤ì–´ë†“ì€ ê²ƒ ê°™ì€ ìƒˆë¡œìš´ ë…¹ë¹›ì´ í¼ì ¸ ë‚˜ê°„ë‹¤. ë°”ëŒì´ë‚˜ ì¡°ê¸ˆ ë¶€ëŠ” ë•ŒëŠ” ê·¸ ì˜ ìë€ ë°€ë“¤ì€ ë¬¼ê²°ê°™ ì´ ëˆ„ì› ë‹¤ ì¼ì–´ë‚¬ë‹¤, ì¼ë¡ ì¼ì²­ìœ¼ë¡œ ì¶¤ì„ ì¶˜ë‹¤. ê·¸ë¦¬ê³  ë´„ì˜ í•œê°€í•¨ì„ ì°¬ì†¡í•˜ëŠ” ì†”ê°œë“¤ì€, ë†’ì€ í•˜ëŠ˜ì—ì„œ ë™ê·¸ë¼ë¯¸ë¥¼ ê·¸ ë¦¬ë©´ì„œ ë”ìš± ë” ì•„ë¦„ë‹¤ìš´ ë´„ì— í–¥ê·¸ëŸ¬ìš´ ì •ì·¨ë¥¼ ë”í•œë‹¤.\\n\\nâ€œë‹¤ìŠ¤í•œ ë´„ ì •ì— ì†Ÿì•„ë‚˜ë¦¬ë‹¤. ë‹¤ìŠ¤í•œ ë´„ ì •ì— ì†Ÿì•„ë‚˜ë¦¬ë‹¤.â€\\n\\n4\\n\\në‚˜ëŠ” ë‘ì–´ ë²ˆ ì†Œë¦¬ë‚˜ê²Œ ìŠì€ ë’¤ì— ë‹´ë°°ë¥¼ ë¶™ì—¬ ë¬¼ì—ˆë‹¤. ë‹´ë±ƒ ë‚´ëŠ” ë¬´ëŸ­ë¬´ëŸ­ í•˜ëŠ˜ë¡œ ì˜¬ë¼ê°„ë‹¤. í•˜ëŠ˜ì—ë„ ë´„ì´ ì™”ë‹¤.\\n\\ní•˜ëŠ˜ì€ ë‚®ì•˜ë‹¤. ëª¨ë€ë´‰ ê¼­ëŒ€ê¸°ì— ì˜¬ë¼ê°€ë©´ ë„‰ë„‰íˆ ë§Œì§ˆ ìˆ˜ê°€ ìˆìœ¼ë¦¬ë§Œí¼ í•˜ëŠ˜ì€ ë‚®ë‹¤. ê·¸ë¦¬ê³  ê·¸ ë‚®ì€ í•˜ëŠ˜ë³´ë‹¤ëŠ” ì˜¤íˆë ¤ ë” ë†’ì´ ìˆëŠ” ë“¯í•œ ë¶„í™ë¹› êµ¬ë¦„ì€, ë­‰ê¸€ë­‰ê¸€ ì—‰ê¸°ë©´ì„œ ì´ë¦¬ ì €ë¦¬ ë‚ ì•„ë‹¤ë‹Œë‹¤.\\n\\në‚˜ëŠ” ì´ëŸ¬í•œ ì•„ë¦„ë‹¤ìš´ ë´„ ê²½ì¹˜ì— ì´ë ‡ê²Œ ë§ˆìŒê» ë´„ì˜ ì†ì‚­ì„ ì„ ë“¤ì„ ë•ŒëŠ”, ì–¸ì œë“  ìœ í† í”¼ì•„ë¥¼ ì•„ë‹ˆ ìƒê°í•  ìˆ˜ ì—†ë‹¤. ìš°ë¦¬ ê°€ ì‹œì‹œê°ê°ìœ¼ë¡œ ì• ë¥¼ ì“°ë©° ìˆ˜ê³ í•˜ëŠ” ê²ƒì€ - ê·¸ ëª©ì ì€ ë¬´ì—‡ ì¸ê°€? ì—­ì‹œ ìœ í† í”¼ì•„ ê±´ì„¤ì— ìˆì§€ ì•Šì„ê¹Œ? ìœ í† í”¼ì•„ë¥¼ ìƒê° í•  ë•ŒëŠ” ì–¸ì œë“  ê·¸ â€˜ìœ„ëŒ€í•œ ì¸ê²©ì˜ ì†Œìœ ìâ€™ë©° â€˜ì‚¬ëŒì˜ ìœ„ëŒ€í•¨ ì„ ëê¹Œì§€ ì¦ê¸´â€™ ì§„ë‚˜ë¼ ì‹œí™©(ç§¦å§‹çš‡)ì„ ìƒê°ì§€ ì•Šì„ ìˆ˜ ì—† ë‹¤.\\n\\nìš°ë¦¬ê°€ ì–´ì°Œí•˜ë©´ ì£½ì§€ë¥¼ ì•„ë‹ˆí• ê¹Œ í•˜ì—¬, ì†Œë…„ ì‚¼ë°±ì„ ë°°ë¥¼ íƒœì›Œ ë¶ˆì‚¬ì•½ì„ êµ¬í•˜ëŸ¬ ë– ë‚˜ë³´ë‚´ë©°, ì˜ˆìˆ ì˜ ì‚¬ì¹˜ë¥¼ ë‹¤í•˜ì—¬ ì•„ ë°©ê¶ì„ ì§€ìœ¼ë©° ë§¤ì¼ ì‹ í•˜ ëª‡ ì²œ ëª…ê³¼ ì”ì¹˜ë¡œì¨ ì¦ê¸°ë©°, ì´ë¦¬ í•˜ì—¬ ì—¬ê¸° í•œ ìœ í† í”¼ì•„ë¥¼ ì„¸ìš°ë ¤ë˜ ì‹œí™©ì€, ëª‡ë§Œì˜ ì—­ì‚¬ê°€ê°€ ì–´ë–»ë‹¤ê³  ìš•ì„ í•˜ë“ , ê·¸ëŠ” ì •ë§ë¡œ ì¸ìƒì˜ í–¥ë½ìë©° ì—­ì‚¬ ì´ í›„ì˜ ì œì¼ í° ìœ„ì¸ì´ë¼ê³  í•  ìˆ˜ê°€ ìˆë‹¤. ê·¸ë§Œí•œ ìˆœì „í•œ ìš©ê¸° ìˆëŠ” ì‚¬ëŒì´ ìˆê³ ì•¼ ìš°ë¦¬ ì¸ë¥˜ì˜ ì—­ì‚¬ëŠ” ëì´ ë‚ ì§€ë¼ë„ í•œ â€˜ì‚¬ëŒâ€™ì„ ê°€ì¡Œì—ˆë‹¤ê³  í•  ìˆ˜ ìˆë‹¤.\\n\\nâ€œí°ì‚¬ëŒì´ì—ˆì—ˆë‹¤.â€\\n\\ní•˜ë©´ì„œ ë‚˜ëŠ” ë¨¸ë¦¬ë¥¼ ë“¤ì—ˆë‹¤.\\n\\n5\\n\\nì´ë•Œë‹¤. ê¸°ìë¬˜ ê·¼ì²˜ì—ì„œ ë¬´ìŠ¨ ìŠ¬í”ˆ ìŒë¥ ì´, ë´„ ê³µê¸°ë¥¼ ì§„ë™ ì‹œí‚¤ë©° ë‚ ì•„ì˜¤ëŠ” ê²ƒì´ ë“¤ë ¸ë‹¤.\\n\\në‚˜ëŠ” ë¬´ì‹¬ì½” ê·€ë¥¼ ê¸°ìš¸ì˜€ë‹¤.\\n\\nâ€˜ì˜ìœ  ë°°ë”°ë¼ê¸°â€™ë‹¤. ê·¸ê²ƒë„ ì›¬ë§Œí•œ ê´‘ëŒ€ë‚˜ ê¸°ìƒì€ ë°œê¿ˆì¹˜ì— ë„ ë¯¸ì¹˜ì§€ ëª»í•˜ë¦¬ë§Œí¼ - ê·¸ë§Œí¼ ê·¸ ë°°ë”°ë¼ê¸°ì˜ ì£¼ì¸ì€ ì˜ ë¶€ ë¥´ëŠ” ì‚¬ëŒì´ì—ˆë‹¤.\\n\\në¹„ë‚˜ì´ë‹¤, ë¹„ë‚˜ì´ë‹¤. ì‚°ì²œí›„í†  ì¼ì›”ì„±ì‹  í•˜ë‚˜ë‹˜ì „ ë¹„ë‚˜ì´ë‹¤. ì‹¤ë‚±ê°™ì€ ìš°ë¦¬ëª©ìˆ¨ ì‚´ë ¤ë‹¬ë¼ ë¹„ë‚˜ì´ë‹¤. ì—ì—ì•¼, ì–´ê·¸ì—¬ì§€ì•¼.\\n\\nì—¬ê¸°ê¹Œì§€ ì´ë¥´ë €ì„ ë•Œì— ì €í¸ ì•„ë˜ ë¬¼ì—ì„œ ì¥ê³  ì†Œë¦¬ì™€ í•¨ê»˜ ê¸°ìƒì˜ ë…¸ë˜ê°€ ìš¸ë¦¬ì–´ì˜¤ë©° ë°°ë”°ë¼ê¸°ëŠ” ê·¸ë§Œ ì•ˆ ë“¤ë¦¬ê²Œ ë˜ì—ˆ ë‹¤. ë‚˜ëŠ” ì´ë…„ ì „ í•œì—¬ë¦„ì„ ì˜ìœ ì„œ ì§€ë‚´ë³¸ ì¼ì´ ìˆë‹¤. ë°°ë”°ë¼ ê¸°ì˜ ë³¸ê³ ì¥ì¸ ì˜ìœ ë¥¼ ëª‡ ë‹¬ ìˆì–´ë³¸ ì‚¬ëŒì€ ê·¸ ë°°ë”°ë¼ê¸°ì— ëŒ€í•˜ì—¬ ì–¸ì œë“  í•œ ì†ì ˆì—†ëŠ” ì• ì²˜ë¡œì›€ì„ ê¹¨ë‹¬ì„ ê²ƒì´ë‹¤.\\n\\nì˜ìœ , ì´ë¦„ì€ ëª¨ë¥´ì§€ë§Œ ì‚°ì— ì˜¬ë¼ê°€ì„œ ë‚´ë ¤ë‹¤ë³´ë©´ ì•ì€ ë§ë§ í•œ í™©í•´ì´ë‹ˆ, ê·¸ê³³ ì €ë…ë•Œì˜ ê²½ì¹˜ëŠ” í•œë²ˆ ë³¸ ì‚¬ëŒì€ ì˜êµ¬íˆ ìŠì„ ìˆ˜ê°€ ì—†ìœ¼ë¦¬ë¼. ë¶ˆë©ì´ ê°™ì€ ì»¤ë‹¤ë€ ì‹œë»˜ê±´ í•´ê°€, ë‚¨ì‹¤ ë‚¨ì‹¤ ë„˜ì¹˜ëŠ” ë°”ë‹¤ì— ë„ë¡œ ë¹ ì§ˆ ë“¯, ë„ë¡œ ì†Ÿì•„ì˜¤ë¥¼ ë“¯ ì¶¤ì„ ì¶” ë©°, ê±°ê¸°ì„œ ë•Œë•Œë¡œ ë³´ì´ì§€ ì•ŠëŠ” ë°°ì—ì„œ ë°°ë”°ë¼ê¸°ë§Œ ìŠ¬í”„ê²Œ ë‚ ì•„ì˜¤ëŠ” ê²ƒì„ ë“¤ì„ ë•Œì—” ëˆˆë¬¼ ë§ì€ ë‚˜ëŠ” ë•Œë•Œë¡œ ëˆˆë¬¼ì„ í˜ ë ¸ë‹¤. ì´ë¡œ ë³´ì•„ì„œ, ì–´ë–¤ ì›ì˜ ì•„ë‚´ê°€ ìê¸°ì˜ ëª¨ë“  ì˜í™”ë¥¼ ë‚¡ ì€ ì‹ ê°™ì´ ë‚´ì–´ ë˜ì§€ê³  ë±ƒì‚¬ëŒê³¼ ì •ì²˜ ì—†ëŠ” ë¬¼ê¸¸ì„ ë– ë‚¬ë‹¤ í•¨ë„ ë¯¿ì§€ ëª»í•  ë§ì´ë„ ìˆ˜ê°€ ì—†ë‹¤.\\n\\n6\\n\\nì˜ìœ ì„œ ëŒì•„ì˜¨ ë’¤ì—ë„ ê·¸ ë°°ë”°ë¼ê¸°ëŠ” ë‚´ ë§ˆìŒì— ê¹Šì´ ìƒˆê¸°ì–´ ì ¸ ìŠì„ ìˆ˜ê°€ ì—†ì—ˆê³  ì–¸ì œ í•œë²ˆ ë‹¤ì‹œ ì˜ìœ ë¥¼ ê°€ì„œ ê·¸ ë…¸ë˜ë¥¼ í•œë²ˆ ë” ë“¤ì–´ë³´ê³  ê·¸ ê²½ì¹˜ë¥¼ ë‹¤ì‹œ í•œë²ˆ ë³´ê³  ì‹¶ì€ ìƒê°ì´ ëŠ˜ ë– ë‚˜ì§€ë¥¼ ì•Šì•˜ë‹¤.\\n\\nì¥ê³ ì†Œë¦¬ì™€ ê¸°ìƒì˜ ë…¸ë˜ëŠ” ë©ê³  ë°°ë”°ë¼ê¸°ë§Œ êµ¬ìŠ¬í”„ê²Œ ë‚ ì•„ ì˜¨ë‹¤. ê²°ê²°ì´ ë¶€ëŠ” ë°”ëŒìœ¼ë¡œ ë§ë¯¸ì•”ì•„ ë•Œë•Œë¡œëŠ” ë“¤ì„ ìˆ˜ê°€ ì—†ìœ¼ë˜, ë‚˜ì˜ ê¸°ì–µê³¼ ê³¡ì¡°ë¥¼ ì¢…í•©í•˜ì—¬ ë“¤ì€ ë°°ë”°ë¼ê¸°ëŠ” ì´ ëŒ€ëª©ì´ë‹¤.\\n\\nê°•ë³€ì— ë‚˜ì™”ë‹¤ê°€ ë‚˜ë¥¼ ë³´ë”ë‹ˆë§Œ, í˜¼ë¹„ë°±ì‚°í•˜ì—¬ ê¿ˆì¸ì§€ ìƒì‹œì¸ì§€ ì™€ë¥´ë¥µ ë‹¬ë ¤ë“¤ì–´ ì„¬ì„¬ì˜¥ìˆ˜ë¡œ ë¶€ì²˜ì¡ê³ , í˜¸ì²œë§ê·¹ í•˜ëŠ” ë§ì´ â€˜í•˜ëŠ˜ë¡œì„œ ë–¨ì–´ì§€ë©° ë•…ìœ¼ë¡œì„œ ì†Ÿì•„ë‚¬ë‚˜. ë°”ëŒê²°ì— ë¬»ì–´ì˜¤ê³  êµ¬ë¦„ê¸¸ì— ìŒ”ì—¬ì™”ë‚˜.â€™ ì´ë¦¬ ì„œë¡œ ë¶™ë“¤ê³  ìš¸ìŒ ìš¸ ì œ, ì¸ë¦¬ ì œì¸ì´ë©° ì¼ê°€ ì¹œì²™ì´ ëª¨ë‘ ëª¨ì—¬,\\n\\nì—¬ê¸°ê¹Œì§€ ë“¤ì€ ë‚˜ëŠ” ë§ˆì¹¨ë‚´ ì°¸ì§€ ëª»í•˜ê³  ë²Œë–¡ ì¼ì–´ì„œì„œ ì†Œë‚˜ ë¬´ê°€ì§€ì— ê±¸ì—ˆë˜ ëª¨ìë¥¼ ë‚´ë ¤ì“°ê³ , ê·¸ê³³ì„ ì°¾ìœ¼ëŸ¬ ëª¨ë€ë´‰ ê¼­ ëŒ€ê¸°ì— ì˜¬ë¼ì„°ë‹¤. ê¼­ëŒ€ê¸°ëŠ” ì¢€ë” ë…¸ë˜ ì†Œë¦¬ê°€ ì˜ ë“¤ë¦°ë‹¤. ê·¸ ëŠ” ë°°ë”°ë¼ê¸°ì˜ ë§¨ ë§ˆì§€ë§‰, ì—¬ê¸°ë¥¼ ë¶€ë¥¸ë‹¤.\\n\\n7\\n\\në°¥ì„ ë¹Œì–´ì„œ ì£½ì„ ì‘¬ì§€ë¼ë„ ì œë°œë•ë¶„ì— ë±ƒë†ˆ ë…¸ë¦‡ì€ í•˜ì§€ ë§ì•„. ì—ì—ì•¼ ì–´ê·¸ì—¬ì§€ì•¼\\n\\nğŸ™ğŸ™Ÿ ê·¸ì˜ ì†Œë¦¬ë¡œì¨ ë°©í–¥ì„ ì°¾ìœ¼ë ¤ë˜ ë‚˜ëŠ”, ê·¸ë§Œ ê·¸ ìë¦¬ì— ì„°ë‹¤.\\n\\nâ€˜ì–´ë”˜ê°€? ê¸°ìë¬˜? í˜¹ì€ ì„ë°€ëŒ€?â€™\\n\\nê·¸ëŸ¬ë‚˜ ë‚˜ëŠ” ì˜¤ë˜ ì„œ ìˆì„ ìˆ˜ê°€ ì—†ì—ˆë‹¤. ì–´ë–»ë“  ì°¾ì•„ë³´ì í•˜ ê³ , í˜„ë¬´ë¬¸ìœ¼ë¡œ ê°€ì„œ ë¬¸ ë°–ì— ì© ë‚˜ì„°ë‹¤. ê¸°ìë¬˜ì˜ ê¹Šì€ ì†”ë°­ ì€ ëˆˆì•ì— ì«™ í¼ì§„ë‹¤.\\n\\nâ€˜ì–´ë”˜ê°€?â€™\\n\\në‚˜ëŠ” ë˜ ë¬¼ì–´ë³´ì•˜ë‹¤.\\n\\nì´ë•Œì— ê·¸ëŠ” ë˜ë‹¤ì‹œ ë°°ë”°ë¼ê¸°ë¥¼ ì‹œì´ˆë¶€í„° ë¶€ë¥¸ë‹¤. ê·¸ ì†Œë¦¬ëŠ” ì™¼í¸ì—ì„œ ì˜¨ë‹¤.\\n\\nì™¼í¸ì´êµ¬ë‚˜ í•˜ë©´ì„œ, ì†Œë¦¬ ë‚˜ëŠ” ê³³ì„ ë”ë“¬ì–´ì„œ ì†Œë‚˜ë¬´ í‹ˆìœ¼ë¡œ í•œì°¸ ëŒë‹¤ê°€, ê²¨ìš° ê¸°ìë¬˜ ì¹˜ê³ ëŠ” ê·¸ì¤‘ í•˜ëŠ˜ì´ ë„“ê³  ë°ì€ ê³³ ì—, í˜¼ìì„œ ë’¹êµ´ê³  ìˆëŠ” ê·¸ë¥¼ ì°¾ì•„ë‚´ì—ˆë‹¤. ë‚˜ì˜ ìƒê°í•œ ë°”ì™€ ê°™ì€ ì–¼êµ´ì´ë‹¤. ì–¼êµ´, ì½”, ì…, ëˆˆ, ëª¸ì§‘ì´ ëª¨ë‘ ë„¤ëª¨ë‚˜ê³  - ê·¸ ì˜ ì´ë§ˆì˜ êµµì€ ì£¼ë¦„ì‚´ê³¼ ì‹œêº¼ë¨¼ ëˆˆì¹ì€, ê³ ìƒ ë§ì´ í•¨ê³¼ ìˆœ ì§„í•œ ì„±ê²©ì„ ë‚˜íƒ€ë‚¸ë‹¤.\\n\\n8\\n\\nê·¸ëŠ” ì–´ë–¤ ì‹ ì‚¬ê°€ ìê¸°ë¥¼ ë“¤ì—¬ë‹¤ë³´ëŠ” ê²ƒì„ ë³´ê³ , ë…¸ë˜ë¥¼ ê·¸ ì¹˜ê³  ì¼ì–´ë‚˜ ì•‰ëŠ”ë‹¤.\\n\\nâ€œì™œ? ê·¸ëƒ¥ í•˜ì§€ìš”.â€\\n\\ní•˜ë©´ì„œ ë‚˜ëŠ” ê·¸ì˜ ê³ì— ê°€ ì•‰ì•˜ë‹¤.\\n\\nâ€œë¨¸â€¦â€\\n\\ní•œ ë¿ ê·¸ëŠ” ëˆˆì„ ë“¤ì–´ì„œ í„°ì§„ í•˜ëŠ˜ì„ ì³ë‹¤ë³¸ë‹¤.\\n\\nì¢‹ì€ ëˆˆì´ì—ˆë‹¤. ë°”ë‹¤ì˜ ë„“ê³  í¼ì´, ìœ ê°ì—†ì´ ê·¸ì˜ ëˆˆì— ë‚˜íƒ€ ë‚˜ ìˆë‹¤. ê·¸ëŠ” ë±ƒì‚¬ëŒì´ë¼ ë‚˜ëŠ” ì§ì‘í•˜ì˜€ë‹¤.\\n\\nâ€œê³ í–¥ì´ ì˜ìœ ìš”?â€\\n\\nâ€œì˜ˆ, ë¨¸, ì˜ìœ ì„œ ë‚˜ê¸°ëŠ” í–ˆë””ë§Œ, í•œ ì´ì‹­ ë…„ ì˜ìœ¤ ê°€ë³´ë””ë‘ ì•Š ì•˜ì´ìš”.â€\\n\\nâ€œì™œ, ì´ì‹­ ë…„ì”© ê³ í–¥ì—˜ ì•ˆê°€ìš”?â€\\n\\nâ€œì‚¬ëŒì˜ ì¼ì´ë¼ë‹ˆ, ë§ˆìŒëŒ€ë¡œ ë©ë°ê¹Œ?â€\\n\\nê·¸ëŠ” ì™œ ê·¸ëŸ¬ëŠ”ì§€, í•œìˆ¨ì„ ì§“ëŠ”ë‹¤.\\n\\nâ€œê±°ì €, ìš´ëª…ì´ ë°ì¼ í˜ì…‰ë””ë‹¤.â€\\n\\nìš´ëª…ì˜ í˜ì´ ì œì¼ ì„¸ë‹¤ëŠ” ê·¸ì˜ ì†Œë¦¬ëŠ” ì‚­ì´ì§€ ëª»í•  ì›í•œê³¼ ë‰˜ìš°ì¹¨ì´ ì„ì—¬ ìˆë‹¤.\\n\\nâ€œê·¸ë˜ìš”?â€\\n\\n9\\n\\në‚˜ëŠ” ë‹¤ë§Œ ê·¸ë¥¼ ê±´ë„ˆë‹¤ë³¼ ë¿ì´ë‹¤.\\n\\ní•œì°¸ ì ì í•˜ë‹ˆ ìˆë‹¤ê°€ ë‚˜ëŠ” ë‹¤ì‹œ ë§í•˜ì˜€ë‹¤.\\n\\nâ€œì ë…¸í˜•ì˜ ê²½í—˜ë‹´ì´ë‚˜ í•œë²ˆ ë“¤ì–´ë´…ì‹œë‹¤. ê°ì¶œ ì¼ì´ ì•„ë‹ˆë©´ í•œë²ˆ ì´ì•¼ê¸°í•´ë³´ì†Œ.â€\\n\\nâ€œë¨¸, ê°ì¶œ ì¼ì€â€¦â€\\n\\nâ€œê·¸ëŸ¼, ì–´ë”” ë“¤ì–´ë´…ì‹œë‹¤ê·¸ë ¤.â€\\n\\nê·¸ëŠ” ë‹¤ì‹œ í•˜ëŠ˜ì„ ì³ë‹¤ë³´ì•˜ë‹¤. ê·¸ëŸ¬ë‚˜ ì¢€ ìˆë‹¤ê°€,\\n\\nâ€œí•˜ë””ìš”.â€\\n\\ní•˜ë©´ì„œ ë‚´ê°€ ë‹´ë°°ë¥¼ ë¶™ì´ëŠ” ê²ƒì„ ë³´ê³  ìê¸°ë„ ë‹´ë°°ë¥¼ ë¶™ì—¬ë¬¼ ê³  ì´ì•¼ê¸°ë¥¼ êº¼ë‚¸ë‹¤.\\n\\nâ€œìŠíˆë””ë‘ ì•ŠëŠ” ì‹­ êµ¬ ë…„ ì „ íŒ”ì›” ì—´ í•˜ë£»ë‚  ì¼ì¸ë°ìš”.â€\\n\\ní•˜ë©´ì„œ ê·¸ê°€ ì´ì•¼ê¸°í•œ ë°”ëŠ” ëŒ€ëµ ì´ì™€ ê°™ì€ ê²ƒì´ë‹¤.\\n\\nê·¸ì˜ ì‚´ë˜ ë§ˆì„ì€ ì˜ìœ  ê³ ì„ì„œ í•œ ì´ì‹­ ë¦¬ ë– ë‚˜ ìˆëŠ” ë°”ë‹¤ë¥¼ í–¥í•œ ì¡°ê·¸ë§Œ ì–´ì´Œì´ë‹¤. ê·¸ì˜ ì‚´ë˜ ì¡°ê·¸ë§Œ ë§ˆì„(ì„¤í” ì§‘ì¯¤ ë˜ ëŠ”)ì—ì„œëŠ” ê·¸ëŠ” ê½¤ ìœ ëª…í•œ ì‚¬ëŒì´ì—ˆë‹¤.\\n\\nê·¸ì˜ ë¶€ëª¨ëŠ” ëª¨ë‘ ì—´ëŒ“ì— ë‚¬ì„ ë•Œ ëŒì•„ê°”ê³ , ë‚¨ì€ ì‚¬ëŒì´ë¼ ê³ ëŠ” ê³ì§‘ì— ë”´ì‚´ë¦¼í•˜ëŠ” ê·¸ì˜ ì•„ìš° ë¶€ì²˜ì™€ ê·¸ ìê¸° ë¶€ì²˜ë¿ì´ ì—ˆë‹¤. ê·¸ë“¤ í˜•ì œê°€ ê·¸ ë§ˆì„ì—ì„œ ì œì¼ ë¶€ìì´ê³  ë˜ ì œì¼ ê³ ê¸° ì¡ì´ë¥¼ ì˜í•˜ì˜€ê³ , ê·¸ì¤‘ ê¸€ì´ ìˆì—ˆê³  ë°°ë”°ë¼ê¸°ë„ ê·¸ ë§ˆì„ì—ì„œ\\n\\n10\\n\\në¹¼ë‚˜ê²Œ ê·¸ í˜•ì œê°€ ì˜ ë¶ˆë €ë‹¤. ë§í•˜ìë©´ ê·¸ í˜•ì œê°€ ê·¸ ë™ë„¤ì˜ ëŒ€í‘œì  ì‚¬ëŒì´ì—ˆë‹¤.\\n\\níŒ”ì›” ë³´ë¦„ì€ ì¶”ì„ëª…ì ˆì´ë‹¤. íŒ”ì›” ì—´ í•˜ë£»ë‚  ê·¸ëŠ” ëª…ì ˆì— ì“¸ ì¥ë„ ë³¼ ê²¸, ê·¸ì˜ ì•„ë‚´ê°€ ëŠ˜ ë¶€ëŸ¬ì›Œí•˜ëŠ” ê±°ìš¸ë„ í•˜ë‚˜ ì‚¬ì˜¬ ê²¸, ì¥ìœ¼ë¡œ í–¥í•˜ì˜€ë‹¤.\\n\\nâ€œë‹¹ì†ë„¤ ì§‘ì— ìˆëŠ” ê²ƒë³´ë‹¤ í° ê±°ì´ìš” ìŠë”” ë§êµ¬ìš”.â€\\n\\nê·¸ì˜ ì•„ë‚´ëŠ” ê¸¸ê¹Œì§€ ë”°ë¼ë‚˜ì˜¤ë©´ì„œ ìŠì§€ ì•Šë„ë¡ ë¶€íƒí•˜ì˜€ë‹¤.\\n\\nâ€œì•ˆ ìŠì–´.â€\\n\\ní•˜ë©´ì„œ ê·¸ëŠ” ë– ì˜¤ë¥´ëŠ” ìƒˆë¹¨ê°„ í–‡ë¹›ì„ ì•ìœ¼ë¡œ ë°›ìœ¼ë©´ì„œ ìê¸° ë§ˆì„ì„ ë‚˜ì„°ë‹¤.\\n\\nê·¸ëŠ” ì•„ë‚´ë¥¼(ì´ë ‡ê²Œ ë§í•˜ê¸°ëŠ” ìš°ìŠµì§€ë§Œ) ê³ ì™€í–ˆë‹¤. ê·¸ì˜ ì•„ ë‚´ëŠ” ì´Œì—ì„œëŠ” ë“œë¬¼ë„ë¡ ì—°ì—°í•˜ê³ ë„ ì˜ˆì˜ê²Œ ìƒê²¼ë‹¤(ê·¸ëŠ” ë‚˜ ì—ê²Œ ì´ë ‡ê²Œ ë§í•˜ì˜€ë‹¤).\\n\\nâ€œì„±ë‚´(í‰ì–‘) ë´ì¤ê³¨(ê°ˆë³´ì´Œ)ì„ ê°€ë‘ ê·¸ë§Œí•œ ê±° ì‰½ë”” ì•Šê°”ì´ ìš”.â€\\n\\nê·¸ëŸ¬ë‹ˆê¹Œ ì´Œì—ì„œëŠ”, ê·¸ë¦¬ê³  ê·¸ ë‹¹ì‹œì—ëŠ” ë‚¨ì—ê²Œ ìš°ìŠµê²Œ ë³´ì´ ë„ë¡ ê·¸ ë‚´ì™¸ì˜ ì‚¬ì´ëŠ” ì¢‹ì•˜ë‹¤. ëŠ™ì€ì´ë“¤ì€ ê³„ì§‘ì—ê²Œ í˜¹í•˜ì§€ ë§ë¼ê³  í”íˆ ê·¸ì—ê²Œ ê¶Œê³ í•˜ì˜€ë‹¤.\\n\\në¶€ì²˜ì˜ ì‚¬ì´ëŠ” ì¢‹ì•˜ì§€ë§Œ - ì•„ë‹ˆ, ì˜¤íˆë ¤ ì¢‹ìœ¼ë¯€ë¡œ ê·¸ëŠ” ì•„ë‚´ ì—ê²Œ ìƒ˜ì„ ë§ì´ í•˜ì˜€ë‹¤. ê·¸ë¦¬ê³  ê·¸ì˜ ì•„ë‚´ëŠ” ì‹œê¸°ë¥¼ ë°›ì„ ì¼ ì„ ë§ì´ í•˜ì˜€ë‹¤. í’ˆí–‰ì´ ë‚˜ì˜ë‹¤ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ê·¸ì˜ ì•„ë‚´ëŠ”\\n\\n11\\n\\nëŒ€ë‹¨íˆ ì²œì§„ìŠ¤ëŸ½ê³  ì¾Œí™œí•œ ì„±ì§ˆë¡œì„œ ì•„ë¬´ì—ê²Œë‚˜ ë§ ì˜í•˜ê³  ì• êµë¥¼ ì˜ ë¶€ë ¸ë‹¤.\\n\\nğŸ™ğŸ™Ÿ ê·¸ ë™ë„¤ì—ì„œëŠ” ë¬´ìŠ¨ ëª…ì ˆì´ë‚˜ ë˜ë©´, ì§‘ì´ ê·¸ì¤‘ ì •ê²°í•¨ì„ í•‘ ê³„ì‚¼ì•„ ì Šì€ì´ë“¤ì€ ëª¨ë‘ ê·¸ì˜ ì§‘ì— ëª¨ì´ê³  í•˜ì˜€ë‹¤. ê·¸ ì Šì€ ì´ë“¤ì€ ëª¨ë‘ ê·¸ì˜ ì•„ë‚´ì—ê²Œ â€˜ì•„ì¦ˆë§ˆë‹ˆâ€™ë¼ ë¶€ë¥´ê³ , ê·¸ì˜ ì•„ë‚´ ëŠ” ì•„ë‚´ë¼ â€˜ì•„ì¦ˆë°”ë‹ˆ ì•„ì¦ˆë°”ë‹ˆâ€™ í•˜ë©° ê·¸ë“¤ê³¼ ì§€ê»„ì´ê³  ì¦ê¸° ë©° ê·¸ ì›ƒê¸° ì˜í•˜ëŠ” ì…ì—ëŠ” ëŠ˜ ì›ƒìŒì„ í˜ë¦¬ê³  ìˆì—ˆë‹¤.\\n\\nê·¸ëŸ´ ë•Œë§ˆë‹¤ ê·¸ëŠ” í•œí¸ êµ¬ì„ì—ì„œ ëˆˆë§Œ í• ëˆê±°ë¦¬ë©° ìˆë‹¤ê°€ ì Š ì€ì´ë“¤ì´ ëŒì•„ê°„ ë’¤ì—ëŠ” ë¶ˆë¬¸ê³¡ì§í•˜ê³  ì•„ë‚´ì—ê²Œ ë¤ë¹„ì–´ë“¤ ì–´, ë°œê¸¸ë¡œ ì°¨ê³  ë•Œë¦¬ë©°, ì´ì „ì— ì‚¬ë‹¤ì£¼ì—ˆë˜ ê²ƒì„ ëª¨ë‘ ê±·ì–´ ì˜¬ë¦°ë‹¤. ì‹¸ì›€ì„ í•  ë•Œì—ëŠ” ì–¸ì œë“  ê³ì§‘ì— ìˆëŠ” ì•„ìš° ë¶€ì²˜ê°€ ë§ë¦¬ëŸ¬ ì˜¤ë©°, ê·¸ë ‡ê²Œ ë˜ë©´ ì–¸ì œë“  ê·¸ëŠ” ì•„ìš° ë¶€ì²˜ê¹Œì§€ ë•Œë ¤ ì£¼ì—ˆë‹¤.\\n\\nê·¸ê°€ ì•„ìš°ì—ê²Œ ê·¸ë ‡ê²Œ êµ¬ëŠ” ë°ëŠ” ì´ìœ ê°€ ìˆì—ˆë‹¤. ê·¸ì˜ ì•„ìš° ëŠ” ì‹œê³¨ ì‚¬ëŒì—ê²ŒëŠ” ì‰½ì§€ ì•Šë„ë¡ ëŠ ë¦„í•œ ìœ„ì—„ì´ ìˆì—ˆê³ , ë§¤ ì¼ ë°”ë‹·ë°”ëŒì„ ì˜ì˜€ì§€ë§Œ ì–¼êµ´ì´ í¬ì—ˆë‹¤. ì´ê²ƒ ë¿ìœ¼ë¡œë„ ì‹œê¸° ê°€ ëœë‹¤ í•˜ë©´ ë˜ì§€ë§Œ, íŠ¹ë³„íˆ ì•„ë‚´ê°€ ê·¸ì˜ ì•„ìš°ì—ê²Œ ì¹œì ˆíˆ í•˜ëŠ” ë°ëŠ”, ê·¸ëŠ” ì†ì´ ë“ì–´ ëª» ê²¬ë””ì—ˆë‹¤.\\n\\nê·¸ê°€ ì˜ìœ ë¥¼ ë– ë‚˜ê¸° ë°˜ë…„ ì „ì¯¤ ? ë‹¤ì‹œ ë§í•˜ìë©´ ê·¸ê°€ ê±°ìš¸ì„ ì‚¬ëŸ¬ ì¥ì— ê°ˆ ë•Œë¶€í„° ë°˜ë…„ ì „ì¯¤ ê·¸ì˜ ìƒì¼ë‚ ì´ì—ˆë‹¤. ê·¸ì˜ ì§‘ ì—ì„œëŠ” ìŒì‹ì„ ì°¨ë ¤ì„œ ì˜ ë¨¹ì—ˆëŠ”ë°, ê·¸ì—ê²ŒëŠ” ê´´ìƒí•œ ë²„ë¦‡ì´ ìˆì—ˆìœ¼ë‹ˆ, ë§›ìˆëŠ” ìŒì‹ì€ ë‚¨ê²¨ë‘ì—ˆë‹¤ê°€ ì¢€ ìˆë‹¤ ë¨¹ê³  í•˜ëŠ” ê²ƒì´ ìŠµê´€ì´ì—ˆë‹¤.\\n\\n12\\n\\nê·¸ì˜ ì•„ë‚´ë„ ì´ ë²„ë¦‡ì€ ì˜ ì•Œ í„°ì¸ë° ê·¸ì˜ ì•„ìš°ê°€ ì ì‹¬ë•Œì¯¤ ì˜¤ë‹ˆê¹Œ, ì•„ê¹Œ ê·¸ê°€ ì•„ê»´ì„œ ë‚¨ê²¨ë‘ì—ˆë˜ ê·¸ ìŒì‹ì„ ì•„ìš°ì—ê²Œ ì£¼ë ¤ í•˜ì˜€ë‹¤. ê·¸ëŠ” ëˆˆì„ ë¶€ë¦…ëœ¨ê³  â€˜ëª» ì£¼ë¦¬ë¼â€™ê³  ì•”í˜¸í•˜ì˜€ì§€ ë§Œ ì•„ë‚´ëŠ” ê·¸ê²ƒì„ ë³´ì•˜ëŠ”ì§€ ëª» ë³´ì•˜ëŠ”ì§€ ê·¸ì˜ ì•„ìš°ì—ê²Œ ì£¼ì–´ ë²„ë ¸ë‹¤. ê·¸ëŠ” ë§ˆìŒì†ì´ ìëª» í¸ì¹˜ ëª»í•˜ì˜€ë‹¤. íŠ¸ì§‘ë§Œ ìˆìœ¼ë©´ ì´ë…„ì„â€¦, ê·¸ëŠ” ë§ˆìŒë¨¹ì—ˆë‹¤.\\n\\nê·¸ì˜ ì•„ë‚´ëŠ” ì‹œì•„ìš°ì—ê²Œ ìƒì„ ì¤€ ë’¤ì— ë¬¼ëŸ¬ì˜¤ë‹¤ê°€ ê·¸ë§Œ ê·¸ì˜ ë°œì„ ì¡°ê¸ˆ ë°Ÿì•˜ë‹¤.\\n\\nâ€œì´ë…„!â€\\n\\nê·¸ëŠ” í˜ê» ë°œì„ ë“¤ì–´ì„œ ì•„ë‚´ë¥¼ ëƒ…ë‹¤ ì°¼ë‹¤. ê·¸ì˜ ì•„ë‚´ëŠ” ìƒ ìœ„ ì— êº¼ê¾¸ëŸ¬ì¡Œë‹¤ê°€ ì¼ì–´ë‚œë‹¤.\\n\\nâ€œì´ë…„, ì‚¬ë‚˜ì´ ë°œì„ ì§“ë°ŸëŠ” ë…„ì´ ì–´ë”” ìˆì–´!â€\\n\\nâ€œê±° ì¢€ ë°Ÿì•„ì„œ ë°œì´ ë¶€ëŸ¬í…Ÿì‰ê¹Œ?â€\\n\\nì•„ë‚´ëŠ” ë‚¯ì´ ìƒˆë¹¨ê°œì ¸ì„œ ìš¸ìŒ ì„ì¸ ì†Œë¦¬ë¡œ ê³ í•¨ì¹œë‹¤.\\n\\nâ€œì´ë…„! ë§ëŒ€ë‹µì´â€¦â€\\n\\nê·¸ëŠ” ì¼ì–´ì„œì„œ ì•„ë‚´ì˜ ë¨¸ë¦¬ì±„ë¥¼ íœ˜ì–´ì¡ì•˜ë‹¤.\\n\\nâ€œí˜•ë‹˜! ì™œ ì´ë¦¬ì‹­ë‹ˆê¹Œ?â€\\n\\nì•„ìš°ê°€ ì¼ì–´ì„œë©´ì„œ ê·¸ë¥¼ ë¶™ì¡ì•˜ë‹¤.\\n\\nâ€œê°€ë§Œ ìˆê±°ë¼, ì´ë†ˆì˜ ìì‹.â€\\n\\n13\\n\\ní•˜ë©°, ê·¸ëŠ” ì•„ìš°ë¥¼ ë°€ì¹œ ë’¤ì— ì•„ë‚´ë¥¼ ë˜ëŠ”ëŒ€ë¡œ ë‚´ë¦¬ì°§ì—ˆë‹¤.\\n\\nâ€œì£½ì¼ ë…„, ì´ë…„! ë‚˜ê°€ê±°ë¼!â€\\n\\nâ€œì£½ì—¬ë¼, ì£½ì—¬ë¼! ë‚œ, ì£½ì–´ë„ ì´ ì§‘ì—ì„  ëª» ë‚˜ê°€!â€\\n\\nâ€œëª» ë‚˜ê°€?â€\\n\\nâ€œëª» ë‚˜ê°€ë”” ì•Šêµ¬. ë‰˜ ì§‘ì´ê²Œâ€¦â€\\n\\nì´ë•Œë‹¤. ê·¸ì˜ ë§ˆìŒì—ëŠ” ê·¸ 'ëª» ë‚˜ê°€ê² ë‹¤'ëŠ” ì•„ë‚´ì˜ ë§ˆìŒì´ í­ ë“¤ì´ë°•í˜”ë‹¤. ê·¸ ì´ìƒ ë•Œë¦¬ê¸°ê°€ ì‹«ì—ˆë‹¤. ìš°ë‘ì»¤ë‹ˆ ëˆˆë§Œ í˜ê¸° ê³  ìˆë‹¤ê°€ ê·¸ëŠ”,\\n\\nâ€œë§í•  ë…„, ê·¸ëŸ¼ ë‚´ê°€ ë‚˜ê°ˆë¼.â€\\n\\ní•˜ê³  ê·¸ë§Œ ë¬¸ ë°–ìœ¼ë¡œ ë›°ì–´ë‚˜ì™€ì„œ,\\n\\nâ€œí˜•ë‹˜, ì–´ë”” ê°‘ë‹ˆê¹Œ?â€\\n\\ní•˜ëŠ” ì•„ìš°ì˜ ë§ì—ëŠ” ëŒ€ë‹µë„ ì•ˆí•˜ê³ , ê³ ë™ë„¤ íƒì£¼ ì§‘ìœ¼ë¡œ ë’¤ ë„ ì•ˆ ëŒì•„ë³´ê³  ê°€ì„œ, ê±°ê¸° ìˆëŠ” ìˆ  íŒŒëŠ” ê³„ì§‘ê³¼ ìˆ ìƒ ì•ì— ë§ˆì£¼ì•‰ì•˜ë‹¤.\\n\\nê·¸ë‚  ì €ë…, ì–¼ê·¼íˆ ì·¨í•œ ê·¸ëŠ” ì•„ë‚´ë¥¼ ìœ„í•˜ì—¬ ë–¡ì„ í•œ ëˆì–´ì¹˜ ì‚¬ ê°€ì§€ê³  ì§‘ìœ¼ë¡œ ëŒì•„ì™”ë‹¤. ì´ë¦¬í•˜ì—¬ ë˜ ì„œë„ˆ ë‹¬ì€ í‰í™”ê°€ ì´ë¥´ë €ë‹¤. ê·¸ëŸ¬ë‚˜ ì´ í‰í™”ê°€ ì–¸ì œê¹Œì§€ë“  ê³„ì†ë  ìˆ˜ê°€ ì—†ì—ˆ ë‹¤. ê·¸ì˜ ì•„ìš°ë¡œ ë§ë¯¸ì•”ì•„ ë˜ í‰í™”ëŠ” ìª¼ê°œì ¸ë‚˜ê°”ë‹¤.\\n\\n14\\n\\nì˜¤ì›” ì´ˆìŠ¹ë¶€í„° ì˜ìœ  ê³ ì„ ì¶œì…ì´ ì¦ë˜ ê·¸ì˜ ì•„ìš°ëŠ” ì˜¤ì›” ê·¸ ë¯ê»˜ë¶€í„°ëŠ” ê³ ì„ì„œ ë©°ì¹ ì”© ë¬µì–´ì˜¤ëŠ” ì¼ì´ ë§ì•˜ë‹¤. í•¨ê»˜, ê³  ì„ì— ì²©ì„ ì–»ì–´ë‘ì—ˆë‹¤ëŠ” ì†Œë¬¸ì´ í¼ì¡Œë‹¤. ì´ ì†Œë¬¸ì´ ìˆì€ ë’¤ ëŠ” ì•„ë‚´ëŠ” ê·¸ì˜ ì•„ìš°ê°€ ê³ ì„ ë“¤ì–´ê°€ëŠ” ê²ƒì„ ë²Œë ˆë³´ë‹¤ë„ ë” ì‹«ì–´í•˜ê³ , ë©°ì¹  ë¬µì–´ì„œ ì˜¤ëŠ” ë•Œë©´ ê³§ ì•„ìš°ì˜ ì§‘ìœ¼ë¡œ ê°€ì„œ ê·¸ ì™€ ë‹´íŒì„ í•˜ë©° ì‹¬ì§€ì–´ ë™ì„œ ë˜ëŠ” ì•„ìš°ì˜ ì²˜ì—ê¹Œì§€ ëª» ê°€ê²Œ í•˜ì§€ ì•ŠëŠ”ë‹¤ê³  ì‹¸ìš°ëŠ” ì¼ì´ ìˆì—ˆë‹¤.\\n\\nì¹ ì›” ì´ˆìŠ¹ê»˜ ê·¸ì˜ ì•„ìš°ëŠ” ê³ ì„ì— ë“¤ì–´ê°€ì„œ ì—´í˜ì¯¤ ë¬µì–´ì˜¨ ì¼ ì´ ìˆì—ˆë‹¤. ì´ë•Œë„ ì „ê³¼ ê°™ì´ ê·¸ì˜ ì•„ë‚´ëŠ” ê·¸ì˜ ì•„ìš°ë©° ê³„ìˆ˜ ì™€ ì‹¸ìš°ë‹¤ ëª»í•˜ì—¬, ë§ˆì¹¨ë‚´ ê·¸ì—ê²Œê¹Œì§€ ì™€ì„œ ì•„ìš°ê°€ ê·¸ëŸ° ëª» ëœ ë°ë¥¼ ë‹¤ë‹ˆëŠ” ê²ƒì„ ê·¸ëƒ¥ ë‘”ë‹¤ê³ , í•´ë³´ì í•œë‹¤. ê·¸ ê¼´ì„ ê³± ê²Œ ë³´ì§€ ì•Šì•˜ë˜ ê·¸ëŠ” ì²«ë§ˆë””ë¡œ ê³ í•¨ì„ ì³¤ë‹¤.\\n\\nâ€œë„¤ê²Œ ìƒê´€ì´ ë¬´ì—ê°€? ë“£ê¸° ì‹«ë‹¤.â€\\n\\nâ€œëª»ë‚œë‘¥ì´. ì•„ìš°ê°€ ê·¸ëŸ° ë¸ ëŒ•ê¸°ëŠ” ê±¸ ë§ë¦¬ë””ë‘ ëª»í•˜ê³ !â€\\n\\në¶„ê¹€ì— ì´ë ‡ê²Œ ê·¸ì˜ ì•„ë‚´ëŠ” ê³ í•¨ì³¤ë‹¤.\\n\\nâ€œì´ë…„, ë¬´ì–¼?â€\\n\\nê·¸ëŠ” ë²Œë–¡ ì¼ì–´ì„°ë‹¤.\\n\\nâ€œëª»ë‚œë‘¥ì´!â€\\n\\nê·¸ ë§ì´ ì±„ ëë‚˜ê¸° ì „ì— ê·¸ì˜ ì•„ë‚´ëŠ” ì•… ì†Œë¦¬ì™€ í•¨ê»˜ ê·¸ ìë¦¬ ì— êº¼ê¾¸ëŸ¬ì¡Œë‹¤.\\n\\nâ€œì´ë…„! ì‚¬ë‚˜ì´ê²Œ ê·¸ë”°ìœ— ë§ë²„ë¦‡ ì–´ë””ì„œ ë°°ì™„!â€\\n\\n15\\n\\nâ€œì—ë¯¸ë„¤ ë•Œë¦¬ëŠ” ê±´ ì–´ë””ì„œ ë°°ì™”ë…¸? ëª»ë‚œë‘¥ì´!â€\\n\\nê·¸ì˜ ì•„ë‚´ëŠ” ìš¸ìŒì†Œë¦¬ë¡œ ë¶€ë¥´ì§–ì—ˆë‹¤.\\n\\nâ€œìƒë…„ ê·¸ëƒ¥? ë‚˜ê°ˆ! ìš°ë¦¬ ì§‘ì— ìˆë”” ë§êµ¬ ë‚˜ê°ˆ!â€\\n\\nê·¸ëŠ” ë‚´ë¦¬ì°§ìœ¼ë©´ì„œ ë¶€ë¥´ì§–ì—ˆë‹¤. ê·¸ë¦¬ê³  ì•„ë‚´ë¥¼ ë¬¸ì„ ì—´ê³  ë°€ ì³¤ë‹¤.\\n\\nâ€œë‚˜ê°€ë”” ì•Šìœ¼ë¦¬.â€\\n\\ní•˜ê³  ê·¸ì˜ ì•„ë‚´ëŠ” ìš¸ë©´ì„œ ë›°ì–´ë‚˜ê°”ë‹¤.\\n\\nâ€œë§í•œ ë…„!â€\\n\\ní† í•˜ëŠ” ë“¯ì´ ì¤‘ì–¼ê±°ë¦¬ê³  ê·¸ëŠ” ê·¸ ìë¦¬ì— ì£¼ì €ì•‰ì•˜ë‹¤.\\n\\nê·¸ì˜ ì•„ë‚´ëŠ” í•´ê°€ ì ¸ì„œ ì–´ë‘ì›Œì ¸ë„ ëŒì•„ì˜¤ì§€ ì•Šì•˜ë‹¤. ì¼ë‹¨ ë‚´ì–´ì«“ê¸°ëŠ” í•˜ì˜€ì§€ë§Œ, ê·¸ëŠ” ì•„ë‚´ì˜ ëŒì•„ì˜´ì„ ê¸°ë‹¤ë¦¬ê³  ìˆì—ˆ ë‹¤. ì–´ë‘ì›Œì ¸ì„œë„ ê·¸ëŠ” ë¶ˆë„ ì•ˆ ì¼œê³ , ì„±ì´ ë‚˜ì„œ ìš°ë“¤ìš°ë“¤ ë–¨ ë©´ì„œ ì•„ë‚´ì˜ ëŒì•„ì˜¤ê¸°ë¥¼ ê¸°ë‹¤ë ¸ë‹¤. ê·¸ëŸ¬ë‚˜ ê·¸ì˜ ì•„ë‚´ì˜ ì°¸ ê¸°ìœ ë“¯ì´ ì›ƒëŠ” ì†Œë¦¬ê°€ ê·¸ì˜ ì•„ìš°ì˜ ì§‘ì—ì„œ ë°¤ìƒˆë„ë¡ ìš¸ë¦¬ì—ˆ ë‹¤. ê·¸ëŠ” ì›€ì©ë„ ì•ˆí•˜ê³  ê·¸ ìë¦¬ì— ì•‰ì•„ì„œ ë°¤ì„ ìƒˆìš´ ë’¤ì—, ìƒˆë²½ ë™í„°ì˜¬ ë•Œ ì•„ë‚´ì™€ ì•„ìš°ë¥¼ ì£½ì´ë ¤ê³  ë¶€ì—Œì— ê°€ì„œ ì‹ì¹¼ì„ ê°€ì§€ê³  ë“¤ì–´ì™€ì„œ ë¬¸ì„ ë²Œì»¥ ì—´ì—ˆë‹¤.\\n\\nê·¸ì˜ ì•„ë‚´ë¡œì„œ ë§Œì•½ ê·¼ì‹¬ìŠ¤ëŸ¬ìš´ ì–¼êµ´ì„ í•˜ê³  ê·¸ ë¬¸ ë°–ì— ìš° ë‘ì»¤ë‹ˆ ì„œì„œ ë¬¸ì„ ë“¤ì—¬ë‹¤ë³´ê³  ìˆì§€ ì•Šì•˜ë”ë©´, ê·¸ëŠ” ì•„ë‚´ì™€ ì•„ìš°ë¥¼ ì£½ì´ê³ ì•¼ ë§ì•˜ìœ¼ë¦¬ë¼.\\n\\n16\\n\\nğŸ™ğŸ™Ÿ ê·¸ëŠ” ì•„ë‚´ë¥¼ ë³´ëŠ” ìˆœê°„, ë§ˆìŒì— ê°€ë“ ì°¨ëŠ” ì‚¬ë‘ì„ ê¹¨ë‹¬ìœ¼ë©´ ì„œ, ì¹¼ì„ ë‚´ë˜ì§€ê³  ë›°ì–´ë‚˜ê°€ì„œ ì•„ë‚´ì˜ ë¨¸ë¦¬ì±„ë¥¼ íœ˜ì–´ì¡ê³  ì´ ë…„ í•˜ë©´ì„œ ë“¤ì–´ì™€ì„œ ëº¨ì„ ë¬¼ì–´ëœ¯ìœ¼ë©´ì„œ í•¨ê»˜ ì´ë¦¬ì €ë¦¬ ìë¹  ì ¸ì„œ ë’¹êµ´ì—ˆë‹¤.\\n\\nê·¸ëŸ° ì´ì•¼ê¸°ëŠ” ë‹¤ í•˜ë ¤ë©´ ëì´ ì—†ìœ¼ë˜ ë‹¤ë§Œ â€˜ê·¸â€™ â€˜ê·¸ì˜ ì•„ë‚´â€™ â€˜ê·¸ì˜ ì•„ìš°â€™ ì„¸ ì‚¬ëŒì˜ ì‚¼ê° ê´€ê³„ëŠ” ëŒ€ëµ ì´ì™€ ê°™ì•˜ë‹¤â€¦.\\n\\nê±°ìš¸ì€ ë§ˆì¹¨ ì¥ì— ë§ˆìŒì— ë§ëŠ” ê²ƒì´ ìˆì—ˆë‹¤. ì§€ê¸ˆ ê²ƒê³¼ ëŒ€ë³´ ë©´, ì–´ë–¤ ë•ŒëŠ” ì½”ë„ í¬ê²Œ ë³´ì´ê³  ì…ì´ ì‘ê²Œë„ ë³´ì´ëŠ” ê²ƒì´ì§€ ë§Œ, ê·¸ ë‹¹ì‹œì—ëŠ” ê·¸ë¦¬ê³  ê·¸ëŸ° ì´Œì—ì„œëŠ” ë‘˜ë„ ì—†ëŠ” ê·€ë¬¼ì´ì—ˆ ë‹¤. ê±°ìš¸ì„ ì‚¬ ê°€ì§€ê³  ì¥ì„ ë³¸ ë’¤ì— ê·¸ëŠ” ì´ ê±°ìš¸ì„ ì•„ë‚´ì—ê²Œ ì£¼ë©´ ê·¸ ê¸°ë»í•  ëª¨ì–‘ì„ ìƒê°í•˜ë©°, ìƒˆë¹¨ê°„ ì €ë… í–‡ë¹›ì„ ë°›ëŠ”, ë„˜ì¹˜ëŠ” ë“¯í•œ ë°”ë‹¤ë¥¼ ì•ˆê³  ìê¸° ì§‘ìœ¼ë¡œ, ëŠ˜ ë“¤ëŸ¬ì˜¤ë˜ íƒì£¼ ì§‘ ì—ë„ ì•ˆ ë“¤ëŸ¬ì„œ ëŒì•„ì™”ë‹¤.\\n\\nê·¸ëŸ¬ë‚˜ ê·¸ê°€ ê·¸ì˜ ì§‘ ë°©ì•ˆì— ë“¤ì–´ì„¤ ë•Œì—ëŠ”, ëœ»ë„ ì•ˆ í•˜ì˜€ë˜ ê´‘ê²½ì´ ê·¸ì˜ ëˆˆì— ë²Œì–´ì ¸ ìˆì—ˆë‹¤.\\n\\në°© ê°€ìš´ë°ëŠ” ë–¡ ìƒì´ ìˆê³ , ê·¸ì˜ ì•„ìš°ëŠ” ìˆ˜ê±´ì´ ë²—ì–´ì ¸ì„œ ëª© ë’¤ë¡œ ëŠ˜ì–´ì§€ê³ , ì €ê³ ë¦¬ ê³ ë¦„ì´ ëª¨ë‘ í’€ì–´ì ¸ ê°€ì§€ê³  í•œí¸ ëª¨ í‰ì´ì— ì„œ ìˆê³ , ì•„ë‚´ë„ ë¨¸ë¦¬ì±„ê°€ ëª¨ë‘ ë’¤ë¡œ ëŠ˜ì–´ì§€ê³ , ì¹˜ë§ˆ ê°€ ë°°ê¼½ ì•„ë˜ë¡œ ëŠ˜ì–´ì§€ë„ë¡ ë˜ì–´ ìˆìœ¼ë©°, ê·¸ì˜ ì•„ë‚´ì™€ ì•„ìš° ëŠ” ê·¸ë¥¼ ë³´ê³ , ì–´ì°Œí•  ì¤„ì„ ëª¨ë¥´ëŠ” ë“¯ì´, ì›€ì°ë„ ì•ˆí•˜ê³  ì„œ ìˆì—ˆë‹¤.\\n\\nì„¸ ì‚¬ëŒì€ í•œì°¸ ë™ì•ˆ ì–´ì´ê°€ ì—†ì–´ì„œ ì„œ ìˆì—ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì¢€ ìˆ ë‹¤ê°€ ë§ˆì¹¨ë‚´ ê·¸ì˜ ì•„ìš°ê°€ ê²¨ìš° ë§í–ˆë‹¤.\\n\\n17\\n\\nâ€œê·¸ë†ˆì˜ ì¥ ì–´ë”” ê°”ë‹ˆ?â€\\n\\nâ€œí¥! ì¥? í›Œë¥­í•œ ì¥ ì¡ëŒ”êµ¬ë‚˜!â€\\n\\nê·¸ëŠ” ë§ì„ ëë‚´ì§€ë„ ì•Šê³ , ì§ì„ ë²—ì–´ë˜ì§€ê³ , ë›°ì–´ê°€ì„œ ì•„ìš° ì˜ ë©±ì‚´ì„ ëŒì–´ì¡ì•˜ë‹¤.\\n\\nâ€œí˜•ë‹˜! ì •ë§ ì¥ê°€â€¦â€\\n\\nâ€œì¥? ì´ë†ˆ! í˜•ìˆ˜í•˜ê³  ê·¸ëŸ° ì¥ ì¡ëŠ” ë†ˆì´ ì–´ë”” ìˆë‹ˆ?â€\\n\\nê·¸ëŠ” ì•„ìš°ë¥¼ ë”°ê·€ë¥¼ ëª‡ ëŒ€ ë•Œë¦° ë’¤ì— ë“±ì„ ë°€ì–´ì„œ ë¬¸ ë°–ì— ë‚´ ì–´ë˜ì¡Œë‹¤. ê·¸ëŸ° ë’¤ì— ì´ì œ ìê¸°ì—ê²Œ ì´ë¥¼ ë§¤ë¥¼ ìƒê°í•˜ê³ , ìš° ë“¤ìš°ë“¤ ë–¨ë©´ì„œ ì•„ë«ëª©ì— ì„œ ìˆëŠ” ì•„ë‚´ì—ê²Œ ë‹¬ë ¤ë“¤ì—ˆë‹¤.\\n\\nâ€œì´ë…„! ì‹œì•„ìš°ì™€ ê·¸ëŸ° ì¥ ì¡ëŠ” ë…„ì´ ì–´ë”” ìˆì–´?â€\\n\\nê·¸ëŠ” ì•„ë‚´ë¥¼ êº¼ê¾¸ëŸ¬ëœ¨ë¦¬ê³  í•¨ë¶€ë¡œ ë‚´ë¦¬ì°§ì—ˆë‹¤.\\n\\nâ€œì •ë§ ì¥ê°€â€¦ ì•„ì´ ì£½ê² ë‹¤.â€\\n\\nâ€œì´ë…„! ë„ˆë‘ ì¥? ì£½ì–´ë¼!â€\\n\\nê·¸ì˜ íŒ”ë‹¤ë¦¬ëŠ” í•¨ë¶€ë¡œ ì•„ë‚´ì˜ ëª¸ì— ì˜¤ë¥´ë‚´ë ¸ë‹¤.\\n\\nâ€œì•„ì´ ì£½ê°”ë‹¤. ì •ë§ ì•„ê¹Œ ì ìœ¼ë‹ˆ(ì‹œì•„ìš°) ì™”ê¸°ì— ë–¡ ìì‹œë¼ êµ¬ ë‚´ë†“ì•˜ë”ë‹ˆâ€¦â€\\n\\nâ€œë“£ê¸° ì‹«ë‹¤! ì‹œì•„ìš° ë¶™ì€ ë…„ì´, ë¬´ìŠ¨ ì”ì†Œë¦´â€¦â€\\n\\nâ€œì•„ì´, ì•„ì´, ì •ë§ì´ì•¼ìš”. ì¥ê°€ í•œ ë§ˆë¦¬ ë‚˜â€¦â€\\n\\n18\\n\\nâ€œê·¸ëƒ¥ ì¥?â€\\n\\nâ€œì¥ ì¡ì„ë˜ë‹¤ê°€â€¦â€\\n\\nâ€œìƒ¹ë…„! ì£½ì–´ë¼! ë¬¼ì—ë˜ë‘ ë¹ ë° ì£½ì–¼!â€\\n\\nê·¸ëŠ” ì‹¤ì»· ë•Œë¦° ë’¤ì—, ì•„ë‚´ë„ ì•„ìš°ì²˜ëŸ¼ ë“±ì„ ë°€ì–´ ì«“ì•˜ë‹¤. ê·¸ ë’¤ì— ê·¸ì˜ ë“±ìœ¼ë¡œ,\\n\\nâ€œê³ ê¸° ë°°ë•Œê¸°ì— ì¥ì‚¬í•´ë¼!â€\\n\\ní† í•˜ì˜€ë‹¤.\\n\\në¶„í’€ì´ëŠ” ì‹¤ì»· í•˜ì˜€ì§€ë§Œ, ê·¸ë˜ë„ ë§ˆìŒì†ì´ ìëª» í¸ì¹˜ ëª»í•˜ì˜€ ë‹¤. ê·¸ëŠ” ì•„ë«ëª©ìœ¼ë¡œ ê°€ì„œ, ë°”ëŒë²½ì„ ì˜ì§€í•˜ê³  ì‹¤ì‹ í•œ ì‚¬ëŒ ê°™ì´ ìš°ë‘ì»¤ë‹ˆ ì„œì„œ ë–¡ ìƒë§Œ ë“¤ì—¬ë‹¤ë³´ê³  ìˆì—ˆë‹¤.\\n\\ní•œ ì‹œê°„â€¦ ë‘ ì‹œê°„â€¦.\\n\\nì„œí¸ìœ¼ë¡œ ë°”ë‹¤ë¥¼ í–¥í•œ ë§ˆì„ì´ë¼, ë‹¤ë¥¸ ê³³ë³´ë‹¤ëŠ” ëŠ¦ê²Œ ì–´ë‘¡ì§€ ë§Œ, ê·¸ë˜ë„ ìˆ ì‹œ(æˆŒæ™‚) ì¯¤ ë˜ì–´ì„œëŠ” ê¹œê¹œí•˜ë‹ˆ ì–´ë‘ì› ë‹¤. ê·¸ ëŠ” ë¶ˆì„ ì¼œë ¤ê³  ë°”ëŒë²½ì—ì„œ ë– ë‚˜ ì„±ëƒ¥ì„ ì°¾ìœ¼ëŸ¬ ëŒì•„ê°”ë‹¤.\\n\\nì„±ëƒ¥ì€ ëŠ˜ ìˆë˜ ìë¦¬ì— ìˆì§€ ì•Šì•˜ë‹¤. ê·¸ë˜ì„œ ì—¬ê¸°ì €ê¸° ë’¤ì  ì´ë…¸ë¼ë‹ˆê¹Œ, ì–´ë–¤ ë‚¡ì€ ì˜· ë­‰ì¹˜ë¥¼ ë“¤ì¹  ë•Œì— ë¬¸ë“ ì¥ ì†Œë¦¬ê°€ ë‚˜ë©´ì„œ ë¬´ì—‡ì´ í›„ë”ë• íŠ€ì–´ë‚˜ì˜¨ë‹¤. ê·¸ë¦¬í•˜ì—¬ ì €í¸ìœ¼ë¡œ ê¸°ì–´ ì„œ ë„ë§í•œë‹¤.\\n\\nâ€œì—­ì‹œ ì¥ëŒ”êµ¬ë‚˜!â€\\n\\n19\\n\\nê·¸ëŠ” ì¡°ê·¸ë§Œ ì†Œë¦¬ë¡œ ë¶€ë¥´ì§–ì—ˆë‹¤. ê·¸ë¦¬ê³  ê·¸ë§Œ ê·¸ ìë¦¬ì— ë§¥ ì—†ì´ ëœì© ì£¼ì €ì•‰ì•˜ë‹¤.\\n\\nì•„ê¹Œ ê·¸ê°€ ë³´ì§€ ëª»í•œ ë•Œì˜ ê´‘ê²½ì´, í™œë™ì‚¬ì§„ê³¼ ê°™ì´ ê·¸ì˜ ë¨¸ ë¦¬ì— ì§€ë‚˜ê°”ë‹¤.\\n\\nì•„ìš°ê°€ ì§‘ì—ë¥¼ ì˜¨ë‹¤. ì•„ìš°ì—ê²Œ ì¹œì ˆí•œ ì•„ë‚´ëŠ” ë–¡ì„ ë¨¹ìœ¼ë¼ê³  ì•„ìš°ì—ê²Œ ë–¡ ìƒì„ ë‚´ë†“ëŠ”ë‹¤. ê·¸ë•Œì— ì–´ë””ì„ ê°€ ì¥ê°€ í•œ ë§ˆë¦¬ ë›°ì–´ë‚˜ì˜¨ë‹¤. ë‘˜(ì•„ìš°ì™€ ì•„ë‚´)ì´ì„œëŠ” ì¥ë¥¼ ì¡ëŠë¼ê³  ëŒì•„ê°„ ë‹¤. í•œì°¸ ì„±í™”ì‹œí‚¤ë˜ ì¥ëŠ” ì–´ëŠ êµ¬ì„ì— ìˆ¨ì–´ë²„ë¦°ë‹¤. ê·¸ë“¤ì€ ì¥ë¥¼ ì°¾ëŠë¼ê³  ë‘ë£©ê±°ë¦°ë‹¤. ê·¸ëŸ´ ë•Œì— ê·¸ê°€ ì§‘ì— ë“¤ì–´ì„  ê²ƒ ì´ë‹¤.\\n\\nâ€œìƒë…„. ì¢€ ìˆìœ¼ë¯„ ì•ˆ ë“¤ì–´ì˜¤ë¦¬â€¦â€\\n\\nê·¸ëŠ” ì–µì§€ë¡œ ë§ˆìŒë¨¹ê³  ê·¸ ìë¦¬ì— ë“œëŸ¬ëˆ„ì› ë‹¤.\\n\\nê·¸ëŸ¬ë‚˜ ì•„ë‚´ëŠ” ë°¤ì´ ê°€ê³  ë‚ ì´ ë°ê¸°ëŠ”ì»¤ë…•, í•´ê°€ ì¤‘ì²œì— ì˜¬ ë¼ë„ ëŒì•„ì˜¤ì§€ë¥¼ ì•Šì•˜ë‹¤. ê·¸ëŠ” ì°¨ì°¨ ê±±ì •ì´ ë‚˜ì„œ ì°¾ì•„ë³´ëŸ¬ ë‚˜ì„°ë‹¤.\\n\\nì•„ìš°ì˜ ì§‘ì—ë„ ì—†ì—ˆë‹¤. ë™ë„¤ë¥¼ ëª¨ë‘ ì°¾ì•„ë³´ì•„ë„ ë³¸ ì‚¬ëŒë„ ì—†ë‹¤ í•œë‹¤.\\n\\nê·¸ë¦¬í•˜ì—¬, ë‚®ì¯¤ í•œ ì‚¼ì‚¬ ë¦¬ ë‚´ë ¤ê°€ì„œ ë°”ë‹·ê°€ì—ì„œ ê²¨ìš° ì•„ë‚´ ë¥¼ ì°¾ê¸°ëŠ” ì°¾ì•˜ì§€ë§Œ, ê·¸ ì•„ë‚´ëŠ” ì´ì „ ê°™ì€ ìƒê¸°ë¡œ ì°¬ ì‚° ì•„ë‚´ ê°€ ì•„ë‹ˆìš”, ëª¸ì€ ë¬¼ì— ë¶ˆì–´ì„œ ê³±ì´ë‚˜ í¬ê²Œ ë˜ê³ , ì´ì „ì— ëŠ˜ ì›ƒìŒì„ í˜ë¦¬ë˜ ì˜ˆìœ ì…ì—ëŠ” ê±°í’ˆì„ ì”ëœ© ë¬¼ì€, ì£½ì€ ì•„ë‚´ì˜€ ë‹¤.\\n\\n20\\n\\nê·¸ëŠ” ì•„ë‚´ë¥¼ ì—…ê³  ì§‘ìœ¼ë¡œ ëŒì•„ì˜¤ê¸°ê¹Œì§€ ì •ì‹ ì´ ì—†ì—ˆë‹¤.\\n\\nì´íŠ¿ë‚  ê°„ë‹¨í•˜ê²Œ ì¥ì‚¬ë¥¼ í•˜ì˜€ë‹¤. ë’¤ì— ë”°ë¼ì˜¤ëŠ” ì•„ìš°ì˜ ì–¼êµ´ ì—ëŠ”,\\n\\nâ€˜í˜•ë‹˜, ì´ê²Œ ì›¬ì¼ì´ì˜¤ë‹ˆê¹Œ?â€™\\n\\ní•˜ëŠ” ë“¯í•œ ì›ë§ì´ ìˆì—ˆë‹¤.\\n\\nğŸ™ğŸ™Ÿ ì¥ì‚¬ë¥¼ ì§€ë‚¸ ì´íŠ¿ë‚ ë¶€í„° ì•„ìš°ëŠ” ê·¸ ì¡°ê·¸ë§Œ ë§ˆì„ì—ì„œ ì—†ì–´ì¡Œ ë‹¤. í•˜ë£¨ ì´í‹€ì€ ì‹¬ìƒíˆ ì§€ëƒˆì§€ë§Œ, ë‹·ìƒˆê°€ ì§€ë‚˜ë„ ì•„ìš°ëŠ” ëŒ ì•„ì˜¤ì§€ ì•Šì•˜ë‹¤. ê·¸ë˜ì„œ ì•Œì•„ë³´ë‹ˆê¹Œ, ê¼­ ê·¸ì˜ ì•„ìš°ê°™ì´ ìƒê¸´ ì‚¬ëŒì´ ì˜¤ë¥™ ì¼ ì „ì— ë©§ì‚°ì ë³´ë”°ë¦¬ë¥¼ í•˜ì—¬ ì§„ ë’¤ì—, ì‹œë»˜ê±´ ì €ë… í•´ë¥¼ ë“±ìœ¼ë¡œ ë°›ê³  ë”ë²…ë”ë²… ë™ìª½ìœ¼ë¡œ ê°€ë”ë¼ í•œë‹¤. ê·¸ ë¦¬í•˜ì—¬ ì—´í˜ì´ ì§€ë‚˜ê³  ìŠ¤ë¬´ë‚ ì´ ì§€ë‚¬ì§€ë§Œ, í•œë²ˆ ë– ë‚œ ê·¸ì˜ ì•„ìš°ëŠ” ëŒì•„ì˜¬ ê¸¸ì´ ì—†ê³ , í˜¼ì ë‚¨ì€ ì•„ìš°ì˜ ì•„ë‚´ëŠ” ë§¤ì¼ í•œ ìˆ¨ìœ¼ë¡œ ì„¸ì›”ì„ ë³´ë‚´ê²Œ ë˜ì—ˆë‹¤.\\n\\nê·¸ë„ ì´ê²ƒì„ ì ìì½” ë³´ê³  ìˆì„ ìˆ˜ê°€ ì—†ì—ˆë‹¤. ê·¸ ë¶ˆí–‰ì˜ ëª¨ë“  ì£„ëŠ” ì£„ ê·¸ì—ê²Œ ìˆì—ˆë‹¤.\\n\\nê·¸ë„ ë§ˆì¹¨ë‚´ ë±ƒì‚¬ëŒì´ ë˜ì–´, ì ìœ¼ë‚˜ë§ˆ ì•„ë‚´ë¥¼ ì‚¼í‚¨ ë°”ë‹¤ì™€ ëŠ˜ ì ‘ê·¼í•˜ë©°, ê°€ëŠ” ê³³ë§ˆë‹¤ ì•„ìš°ì˜ ì†Œì‹ì„ ì•Œì•„ë³´ë ¤ê³ , ì–´ë–¤ ë°°ë¥¼ ì–»ì–´ íƒ€ê³  ë¬¼ê¸¸ì„ ë‚˜ì„°ë‹¤.\\n\\nê·¸ëŠ” ê°€ëŠ” ê³³ë§ˆë‹¤ ì•„ìš°ì˜ ì´ë¦„ê³¼ ëª¨ìŠµì„ ë§í•˜ì—¬ ë¬¼ì—ˆìœ¼ë‚˜, ì•„ìš°ì˜ ì†Œì‹ì€ ì•Œ ìˆ˜ê°€ ì—†ì—ˆë‹¤.\\n\\n21\\n\\nì´ë¦¬í•˜ì—¬ ê¿ˆê²°ê°™ì´ ì‹­ ë…„ì„ ì§€ë‚´ì„œ êµ¬ë…„ ì „ ê°€ì„, íƒíƒíˆ ë‚€ ì•ˆê°œë¥¼ ê¿°ë©° ì—°ì•ˆ(å»¶å®‰) ë°”ë‹¤ë¥¼ ì§€ë‚˜ê°€ë˜ ê·¸ì˜ ë°°ëŠ”, ëª¹ì‹œ ë¶€ëŠ” ë°”ëŒìœ¼ë¡œ ë§ë¯¸ì•”ì•„ íŒŒì„ ì„ í•˜ì—¬ ë²— ëª‡ ì‚¬ëŒì€ ì£½ê³ , ê·¸ ëŠ” ì •ì‹ ì„ ìƒê³  ë¬¼ìœ„ì— ë– ëŒê³  ìˆì—ˆë‹¤.\\n\\nê·¸ê°€ ì •ì‹ ì„ ì°¨ë¦° ë•ŒëŠ” ë°¤ì´ì—ˆë‹¤. ê·¸ë¦¬ê³  ì–´ëŠë§ ê·¸ëŠ” ë­ ìœ„ ì— ì˜¬ë¼ì™€ ìˆì—ˆê³  ê·¸ë¥¼ ë§ë¦¬ìš°ëŠë¼ê³  ìƒˆë¹¨ê°›ê²Œ í”¼ì›Œë†“ì€ ë¶ˆ ë¹›ìœ¼ë¡œ ìê¸°ë¥¼ ê°„í˜¸í•˜ëŠ” ì•„ìš°ë¥¼ ë³´ì•˜ë‹¤.\\n\\nê·¸ëŠ” ì´ìƒíˆë„ ë†€ë¼ì§€ ì•Šê³ , ì²œì—°í•˜ê²Œ ë¬¼ì—ˆë‹¤.\\n\\nâ€œë„ˆ, ì–´ã……ê°œ(ì–´ë–»ê²Œ) ì—¬ê¸° ì™„?â€\\n\\nì•„ìš°ëŠ” ì ìì½” í•œì°¸ ìˆë‹¤ê°€ ê²¨ìš° ëŒ€ë‹µí•˜ì˜€ë‹¤.\\n\\nâ€œí˜•ë‹˜, ê±°ì € ë‹¤ ìš´ëª…ì´ì™¼ë‹¤.â€\\n\\në”°ëœ»í•œ ë¶ˆê¸°ìš´ì— ê¹œë¹¡ ì ì´ ë“¤ë ¤ë‹¤ê°€ ê·¸ëŠ” í™”ë‹¥ë‹¥ ê¹¨ë©´ì„œ ë˜ ë§í–ˆë‹¤.\\n\\nâ€œì‹­ ë…„ ë™ì•ˆì— ë˜ê²Œ íŒŒë¬êµ¬ë‚˜.â€\\n\\nâ€œí˜•ë‹˜, ë‚˜ë‘ ë³€í–ˆê±°ë‹ˆì™€ í˜•ë‹˜ë„ ëª¹ì‹œ ëŠ™ìœ¼ì…¨ì‰ë‹¤.â€\\n\\nì´ ë§ì„ ê¿ˆê²°ê°™ì´ ë“¤ìœ¼ë©´ì„œ ê·¸ëŠ” ë˜ í˜¼í˜¼íˆ ì ì´ ë“¤ì—ˆë‹¤. ê·¸ ë¦¬í•˜ì—¬ ë‘ì–´ ì‹œê°„, ê¿€ë³´ë‹¤ë„ ë‹¨ ì ì„ ì” ë’¤ì— ê¹¨ì–´ë³´ë‹ˆ, ì•„ê¹Œ ê°™ì´ ë¹¨ê°„ ë¶ˆì€ í”¼ì–´ ìˆì§€ë§Œ ì•„ìš°ëŠ” ì–´ë””ë¡œ ê°”ëŠ”ì§€ ì—†ì–´ì¡Œ ë‹¤. ê³ì˜ ì‚¬ëŒì—ê²Œ ë¬¼ì–´ë³´ë‹ˆê¹Œ ì•„ê¹Œ ì•„ìš°ëŠ” í˜•ì˜ ì–¼êµ´ì„ ë¬¼ ë„ëŸ¬ë¯¸ í•œì°¸ ë“¤ì—¬ë‹¤ë³´ê³  ìˆë‹¤ê°€, ìƒˆë¹¨ê°„ ë¶ˆë¹›ì„ ë“±ìœ¼ë¡œ ë°›ìœ¼\\n\\n22\\n\\në©´ì„œ, ë”ë²…ë”ë²… ì•„ë¬´ë§ ì—†ì´ ì–´ë‘ì›€ ê°€ìš´ë°ë¡œ ì‚¬ë¼ì¡Œë‹¤ í•œ ë‹¤.\\n\\nì´íŠ¿ë‚  ì•„ë¬´ë¦¬ ì•Œì•„ë³´ì•„ì•¼ ê·¸ì˜ ì•„ìš°ëŠ” ì¢…ì ì´ ì—†ì–´ì§€ê³  ì•Œ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, ê·¸ëŠ” í•˜ë¦´ì—†ì´ ë‹¤ë¥¸ ë°°ë¥¼ ì–»ì–´ íƒ€ê³  ë˜ ë¬¼ê¸¸ì„ ë– ë‚¬ë‹¤. ê·¸ë¦¬í•˜ì—¬ ê·¸ì˜ ë°°ê°€ í•´ì£¼ì— ì´ë¥´ë €ì„ ë•Œ, ê·¸ëŠ” í•´ì£¼ ì¥ì— ë“¤ì–´ê°€ì„œ ë¬´ì—‡ì„ ì‚¬ë ¤ë‹¤ê°€, ì €í¸ ë§ì€í¸ ê°€ê²Œì— ê±¸í• ê·¸ì˜ ì•„ìš° ê°™ì€ ì‚¬ëŒì´ ìˆìœ¼ë¯€ë¡œ ë›°ì–´ê°€ì„œ ë³´ë‹ˆ ê·¸ëŠ” ë²Œì¨ ì—†ì–´ì¡Œë‹¤. ë°°ê°€ í•´ì£¼ì—ëŠ” ì˜¤ë˜ ë¨¸ë¬¼ì§€ ì•Šìœ¼ë¯€ë¡œ ê·¸ëŠ” ë§ˆìŒì€ í•´ì£¼ì— ë‚¨ê²¨ë‘ê³ , ë˜ë‹¤ì‹œ ë°”ë‹·ê¸¸ì„ ë– ë‚¬ë‹¤.\\n\\nê·¸ ë’¤ì— ì‚¼ ë…„ì„ ì´ë¦¬ì €ë¦¬ ëŒì•„ë‹¤ë…”ì–´ë„ ì•„ìš°ëŠ” ë‹¤ì‹œ ë³¼ ìˆ˜ ê°€ ì—†ì—ˆë‹¤.\\n\\nê·¸ë¦¬í•˜ì—¬ ì‚¼ ë…„ì„ ì§€ë‚´ì„œ ì§€ê¸ˆë¶€í„° ìœ¡ ë…„ ì „ì—, ê·¸ì˜ íƒ„ ë°°ê°€ ê°•í™”ë„ë¥¼ ì§€ë‚  ë‚ ì—, ë°”ë‹¤ë¥¼ í–¥í•œ ê°€íŒŒë¡œìš´ ë«¼ì¼ ì—ì„œ ë°”ë‹¤ë¥¼ í–¥í•˜ì—¬ ë‚ ì•„ì˜¤ëŠ” ë°°ë”°ë¼ê¸°ë¥¼ ë“¤ì—ˆë‹¤. ê·¸ê²ƒë„ ì–´ë–¤ êµ¬ì ˆê³¼ ê³¡ ì¡°ëŠ” ê·¸ì˜ ì•„ìš° íŠ¹ì‹ìœ¼ë¡œ ë³€ê²½ëœ - ê·¸ì˜ ì•„ìš°ê°€ ì•„ë‹ˆë©´ ë¶€ë¥¼ ì‚¬ëŒì´ ì—†ëŠ”, ê·¸ ë°°ë”°ë¼ê¸°ì´ë‹¤.\\n\\në°°ê°€ ê°•í™”ë„ì—ëŠ” ë¨¸ë¬´ë¥´ì§€ ì•Šì•„ì„œ ê±°ì € ì§€ë‚˜ê°”ìœ¼ë‚˜, ì¸ì²œì„œ ì—´í˜ì¯¤ ë¨¸ë¬´ë¥´ê²Œ ë˜ì—ˆìœ¼ë¯€ë¡œ, ê·¸ëŠ” ê³§ ë‚´ë ¤ì„œ ê°•í™”ë„ë¡œ ê±´ë„ˆ ê°€ ë³´ì•˜ë‹¤. ê±°ê¸°ì„œ ì´ë¦¬ì €ë¦¬ ì°¾ì•„ë‹¤ë‹ˆë‹¤ê°€, ì–´ë–¤ ì¡°ê·¸ë§Œ ê° ì£¼ì§‘ì—ì„œ ë¬¼ì–´ë³´ë‹ˆ, ì´ë¦„ë„ ê·¸ì˜ ì•„ìš°ìš”, ìƒê¸´ ëª¨ìŠµë„ ê·¸ì˜ ì•„ìš°ì¸ ì‚¬ëŒì´ ë¬µì–´ ìˆê¸°ëŠ” í•˜ì˜€ìœ¼ë‚˜, ì‚¬ë‚˜í˜ ì „ì— ë„ë¡œ ì¸ ì²œìœ¼ë¡œ ê°”ë‹¤ í•œë‹¤. ê·¸ëŠ” ê³§ ëŒì•„ì„œì„œ ì¸ì²œìœ¼ë¡œ ê±´ë„ˆì™€ì„œ ì°¾ ì•„ë³´ì•˜ì§€ë§Œ, ê·¸ ì¡°ê·¸ë§Œ ì¸ì²œì„œë„ ê·¸ì˜ ì•„ìš°ë¥¼ ì°¾ì„ ë°”ì´ ì—† ì—ˆë‹¤.\\n\\n23\\n\\nê·¸ ë’¤ì— ëˆˆ ì˜¤ê³  ë¹„ ì˜¤ë©°, ìœ¡ë…„ì´ ì§€ë‚¬ì§€ë§Œ, ê·¸ëŠ” ë‹¤ì‹œ ì•„ìš° ë¥¼ ë§Œë‚˜ë³´ì§€ ëª»í•˜ê³  ì•„ìš°ì˜ ìƒì‚¬ê¹Œì§€ë„ ì•Œ ìˆ˜ê°€ ì—†ë‹¤.\\n\\në§ì„ ëë‚¸ ê·¸ì˜ ëˆˆì—ëŠ” ì €ë… í•´ì— ë°˜ì‚¬í•˜ì—¬ ëª‡ ë°©ìš¸ì˜ ëˆˆë¬¼ ì´ ë°˜ì§ì¸ë‹¤.\\n\\në‚˜ëŠ” í•œì°¸ ìˆë‹¤ê°€ ê²¨ìš° ë¬¼ì—ˆë‹¤.\\n\\nâ€œë…¸í˜• ê³„ìˆ˜ëŠ”?â€\\n\\nâ€œëª¨ë¥´ë””ì˜¤. ì´ì‹­ ë…„ì„ ì˜ìœ ëŠ” ì•ˆê°€ë´¤ìœ¼ë‹ˆë‚€ìš”.â€\\n\\nâ€œë…¸í˜•ì€ ì´ì œ ì–´ë””ë£¨ ê°ˆ í…Œìš”?â€\\n\\nâ€œê²ƒë‘ ëª¨ë¥´ë””ìš”. ë©ì²˜ê°€ ìˆë‚˜ìš”? ë°”ëŒ ë¶€ëŠ” ëŒ€ë¡œ ëª°ë ¤ëŒ•ê¸°ë”” ì˜¤.â€\\n\\nê·¸ëŠ” ë‹¤ì‹œ í•œë²ˆ ë‚˜ë¥¼ ìœ„í•˜ì—¬ ë°°ë”°ë¼ê¸°ë¥¼ ë¶ˆë €ë‹¤. ì•„ì•„, ê·¸ ì† ì— ì ê²¨ ìˆëŠ” ì‚­ì´ì§€ ëª»í•  ë‰˜ìš°ì¹¨, ë°”ë‹¤ì— ëŒ€í•œ ì• ì²˜ë¡œìš´ ê·¸ ë¦¬ì›€.\\n\\në…¸ë˜ë¥¼ ëë‚¸ ë‹¤ìŒì— ê·¸ëŠ” ì¼ì–´ì„œì„œ ì‹œë»˜ê±´ ì €ë… í•´ë¥¼ ì”ëœ© ë“±ìœ¼ë¡œ ë°›ê³ , ì„ë°€ëŒ€ë¡œ í–¥í•˜ì—¬ ë”ë²…ë”ë²… ê±¸ì–´ê°„ë‹¤. ë‚˜ëŠ” ê·¸ ë¥¼ ë§ë¦´ í˜ì´ ì—†ì–´ì„œ, ë©€ê±°ë‹ˆ ê·¸ì˜ ë“±ë§Œ ë°”ë¼ë³´ê³  ì•‰ì•„ ìˆì—ˆ ë‹¤.\\n\\nê·¸ë‚  ë°¤, ì§‘ì— ëŒì•„ì™€ì„œë„ ê·¸ ë°°ë”°ë¼ê¸°ì™€ ê·¸ì˜ ìˆ™ëª…ì  ê²½í—˜ ë‹´ì´ ê·€ì— ìŸìŸíˆ ìš¸ë¦¬ì–´ì„œ ì ì„ ëª» ì´ë£¨ê³ , ì´íŠ¿ë‚  ì•„ì¹¨ ê¹¨ ì–´ì„œ ì¡°ë°˜ë„ ì•ˆë¨¹ê³  ê¸°ìë¬˜ë¡œ ë›°ì–´ê°€ì„œ ë˜ë‹¤ì‹œ ê·¸ë¥¼ ì°¾ì•„ë³´ ì•˜ë‹¤. ê·¸ê°€ ì–´ì œ ê¹”ê³  ì•‰ì•˜ë˜ í’€ì€ ëª¨ë‘ í•œí¸ìœ¼ë¡œ ëˆ„ì›Œì„œ ê·¸\\n\\n24\\n\\nê°€ ë‹¤ë…€ê°ì„ ê¸°ë…í•˜ë˜, ê·¸ëŠ” ê·¸ ê·¼ì²˜ì— ë³´ì´ì§€ ì•Šì•˜ë‹¤. ê·¸ëŸ¬ ë‚˜ - ê·¸ëŸ¬ë‚˜ ë°°ë”°ë¼ê¸°ëŠ” ì–´ë””ì„ ê°€ ìŸìŸíˆ ìš¸ë¦¬ì–´ì„œ ëª¨ë“  ì†Œ ë‚˜ë¬´ë“¤ì„ ë–¨ë¦¬ì§€ ì•Šê³ ëŠ” ì•ˆ ë‘ê² ë‹¤ëŠ” ë“¯ì´ ë‚ ì•„ì˜¨ë‹¤.\\n\\nâ€œëª¨ë€ë´‰(ç‰¡ä¸¹å³°)ì´ë‹¤. ëª¨ë€ë´‰ì— ìˆë‹¤.â€\\n\\ní•˜ê³  ë‚˜ëŠ” í•œìˆ¨ì— ëª¨ë€ë´‰ìœ¼ë¡œ ë›°ì–´ê°”ë‹¤. ëª¨ë€ë´‰ì—ëŠ” ì‚¬ëŒì´ í•˜ë‚˜ë„ ì—†ë‹¤. ë¶€ë²½ë£¨(æµ®ç¢§æ¨“)ì—ë„ ì—†ë‹¤.\\n\\nâ€œì„ë°€ëŒ€(â¼„å¯†è‡º)ë‹¤.â€\\n\\ní•˜ê³  ë‚˜ëŠ” ë‹¤ì‹œ ì„ë°€ëŒ€ë¡œ ê°”ë‹¤. ì„ë°€ëŒ€ì—ì„  ë¶€ë²½ë£¨ë¥¼ ì—°í•œ, ì§€ì˜¥ê¹Œì§€ ì—°í•œ ë“¯í•œ ê³¨ì§œê¸°ì— ë¬¼ í•œ ë°©ìš¸ì„ ì•ˆ ìƒˆì´ë¦¬ë¼ê³  ë¹½ë¹½ì´ ë‚œ ì†Œë‚˜ë¬´ì˜ ê·¸ ëª¨ë“  ììì€ ë–¨ë¦¬ëŠ” ë°°ë”°ë¼ê¸°ë¥¼ ë¶€ë¥´ ê³  ìˆì§€ë§Œ, ê·¸ëŠ” ì—¬ê¸°ë„ ìˆì§€ ì•Šë‹¤. ê¸°ìë¬˜ì˜, í•˜ëŠ˜ì„ í–¥í•˜ì—¬ í¼ì ¸ë‚˜ê°„ ê·¸ ëª¨ë“  ì†Œë‚˜ë¬´ì˜ ì²œë§Œì˜ ììë„, ê·¸ ì•„ë˜ìª½ í¼ì§„ ì²œë§Œì˜ í’€ë“¤ë„, ëª¨ë‘ ê·¸ ë°°ë”°ë¼ê¸°ë¥¼ ìŠ¬í”„ê²Œ ë¶€ë¥´ê³  ìˆì§€ë§Œ, ê·¸ëŠ” ì´ ì¡°ê·¸ë§Œ ëª¨ë€ë´‰ ì¼ëŒ€ì—ì„œ ì°¾ì„ ìˆ˜ê°€ ì—†ì—ˆë‹¤.\\n\\nê°•ê°€ì— ë‚˜ê°€ì„œ ì•Œì•„ë³´ë‹ˆ, ê·¸ì˜ ë°°ëŠ” ì˜¤ëŠ˜ ìƒˆë²½ì— ë– ë‚¬ë‹¤ í•œ ë‹¤. ê·¸ ë’¤ì— ì—¬ë¦„ê³¼ ê°€ì„ì´ ê°€ê³  ì¼ë…„ì´ ì§€ë‚˜ì„œ ë‹¤ì‹œ ë´„ì´ ì´ ë¥´ë €ìœ¼ë˜, ì ê¹ í‰ì–‘ì„ ë‹¤ë…€ê°„ ê·¸ëŠ” ê·¸ ìˆ™ëª…ì  ê²½í—˜ë‹´ê³¼ ìŠ¬ í”ˆ ë°°ë”°ë¼ê¸°ë¥¼ ë‘ì—ˆì„ ë¿, ë‹¤ì‹œ ì¡°ê·¸ë§Œ ëª¨ë€ë´‰ì— ë‚˜íƒ€ë‚˜ì§€ ì•ŠëŠ”ë‹¤.\\n\\nëª¨ë€ë´‰ê³¼ ê¸°ìë¬˜ì— ë‹¤ì‹œ ë´„ì´ ì´ë¥´ëŸ¬ì„œ, ì‘ë…„ì— ê·¸ê°€ ê¹”ê³  ì•‰ì•„ì„œ ë¶€ëŸ¬ì¡Œë˜ í’€ë“¤ë„ ë‹¤ì‹œ ê³§ê²Œ ëŒ€ê°€ ë‚˜ì„œ ìì£¼ë¹› ê½ƒì´ í”¼ë ¤ í•˜ì§€ë§Œ ëì—†ëŠ” ë‰˜ìš°ì¹¨ì„ ë‹¤ë§Œ í•œë‚± ë°°ë”°ë¼ê¸°ë¡œ í•˜ì†Œì—° í•˜ëŠ” ê·¸ëŠ”, ì´ ì¡°ê·¸ë§Œ ëª¨ë€ë´‰ê³¼ ê¸°ìë¬˜ì—ì„œ ë‹¤ì‹œ ë³¼ ìˆ˜ê°€ ì—†\\n\\n25\\n\\nì—ˆë‹¤. ë‹¤ë§Œ ê·¸ê°€ ë‚¨ê¸°ê³  ê°„ ë°°ë”°ë¼ê¸°ë§Œ ì¶”ì–µí•˜ëŠ” ë“¯ì´ ëª¨ë“  ììì´ ì†ì‚­ì´ê³  ìˆì„ ë”°ë¦„ì´ë‹¤.\\n\\n26\\n\\nì´ ì €ì‘ë¬¼ì€ ì €ìê°€ ì‚¬ë§í•œ ì§€ 50ë…„ì´ ë„˜ì—ˆìœ¼ë¯€ ë¡œ, ì €ìê°€ ì‚¬ë§í•œ í›„ 50ë…„(ë˜ëŠ” ê·¸ ì´í•˜)ì´ ì§€ë‚˜ ë©´ ì €ì‘ê¶Œì´ ì†Œë©¸í•˜ëŠ” êµ­ê°€ì—ì„œ í¼ë¸”ë¦­ ë„ë©”ì¸ì… ë‹ˆë‹¤.\\n\\n1929ë…„ì—ì„œ 1977ë…„ ì‚¬ì´ì— ì¶œíŒë˜ì—ˆë‹¤ë©´ ë¯¸êµ­ì—ì„œ í¼ë¸” ë¦­ ë„ë©”ì¸ì´ ì•„ë‹ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ë¯¸êµ­ì—ì„œ í¼ë¸”ë¦­ ë„ë©”ì¸ ì¸ ì €ì‘ì—ëŠ” {{PD-1996}}ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.\\n\\nì£¼ì˜\\n\\n27\\n\\nAbout this digital edition\\n\\nThis e-book comes from the online library Wikisource[1]. This multilingual digital library, built by volunteers, is committed to developing a free accessible collection of publications of every kind: novels, poems, magazines, letters...\\n\\nWe distribute our books for free, starting from works not copyrighted or published under a free license. You are free to use our e-books for any purpose (including commercial exploitation), under the terms of the Creative Commons Attribution-ShareAlike 3.0 Unported[2] license or, at your choice, those of the GNU FDL[3].\\n\\nWikisource is constantly looking for new members. During the realization of this book, it's possible that we made some errors. You can report them at this page[4].\\n\\nThe following users contributed to this book:\\n\\nCaï¬€elice~kowikisource Mineralsab Salamander724 Kwamikagami Tene~commonswiki Rocket000\\n\\n28\\n\\nBastique Andux Amgine Boris23 KABALINI Bromskloss AzaToth Bender235 PatrÃ­ciaR\\n\\n1. â†‘ https://wikisource.org 2. â†‘ https://www.creativecommons.org/licenses/by-sa/3.0 3. â†‘ https://www.gnu.org/copyleft/fdl.html 4. â†‘ https://wikisource.org/wiki/Wikisource:Scriptorium\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 13\n",
    "docs[idx].metadata\n",
    "docs[idx].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04a1e8eb-2569-43f3-a458-dd020a322c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DirectoryLoader(\n",
    "    \"data\", # ì½ì–´ë“¤ì¼ ë¬¸ì„œë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬.\n",
    "    glob=[\"*.txt\"],   # ì½ì„ íŒŒì¼ë“¤ì˜ í™•ì¥ìë¥¼ ì§€ì •.\n",
    "    recursive=False, # í•˜ìœ„ë””ë ‰í† ë¦¬ê¹Œì§€ ê²€ìƒ‰í• ì§€ ì—¬ë¶€.\n",
    ")\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "606579fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d910f155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data/olympic.txt'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[2].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de26ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275ba5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8314a70c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15823c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "300bddc2",
   "metadata": {},
   "source": [
    "# Chunking (ë¬¸ì„œ ë¶„í• )\n",
    "\n",
    "![rag_split](figures/rag_split.png)\n",
    "\n",
    "- Load í•œ ë¬¸ì„œë¥¼ ì§€ì •í•œ ê¸°ì¤€ì˜ ë©ì–´ë¦¬(chunk)ë¡œ ë‚˜ëˆ„ëŠ” ì‘ì—…ì„ ì§„í–‰í•œë‹¤.\n",
    "\n",
    "## ë‚˜ëˆ„ëŠ” ì´ìœ \n",
    "1. **ì„ë² ë”© ëª¨ë¸ì˜ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ**\n",
    "    - ëŒ€ë¶€ë¶„ì˜ ì–¸ì–´ ëª¨ë¸ì€ í•œ ë²ˆì— ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í† í° ìˆ˜ì— ì œí•œì´ ìˆë‹¤. ì „ì²´ ë¬¸ì„œë¥¼ í†µì§¸ë¡œ ì…ë ¥í•˜ë©´ ì´ ì œí•œì„ ì´ˆê³¼í•  ìˆ˜ ìˆì–´ ì²˜ë¦¬ê°€ ë¶ˆê°€ëŠ¥í•´ì§„ë‹¤.\n",
    "2. **ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ**\n",
    "    - í° ë¬¸ì„œ ì „ì²´ë³´ë‹¤ëŠ” íŠ¹ì • ì£¼ì œë‚˜ ë‚´ìš©ì„ ë‹¤ë£¨ëŠ” ì‘ì€ chunkê°€ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ë” ì •í™•í•˜ê²Œ ë§¤ì¹­ëœë‹¤. ì˜ˆë¥¼ ë“¤ì–´, 100í˜ì´ì§€ ë§¤ë‰´ì–¼ì—ì„œ íŠ¹ì • ê¸°ëŠ¥ì— ëŒ€í•œ ì§ˆë¬¸ì´ ìˆì„ ë•Œ, í•´ë‹¹ ê¸°ëŠ¥ì„ ì„¤ëª…í•˜ëŠ” ëª‡ ê°œì˜ ë¬¸ë‹¨ë§Œ ê²€ìƒ‰ë˜ëŠ” ê²ƒì´ ë” íš¨ê³¼ì ì´ë‹¤.\n",
    "    - ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ ë¬¸ì„œì˜ ëª¨ë“  ë‚´ìš©ì´ ë‹¤ ê´€ë ¨ìˆëŠ” ê²ƒì€ ì•„ë‹ˆë‹¤. Chunkingì„ í†µí•´ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¶€ë¶„ë§Œ ì„ ë³„ì ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆì–´ ë‹µë³€ì˜ í’ˆì§ˆì´ í–¥ìƒëœë‹¤.\n",
    "    - ì „ì²´ ë¬¸ì„œì—ëŠ” ì§ˆë¬¸ê³¼ ë¬´ê´€í•œ ë‚´ìš©ë“¤ì´ ë§ì´ í¬í•¨ë˜ì–´ ìˆì–´ ëª¨ë¸ì´ í˜¼ë€ì„ ê²ªì„ ìˆ˜ ìˆë‹¤. ì ì ˆí•œ í¬ê¸°ì˜ chunkëŠ” ì´ëŸ° ë…¸ì´ì¦ˆë¥¼ ì¤„ì—¬ì¤€ë‹¤.\n",
    "3. **ê³„ì‚° íš¨ìœ¨ì„±**\n",
    "    - ë²¡í„° ìœ ì‚¬ë„ ê³„ì‚°, ì„ë² ë”© ìƒì„± ë“±ì˜ ì‘ì—…ì´ ì‘ì€ chunk ë‹¨ìœ„ë¡œ ìˆ˜í–‰ë  ë•Œ ë” ë¹ ë¥´ê³  íš¨ìœ¨ì ì´ë‹¤. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ë„ ì¤„ì¼ ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "## ì£¼ìš” Spliter\n",
    "- https://api.python.langchain.com/en/latest/text_splitters_api_reference.html\n",
    "\n",
    "### CharacterTextSplitter\n",
    "ê°€ì¥  ê¸°ë³¸ì ì¸ Text spliter\n",
    "- í•œê°œì˜ êµ¬ë¶„ìë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬í•œë‹¤. (default: \"\\n\\n\")\n",
    "    - ë¶„ë¦¬ëœ ì¡°ê°ì´ chunk size ë³´ë‹¤ ì‘ìœ¼ë©´ ë‹¤ìŒ ì¡°ê°ê³¼ í•©ì¹  ìˆ˜ ìˆë‹¤.\n",
    "        - í•©ì³¤ì„ë•Œ chuck_size ë³´ë‹¤ í¬ë©´ ì•ˆ í•©ì¹œë‹¤. chuck_size ì´ë‚´ë©´ í•©ì¹œë‹¤.\n",
    "    - ë‚˜ëˆ„ëŠ” ê¸°ì¤€ì€ êµ¬ë¶„ìì´ê¸° ë•Œë¬¸ì— chunk_size ë³´ë‹¤ ê¸€ììˆ˜ê°€ ë§ì„ ìˆ˜ ìˆë‹¤.\n",
    "- chunk size: ë¶„ë¦¬ëœ ë¬¸ì„œ(chunk) ê¸€ììˆ˜ ì´ë‚´ì—ì„œ ë¶„ë¦¬ë˜ë„ë¡ í•œë‹¤.\n",
    "    -  êµ¬ë¶„ìë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬í•œë‹¤. êµ¬ë¶„ìë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬í•œ ë¬¸ì„œ ì¡°ê°ì´ chunk size ë³´ë‹¤ í¬ë”ë¼ë„ ê·¸ëŒ€ë¡œ ìœ ì§€í•œë‹¤. ì¦‰ chunk_sizeê°€ ìš°ì„ ì´ ì•„ë‹ˆë¼ **seperator** ê°€ ìš°ì„ ì´ë‹¤.\n",
    "- ì£¼ìš” íŒŒë¼ë¯¸í„°\n",
    "    - chunk_size: ê° ì¡°ê°ì˜ ìµœëŒ€ ê¸¸ì´ë¥¼ ì§€ì •.\n",
    "    - seperator: êµ¬ë¶„ ë¬¸ìì—´ì„ ì§€ì •. (default: '\\n\\n')\n",
    "- CharacterTextSplitterëŠ” ë‹¨ìˆœ ìŠ¤í”Œë¦¬í„°ë¡œ overlapê¸°ëŠ¥ì„ ì§€ì›í•˜ì§€ëŠ” ì•ŠëŠ”ë‹¤. ë‹¨ seperatorê°€ ë¹ˆë¬¸ìì—´(\"\") ì¼ ê²½ìš°ì—ëŠ” overlap ê¸°ëŠ¥ì„ ì§€ì›í•œë‹¤. overlapì´ë€ ê° ì´ì „ ì²­í¬ì˜ ë’·ë¶€ë¶„ì˜ ë¬¸ìì—´ì„ ì•ì— ë¶™ì—¬ ë¬¸ë§¥ì„ ìœ ì§€í•˜ëŠ” ê²ƒì„ ë§í•œë‹¤.\n",
    "  \n",
    "### RecursiveCharacterTextSplitter\n",
    "- RecursiveCharacterTextSplitterëŠ” **ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì§€ì •ëœ ìµœëŒ€ ê¸¸ì´(chunk_size) ì´í•˜ë¡œ ë‚˜ëˆ„ëŠ” ë° íš¨ê³¼ì ì¸ í…ìŠ¤íŠ¸ ë¶„í• ê¸°**(splitter)ì´ë‹¤.\n",
    "- ì—¬ëŸ¬ **êµ¬ë¶„ì(separators)ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì ìš©**í•˜ì—¬, ê°€ëŠ¥í•œ í•œ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ë‹¨/ë¬¸ì¥/ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ê³ , ìµœì¢…ì ìœ¼ë¡œëŠ” í¬ê¸° ì œí•œì„ ë§Œì¡±ì‹œí‚¨ë‹¤.\n",
    "- ë¶„í•  ê¸°ì¤€ ë¬¸ì\n",
    "    1. ë‘ ê°œì˜ ì¤„ë°”ê¿ˆ ë¬¸ì (\"\\n\\n\")\n",
    "    2. í•œ ê°œì˜ ì¤„ë°”ê¿ˆ ë¬¸ì (\"\\n\")\n",
    "    3. ê³µë°± ë¬¸ì (\" \")\n",
    "    4. ë¹ˆ ë¬¸ìì—´ (\"\")\n",
    "- ì‘ë™ ë°©ì‹\n",
    "    1. ë¨¼ì € ê°€ì¥ ë†’ì€ ìš°ì„ ìˆœìœ„ì˜ êµ¬ë¶„ì(\"\\n\\n\")ë¡œ ë¶„í• ì„ ì‹œë„í•œë‹¤.\n",
    "    2. ë¶„í• ëœ ì¡°ê° ì¤‘ **chunk_sizeë¥¼ ì´ˆê³¼í•˜ëŠ” ì¡°ê°**ì— ëŒ€í•´ ë‹¤ìŒ ìš°ì„ ìˆœìœ„ êµ¬ë¶„ì(\"\\n\" â†’ \" \" â†’ \"\")ë¡œ ì¬ê·€ì ìœ¼ë¡œ ì¬ë¶„í• í•œë‹¤.\n",
    "    3. ì´ ê³¼ì •ì„ í†µí•´ ëª¨ë“  ì¡°ê°(chunk)ì´ chunk_sizeë¥¼ ì´ˆê³¼í•˜ì§€ ì•Šë„ë¡ ë§Œë“ ë‹¤.  \n",
    "- ì£¼ìš” íŒŒë¼ë¯¸í„°\n",
    "    - chunk_size: ê° ì¡°ê°ì˜ ìµœëŒ€ ê¸¸ì´ë¥¼ ì§€ì •.\n",
    "    - chunk_overlap: ì—°ì†ëœ ì²­í¬ë“¤ ê°„ì˜ ê²¹ì¹˜ëŠ” ë¬¸ì ìˆ˜ë¥¼ ì„¤ì •. ìƒˆë¡œìš´ ì²­í¬ ìƒì„± ì‹œ ì´ì „ ì²­í¬ì˜ ë§ˆì§€ë§‰ ë¶€ë¶„ì—ì„œ ì§€ì •ëœ ìˆ˜ë§Œí¼ì˜ ë¬¸ìë¥¼ ê°€ì ¸ì™€ì„œ ìƒˆ ì²­í¬ì˜ ì•ë¶€ë¶„ì— í¬í•¨ì‹œì¼œ, ì²­í¬ ê²½ê³„ì—ì„œ ë¬¸ë§¥ì˜ ì—°ì†ì„±ì„ ìœ ì§€í•œë‹¤.\n",
    "      - êµ¬ë¶„ìì— ì˜í•´ ì²­í¬ê°€ ë‚˜ëˆ ì§€ë©´ ì •ìƒì ì¸ ë¶„ë¦¬ì´ë¯€ë¡œ overlapì´ ì ìš©ë˜ì§€ ì•ŠëŠ”ë‹¤.\n",
    "      - ì •ìƒì  êµ¬ë¶„ìë¡œ ë‚˜ëˆŒ ìˆ˜ ì—†ì–´ chunk_sizeì— ë§ì¶° ì˜ë¼ì§„ ê²½ìš° ë¬¸ë§¥ì˜ ì—°ê²°ì„±ì„ ìœ„ì•  overlapì„ ì ìš©í•œë‹¤.\n",
    "    - separators(list): êµ¬ë¶„ìë¥¼ ì§€ì •í•œë‹¤. ì§€ì •í•˜ë©´ ê¸°ë³¸ êµ¬ë¶„ìê°€ ì§€ì •í•œ ê²ƒìœ¼ë¡œ ë³€ê²½ëœë‹¤.\n",
    "\n",
    "#### ë©”ì†Œë“œ\n",
    "- `split_documents(Iterable[Document]) : List[Document]`\n",
    "    - Document ëª©ë¡ì„ ë°›ì•„ split ì²˜ë¦¬í•œë‹¤.\n",
    "- `split_text(str) : List[str]`\n",
    "    - string textë¥¼ ë°›ì•„ì„œ split ì²˜ë¦¬í•œë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35a08d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"ê°€ê°ê°„ê°‡ê°ˆê°‰ê°Šê°ê°‘ê°’ê°“ê°”ê°•ê°–ê°—ê°™ê°šê°›ê°œê°ê° ê°¤ê°¬ê°­ê°¯ê°°\n",
    "\n",
    "aadlskfjadklsfjakldfjadklsjadfsklê°¸ê°¹ê°¼ê±€ê±‹ê±ê±”ê±˜ê±œê±°ê±±ê±´ê±·ê±¸ê±ºê²€ê²ê²ƒê²‰ê²Šê²‹ê²Œê²\n",
    "\n",
    "ë±ë³ëµë¼ë½ë€ë„ëŒëëë\n",
    "\n",
    "ë‘ë’ë–ë—ë˜ë™ëœë ë¨ë©ë«ë¬ë­ë´ëµë¸ëŸ‡ëŸ‰ëŸ¬ëŸ­ëŸ°ëŸ´ëŸ¼ëŸ½ëŸ¿ë €ë ë ‡ë ˆë ‰ë Œë ë ˜ë ™ë ›ë ë‚˜ë‚™ë‚šASDFFGHJJKKLLLQWE\n",
    "\n",
    "ë©¨ë©©ë©° \n",
    "\n",
    "ë©±ë©´ë©¸ëªƒëª„ëª…ëª‡ëªŒëª¨ëª©ëª«ëª¬ëª°ëª²ëª¸ëª¹ëª»ëª½ë«„ë«ˆë«˜ë«™ë«¼ë¬€ë¬„ë¬ë¬ë¬‘ë¬˜ë¬œë¬ ë¬©ë¬«ë¬´ë¬µë¬¶ë¬¸ë¬»ë¬¼ë¬½ë¬¾ë­„ë­…ë­‡ë­‰ë­ë­ABCDEFGHIJ\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3725f8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "# chunk_size > chunk_overlap   =>   êµ­ë£°\n",
    "spliter = CharacterTextSplitter(\n",
    "    chunk_size = 60,                                    # 60ê¸€ìë¡œ ìë¦„\n",
    "    chunk_overlap = 10,                                 # ê²¹ì¹˜ëŠ” ë¬¸ì ìˆ˜ ì§€ì •\n",
    "    # separator = \"\"                                      # defaul : \"\\n\\n\"\n",
    ")\n",
    "docs = spliter.split_text(text)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee0c8840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "ê°€ê°ê°„ê°‡ê°ˆê°‰ê°Šê°ê°‘ê°’ê°“ê°”ê°•ê°–ê°—ê°™ê°šê°›ê°œê°ê° ê°¤ê°¬ê°­ê°¯ê°°\n",
      "56\n",
      "aadlskfjadklsfjakldfjadklsjadfsklê°¸ê°¹ê°¼ê±€ê±‹ê±ê±”ê±˜ê±œê±°ê±±ê±´ê±·ê±¸ê±ºê²€ê²ê²ƒê²‰ê²Šê²‹ê²Œê²\n",
      "11\n",
      "ë±ë³ëµë¼ë½ë€ë„ëŒëëë\n",
      "56\n",
      "ë‘ë’ë–ë—ë˜ë™ëœë ë¨ë©ë«ë¬ë­ë´ëµë¸ëŸ‡ëŸ‰ëŸ¬ëŸ­ëŸ°ëŸ´ëŸ¼ëŸ½ëŸ¿ë €ë ë ‡ë ˆë ‰ë Œë ë ˜ë ™ë ›ë ë‚˜ë‚™ë‚šASDFFGHJJKKLLLQWE\n",
      "3\n",
      "ë©¨ë©©ë©°\n",
      "57\n",
      "ë©±ë©´ë©¸ëªƒëª„ëª…ëª‡ëªŒëª¨ëª©ëª«ëª¬ëª°ëª²ëª¸ëª¹ëª»ëª½ë«„ë«ˆë«˜ë«™ë«¼ë¬€ë¬„ë¬ë¬ë¬‘ë¬˜ë¬œë¬ ë¬©ë¬«ë¬´ë¬µë¬¶ë¬¸ë¬»ë¬¼ë¬½ë¬¾ë­„ë­…ë­‡ë­‰ë­ë­ABCDEFGHIJ\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(len(doc))\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c57ae7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 6, langchain_core.documents.base.Document)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "document = Document(page_content=text)\n",
    "docs2 = spliter.split_documents([document])\n",
    "type(docs2), len(docs2), type(docs2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed5b25cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='ê°€ê°ê°„ê°‡ê°ˆê°‰ê°Šê°ê°‘ê°’ê°“ê°”ê°•ê°–ê°—ê°™ê°šê°›ê°œê°ê° ê°¤ê°¬ê°­ê°¯ê°°'\n",
      "page_content='aadlskfjadklsfjakldfjadklsjadfsklê°¸ê°¹ê°¼ê±€ê±‹ê±ê±”ê±˜ê±œê±°ê±±ê±´ê±·ê±¸ê±ºê²€ê²ê²ƒê²‰ê²Šê²‹ê²Œê²'\n",
      "page_content='ë±ë³ëµë¼ë½ë€ë„ëŒëëë'\n",
      "page_content='ë‘ë’ë–ë—ë˜ë™ëœë ë¨ë©ë«ë¬ë­ë´ëµë¸ëŸ‡ëŸ‰ëŸ¬ëŸ­ëŸ°ëŸ´ëŸ¼ëŸ½ëŸ¿ë €ë ë ‡ë ˆë ‰ë Œë ë ˜ë ™ë ›ë ë‚˜ë‚™ë‚šASDFFGHJJKKLLLQWE'\n",
      "page_content='ë©¨ë©©ë©°'\n",
      "page_content='ë©±ë©´ë©¸ëªƒëª„ëª…ëª‡ëªŒëª¨ëª©ëª«ëª¬ëª°ëª²ëª¸ëª¹ëª»ëª½ë«„ë«ˆë«˜ë«™ë«¼ë¬€ë¬„ë¬ë¬ë¬‘ë¬˜ë¬œë¬ ë¬©ë¬«ë¬´ë¬µë¬¶ë¬¸ë¬»ë¬¼ë¬½ë¬¾ë­„ë­…ë­‡ë­‰ë­ë­ABCDEFGHIJ'\n"
     ]
    }
   ],
   "source": [
    "for d in docs2:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb96813e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 9\n"
     ]
    }
   ],
   "source": [
    "spliter2 = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 50,\n",
    "    chunk_overlap = 10\n",
    "    # ,separators=[\"ì²«ë²ˆì¨° êµ¬ë¶„ì\", \"ë‘ë²ˆì§¸ êµ¬ë¶„ì\", ...]\n",
    ")\n",
    "\n",
    "result = spliter2.split_text(text)\n",
    "print(type(result), len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5cd8206f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26||ê°€ê°ê°„ê°‡ê°ˆê°‰ê°Šê°ê°‘ê°’ê°“ê°”ê°•ê°–ê°—ê°™ê°šê°›ê°œê°ê° ê°¤ê°¬ê°­ê°¯ê°°\n",
      "======================================================================\n",
      "49||aadlskfjadklsfjakldfjadklsjadfsklê°¸ê°¹ê°¼ê±€ê±‹ê±ê±”ê±˜ê±œê±°ê±±ê±´ê±·ê±¸ê±ºê²€\n",
      "======================================================================\n",
      "17||ê±”ê±˜ê±œê±°ê±±ê±´ê±·ê±¸ê±ºê²€ê²ê²ƒê²‰ê²Šê²‹ê²Œê²\n",
      "======================================================================\n",
      "11||ë±ë³ëµë¼ë½ë€ë„ëŒëëë\n",
      "======================================================================\n",
      "49||ë‘ë’ë–ë—ë˜ë™ëœë ë¨ë©ë«ë¬ë­ë´ëµë¸ëŸ‡ëŸ‰ëŸ¬ëŸ­ëŸ°ëŸ´ëŸ¼ëŸ½ëŸ¿ë €ë ë ‡ë ˆë ‰ë Œë ë ˜ë ™ë ›ë ë‚˜ë‚™ë‚šASDFFGHJJK\n",
      "======================================================================\n",
      "17||ASDFFGHJJKKLLLQWE\n",
      "======================================================================\n",
      "3||ë©¨ë©©ë©°\n",
      "======================================================================\n",
      "49||ë©±ë©´ë©¸ëªƒëª„ëª…ëª‡ëªŒëª¨ëª©ëª«ëª¬ëª°ëª²ëª¸ëª¹ëª»ëª½ë«„ë«ˆë«˜ë«™ë«¼ë¬€ë¬„ë¬ë¬ë¬‘ë¬˜ë¬œë¬ ë¬©ë¬«ë¬´ë¬µë¬¶ë¬¸ë¬»ë¬¼ë¬½ë¬¾ë­„ë­…ë­‡ë­‰ë­ë­AB\n",
      "======================================================================\n",
      "18||ë¬½ë¬¾ë­„ë­…ë­‡ë­‰ë­ë­ABCDEFGHIJ\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "for r in result:\n",
    "    print(len(r), r, sep=\"||\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12edb31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='ê°€ê°ê°„ê°‡ê°ˆê°‰ê°Šê°ê°‘ê°’ê°“ê°”ê°•ê°–ê°—ê°™ê°šê°›ê°œê°ê° ê°¤ê°¬ê°­ê°¯ê°°'),\n",
       " Document(metadata={}, page_content='aadlskfjadklsfjakldfjadklsjadfsklê°¸ê°¹ê°¼ê±€ê±‹ê±ê±”ê±˜ê±œê±°ê±±ê±´ê±·ê±¸ê±ºê²€'),\n",
       " Document(metadata={}, page_content='ê±”ê±˜ê±œê±°ê±±ê±´ê±·ê±¸ê±ºê²€ê²ê²ƒê²‰ê²Šê²‹ê²Œê²'),\n",
       " Document(metadata={}, page_content='ë±ë³ëµë¼ë½ë€ë„ëŒëëë'),\n",
       " Document(metadata={}, page_content='ë‘ë’ë–ë—ë˜ë™ëœë ë¨ë©ë«ë¬ë­ë´ëµë¸ëŸ‡ëŸ‰ëŸ¬ëŸ­ëŸ°ëŸ´ëŸ¼ëŸ½ëŸ¿ë €ë ë ‡ë ˆë ‰ë Œë ë ˜ë ™ë ›ë ë‚˜ë‚™ë‚šASDFFGHJJK'),\n",
       " Document(metadata={}, page_content='ASDFFGHJJKKLLLQWE'),\n",
       " Document(metadata={}, page_content='ë©¨ë©©ë©°'),\n",
       " Document(metadata={}, page_content='ë©±ë©´ë©¸ëªƒëª„ëª…ëª‡ëªŒëª¨ëª©ëª«ëª¬ëª°ëª²ëª¸ëª¹ëª»ëª½ë«„ë«ˆë«˜ë«™ë«¼ë¬€ë¬„ë¬ë¬ë¬‘ë¬˜ë¬œë¬ ë¬©ë¬«ë¬´ë¬µë¬¶ë¬¸ë¬»ë¬¼ë¬½ë¬¾ë­„ë­…ë­‡ë­‰ë­ë­AB'),\n",
       " Document(metadata={}, page_content='ë¬½ë¬¾ë­„ë­…ë­‡ë­‰ë­ë­ABCDEFGHIJ')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = spliter2.split_documents([document])\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4461fa92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "# olympic.txtë¥¼ ì½ì–´ì„œ split ì²˜ë¦¬\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 1. ë¬¸ì„œ Load\n",
    "path = \"data/olympic.txt\"\n",
    "loader = TextLoader(path, encoding=\"utf-8\")\n",
    "docs = loader.load()\n",
    "\n",
    "# 2. loadí•œ ë¬¸ì„œë¥¼ split\n",
    "spliter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "split_docs = spliter.split_documents(docs)\n",
    "print(len(split_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "05193ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 498,\n",
       " 403,\n",
       " 414,\n",
       " 239,\n",
       " 262,\n",
       " 5,\n",
       " 496,\n",
       " 222,\n",
       " 270,\n",
       " 338,\n",
       " 310,\n",
       " 434,\n",
       " 456,\n",
       " 498,\n",
       " 5,\n",
       " 496,\n",
       " 135,\n",
       " 446,\n",
       " 413,\n",
       " 4,\n",
       " 498,\n",
       " 120,\n",
       " 356,\n",
       " 233,\n",
       " 400,\n",
       " 392,\n",
       " 310,\n",
       " 221,\n",
       " 496,\n",
       " 226,\n",
       " 428,\n",
       " 362,\n",
       " 495,\n",
       " 379,\n",
       " 311,\n",
       " 355,\n",
       " 268,\n",
       " 405,\n",
       " 2,\n",
       " 495,\n",
       " 495,\n",
       " 242,\n",
       " 362,\n",
       " 493,\n",
       " 374,\n",
       " 236,\n",
       " 329,\n",
       " 297,\n",
       " 459,\n",
       " 498,\n",
       " 154,\n",
       " 401,\n",
       " 444,\n",
       " 466,\n",
       " 352,\n",
       " 499,\n",
       " 111,\n",
       " 10,\n",
       " 498,\n",
       " 217]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_list = [len(d.page_content) for d in split_docs]                        # splitëœ ë¬¸ì„œë“¤ì˜ ê¸€ììˆ˜\n",
    "len_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "89bf463f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜¬ë¦¼í”½(ì˜ì–´: Olympic Games, í”„ë‘ìŠ¤ì–´: Jeux olympiques)ì€ ì „ ì„¸ê³„ ê° ëŒ€ë¥™ ê°êµ­ì—ì„œ ëª¨ì¸ ìˆ˜ì²œ ëª…ì˜ ì„ ìˆ˜ê°€ ì°¸ê°€í•´ ì—¬ë¦„ê³¼ ê²¨ìš¸ì— ìŠ¤í¬ì¸  ê²½ê¸°ë¥¼ í•˜ëŠ” êµ­ì œì ì¸ ëŒ€íšŒì´ë‹¤. ì „ ì„¸ê³„ì—ì„œ ê°€ì¥ í° ì§€êµ¬ì´Œ ìµœëŒ€ì˜ ìŠ¤í¬ì¸  ì¶•ì œì¸ ì˜¬ë¦¼í”½ì€ ì„¸ê³„ì—ì„œ ê°€ì¥ ì¸ì§€ë„ìˆëŠ” êµ­ì œ í–‰ì‚¬ì´ë‹¤. ì˜¬ë¦¼í”½ì€ 2ë…„ë§ˆë‹¤ í•˜ê³„ ì˜¬ë¦¼í”½ê³¼ ë™ê³„ ì˜¬ë¦¼í”½ì´ ë²ˆê°ˆì•„ ì—´ë¦¬ë©°, êµ­ì œ ì˜¬ë¦¼í”½ ìœ„ì›íšŒ(IOC)ê°€ ê°ë…í•˜ê³  ìˆë‹¤. ë˜í•œ ì˜¤ëŠ˜ë‚ ì˜ ì˜¬ë¦¼í”½ì€ ê¸°ì›ì „ 8ì„¸ê¸°ë¶€í„° ì„œê¸° 5ì„¸ê¸°ì— ì´ë¥´ê¸°ê¹Œì§€ ê³ ëŒ€ ê·¸ë¦¬ìŠ¤ ì˜¬ë¦¼í”¼ì•„ì—ì„œ ì—´ë ¸ë˜ ì˜¬ë¦¼í”¼ì•„ ì œì „ì—ì„œ ë¹„ë¡¯ë˜ì—ˆë‹¤. ê·¸ë¦¬ê³  19ì„¸ê¸° ë§ì— í”¼ì—ë¥´ ë“œ ì¿ ë² ë¥´íƒ± ë‚¨ì‘ì´ ê³ ëŒ€ ì˜¬ë¦¼í”¼ì•„ ì œì „ì—ì„œ ì˜ê°ì„ ì–»ì–´, ê·¼ëŒ€ ì˜¬ë¦¼í”½ì„ ë¶€í™œì‹œì¼°ë‹¤. ì´ë¥¼ ìœ„í•´ ì¿ ë² ë¥´íƒ± ë‚¨ì‘ì€ 1894ë…„ì— IOCë¥¼ ì°½ì„¤í–ˆìœ¼ë©°, 2ë…„ ë’¤ì¸ 1896ë…„ì— ê·¸ë¦¬ìŠ¤ ì•„í…Œë„¤ì—ì„œ ì œ 1íšŒ ì˜¬ë¦¼í”½ì´ ì—´ë ¸ë‹¤. ì´ë•Œë¶€í„° IOCëŠ” ì˜¬ë¦¼í”½ ìš´ë™ì˜ ê°ë… ê¸°êµ¬ê°€ ë˜ì—ˆìœ¼ë©°, ì¡°ì§ê³¼ í™œë™ì€ ì˜¬ë¦¼í”½ í—Œì¥ì„ ë”°ë¥¸ë‹¤. ì˜¤ëŠ˜ë‚  ì „ ì„¸ê³„ ëŒ€ë¶€ë¶„ì˜\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print(split_docs[idx].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "639cce29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# ë¬¸ì„œ ë¡œë“œ\n",
    "path = \"data/novel/ë©”ë°€ê½ƒ_í•„_ë¬´ë µ_ì´íš¨ì„.pdf\"\n",
    "loader = PyPDFLoader(path)\n",
    "docs = loader.load()\n",
    "\n",
    "# split\n",
    "split_docs = spliter.split_documents(docs)\n",
    "len(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a4329ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "ë©”ë°€ê½ƒ  í•„  ë¬´ë µ\n",
      "Exported from Wikisource on 2024 ë…„  11 ì›”  24 ì¼\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "print(split_docs[idx].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf15e35c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed87439d",
   "metadata": {},
   "source": [
    "## Token ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆ„ê¸°\n",
    "\n",
    "- LLM ì–¸ì–´ ëª¨ë¸ë“¤ì€ ì…ë ¥ í† í° ìˆ˜ ì œí•œì´ ìˆì–´ì„œ ìš”ì²­ì‹œ ì œí•œ í† í°ìˆ˜ ì´ìƒì˜ í”„ë¡¬í”„íŠ¸ëŠ” ì „ì†¡í•  ìˆ˜ ì—†ë‹¤.\n",
    "- ë”°ë¼ì„œ í…ìŠ¤íŠ¸ë¥¼ chunkë¡œ ë¶„í• í•  ë•ŒëŠ” ê¸€ììˆ˜ ë³´ë‹¤ **í† í° ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í¬ê¸°ë¥¼ ì§€ì •í•˜ëŠ” ê²ƒ**ì´ ì¢‹ë‹¤.  \n",
    "- í† í°ê¸°ë°˜ ë¶„í• ì€ í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ë¥¼ ìœ ì§€í•˜ë©´ì„œ ë¶„í• í•˜ëŠ” ë°©ì‹ì´ë¯€ë¡œ ë¬¸ì ê¸°ë°˜ ë¶„í• ê³¼ ê°™ì´ ë‹¨ì–´ê°€ ì¤‘ê°„ì˜ë¦¬ëŠ” ê²ƒë“¤ì„ ë°©ì§€í•  ìˆ˜ ìˆë‹¤. \n",
    "- í† í° ìˆ˜ ê³„ì‚°í•  ë•ŒëŠ” ì‚¬ìš©í•˜ëŠ” ì–¸ì–´ ëª¨ë¸ì— ì‚¬ìš©ëœ ê²ƒê³¼ ë™ì¼í•œ tokenizerë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤.\n",
    "  - ì˜ˆë¥¼ ë“¤ì–´ OpenAIì˜ GPT ëª¨ë¸ì„ ì‚¬ìš©í•  ê²½ìš° tiktoken ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•˜ì—¬ í† í° ìˆ˜ë¥¼ ì •í™•í•˜ê²Œ ê³„ì‚°í•  ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "### [tiktoken](https://github.com/openai/tiktoken) tokenizer ê¸°ë°˜ ë¶„í• \n",
    "- OpenAIì—ì„œ GPT ëª¨ë¸ì„ í•™ìŠµí•  ë•Œ ì‚¬ìš©í•œ `BPE` ë°©ì‹ì˜ tokenizer. **OpenAI ì–¸ì–´ëª¨ë¸ì„ ì‚¬ìš©í•  ê²½ìš° ì´ê²ƒì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢€ ë” ì •í™•í•˜ê²Œ  í† í°dmf ê³„ì‚°í•  ìˆ˜ ìˆë‹¤.**\n",
    "- Splitter.from_tiktoken_encoder() ë©”ì†Œë“œë¥¼ ì´ìš©í•´ ìƒì„±\n",
    "  - `RecursiveCharacterTextSplitter.from_tiktoken_encoder()`\n",
    "  - `CharacterTextSplitter.from_tiktoken_encoder()`\n",
    "- íŒŒë¼ë¯¸í„°\n",
    "  - encode_name: ì¸ì½”ë”© ë°©ì‹(í† í°í™” ê·œì¹™)ì„ ì§€ì •. OpenAIëŠ” GPT ëª¨ë¸ë“¤ ë§ˆë‹¤ ë‹¤ë¥¸ ë°©ì‹ì„ ì‚¬ìš©í–ˆë‹¤. ê·¸ë˜ì„œ ì‚¬ìš©í•˜ë ¤ëŠ” ëª¨ë¸ì— ë§ëŠ” ì¸ì½”ë”© ë°©ì‹ì„ ì§€ì •í•´ì•¼ í•œë‹¤.\n",
    "    - `cl100k_base`: GPT-4 ë° GPT-3.5-Turbo ëª¨ë¸ì—ì„œ ì‚¬ìš©ëœ ë°©ì‹.\n",
    "    - `r50k_base:` GPT-3 ëª¨ë¸ì—ì„œ ì‚¬ìš©ëœ ë°©ì‹ \n",
    "  - chunk_size, chunk_overlap, separators íŒŒë¼ë¯¸í„° (ìœ„ì™€ ë™ì¼)\n",
    "- tiktoken ì„¤ì¹˜\n",
    "  - `pip install tiktoken`\n",
    "\n",
    "### HuggingFace Tokenizer\n",
    "- HuggingFace ëª¨ë¸ì„ ì‚¬ìš©í•  ê²½ìš° ê·¸ ëª¨ë¸ì´ ì‚¬ìš©í•œ tokenizerë¥¼ ì´ìš©í•´ í† í° ê¸°ë°˜ìœ¼ë¡œ ë¶„í•  í•œë‹¤.\n",
    "  - ë‹¤ë¥¸ tokenizerë¥¼ ì´ìš©í•´ ë¶„í•  í•  ê²½ìš° í† í° ìˆ˜ ê³„ì‚°ì´ ë‹¤ë¥´ê²Œ ë  ìˆ˜ìˆë‹¤.\n",
    "- `from_huggingface_tokenizer()` ë©”ì†Œë“œë¥¼ ì´ìš©.\n",
    "  - íŒŒë¼ë¯¸í„°\n",
    "    - tokenizer: HuggingFace tokenizer ê°ì²´\n",
    "    - chunk_size, chunk_overlap, separators íŒŒë¼ë¯¸í„° (ìœ„ì™€ ë™ì¼)\n",
    "- `transformers` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì•¼ í•œë‹¤.\n",
    "  - `pip install transformers` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d99796ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = TextLoader(\"data/olympic.txt\", encoding=\"utf-8\")\n",
    "\n",
    "spliter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    model_name=\"gpt-4o-mini\",                                       # ì§€ì •í•œ ëª¨ë¸ì„ í•™ìŠµí•  ë•Œ ì‚¬ìš©í•œ tokenizerë¥¼ ì‚¬ìš©\n",
    "    chunk_size=200,                                                 # í† í°ìˆ˜ ê¸°ì¤€\n",
    "    chunk_overlap=0\n",
    ")\n",
    "docs = loader.load_and_split(spliter)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aa6dba29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜¬ë¦¼í”½(ì˜ì–´: Olympic Games, í”„ë‘ìŠ¤ì–´: Jeux olympiques)ì€ ì „ ì„¸ê³„ ê° ëŒ€ë¥™ ê°êµ­ì—ì„œ ëª¨ì¸ ìˆ˜ì²œ ëª…ì˜ ì„ ìˆ˜ê°€ ì°¸ê°€í•´ ì—¬ë¦„ê³¼ ê²¨ìš¸ì— ìŠ¤í¬ì¸  ê²½ê¸°ë¥¼ í•˜ëŠ” êµ­ì œì ì¸ ëŒ€íšŒì´ë‹¤. ì „ ì„¸ê³„ì—ì„œ ê°€ì¥ í° ì§€êµ¬ì´Œ ìµœëŒ€ì˜ ìŠ¤í¬ì¸  ì¶•ì œì¸ ì˜¬ë¦¼í”½ì€ ì„¸ê³„ì—ì„œ ê°€ì¥ ì¸ì§€ë„ìˆëŠ” êµ­ì œ í–‰ì‚¬ì´ë‹¤. ì˜¬ë¦¼í”½ì€ 2ë…„ë§ˆë‹¤ í•˜ê³„ ì˜¬ë¦¼í”½ê³¼ ë™ê³„ ì˜¬ë¦¼í”½ì´ ë²ˆê°ˆì•„ ì—´ë¦¬ë©°, êµ­ì œ ì˜¬ë¦¼í”½ ìœ„ì›íšŒ(IOC)ê°€ ê°ë…í•˜ê³  ìˆë‹¤. ë˜í•œ ì˜¤ëŠ˜ë‚ ì˜ ì˜¬ë¦¼í”½ì€ ê¸°ì›ì „ 8ì„¸ê¸°ë¶€í„° ì„œê¸° 5ì„¸ê¸°ì— ì´ë¥´ê¸°ê¹Œì§€ ê³ ëŒ€ ê·¸ë¦¬ìŠ¤ ì˜¬ë¦¼í”¼ì•„ì—ì„œ ì—´ë ¸ë˜ ì˜¬ë¦¼í”¼ì•„ ì œì „ì—ì„œ ë¹„ë¡¯ë˜ì—ˆë‹¤. ê·¸ë¦¬ê³  19ì„¸ê¸° ë§ì— í”¼ì—ë¥´ ë“œ ì¿ ë² ë¥´íƒ± ë‚¨ì‘ì´ ê³ ëŒ€ ì˜¬ë¦¼í”¼ì•„\n"
     ]
    }
   ],
   "source": [
    "print(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30b4d3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huggingface Tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "model_id = \"beomi/kcbert-base\"                      # ì‚¬ìš©í•  LLM ëª¨ë¸ì˜ ID\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dbf9ddbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spliter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer=tokenizer,\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "docs = loader.load_and_split(spliter)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591dc456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
