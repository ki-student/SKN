{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cff5b412-7083-4729-b85e-203069873ce7",
   "metadata": {},
   "source": [
    "# Chroma Vector Database\n",
    "- Chroma는 대규모 언어 모델(LLM) 애플리케이션 구축을 위해 설계된 AI 네이티브 **오픈 소스 벡터 데이터베이스**다.    \n",
    "- 임베딩 저장소, 쿼리 및 검색 등의 핵심 기능을 제공하여 개발자들이 효율적으로 작업할 수 있도록 돕는다. \n",
    "- https://www.trychroma.com/\n",
    "  \n",
    "## Chroma의 주요 특징\n",
    "\n",
    "- **오픈 소스 라이선스** \n",
    "  - Apache 2.0 라이선스에 따라 제공되어 누구나 자유롭게 사용하고 수정할 수 있다. \n",
    "- **다양한 개발 환경 지원**\n",
    "  -  Python 및 JavaScript/TypeScript SDK를 지원하여 다양한 Langchain 과 연동하여 활용할 수 있다. \n",
    "- **유연한 데이터 저장 옵션**\n",
    "  -  HTTP 방식, 디스크 저장 방식, 인메모리 방식을 선택하여 데이터를 저장할 수 있어 사용자 입장에서 매우 편리하다. \n",
    "- **간편한 사용법** \n",
    "  - 설치 및 사용법이 매우 간단하여 빠르게 프로토타입을 개발하고 검증할 수 있다. \n",
    "\n",
    "## 설치\n",
    "- pip로 chromadb 설치시 **windows**에서는 c컴파일러 관련되어 에러가 난다. **conda 를 이용해 설치한다.**\n",
    "- `conda install conda-forge::chromadb`\n",
    "- `pip install langchain-chroma`\n",
    "- `pip install chromadb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70ea95b-9244-4208-9d99-bb8698cc5d43",
   "metadata": {},
   "source": [
    "# Chroma API 를 이용해 연동\n",
    "- https://docs.trychroma.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70971742-500d-4470-89b0-b82f0b7cc30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b7e66bf-e527-4bf2-a1c0-bfbb42fad70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UUID('aea44c69-754c-4530-8e5f-b29192d890c2')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "uuid4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8011c707-5a8e-4333-bb5f-c13bed9b30b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "# 추가할 데이터\n",
    "document_list = [\n",
    "        \"This is a document about pineapple\",\n",
    "        \"This is a document about oranges\",\n",
    "        \"This is a document about sports\",\n",
    "        \"This is a document about langchain\",\n",
    "]\n",
    "ids = [str(uuid4()) for _ in range(len(document_list))]                         # DB 저장 시 지정할 각 문서들의 ID 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3aa6c24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01c0b536-6a91-4a72-8e7a-a1ed020312d5',\n",
       " '402ddb82-87ec-491f-b247-9eaf96881043',\n",
       " '94043613-c8e0-45af-b77e-8e0ed4fade71',\n",
       " '22226f66-6e05-44d9-9cb1-500af61259a9']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52969599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# 외부 Embedding 모델\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "import os\n",
    "print(load_dotenv())\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                api_key=OPENAI_API_KEY,\n",
    "                model_name=\"text-embedding-3-small\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32f4e5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1014cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection - Database\n",
    "# Chroma DB와 연결\n",
    "# import chromadb\n",
    "\n",
    "# # client = chromadb.Client()                                                      # InMemory DB (데이터를 메모리에 저장)\n",
    "# client = chromadb.PersistentClient(path=\"vector_store/chroma/my_db\")            # Local 파일에 저장\n",
    "# # client = chromadb.HttpClient(host=\"ip주소\", port=8000)                           # 서버로 서비스하는 chromadb에 연결\n",
    "\n",
    "# # collections(DB)를 생성\n",
    "# collection_name = \"test_db\"\n",
    "# collection = client.create_collections(\n",
    "#     name=collection_name,\n",
    "#     get_or_create=True                                                          # collections가 있으면 연결, 없으면 생성\n",
    "#     # False: 이미 있는 collection 이면 Exception\n",
    "# )\n",
    "\n",
    "import chromadb\n",
    "\n",
    "# PersistentClient로 로컬 파일에 저장\n",
    "# client = chromadb.PersistentClient(path=\"vector_store/chroma/my_db\")\n",
    "client = chromadb.Client()\n",
    "# collection(DB)을 생성 또는 연결\n",
    "collection_name = \"test_db\"\n",
    "collection = client.get_or_create_collection(\n",
    "    name=collection_name,\n",
    "    metadata={\"hnsw:space\":\"cosine\"},\n",
    "    embedding_function = openai_ef\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "564622ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### 데이터 추가\n",
    "collection.add(documents = document_list, ids = ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "404b4c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['330c62f3-aaca-4d07-adcc-006be4dbeeff',\n",
       "   'a57f4eb5-60cc-453d-8a61-54c1fa41437d'],\n",
       "  ['a57f4eb5-60cc-453d-8a61-54c1fa41437d',\n",
       "   '330c62f3-aaca-4d07-adcc-006be4dbeeff']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['This is a document about langchain',\n",
       "   'This is a document about pineapple'],\n",
       "  ['This is a document about pineapple',\n",
       "   'This is a document about langchain']],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[None, None], [None, None]],\n",
       " 'distances': [[0.7781242728233337, 0.814582347869873],\n",
       "  [0.7556754350662231, 0.8807660341262817]]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### 유사도 검색\n",
    "result = collection.query(\n",
    "    query_texts = [\"deeplearning\", \"hawaii\"],               # 질문\n",
    "    n_results=2,                                            # 검색 결과 수\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a70fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c8460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb8d7bba-a840-477e-9ef3-666b1d5c1301",
   "metadata": {},
   "source": [
    "# Langchain을 이용해 Chroma 연동\n",
    "\n",
    "## Data 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d281e998-76c4-46b7-8e96-ddd08e7ba42c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T12:09:44.559588Z",
     "iopub.status.busy": "2024-12-02T12:09:44.558586Z",
     "iopub.status.idle": "2024-12-02T12:09:46.061566Z",
     "shell.execute_reply": "2024-12-02T12:09:46.061566Z",
     "shell.execute_reply.started": "2024-12-02T12:09:44.559588Z"
    }
   },
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=1,\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=2,\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=3,\n",
    ")\n",
    "\n",
    "document_4 = Document(\n",
    "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=4,\n",
    ")\n",
    "\n",
    "document_5 = Document(\n",
    "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=5,\n",
    ")\n",
    "\n",
    "document_6 = Document(\n",
    "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    "    id=6,\n",
    ")\n",
    "\n",
    "document_7 = Document(\n",
    "    page_content=\"The top 10 soccer players in the world right now.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    "    id=7,\n",
    ")\n",
    "\n",
    "document_8 = Document(\n",
    "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=8,\n",
    ")\n",
    "\n",
    "document_9 = Document(\n",
    "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=9,\n",
    ")\n",
    "\n",
    "document_10 = Document(\n",
    "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=10,\n",
    ")\n",
    "document_list = [document_1,document_2,document_3,document_4,document_5,document_6,document_7,document_8,document_9,document_10]\n",
    "ids = [str(uuid4()) for _ in range(len(document_list))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd05fc0a-c00e-4df8-a455-0333cbf17821",
   "metadata": {},
   "source": [
    "## Vector Store 생성, 연결\n",
    "- Chroma.from_documents()\n",
    "  - VectorStore를 초기화(생성)하고 문서를 추가한다.\n",
    "  - persist_directory를 지정하지 않으면 메모리에 저장된다.\n",
    "- Chroma()\n",
    "  - VectorStore와 연결."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3aeed090-a67f-4599-a47d-0fe8b034603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "COLLECTION_NAME = \"example\"                                         # 컬렉션 이름(RDB의 Database 개념)\n",
    "PERSISTENT_PATH = \"vector_store/chroma/example_db\"                  # 저장할 로컬 경로\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# 1. 연결(생성) 하면서 document들을 저장(upsert) -> RDB에서는 upsert가 insert\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=document_list,\n",
    "    ids=ids,\n",
    "    embedding=embedding_model,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    persist_directory=PERSISTENT_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0200a08d-7734-4b3e-874b-8d27b14f3369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 연결(생성)\n",
    "vector_store2 = Chroma(\n",
    "    embedding=embedding_model,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    persist_directory=PERSISTENT_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16c700e-54ec-43a9-890b-ae804cf3ca3f",
   "metadata": {},
   "source": [
    "## VectorStore 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8ebf6ab-776b-4ae8-be97-7046de1873c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "coll = vector_store._collection                        # 연결된 collection 정보 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c586ed7-7d81-4a5f-ac49-f476ee980bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051a46bf-3d08-4c00-97d1-f71488b39c76",
   "metadata": {},
   "source": [
    "## Add (추가)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c040506-b68c-43ed-95d7-3184a10dc742",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_11 = Document(\n",
    "    page_content=\"랭체인은 대규모 언어 모델(LLM)을 효과적으로 활용하기 위한 도구와 프레임워크를 제공하는 오픈소스 라이브러리입니다.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=10,\n",
    ")\n",
    "\n",
    "document_12 = Document(\n",
    "    page_content=\"랭체인은 체인 구조를 사용하여 여러 LLM 작업을 연결하고, 이를 통해 더 복잡하고 맞춤화된 자연어 처리 애플리케이션을 개발할 수 있게 합니다\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=10,\n",
    ")\n",
    "\n",
    "document_13 = Document(\n",
    "    page_content=\"랭체인, AI 활용의 새 시대를 열다: 복잡한 언어 처리도 간단하게!\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92f9d5f9-aef7-4a5a-aec9-dbbd0ade4adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['debffbaa-ec69-4adf-b5b6-dcbcf2cafca2',\n",
       " '28e651c9-3e19-4fa6-b4a5-33e2aa6ce9f1',\n",
       " 'f1739290-7528-4be6-8f79-2ae101979d19']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(\n",
    "    [document_11, document_12, document_13],\n",
    "    ids = [str(uuid4()), str(uuid4()), str(uuid4())]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e06e137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f0d979-ea73-4dfb-abe5-ff328cc77b3e",
   "metadata": {},
   "source": [
    "## Update(갱신)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9cf981b7-80e3-4a2f-b607-d73c409fdfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_document_13 = Document(\n",
    "    page_content=\"랭체인, AI 활용의 새 시대를 열다: 복잡한 언어 처리도 간단하게?\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2960f4a5-6407-49cc-9272-7b8f37cc3dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.update_document(\n",
    "    document_id=\"f1739290-7528-4be6-8f79-2ae101979d19\",             # 바꿀 문서의 ID\n",
    "    document=new_document_13                                        # 바꿀 내용을 가진 Document 객체\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7cc76d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_document_12 = Document(\n",
    "    page_content=\"랭체인은 체인 구조를 사용하여 여러 LLM 작업을 연결한다.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "update_document_13 = Document(\n",
    "    page_content=\"랭체인, AI 활용의 새 시대를 열다: 복잡한 언어 처리도 간단하게!\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "update_docs = [update_document_12, update_document_13]\n",
    "update_ids = ['28e651c9-3e19-4fa6-b4a5-33e2aa6ce9f1',\n",
    "  'f1739290-7528-4be6-8f79-2ae101979d19']\n",
    "\n",
    "vector_store.update_documents(documents=update_docs, ids=update_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0db0fda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['5630d14d-45d1-4339-a6cf-10abc6c311a5',\n",
       "  'b885ef90-1f90-4f81-9d88-52b5a3c1dc24',\n",
       "  '2d4c0f7d-e700-41bb-a1f1-a71ec3233c04',\n",
       "  '7d6902f2-05b1-4357-9b8e-919538dafa9b',\n",
       "  'a2b3d8b2-f4cd-4db4-beca-db2903c581e8',\n",
       "  'd1236fd3-a0d9-4abc-b66b-986a5f0a767e',\n",
       "  'b8dad090-16d7-4616-ad13-cd1e7252e7be',\n",
       "  '82172976-e1e3-447e-8453-482cfe87bdd2',\n",
       "  'e063b2e2-e467-4d72-9025-3f8f1ffb9ff6',\n",
       "  '4286fffe-c892-402c-b68d-7652b982962e',\n",
       "  'debffbaa-ec69-4adf-b5b6-dcbcf2cafca2',\n",
       "  '28e651c9-3e19-4fa6-b4a5-33e2aa6ce9f1',\n",
       "  'f1739290-7528-4be6-8f79-2ae101979d19'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['I had chocolate chip pancakes and scrambled eggs for breakfast this morning.',\n",
       "  'The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.',\n",
       "  'Building an exciting new project with LangChain - come check it out!',\n",
       "  'Robbers broke into the city bank and stole $1 million in cash.',\n",
       "  \"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
       "  'Is the new iPhone worth the price? Read this review to find out.',\n",
       "  'The top 10 soccer players in the world right now.',\n",
       "  'LangGraph is the best framework for building stateful, agentic applications!',\n",
       "  'The stock market is down 500 points today due to fears of a recession.',\n",
       "  'I have a bad feeling I am going to get deleted :(',\n",
       "  '랭체인은 대규모 언어 모델(LLM)을 효과적으로 활용하기 위한 도구와 프레임워크를 제공하는 오픈소스 라이브러리입니다.',\n",
       "  '랭체인은 체인 구조를 사용하여 여러 LLM 작업을 연결한다.',\n",
       "  '랭체인, AI 활용의 새 시대를 열다: 복잡한 언어 처리도 간단하게!'],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents'],\n",
       " 'data': None,\n",
       " 'metadatas': [{'source': 'tweet'},\n",
       "  {'source': 'news'},\n",
       "  {'source': 'tweet'},\n",
       "  {'source': 'news'},\n",
       "  {'source': 'tweet'},\n",
       "  {'source': 'website'},\n",
       "  {'source': 'website'},\n",
       "  {'source': 'tweet'},\n",
       "  {'source': 'news'},\n",
       "  {'source': 'tweet'},\n",
       "  {'source': 'tweet'},\n",
       "  {'source': 'website'},\n",
       "  {'source': 'news'}]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 데이터 조회\n",
    "# coll.get()\n",
    "vector_store.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c783830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28084f0a-4baf-4f94-8d06-6992d7551d81",
   "metadata": {},
   "source": [
    "## Delete(삭제)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37216a6d-7192-438a-99f3-c1de8e2a0728",
   "metadata": {},
   "outputs": [],
   "source": [
    "del_ids = ['b885ef90-1f90-4f81-9d88-52b5a3c1dc24',\n",
    "  '2d4c0f7d-e700-41bb-a1f1-a71ec3233c04']\n",
    "vector_store.delete(ids=del_ids)                               # [삭제할 문서들의 id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c82b1400-e241-4e83-bdb6-c3fb0157306f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3350ace1-7997-4e5b-a6b1-52a5741a41ce",
   "metadata": {},
   "source": [
    "## Query(조회)\n",
    "- `similarity_search(query, k, filter)`\n",
    "  - 저장되 있는 item들 중 질의와 가장 유사한 것 k개를 찾는다. \n",
    "  - 찾은 결과를 filter 조건으로 필터링 한다. filter 조건은 meta-data의 정보를 이용한다.\n",
    "  - 질의어(query)는 text(자연어)로 입력한다.\n",
    "- `similarity_search_with_score(query, k, filter)`\n",
    "  - 저장되 있는 item들 중 질의와 가장 유사한 것 k개를 찾아 유사도 점수와 함께 반환\n",
    "- `similarity_search_by_vector(embedding, k, filter)`\n",
    "  - Embedding Vector 를 질의로 입력한다. (질의(query)를 문장이 아니라 embedding vector로 입력.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc28dff1-8241-4200-84ad-a3994595e9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='debffbaa-ec69-4adf-b5b6-dcbcf2cafca2', metadata={'source': 'tweet'}, page_content='랭체인은 대규모 언어 모델(LLM)을 효과적으로 활용하기 위한 도구와 프레임워크를 제공하는 오픈소스 라이브러리입니다.'),\n",
       " Document(id='28e651c9-3e19-4fa6-b4a5-33e2aa6ce9f1', metadata={'source': 'website'}, page_content='랭체인은 체인 구조를 사용하여 여러 LLM 작업을 연결한다.'),\n",
       " Document(id='82172976-e1e3-447e-8453-482cfe87bdd2', metadata={'source': 'tweet'}, page_content='LangGraph is the best framework for building stateful, agentic applications!')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    query=\"Langchain이란 무엇인가요?\",\n",
    "    k=3\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "73dce0f2-59e3-4c69-acac-82d606b9fe28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='5630d14d-45d1-4339-a6cf-10abc6c311a5', metadata={'source': 'tweet'}, page_content='I had chocolate chip pancakes and scrambled eggs for breakfast this morning.'),\n",
       "  1.6316311359405518),\n",
       " (Document(id='4286fffe-c892-402c-b68d-7652b982962e', metadata={'source': 'tweet'}, page_content='I have a bad feeling I am going to get deleted :('),\n",
       "  1.8168842792510986),\n",
       " (Document(id='d1236fd3-a0d9-4abc-b66b-986a5f0a767e', metadata={'source': 'website'}, page_content='Is the new iPhone worth the price? Read this review to find out.'),\n",
       "  1.8391940593719482)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vector_store.similarity_search_with_score(\n",
    "    query=\"다이어트에 좋은 음식은 뭐가 있을까요?\",\n",
    "    k=3,\n",
    "    # filter={\"source\":\"tweet\"}                               # metadata의 source키값이 tweet\n",
    "    filter={\"source\":{\"$ne\":\"news\"}}                         # news가 아닌 값\n",
    ")\n",
    "# 1. filter에 설정과 metadata를 비교해서 조회\n",
    "# 2. 1에서 조회된 문서들과 query간의 유사도를 체크\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cdf1d1-ea47-468d-8eef-d6681f7533f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
